{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext autoreload\n",
    "\n",
    "from src.utils import ROOT_DIR\n",
    "import sys\n",
    "sys.path.append(ROOT_DIR)\n",
    "\n",
    "from src.dataset import CustomDataset\n",
    "from src.fcm import FCM\n",
    "from src.fcm import train_epoch, eval_epoch, acc, f1\n",
    "import torch\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import requests\n",
    "import torch\n",
    "from src.dataset import CustomDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "DATASET_PATH = os.path.join(ROOT_DIR, 'data', 'MMHS150K', 'MMHS150K_with_img_text.csv')\n",
    "df = pd.read_csv(DATASET_PATH)\n",
    "\n",
    "# Load the saved predictions\n",
    "\n",
    "PREDICTIONS_PATH = os.path.join(ROOT_DIR,'data', 'results','FCM', 'fcm_predictions.json')\n",
    "OUTPUTS_PATH = os.path.join(ROOT_DIR, 'data','results','FCM', 'fcm_outputs.json')\n",
    "\n",
    "import json\n",
    "with open(PREDICTIONS_PATH, 'r') as f:\n",
    "    predictions = json.load(f)\n",
    "with open(OUTPUTS_PATH, 'r') as f:\n",
    "    outputs = json.load(f)\n",
    "    \n",
    "# For each index, get the binary_hate and label\n",
    "pred_keys = [int(k) for k in predictions.keys()]\n",
    "\n",
    "df_test = df[df[\"index\"].isin(pred_keys)]\n",
    "df_test[\"pred\"] = [predictions[str(k)] for k in df_test[\"index\"]]\n",
    "df_test[\"output\"] = [outputs[str(k)] for k in df_test[\"index\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare \"binary_hate\" and \"pred\" to get the accuracy and F1 score\n",
    "acc_score = acc(df_test[\"binary_hate\"], df_test[\"pred\"])\n",
    "f1_score = f1(df_test[\"binary_hate\"], df_test[\"pred\"])\n",
    "\n",
    "print(f\"Accuracy: {acc_score}\")\n",
    "print(f\"F1 score: {f1_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the ROC curve\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import numpy as np\n",
    "\n",
    "fpr, tpr, _ = roc_curve(df_test[\"binary_hate\"], df_test[\"output\"])\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "lw = 2\n",
    "plt.plot(fpr, tpr, color='darkorange',\n",
    "         lw=lw, label='ROC curve FCM (area = %0.2f)' % roc_auc)\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC curve')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the distribution of the outputs / predictions\n",
    "fig, ax = plt.subplots(1, 2, figsize=(15, 5))\n",
    "ax[0].hist(df_test[\"output\"], bins=50)\n",
    "ax[0].set_title(\"Distribution of the outputs\")\n",
    "ax[0].set_xlabel(\"Output\")\n",
    "ax[0].set_ylabel(\"Count\")\n",
    "\n",
    "ax[1].hist(df_test[\"pred\"], bins=50)\n",
    "ax[1].set_title(\"Distribution of the predictions\")\n",
    "ax[1].set_xlabel(\"Prediction\")\n",
    "ax[1].set_ylabel(\"Count\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "cm = confusion_matrix(df_test[\"binary_hate\"], df_test[\"pred\"])\n",
    "\n",
    "print(\"True positive rate: \", cm[1, 1] / (cm[1, 1] + cm[1, 0]))\n",
    "print(\"True negative rate: \", cm[0, 0] / (cm[0, 0] + cm[0, 1]))\n",
    "\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel('Predicted labels')\n",
    "plt.ylabel('True labels')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 100\n",
    "image_index = df_test[\"index\"].values[idx]\n",
    "\n",
    "img_path = os.path.join(ROOT_DIR, 'data', 'MMHS150K', 'img_resized', str(image_index) + '.jpg')\n",
    "image = Image.open(img_path)\n",
    "\n",
    "# Normalize the image between 0 and 1\n",
    "means_std_path = os.path.join(ROOT_DIR, \"data\", \"MMHS150K\", \"means_stds.csv\")\n",
    "means_stds = pd.read_csv(means_std_path)\n",
    "mean = [means_stds[\"mean_red\"][0], means_stds[\"mean_green\"][0], means_stds[\"mean_blue\"][0]]\n",
    "std = [means_stds[\"std_red\"][0], means_stds[\"std_green\"][0], means_stds[\"std_blue\"][0]]\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((299, 299)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(\n",
    "            mean=mean,\n",
    "            std=std,\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "image_norm1 = transform(image)\n",
    "\n",
    "mean = [0.485, 0.456, 0.406]\n",
    "std = [0.229, 0.224, 0.225]\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((299, 299)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(\n",
    "            mean=mean,\n",
    "            std=std,\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "img_norm2 = transform(image)\n",
    "\n",
    "# Plot the distributions of values for the three images (image, image_norm1, image_norm2)\n",
    "fig, ax = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "ax[0].hist(np.array(image).flatten(), bins=50)\n",
    "ax[0].set_title(\"Distribution of the image values\")\n",
    "ax[0].set_xlabel(\"Value\")\n",
    "ax[0].set_ylabel(\"Count\")\n",
    "\n",
    "ax[1].hist(image_norm1.flatten(), bins=50)\n",
    "ax[1].set_title(\"Distribution of the image values (normalized between 0 and 1)\")\n",
    "ax[1].set_xlabel(\"Value\")\n",
    "ax[1].set_ylabel(\"Count\")\n",
    "\n",
    "ax[2].hist(img_norm2.flatten(), bins=50)\n",
    "ax[2].set_title(\"Distribution of the image values (normalized with mean and std)\")\n",
    "ax[2].set_xlabel(\"Value\")\n",
    "ax[2].set_ylabel(\"Count\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
