{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext autoreload\n",
    "\n",
    "import os\n",
    "ROOT_DIR = os.path.dirname(os.path.abspath(''))\n",
    "import sys\n",
    "sys.path.append(ROOT_DIR)\n",
    "\n",
    "from src.dataset import CustomDataset\n",
    "from src.fcm import FCM\n",
    "from src.fcm import train_epoch, eval_epoch, acc, f1\n",
    "import torch\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import requests\n",
    "import torch\n",
    "from src.dataset import CustomDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = os.path.join(ROOT_DIR, 'data', 'MMHS150K', 'MMHS150K_with_img_text.csv')\n",
    "df = pd.read_csv(DATASET_PATH)\n",
    "\n",
    "RESULTS_PATH = os.path.join(ROOT_DIR, 'results', 'fcm_predictions.json')\n",
    "\n",
    "# The JSON is a dictionary with the following structure:\n",
    "# {\n",
    "#    \"index1\": pred1,\n",
    "#    \"index2\": pred2,\n",
    "#    ...\n",
    "# }\n",
    "# Load the JSON\n",
    "import json\n",
    "with open(RESULTS_PATH, 'r') as f:\n",
    "    results = json.load(f)\n",
    "    \n",
    "# For each index, get the binary_hate and label\n",
    "keys_results = [int(k) for k in results.keys()]\n",
    "\n",
    "df_test = df[df[\"index\"].isin(keys_results)]\n",
    "df_test[\"pred\"] = [results[str(k)] for k in df_test[\"index\"]]\n",
    "\n",
    "display(df_test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare \"binary_hate\" and \"pred\" to get the accuracy and F1 score\n",
    "acc_score = acc(df_test[\"binary_hate\"], df_test[\"pred\"])\n",
    "f1_score = f1(df_test[\"binary_hate\"], df_test[\"pred\"])\n",
    "\n",
    "print(f\"Accuracy: {acc_score}\")\n",
    "print(f\"F1 score: {f1_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
