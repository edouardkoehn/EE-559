{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple scripts to evaluate the results of LLAva"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext autoreload\n",
    "\n",
    "from src.dataset import CustomDataset\n",
    "from src.utils import ROOT_DIR\n",
    "\n",
    "import os\n",
    "from sklearn.metrics import confusion_matrix,ConfusionMatrixDisplay\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from torchvision import transforms\n",
    "import json\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_label2id(res_dict):\n",
    "    \"\"\"Simple method to convert the label from string to int\"\"\"\n",
    "    label2id={'not hateful':0,'hateful':1}\n",
    "    for key, val in res_dict.items():\n",
    "        res_dict[key]=label2id[val]\n",
    "    return res_dict\n",
    "\n",
    "def convert_id2label(res_dict):\n",
    "    \"\"\"Simple method to convert the label from int to string\"\"\"\n",
    "    id2label={0:'not hateful',1:'hateful'}\n",
    "    for key, val in res_dict.items():\n",
    "        res_dict[key]=id2label[val]\n",
    "    return res_dict\n",
    "\n",
    "def find_label(res_dict, dataset):\n",
    "    \"\"\"simple method to align the label with the prediction \"\"\"\n",
    "    y_pred=[val for key, val in res_dict.items()]\n",
    "    y_label=[dataset.get_data_from_index(int(key))['binary_hate'].values[0] for key, val in res_dict.items()]\n",
    "    return y_pred,y_label\n",
    "\n",
    "def compute_confusion_matrix(y_pred, y_label):\n",
    "    tn, fp, fn, tp = confusion_matrix(y_label, y_pred).ravel()\n",
    "    return tn, fp, fn, tp\n",
    "\n",
    "def compute_accuracy(y_pred, y_label):\n",
    "    return accuracy_score(y_label, y_pred, normalize=True)\n",
    "\n",
    "def get_Lava_results_1(path_results,  test_data):\n",
    "    with open(path_results,'r') as f:\n",
    "        lava_prediction=json.load(f)\n",
    "    \n",
    "    lava_prediction=convert_label2id(lava_prediction)\n",
    "    index=np.array([int(key) for key, val in lava_prediction.items()])\n",
    "    prediction=np.array([int(val) for key, val in lava_prediction.items()])\n",
    "   \n",
    "    lava_prediction=np.concatenate([ np.expand_dims(index,axis=1),  np.expand_dims(prediction, axis=1)], axis=1)\n",
    "    return lava_prediction\n",
    "\n",
    "def find_intersection_set(index_1, index_2, index_3, index_4):\n",
    "    set1=set(index_1)\n",
    "    set2=set(index_2)\n",
    "    set3=set(index_3)\n",
    "    set4=set(index_4)\n",
    "    inter=set1.intersection(set2)\n",
    "    inter=inter.intersection(set3)\n",
    "    inter=inter.intersection(set4)\n",
    "    return list(inter)\n",
    "\n",
    "def compute_matrix_data(index_set,matrix_1 ,matrix_2,matrix_3,matrix_4, prompt1,prompt2,prompt3, prompt4):\n",
    "    \"\"\"Simple method for extracting the value of matrix_1[:,1] that \"\"\"\n",
    "    p1=matrix_1[np.isin(matrix_1[:, 0], index_set),:][:,1]\n",
    "    p2=matrix_2[np.isin(matrix_2[:, 0], index_set),:][:,1]\n",
    "    p3=matrix_3[np.isin(matrix_3[:, 0], index_set),:][:,1]\n",
    "    p4=matrix_4[np.isin(matrix_4[:, 0], index_set),:][:,1]\n",
    "\n",
    "    matrix=np.column_stack((index_set, p1, p2, p3,p4))\n",
    "    #df=pd.DataFrame(data=matrix.T)\n",
    "    df=pd.DataFrame(data=matrix[:,1:], columns=[prompt1, prompt2, prompt3,prompt4 ],index=matrix[:,0])\n",
    "    return df\n",
    "\n",
    "def get_level_agrement_dataset(index_set, dataset):\n",
    "    return [{ idx:dataset.get_data_from_index(int(idx))['hate_speech'].values[0]} for idx in index_set]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.Resize((299, 299)), transforms.ToTensor()])\n",
    "# load the data\n",
    "test_data = CustomDataset(\n",
    "    csv_file=os.path.join(ROOT_DIR, \"data\", \"MMHS150K\", \"MMHS150K_text_in_image.csv\"),\n",
    "    img_dir=os.path.join(ROOT_DIR, \"data\", \"MMHS150K\", \"img_resized/\"),\n",
    "    split=\"test\",\n",
    "    transform=transform,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path=os.path.join(ROOT_DIR,'data', 'results', 'Llava','Lava0S_prediction_on_test_final.json')\n",
    "pred_lava_image_only=get_Lava_results_1(path, test_data)\n",
    "\n",
    "path=os.path.join(ROOT_DIR,'data', 'results','Llava', 'Lava0S_tweet_only_prediction_on_test_final.json')\n",
    "pred_laval_tweet_only=get_Lava_results_1(path,test_data)\n",
    "\n",
    "path=os.path.join(ROOT_DIR,'data', 'results', 'Llava','Lava0S_tweet_prediction_on_test_final.json')\n",
    "pred_laval_image_and_tweet=get_Lava_results_+(path,test_data)\n",
    "\n",
    "path=os.path.join(ROOT_DIR,'data', 'results', 'Llava','Lava0S_tweet_informed_prediction_on_test_final.json')\n",
    "pred_laval_image_and_tweet_informed=get_Lava_results_1(path,test_data)\n",
    "\n",
    "path=os.path.join(ROOT_DIR,'data', 'results','Llava', 'Lava0S_tweet_informed_2_prediction_on_test_final.json')\n",
    "pred_laval_image_and_tweet_informed_2=get_Lava_results_1(path,test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_set=find_intersection_set(pred_lava_image_only[:,0],\n",
    "                      pred_laval_tweet_only[:,0],\n",
    "                      pred_laval_image_and_tweet[:,0],\n",
    "                       pred_laval_image_and_tweet_informed[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix=compute_matrix_data(index_set,pred_lava_image_only ,\n",
    "                           pred_laval_tweet_only,\n",
    "                           pred_laval_image_and_tweet,\n",
    "                           pred_laval_image_and_tweet_informed,\n",
    "                           'Image_only',\n",
    "                           'Tweet_only',\n",
    "                           'Image_Tweet',\n",
    "                           'Image_Tweet_informed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'matrix' is your DataFrame\n",
    "correlation_matrix = matrix.corr('spearman')\n",
    "mask = np.array([\n",
    "                [False,  True,  True, True],\n",
    "                [False,  False,  True,True],\n",
    "                [False, False,  False,True],\n",
    "                [False, False,  False,False]])\n",
    "hue_neg, hue_pos = 250, 15\n",
    "cmap = sns.diverging_palette(hue_neg, hue_pos, center=\"dark\", as_cmap=True)\n",
    "# Plot the heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation_matrix,mask=mask, annot=True, cmap=cmap, vmin=-1, vmax=1,xticklabels=matrix.columns, yticklabels=matrix.columns )\n",
    "plt.title('Level of agreement between prompt')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
