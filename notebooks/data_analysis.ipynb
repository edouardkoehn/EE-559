{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First dataset: All memes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = 'MMHS150K/MMHS150K.csv'\n",
    "\n",
    "dataset = pd.read_csv(DATASET_PATH)\n",
    "label_dict = {0: 'No hate speech', 1: 'Racist', 2: 'Sexist', 3: 'Homophobe', 4: 'Religion', 5: 'Other hate'}\n",
    "\n",
    "# is there a text on the image?\n",
    "dataset['text_in_image'] = dataset['img_text'].isna().apply(lambda x: not x)\n",
    "\n",
    "display(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of each label\n",
    "label_count = np.zeros(6)\n",
    "\n",
    "# Go trough each row of the dataset\n",
    "for index, row in dataset.iterrows():\n",
    "    # Get the label of the current row\n",
    "    labels = row['labels'][1:-1].split(',')\n",
    "    \n",
    "    for label in labels:\n",
    "        label_count[int(label)] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the number of each label in a camembert\n",
    "fig, ax = plt.subplots()\n",
    "ax.pie(label_count, labels=label_dict.values(), autopct='%1.1f%%')\n",
    "ax.axis('equal')\n",
    "ax.set_title('Number of each label in the dataset')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to very unbalanced class, we will work with a binary label: Hate or No Hate.\n",
    "\n",
    "Then, we still have 3 labels per tweet, do we do a majority vote to decide the label of the tweet? Or do we consider the tweet as a multi-label classification problem?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot on the left the barplot of hate_speech and on the right of binary_hate\n",
    "fig, ax = plt.subplots(1, 2, figsize=(12, 6))\n",
    "sns.countplot(x='hate_speech', data=dataset, ax=ax[0])\n",
    "ax[0].set_title('Number of each hate_speech value')\n",
    "ax[0].set_xticklabels(sorted([f'{i:.2f}' for i in dataset[\"hate_speech\"].unique()]))\n",
    "sns.countplot(x='binary_hate', data=dataset, ax=ax[1])\n",
    "ax[1].set_title('Number of each binary_hate value')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we compute an average of the 3 labels, we can have a value between 0 and 1, but as seen in the previous plots, the average get only one out of mainly 4 values: 0, 0.33, 0.67, 1, which are not at all balanced. We decide to do a majority vote to decide the label of the tweet.\n",
    "\n",
    "Let's check the distribution in the split datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Size of the dataset:', dataset.shape[0])\n",
    "print('Size of the training set:', dataset[dataset['split'] == 'train'].shape[0])\n",
    "print('Size of the validation set:', dataset[dataset['split'] == 'val'].shape[0])\n",
    "print('Size of the test set:', dataset[dataset['split'] == 'test'].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the data into train, test and val and plot binary_hate\n",
    "train = dataset[dataset['split'] == 'train']\n",
    "test = dataset[dataset['split'] == 'test']\n",
    "val = dataset[dataset['split'] == 'val']\n",
    "\n",
    "fig, ax = plt.subplots(1, 3, figsize=(18, 6))\n",
    "sns.countplot(x='binary_hate', data=train, ax=ax[0])\n",
    "ax[0].set_title('Train')\n",
    "sns.countplot(x='binary_hate', data=test, ax=ax[1])\n",
    "ax[1].set_title('Test')\n",
    "sns.countplot(x='binary_hate', data=val, ax=ax[2])\n",
    "ax[2].set_title('Validation')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Will have to rebalance the train set, or work with only a part of it.\n",
    "\n",
    "Let's look at the presence of text in the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many tweets have text on the image (img_text not NaN)\n",
    "print('Number of tweets with text on the image:', dataset['img_text'].count())\n",
    "print('Number of tweets without text on the image:', len(dataset) - dataset['img_text'].count())\n",
    "print(f'Percentage of tweets with text on the image: {dataset[\"img_text\"].count() / len(dataset) * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the three datasets, separate in hate and no hate and plot number of tweets with text on the image\n",
    "fig, ax = plt.subplots(3, 3, figsize=(18, 12))\n",
    "\n",
    "# Train\n",
    "sns.countplot(x='text_in_image', data=train[train['binary_hate'] == 0], ax=ax[0][0])\n",
    "ax[0][0].set_title('Train - No hate')\n",
    "sns.countplot(x='text_in_image', data=train[train['binary_hate'] == 1], ax=ax[0][1])\n",
    "ax[0][1].set_title('Train - Hate')\n",
    "sns.countplot(x='text_in_image', data=train, ax=ax[0][2])\n",
    "ax[0][2].set_title('Train - All')\n",
    "\n",
    "# Test\n",
    "sns.countplot(x='text_in_image', data=test[test['binary_hate'] == 0], ax=ax[1][0])\n",
    "ax[1][0].set_title('Test - No hate')\n",
    "sns.countplot(x='text_in_image', data=test[test['binary_hate'] == 1], ax=ax[1][1])\n",
    "ax[1][1].set_title('Test - Hate')\n",
    "sns.countplot(x='text_in_image', data=test, ax=ax[1][2])\n",
    "ax[1][2].set_title('Test - All')\n",
    "\n",
    "# Validation\n",
    "sns.countplot(x='text_in_image', data=val[val['binary_hate'] == 0], ax=ax[2][0])\n",
    "ax[2][0].set_title('Validation - No hate')\n",
    "sns.countplot(x='text_in_image', data=val[val['binary_hate'] == 1], ax=ax[2][1])\n",
    "ax[2][1].set_title('Validation - Hate')\n",
    "sns.countplot(x='text_in_image', data=val, ax=ax[2][2])\n",
    "ax[2][2].set_title('Validation - All')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute percentage of tweets with text on the image for each of the previous plots and do heatmap\n",
    "percentage_img_text = np.zeros((3, 3))\n",
    "\n",
    "# Train\n",
    "percentage_img_text[0][0] = train[train['binary_hate'] == 0]['img_text'].count() / len(train[train['binary_hate'] == 0]) * 100\n",
    "percentage_img_text[0][1] = train[train['binary_hate'] == 1]['img_text'].count() / len(train[train['binary_hate'] == 1]) * 100\n",
    "percentage_img_text[0][2] = train['img_text'].count() / len(train) * 100\n",
    "\n",
    "# Test\n",
    "percentage_img_text[1][0] = test[test['binary_hate'] == 0]['img_text'].count() / len(test[test['binary_hate'] == 0]) * 100\n",
    "percentage_img_text[1][1] = test[test['binary_hate'] == 1]['img_text'].count() / len(test[test['binary_hate'] == 1]) * 100\n",
    "percentage_img_text[1][2] = test['img_text'].count() / len(test) * 100\n",
    "\n",
    "# Validation\n",
    "percentage_img_text[2][0] = val[val['binary_hate'] == 0]['img_text'].count() / len(val[val['binary_hate'] == 0]) * 100\n",
    "percentage_img_text[2][1] = val[val['binary_hate'] == 1]['img_text'].count() / len(val[val['binary_hate'] == 1]) * 100\n",
    "percentage_img_text[2][2] = val['img_text'].count() / len(val) * 100\n",
    "\n",
    "# Plot the heatmap\n",
    "fig, ax = plt.subplots()\n",
    "sns.heatmap(percentage_img_text, annot=True, xticklabels=['No hate', 'Hate', 'All'], yticklabels=['Train', 'Test', 'Validation'])\n",
    "ax.set_title('Percentage of tweets with text on the image')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Second dataset: keeping only 'real' memes\n",
    "\n",
    "We will keep only the memes that have text in them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load second dataset (with tweet with text on the image)\n",
    "DATASET_PATH = 'MMHS150K/MMHS150K_text_in_image.csv'\n",
    "dataset2 = pd.read_csv(DATASET_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of each label\n",
    "label_count = np.zeros(6)\n",
    "\n",
    "# Go trough each row of the dataset\n",
    "for index, row in dataset2.iterrows():\n",
    "    # Get the label of the current row\n",
    "    labels = row['labels'][1:-1].split(',')\n",
    "    \n",
    "    for label in labels:\n",
    "        label_count[int(label)] += 1\n",
    "        \n",
    "# Plot the number of each label in a camembert\n",
    "fig, ax = plt.subplots()\n",
    "ax.pie(label_count, labels=label_dict.values(), autopct='%1.1f%%')\n",
    "ax.axis('equal')\n",
    "ax.set_title('Number of each label in the dataset')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot binary_hate for the new dataset\n",
    "fig, ax = plt.subplots()\n",
    "sns.countplot(x='binary_hate', data=dataset2, ax=ax)\n",
    "ax.set_title('Number of each binary_hate value for the new dataset')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot distribution of length of tweet_text for each label binary_hate\n",
    "fig, ax = plt.subplots()\n",
    "sns.histplot(dataset2[dataset2['binary_hate'] == 0]['tweet_text_clean'].str.len(), ax=ax, color='blue', label='No hate')\n",
    "sns.histplot(dataset2[dataset2['binary_hate'] == 1]['tweet_text_clean'].str.len(), ax=ax, color='red', label='Hate')\n",
    "ax.set_title('Distribution of length of tweet_text for each label binary_hate')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute number of words in img_text\n",
    "dataset2['nb_words_img_text'] = dataset2['img_text'].apply(lambda x: len(x.split()))\n",
    "\n",
    "print(\"95th percentile of number of words in img_text:\", dataset2['nb_words_img_text'].quantile(0.95))\n",
    "\n",
    "dataset3 = dataset2[dataset2['nb_words_img_text'] < dataset2['nb_words_img_text'].quantile(0.95)]\n",
    "\n",
    "# Box plot of number of words in img_text for each label binary_hate\n",
    "fig, ax = plt.subplots()\n",
    "sns.boxplot(x='binary_hate', y='nb_words_img_text', data=dataset3, ax=ax)\n",
    "ax.set_title('Number of words in img_text for each label binary_hate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(dataset3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
