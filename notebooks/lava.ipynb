{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext autoreload\n",
    "\n",
    "from src.dataset import CustomDataset\n",
    "from src.utils import ROOT_DIR\n",
    "from src.models import Lava\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "import torch\n",
    "import time\n",
    "from torchvision import transforms\n",
    "import json\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Script to run lava with the image only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Script to evaluate the model\n",
    "#Load the \n",
    "\n",
    "#To run this script you need to have \n",
    "batch_size=2\n",
    "result_path=os.path.join(ROOT_DIR, \"data\", \"results\", \"Lava0S_debug.json\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "transform = transforms.Compose([transforms.Resize((299, 299)),\n",
    "                                transforms.ToTensor()])\n",
    "#load the data\n",
    "dataset = CustomDataset(\n",
    "    csv_file=os.path.join(ROOT_DIR, \"data\", \"MMHS150K\", \"MMHS150K_text_in_image.csv\"),\n",
    "    img_dir=os.path.join(ROOT_DIR, \"data\", \"MMHS150K\", \"img_resized/\"),\n",
    "    split=\"test\",\n",
    "    transform=transform\n",
    ")\n",
    "test_loader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "print(f'Loading the model_{time.strftime(\"%H:%M:%S\", time.localtime())}')\n",
    "model = Lava(os.path.join(ROOT_DIR, \"data\", \"config\", \"config_Lava0S.json\"),device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the prediction\n",
    "output={}\n",
    "index=0\n",
    "print(f'Computing the predictions_{time.strftime(\"%H:%M:%S\", time.localtime())}')\n",
    "for i, data_dict in enumerate(test_loader):\n",
    "    data=data_dict\n",
    "    data['image']=data['image'].to(device)\n",
    "    prediction = model(data)\n",
    "    for i in range(data['image'].shape[0]):\n",
    "        output[int(prediction['index'][i])]=prediction['generation'][i]\n",
    "    print(f'{index}_{time.strftime(\"%H:%M:%S\", time.localtime())}')\n",
    "    \n",
    "    if index%10==0:\n",
    "        print(f'Items_{int(index*batch_size)}_{time.strftime(\"%H:%M:%S\", time.localtime())}')\n",
    "        with open(result_path, \"w\") as f:\n",
    "            json.dump(output, f)\n",
    "    if index==20:\n",
    "        break\n",
    "    index+=1\n",
    "#Save the resutls\n",
    "with open(result_path, \"w\") as f:\n",
    "        json.dump(output, f)  \n",
    "print(f'Process completed_{time.strftime(\"%H:%M:%S\", time.localtime())}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reformat the results\n",
    "with open(result_path, \"r\") as f:\n",
    "        result=json.load(f)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parsed the output\n",
    "result_parsed={}\n",
    "for key, value in result.items():\n",
    "    result_parsed[key]={}\n",
    "    generation=value.split('\\nASSISTANT: ')\n",
    "    if generation[1][-2:]!='\"}':\n",
    "        generation[1]=\"\".join([generation[1], '\"}'])\n",
    "    result_parsed[key]=json.loads(generation[1])   \n",
    "result_path=os.path.join(ROOT_DIR, \"data\", \"results\", \"Lava0S_debug_prediction_reformated.json\")\n",
    "with open(result_path, \"w\") as f:\n",
    "        json.dump(result_parsed, f)  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert to the final output\n",
    "result_final={}\n",
    "for key, value in result_parsed.items():\n",
    "    result_final[key]=value['Classification']\n",
    "result_path=os.path.join(ROOT_DIR, \"data\", \"results\", \"Lava0S_prediction_debug_final.json\")\n",
    "with open(result_path, \"w\") as f:\n",
    "        json.dump(result_final, f)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Script to run Lava on image with tweet image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Script to evaluate the model\n",
    "#Load the \n",
    "\n",
    "#To run this script you need to have \n",
    "batch_size=2\n",
    "result_path=os.path.join(ROOT_DIR, \"data\", \"results\", \"Lava0S_debug_tweet.json\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "transform = transforms.Compose([transforms.Resize((299, 299)),\n",
    "                                transforms.ToTensor()])\n",
    "#load the data\n",
    "dataset = CustomDataset(\n",
    "    csv_file=os.path.join(ROOT_DIR, \"data\", \"MMHS150K\", \"MMHS150K_text_in_image.csv\"),\n",
    "    img_dir=os.path.join(ROOT_DIR, \"data\", \"MMHS150K\", \"img_resized/\"),\n",
    "    split=\"test\",\n",
    "    transform=transform\n",
    ")\n",
    "test_loader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "print(f'Loading the model_{time.strftime(\"%H:%M:%S\", time.localtime())}')\n",
    "model = Lava(os.path.join(ROOT_DIR, \"data\", \"config\", \"config_Lava0S_tweet.json\"),device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output={}\n",
    "index=0\n",
    "print(f'Computing the predictions_{time.strftime(\"%H:%M:%S\", time.localtime())}')\n",
    "for i, data_dict in enumerate(test_loader):\n",
    "    data=data_dict\n",
    "    data['image']=data['image'].to(device)\n",
    "    prediction = model(data)\n",
    "    for i in range(data['image'].shape[0]):\n",
    "        output[int(prediction['index'][i])]=prediction['generation'][i]\n",
    "    print(f'{index}_{time.strftime(\"%H:%M:%S\", time.localtime())}')\n",
    "    \n",
    "    if index%10==0:\n",
    "        print(f'Items_{int(index*batch_size)}_{time.strftime(\"%H:%M:%S\", time.localtime())}')\n",
    "        with open(result_path, \"w\") as f:\n",
    "            json.dump(output, f)\n",
    "    if index==20:\n",
    "        break\n",
    "    index+=1\n",
    "#Save the resutls\n",
    "with open(result_path, \"w\") as f:\n",
    "        json.dump(output, f)  \n",
    "print(f'Process completed_{time.strftime(\"%H:%M:%S\", time.localtime())}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reformat the results\n",
    "with open(result_path, \"r\") as f:\n",
    "        result=json.load(f) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parsed the output\n",
    "# Parsed the output\n",
    "result_parsed={}\n",
    "for key, value in result.items():\n",
    "    result_parsed[key]={}\n",
    "    generation=value.split('\\nASSISTANT: ')\n",
    "    if generation[1][-2:]!='\"}':\n",
    "        generation[1]=\"\".join([generation[1], '\"}'])\n",
    "    result_parsed[key]=json.loads(generation[1])   \n",
    "result_path=os.path.join(ROOT_DIR, \"data\", \"results\", \"Lava0S_debug_tweet_prediction_reformated.json\")\n",
    "with open(result_path, \"w\") as f:\n",
    "        json.dump(result_parsed, f)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert to the final output\n",
    "result_final={}\n",
    "for key, value in result_parsed.items():\n",
    "    result_final[key]=value['Classification']\n",
    "result_path=os.path.join(ROOT_DIR, \"data\", \"results\", \"Lava0_debug_tweet_final.json\")\n",
    "with open(result_path, \"w\") as f:\n",
    "        json.dump(result_final, f)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lava informed prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Script to evaluate the model\n",
    "#Load the \n",
    "\n",
    "#To run this script you need to have \n",
    "batch_size=2\n",
    "result_path=os.path.join(ROOT_DIR, \"data\", \"results\", \"Lava0S_debug_tweet.json\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "transform = transforms.Compose([transforms.Resize((299, 299)),\n",
    "                                transforms.ToTensor()])\n",
    "#load the data\n",
    "dataset = CustomDataset(\n",
    "    csv_file=os.path.join(ROOT_DIR, \"data\", \"MMHS150K\", \"MMHS150K_text_in_image.csv\"),\n",
    "    img_dir=os.path.join(ROOT_DIR, \"data\", \"MMHS150K\", \"img_resized/\"),\n",
    "    split=\"test\",\n",
    "    transform=transform\n",
    ")\n",
    "test_loader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "print(f'Loading the model_{time.strftime(\"%H:%M:%S\", time.localtime())}')\n",
    "model = Lava(os.path.join(ROOT_DIR, \"data\", \"config\", \"config_Lava0S_tweet.json\"),device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.prompt_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt=\"USER:<image>\\nDefinition: Hate speech can be conveyed through any form of expression, including images, cartoons, memes, objects, gestures and symbols and it can be disseminated offline or online. Hate speech is discriminatory (biased, bigoted or intolerant) or pejorative (prejudiced, contemptuous or demeaning) of an individual or group. Hate speech calls out real or perceived identity factors of an individual or a group, including: religion, ethnicity, nationality, race, colour, descent, gender, but also characteristics such as language, economic or social origin, disability, health status, or sexual orientation, among many others. Based on this image and the following tweet text, do you think that this image is a hateful meme?  You will output a JSON format as follows: {'Classification': 'hateful,not hateful','Explaination': 'Why you have chosen this classification'}.Tweet text:\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.prompt_text=prompt.replace(\"'\", '\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output={}\n",
    "index=0\n",
    "print(f'Computing the predictions_{time.strftime(\"%H:%M:%S\", time.localtime())}')\n",
    "for i, data_dict in enumerate(test_loader):\n",
    "    data=data_dict\n",
    "    data['image']=data['image'].to(device)\n",
    "    prediction = model(data)\n",
    "    for i in range(data['image'].shape[0]):\n",
    "        output[int(prediction['index'][i])]=prediction['generation'][i]\n",
    "    print(f'{index}_{time.strftime(\"%H:%M:%S\", time.localtime())}')\n",
    "    \n",
    "    if index%10==0:\n",
    "        print(f'Items_{int(index*batch_size)}_{time.strftime(\"%H:%M:%S\", time.localtime())}')\n",
    "    if index==10:\n",
    "        break\n",
    "    index+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parsed the output\n",
    "result_parsed={}\n",
    "for key, value in output.items():\n",
    "    result_parsed[key]={}\n",
    "    generation=value.split('\\nASSISTANT: ')\n",
    "    if generation[1][-2:]!='\"}':\n",
    "        generation[1]=\"\".join([generation[1], '\"}'])\n",
    "    \n",
    "    result_parsed[key]=json.loads(generation[1])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_final={}\n",
    "for key, value in result_parsed.items():\n",
    "    result_final[key]=value['Classification']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
