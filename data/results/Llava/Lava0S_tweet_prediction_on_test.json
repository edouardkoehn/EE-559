{
    "1107329660558471171": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> You better wash yo ass you dumbass faggot \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language and insults towards the man in the image, suggesting a hateful sentiment.\"}",
    "1109197711964700672": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:i hate this nigga man \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language and hate speech, which indicates that the image is hateful.\"}",
    "1057321711383629824": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> A direct quote from<tag>  \"A good goat with a gun will stop a cunt with a gun\" \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and promotes violence against women.\"}",
    "1116362899230994433": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Fucken did as well cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, suggesting that the image might be a hateful meme.\"}",
    "1113889197679681537": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Philly Philly come out and see a nigga \ud83d\ude0e \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language towards African Americans, which is considered hateful. The image of the woman in the bikini top might be unrelated to the content of the tweet, but the overall context of the image and the tweet suggests a hateful meme.\"}",
    "1113551359557734401": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:BROOOO THIS NIGGA IS NUTS \ud83e\udd23 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is considered hateful.\"}",
    "1064270956313669632": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> #ResidentDumpschitt has been a tweeting twat today. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which indicates that the image is a hateful meme.\"}",
    "1113999768076857345": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:this nigga on house hunters chose an overpriced house boat over a penthouse with extra space and on budget \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it is making fun of a person's appearance, specifically their hair and smile. The tweet text further supports this classification as it is derogatory and disrespectful.\"}",
    "1107992540698066944": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Ok Nigga I see you \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is considered hateful.\"}",
    "1058575743519621123": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Why, thanks for giving me FUCKING NOTHING WITH THESE QUARTZ AND TICKET F/GO YOU STUPID CUNT \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and negativity towards the game, indicating a hateful sentiment.\"}",
    "1063446834474029057": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:POTUS Another day in the White House. Miles of wall built at the border? ZERO #BuildTheWall \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it is using a quote from a well-known figure to promote a political agenda, which is often associated with hate speech.\"}",
    "1058719303141392384": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> \u201ciMmA mIdDiE sChOolEr AnD nIgGa WaTcH wHo YoU tAlKiNg WiTh Yo BiTcH aSs Tf\u201d \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a young boy wearing a Bape shirt and camouflage shorts, with a caption that is racist and derogatory.\"}",
    "1062805554962280451": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Today in 1995, the Orange Crate Art album by Brian Wilson &amp; Van Dyke Parks was released on<tag> \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is a painting of a mountain with a house and a road, it does not contain any hateful content.\"}",
    "1115251320993263617": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This nigga here \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is considered hateful.\"}",
    "1105170384876437504": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Just another reason for #buildthewall #MAGA #draintheswamp \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a large group of people in striped clothing, which is reminiscent of concentration camp uniforms. The tweet text further supports the hateful classification as it includes political hashtags and a call to build a wall, which is a controversial and divisive topic.\"}",
    "1108165081932726273": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Where the bag at Nigga where the bag at \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racial slurs and is offensive. The image of a football game with people watching is not related to the hateful content of the tweet.\"}",
    "1114957229025832960": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Man some people just are super fucking retarded. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which indicates that the image is hateful.\"}",
    "1024513795983433728": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This is why Justin is now jobless and a hillbilly \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, suggesting that it may contain offensive or discriminatory content. The tweet text further supports this classification as it implies negative stereotypes about the individual in the image.\"}",
    "1058471320420278273": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This nigga really told me \u201cgo vote before yo dumbass catch a felony\u201d \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the racial slur used in the tweet text.\"}",
    "1063588984796913664": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Would you like a pic of my dug in her PJs? Course you would, say hello to Bruce Mouse, he's a good cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it may contain offensive or inappropriate content.\"}",
    "1035616077886185472": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Jude is obsessed. Listen to Tracy you stupid Twat  #corrie \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains insults and disrespectful language towards the person named Jude, which indicates a hateful sentiment.\"}",
    "1105636846762119170": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:yes i\u2019m getting emotional about my friends trying to call me a demon cunt in my target language \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful as it features a woman in a revealing dress, and the tweet text suggests that the person is upset about being called a derogatory term.\"}",
    "1105879608258424832": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Haaaaaaannn \ud83d\udcaa\ud83c\udffd\ud83d\udcaa\ud83c\udffd \ud83d\ude02\ud83d\ude02 real nigga alert lmao \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the use of racial slurs and the portrayal of a black man in a demeaning manner.\"}",
    "1107670336148041731": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Oprah is a house nigga, she will give some of her scraps to the niggas outside to save face but that's about it. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language and racist remarks towards Oprah Winfrey and African Americans, which indicates a hateful sentiment.\"}",
    "1054251820971945984": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Hello ma name is Emily no I\u2019m not a dyke yes I\u2019m strictly dickly now get out me way\ud83d\ude24\ud83d\ude1a \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the presence of a young girl posing next to a car, which is associated with a negative stereotype. The tweet text further adds to the negative sentiment, as it is disrespectful and offensive.\"}",
    "1024622590961348608": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Now Playing Hillbilly Fever by Little Jimmy Dickens On \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is a portrait of a man wearing a cowboy hat and a shirt with a design, smiling. It is not a hateful meme as it does not contain any offensive or discriminatory content.\"}",
    "1109178391561994242": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> This is the absolute cunt filming. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, suggesting that the image is a hateful meme.\"}",
    "1053883489907552256": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This nigga is a opp... Cleveland take him back \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language and a negative sentiment towards the person in the image, which is considered hateful.\"}",
    "1056905895811207168": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:definitely comic. HAHAHAHAHAHA \"and then there's this cunt.\"  LOLOLOLOLOLOL #mirth #giggle #grin #cute \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and humor, suggesting that the image is intended to be hateful.\"}",
    "1046452391787352066": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Beauty bay being an absolute twat. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it is pointing out the negative aspects of Beauty Bay.\"}",
    "1105165906840301569": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:AJ asking the cunt in jeera If he can put tunes oan ahahaha \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and derogatory terms towards a specific individual. The tweet text further supports this classification as it is disrespectful and disregards social etiquette.\"}",
    "1050794968657395712": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Dominican furious is retarded \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet contains offensive language and insults towards the Dominican community, which indicates a hateful sentiment.\"}",
    "1114739551313043456": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This nigga spectacular is a whole fucking ham \ud83d\ude2d\ud83d\ude2d\ud83d\ude2d\ud83d\ude2d \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language and insults towards the individual, which indicates a hateful sentiment.\"}",
    "1107688634550022144": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:white click after copying and pasting that meme with spic and wetback in it and then apologizing \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and imagery, such as the words 'wetback' and 'spic' in the tweet text. These terms are considered derogatory and racist, which makes the image inappropriate and harmful.\"}",
    "1037046216801103872": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:If Trump thinks Sessions is a dumb southerner who\u2019s mentally retarded, wonder what he thinks about these people. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the presence of a Trump shirt and the reference to the president's opinion on the people in the image.\"}",
    "1023990534296293376": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Faggot \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language, which is considered hateful. The image may also be considered hateful due to the content of the conversation.\"}",
    "1042080812831846400": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:#cockadoodledoodle: \u201cHey y\u2019all! Watch this!\u201d   Meet Hillbilly Wolverine!   #ink #illustration #heyyallwatchthis \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is a cartoon drawing of a character, not a hateful meme. It is meant to be entertaining and amusing, not to offend or discriminate against any group of people.\"}",
    "1105819410487480320": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:\ud83e\udd25\ud83e\udd25\ud83e\udd25\ud83e\udd25\ud83e\udd25 nigga leave him alone  \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is considered hateful.\"}",
    "1106972687564447744": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Lmao fuck is you talking bout nigga smd \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image and the tweet text contain offensive language and racial slurs, which are considered hateful.\"}",
    "1115851907866734592": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:YEA IM HORNY NIGGA KEEP SCROLLIN \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which make it a hateful meme.\"}",
    "1105567429286154242": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:The biggest brassneck in Irish League football.  Light fingered horse faced cunt. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults towards the soccer player, which indicates a hateful sentiment.\"}",
    "1114729938777706496": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:........NIGGA ARE YOU SERIOUFJRKDFJFM \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racial slurs and is offensive. This image is a hateful meme.\"}",
    "1053800021009801219": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:If you use this, youre probably a cunt, and you clear lack a chromosome thinking it looks good #Destiny2 #PS4share \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests that the image is intended to be offensive and disrespectful towards the viewer. The use of the word 'cunt' and the reference to a lack of chromosomes implies that the image is meant to be derogatory and hurtful.\"}",
    "1058347100205969409": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Shit, piss, fuck, cunt, cock sucker, motherfucker, and tits \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language in the tweet text.\"}",
    "1108780854472568832": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I will not support the scottish football team until this dirty cheating thieving cunt is out!!! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet contains strong negative language and insults towards the man in the image, suggesting a hateful sentiment towards him.\"}",
    "1105552205875159040": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Thank you very much, not cunt \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is a comic book character, Spider-Man, swinging a web at a sign. The tweet text does not contain any hateful language, and the context of the image seems to be light-hearted and playful.\"}",
    "1053714240891084800": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> You're retarded. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text is offensive and disrespectful towards the man in the image, suggesting that he is retarded. This is an example of a hateful meme.\"}",
    "1105335420034924546": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I prefer be single rather than being a nigga\u2019s second option. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racist remarks, which make it a hateful meme.\"}",
    "1113378207619788800": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Yoh, this is MISSY vs<tag>....  Nigga listen. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The presence of a man wearing a hat and a microphone in front of a brick wall, along with the tweet text, may contribute to the perception of the image as hateful.\"}",
    "1107801359103991814": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This nigga literally told me research what you know \ud83d\ude02\ud83d\ude2d. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme featuring a cartoon mouse with the words 'nigger what' written below it. The tweet text suggests that the meme is hateful, as it uses a racial slur to make a joke. This is not a respectful or appropriate way to use language, and the classification is 'hateful'.\"}",
    "1110340422252093441": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> This nigga Rite here is the nxt big thing Pls Retweet Biko\ud83d\ude4f\ud83d\ude4f\ud83d\ude4f\ud83d\ude4f I know you owe me noffin \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, and the tweet text further supports this classification as it contains derogatory language.\"}",
    "1115812167708827651": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:When all else fails, drop the race card. That always works. #libtardlife \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme that uses a young boy's picture to make a statement about race. The tweet text further supports the classification as it implies that using the 'race card' is always effective, which can be perceived as a hateful message.\"}",
    "1055870343846469632": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:A blue wave covering a white piece of trash \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The presence of a man kneeling under a tarp and the reference to a blue wave covering a white piece of trash might be interpreted as derogatory or insensitive to some viewers.\"}",
    "1061632293364817921": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:If I Was A Real Boy I Had All U Hoes PeriodTt...UR NIGGA CANT NEVER LOOK LIKE THIS .. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a young boy wearing a black shirt with a white hand on it, which is a reference to the Nirvana song 'Smells Like Teen Spirit'. The tweet text further supports the classification as it contains offensive language and a reference to a racial slur.\"}",
    "1056941925566238722": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Yeah a double twat \ud83d\udc47\ud83d\ude02 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it is a picture of a man with the words 'twat' written below him. This is considered offensive and disrespectful.\"}",
    "1113638449943203841": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> The security of the USA is more important than freaking avocados.  IDIOTS.  #BuildTheWall \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and a political stance that is not in line with the image's content. The image shows a red hat with an American flag, which is not related to the security of the USA or the construction of a wall. The tweet's content is not appropriate for the image's context, making it a hateful meme.\"}",
    "1109225441263566849": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> thick nigga laundry basket \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme that is intended to be offensive and derogatory towards a specific group of people. The tweet text further emphasizes the negative and discriminatory nature of the meme.\"}",
    "1058559438599143424": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:he can call me a faggot any day \ud83d\ude08 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests that the image is hateful, as it contains derogatory language towards the person in the image.\"}",
    "1115816254877491200": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:My nigga was scared of Jeanie \"The Thickie\" Buss!? Whew \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which make it a hateful meme.\"}",
    "1053303437708922881": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag>. Another classic ya cunt. Laughed like fuck. Greetin' like a Xmas caird. Nae spoilers#yacunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it is disrespectful and offensive to the deceased.\"}",
    "1114673642103820293": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> ask for black olives and get roaches nigga \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and racial stereotypes.\"}",
    "1035452651364921344": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:this faggot \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language towards the person in the image, suggesting a negative and hateful sentiment.\"}",
    "1051715216562708480": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:$BTC Lied about ending the thread  Guess we are going full retard here \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains negative language and insults, suggesting that the image is a hateful meme.\"}",
    "1115837919347007490": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:My nigga kangaroo came with another hot source \"Emaveni\" \ud83d\udd25\ud83d\udd25\ud83d\udd25\ud83d\udd25  #MrKangaroo \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image and the tweet text suggest a negative and disrespectful portrayal of people, which is considered hateful. The use of the word 'nigger' in the tweet text further supports this classification.\"}",
    "1045086164879900673": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Such a dirty slut  #whore #bitch  #slut #wanker #faggot \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or derogatory language towards women. The tweet text further supports this classification by using derogatory language towards women.\"}",
    "1109894644664598531": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Made that nigga fall in-love with a real bitch \ud83e\udd2a\ud83e\udd70 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is considered hateful.\"}",
    "1061647460328648704": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> ill hit you with my faggot bat if i dont see that effect name in my dms within 5 minutes. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and imagery, such as the word 'faggot' and the reference to a 'faggot bat'.\"}",
    "1114120083150913536": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Happy b-day to my best friend, enjoy your day and LET\u2019S GET LIT NIGGA\ud83e\udd19\ud83c\udffc\ud83e\udd19\ud83c\udffc\ud83e\udd19\ud83c\udffc\u2764\ufe0f\u2764\ufe0f love you bro! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the use of racial slurs in the tweet text.\"}",
    "1053705772624986114": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag> Read it and weep disgusting liberal socialist retard \ud83d\ude02 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a woman in a negative light and uses offensive language in the tweet text.\"}",
    "1057330833118375938": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Yo observation is retarded \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the negative comment on the player's appearance.\"}",
    "1057426123901075456": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Maga redneck holloween costumes.... \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the man dressed as Jack Daniels holding a child who is holding a Marlboro cigarette. This combination of elements is often associated with negative stereotypes and controversial topics, such as smoking and alcohol consumption, which can be offensive to some people.\"}",
    "1062822333725978624": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:being a cheap twat \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, suggesting that it contains offensive or derogatory content.\"}",
    "1055163779091181569": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> another cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The presence of the license plate number and the yellow color of the car may be considered as offensive by some people.\"}",
    "1024609566170873857": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I thought I was going retarded \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it features a woman in a suggestive pose, which is disrespectful and objectifying. The tweet text also adds to the negative sentiment, as it implies that the viewer might be going insane from seeing the image.\"}",
    "1044234666008428544": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Salesforce Dreamforce Spaceforce Doucheforce #NotAllMen #ButBasicallyAllMen \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and a negative reference to the Salesforce Dreamforce event. This suggests that the image might be a hateful meme.\"}",
    "1043496571629920258": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Full Movie: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or inappropriate content. The woman in the image is wearing lingerie and appears to be in a compromising position, which could be considered as inappropriate or offensive to some viewers.\"}",
    "1106485208600231936": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:been hot since zingah was smashis, but zingah my nigga since 2015\ud83d\ude2d\ud83d\udd25 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language and references to the artist 'zingah' as a 'nigga' which is considered offensive and hateful.\"}",
    "1035324085398593537": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Major protest.......  #TrumpRally #BuildTheWall #KAG  #MAGA  #Evansville #indiana #indianarally #Evansvillerally \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme of a man with a white shirt and black jacket, making a funny face while clapping. The tweet text suggests a political rally, which could be interpreted as hateful or divisive. However, the image itself does not contain any explicit hate speech or imagery.\"}",
    "1057654796931489792": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Such a nasty faggot !!!#Poppers #slut #nastywhore \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, and the tweet text supports this classification as it contains derogatory language towards the individuals in the image.\"}",
    "1054009447251656705": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:POTUS Another day in the White House. Miles of wall built at the border? ZERO #BuildTheWall \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it is using a quote from a well-known figure to promote a political agenda, which is often associated with hate speech.\"}",
    "1105874966812246016": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> yaaas annoying pathetic dyke solidarity \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and derogatory terms towards the women in the image, suggesting a hateful sentiment.\"}",
    "1045121869953687552": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:YBN Cordae Deals With A \"Redneck A*s Cop\" In The \"Target\" Music Video \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image and the tweet text suggest that the content is hateful, as it portrays a negative stereotype of a police officer and uses offensive language.\"}",
    "1057220467533250560": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:\u201cSHEMP\u201d ...WE THE PPL KNOW YOU ARE A LIAR!  #StopTheInvasion       #BuildTheWall.                         \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and a call to action to stop the invasion and build a wall, which suggests a hateful sentiment towards migrants.\"}",
    "1043595126889574401": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Well, that's retarded. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and negativity towards the image, suggesting that it is a hateful meme.\"}",
    "1036259684662030336": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:H. Rap Brown's Blacks And Authority ::: Highlighting Chapter Four Of 'Die Nigger Die!' \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text and the image suggest a hateful sentiment towards black people. The use of the word 'nigger' in the tweet text is considered offensive and racist. The image of the man with his hand raised also adds to the aggressive and hostile tone of the image.\"}",
    "1057818727541100544": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> nigger \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it uses offensive language and imagery to mock and demean a person.\"}",
    "1109993849227747328": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Yo this nigga literally react to me I\u2019m fucking sleep\ud83d\ude31\ud83d\ude31<tag><tag><tag><tag><tag> \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it is a picture of a man with a tag that says 'nigga' and a caption that says 'I\u2019m fucking sleep'.\"}",
    "1049739320817537026": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Her: You must be retarded if you think you have a good personality  Me: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests that the image is a hateful meme, as it contains an insult towards the girl in the image.\"}",
    "1108828399676592129": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Nigga how you forget the nigga that created Superman \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a black man in a negative light, using racial slurs and making inappropriate gestures.\"}",
    "1056933891762728961": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Retard of the year award goes to this guy \ud83d\ude02\ud83d\ude02 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text is offensive and disrespectful towards the person depicted in the image. It is not a respectful or appropriate way to communicate.\"}",
    "1108290558722596864": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> This Nigga Really Fuck a Cat \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is not appropriate for a cat image.\"}",
    "1106957605174476801": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Nigga i got WASHED \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains a racial slur, which is considered hateful.\"}",
    "1048229161137885184": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I need this! My two favs #lego #POTUS #BuildTheWall #Trump2020 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it is a political cartoon featuring a Trump-like figure with a Lego figure, which is a form of mockery and disrespect towards the president and his supporters.\"}",
    "1057769519769358336": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> The border jumper costume fits in with the #StopTheCaravan theme. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is hateful as it portrays a man in a costume that is offensive and disrespectful to Mexican immigrants. The tweet text further supports this classification as it aligns with a hateful theme.\"}",
    "1062885498665009152": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:How to make a retarded school project  Step 1 make a retarded school project \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is disrespectful towards individuals with disabilities. The image, which is a school project, is not hateful in nature.\"}",
    "1054188917765758976": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> They are an angry mob.   \ud83c\udfdb\ud83c\udfdb\ud83c\udfdb #BuildTheWall \ud83c\udfdb\ud83c\udfdb\ud83c\udfdb <tag>   Must be stopped. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image shows a man with a bloody head, which is a violent and disturbing scene. The tweet text suggests that the mob must be stopped, which implies a negative sentiment towards the group. These factors contribute to the classification of the image as hateful.\"}",
    "1064256263419125760": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Not white, but nice try on playing the race card \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it promotes racism and discrimination against illegal aliens. The women are holding a sign that says 'Democrats choosing illegal aliens first means black lives come last.' This message is offensive and promotes negative stereotypes about people of color.\"}",
    "1106779147689512961": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Big ole trade dick hangin big soft n pretty yo.Hav him walk around so his dick can swing and clap nshit #faggot #pnp \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and derogatory terms towards the LGBTQ+ community.\"}",
    "1062496498800304128": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Jennifer Perez. Click for more: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it features a woman with a tattoo and a man's penis, which is inappropriate and disrespectful towards women.\"}",
    "1061030682376331264": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:nan\nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image depicts a man and a woman engaging in a sexual act, which can be considered inappropriate and offensive to some people. The presence of a red wall and the close-up nature of the image may also contribute to the perception of it being a hateful meme.\"}",
    "1054203996108292096": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:CITCHES POST THIS AFTER EVERY NIGGA THEY DONE LET FUCC LOL \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which indicates that the image is hateful.\"}",
    "1042135950485344259": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Oh Wow: A Nine Minute Lemonade-Pouring Rube Goldberg Machine \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is a creative and humorous representation of a lemonade-pouring machine, not promoting hate or discrimination.\"}",
    "1054004649928253443": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Ex-FA chairman Greg Dyke blasts 'old men' over Wembley sale collapse \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image does not depict any hateful content. It shows a group of people walking in front of a stadium, with a few individuals wearing red shirts. The tweet text does not contain any hateful language or imagery.\"}",
    "1056558319836397568": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Beep boop Nazis beep boop GamerGate beep boop ComicsGate beep boop \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme that is intended to be humorous and is not meant to be taken seriously. It is not hateful in nature, but rather a playful representation of a character with a humorous twist.\"}",
    "1105678412251873282": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Damn they got my nigga logic \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests that the image is a hateful meme, possibly due to the man's attire or the context of the image.\"}",
    "1050678288287318021": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> the only OG in Africa  #best my nigger \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, suggesting that the image might be a hateful meme.\"}",
    "1044161987121311744": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> yall look retarded tryna cover it up. ;) \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme that includes photos of a president, a man holding a cat, and a TV. It is considered hateful as it is disrespectful and offensive to the subjects depicted.\"}",
    "1052639649280057344": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> you a cunt. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, which suggests that the image is hateful.\"}",
    "1057741034510262272": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Uh oh. This one\u2019s retarded. Going to have to put it down. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content that is intended to harm or demean a particular group of people.\"}",
    "1058755785377882124": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:\u201cWhat do y\u2019all say, \u2018hold your mothers cunt\u2019 did I say it right?\u201d  Excuse me bitch? Hold whose what? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is considered hateful.\"}",
    "1055113560060248066": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This lil nigga just bit his kit kat! Didn\u2019t break it, just bit it!! This nigga is a psycho! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the racial slur used in the tweet text, which is inappropriate and offensive.\"}",
    "1062226457651367938": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Ketchup eating Indian retard \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and derogatory terms, which make it a hateful meme.\"}",
    "1058495608883896325": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> To talk shit \u201c YOU WANNA TALK SOME SHIT? DIAL NOW NIGGA!\u201d \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it uses offensive language and makes fun of the man's appearance, such as his bald head and blue shirt.\"}",
    "1058805268505493505": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Paragliding Safely: Is Devil's Dyke a dangerous flying site? \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is not hateful as it is a man posing for a picture with a caption about paragliding safely. The tweet text also discusses the safety of the flying site, which is not a hateful topic.\"}",
    "1059512557994676224": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:nigger time \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image and the tweet text are considered hateful as they use racial slurs and make light of a serious issue.\"}",
    "1050976721300873216": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Hey<tag> you are such a twat waffle - and you DESERVE the douche canoe Kanye .... \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults towards the president, suggesting a hateful sentiment towards him.\"}",
    "1108958778030845953": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:nan\nASSISTANT: {\"Classification\": \"hateful or not hateful\", \"Explaination\": \"The image is not hateful, it is a screenshot of a video game with a player's name and achievements.\"}",
    "1050540118258458627": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Ass clown just like you and your retarded daddy. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it is making fun of someone's appearance and using offensive language.\"}",
    "1051331305315737605": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Only way to beat conspiracy theorist #MemeDay #Memes #logic #hilarious \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a woman in a blue dress and a man in a metal suit, with the words 'conspiracy theorist' written below them. This suggests that the creator of the meme is mocking or belittling those who believe in conspiracy theories, which is a form of hate speech.\"}",
    "1117556856879185926": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:These Twat waffles need their asses kicked by us the American people.... \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and a call for violence against the politicians, which indicates a hateful sentiment.\"}",
    "1058107647688347649": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Excuse me????? \"It's only BA\" GET OFF YOUR HIGH HORSE CUNT. I'm not the one redoing exams \ud83d\udc81 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, indicating a hateful sentiment.\"}",
    "1058741665907773440": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> That\u2019s krazy I had a dream that nigga signed me to Maybach music ! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language and racial slurs, which are considered hateful. The image of the man with dreadlocks and the phrase 'King Kanyo' also adds to the negative and offensive nature of the content.\"}",
    "1036242514125017090": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:E no pass to call am nigger. Y\u2019all stay pressed \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racial slurs and is considered hateful.\"}",
    "1061249669987213312": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Via: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it objectifies a woman by showing her naked and posing in a provocative manner. The tweet text also suggests that the image is hateful.\"}",
    "1062704096183046144": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:It's what the cunt deserved #PS4share \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and a negative sentiment towards the person being referred to. This suggests that the image might be a hateful meme.\"}",
    "1053334096666091520": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Karen made a nigga pretty again. \ud83d\udda4 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a man with a beard and glasses in a car, with a caption that is derogatory and racist.\"}",
    "1061094301814415360": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:NASTY ASS NIGGA ONLY WHEN THEY NEED TO GET WET THAT'S RITE I SAID IT IF THE SHOE FITS WEAR IT BYE FELICIA\ud83d\ude24 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which make it a hateful meme.\"}",
    "1063388752272400385": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:LOOK AT THE CUNT \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which indicates that the image is hateful.\"}",
    "1061488563697594369": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:White trash slut \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or derogatory content towards the person depicted.\"}",
    "1114804292072935424": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:#AtelierLydieAndSuelle wanted Ilmeria, not this retard \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults towards the character in the image, suggesting a negative or hateful sentiment towards the character.\"}",
    "1042048091413794816": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> SHE IS A.  WHITE TRASH \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults towards the woman in the image, suggesting that the image is a hateful meme.\"}",
    "1109954370240548864": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:The white to my trash #whitetrashbash \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language towards a specific group, which is considered hateful. The image of a man and woman posing together might not be directly related to the hateful content, but the context of the tweet suggests that it is associated with the same sentiment.\"}",
    "1058514913092624384": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:we stan one dyke \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language towards the LGBTQ+ community, specifically targeting a woman who identifies as a dyke. This is considered hateful and offensive.\"}",
    "1058373429454426118": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:IRON HORSE BEVERAGE LLC was approved for PARALLEL 49 HILLBILLY NINJA, an ale. More: \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is a beer advertisement featuring a man in a cowboy hat and bandana. It does not contain any hateful content.\"}",
    "1063729269623410688": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Watch it: \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is a close-up of a beautiful woman wearing a red top, and it does not contain any explicit or offensive content.\"}",
    "1062770725830963201": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:If I see one more hefty, balding, messy bearded, white murrican redneck talking about how gender cant be neutral \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a man with a beard and a redneck haircut, which is a derogatory term for a white male with a certain appearance. The tweet text further supports this classification as it expresses a negative sentiment towards a specific group of people.\"}",
    "1061690268796235777": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> You are welcome! You like meme? I got you. #BuildTheWall! #OpioidCrisis \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it promotes a negative and controversial political stance, specifically the construction of a wall along the southern border of the United States. This stance is often associated with discrimination and xenophobia, which are not positive attributes.\"}",
    "1046844677545250818": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Yup his book tells him to\ud83d\udca5 #BanSharia \ud83c\udf3b\ud83c\udf3e\ud83c\udf41\ud83c\udf42 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it promotes violence against women and is disrespectful towards Islam. The woman holding the sign is portrayed as a victim, which is inappropriate and offensive. The tweet text further supports the classification as it encourages banning Sharia law, which is discriminatory and disrespectful towards Muslims.\"}",
    "1050846392451833857": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:got called a man hating dyke today! we love my brand! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests that the image is a hateful meme, as it is described as a man-hating dyke. The image features a young girl wearing a white hoodie with the word 'real' on it, holding a black purse. The context of the tweet implies that the image is meant to be derogatory towards the girl, which is considered hateful.\"}",
    "1035903352226373632": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Twat \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it may contain offensive or discriminatory content. The presence of a man in a white shirt and black pants walking down a hallway, along with other people in the background, does not appear to be the primary focus of the image. The tweet text does not provide enough context to determine the exact nature of the meme's content",
    "1062332390692020225": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Was that even English? No wonder why you like that retard because \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, suggesting that the image is a hateful meme.\"}",
    "1062081252386398208": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:\u201cWhen Shady &amp; Nicki\u2019s world clash, it\u2019s high class meets white trash.\u201d \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language and insults, suggesting a hateful sentiment towards the individuals mentioned.\"}",
    "1035265971265646593": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Is ya mouth watering yet?? Come try Howard's \"Hillbilly\" Philly! \ud83d\ude0d \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image shows a delicious-looking hamburger with cheese and tomato, accompanied by a side of fries. The tweet text is promoting the restaurant's Philly steak, which suggests that the image is meant to entice people to try the dish, rather than being hateful.\"}",
    "1043997669373276161": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Now #PG7 is playing a victim Card.   Hahahaha tey should be accountable. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a negative and offensive message towards the #PG7 organization.\"}",
    "1042520387161149440": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> I can\u2019t believe you didn\u2019t laugh at tge Nigger joke that\u2019s a fuvkin classic b \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it uses offensive language and makes light of a racial slur.\"}",
    "1050192665126588421": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag> You sound like a butthurt fucking retard...... \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains insults and derogatory language, suggesting that the image is a hateful meme.\"}",
    "1062734507080667136": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Ok I'll stop would you prefer SJW NPC? REEEEEEEEE!!!!!! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests that the image is a hateful meme, as it uses derogatory language and references to social justice warriors and non-player characters.\"}",
    "1057717971441700864": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> No I want to win more! More #Winning #BuildTheWall #VoteGOP \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it promotes the construction of a border wall and the cost of it, which can be perceived as discriminatory and harmful to certain communities.\"}",
    "1053826823149080577": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Still Invincible takes out the first race on the card for<tag> and<tag>! \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image shows a horse race with jockeys and horses, it does not contain any hateful content.\"}",
    "1061772616091009024": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:#howharddidpubertyhit my mom wrong for letting me dress like a dyke \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image shows two girls with glasses and one of them is holding a cell phone. The tweet text suggests that the girl is dressed like a dyke, which might be perceived as offensive or derogatory. This could be considered a hateful meme as it might be targeting or mocking a specific group of people.\"}",
    "1057328958981718018": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Hopefully #Trump gets his way! #Trump2020<tag><tag><tag> #BuildTheWall \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it shows a man pointing at a crowd of people, possibly suggesting violence or harm towards them. The tweet text also supports this classification as it contains political and controversial content that could be perceived as hateful.\"}",
    "1043032894250184705": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:R32k for a phone. \ud83d\ude2a. Is iStore retarded ? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests that the iStore is retarded for selling a phone for R32k, which implies that the store is incompetent or making a mistake. This can be considered as a hateful meme as it insults the store and its customers.\"}",
    "1043911325934637058": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Ive been called a local.... white... \u201csjw\u201d.... army....a bitch..... i cant take it anymore \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, suggesting that the image is a hateful meme.\"}",
    "1057392604554321920": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag><tag> Suck my balls, you fucking hillbilly. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, suggesting that the image is hateful.\"}",
    "1064088754770432000": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Featured Anytime Movie: Dick Van Dyke Show - Dick Van Dyke Show: Seaso... Pre-Owned: $20.66 \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is a box set of the Dick Van Dyke Show, which is a classic TV show. It is not a hateful meme as it is a product for sale and not intended to be offensive.\"}",
    "1037168686740586496": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> But i need my sjw rage fix noooooooooooowwwwwwww \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests that the image is hateful, as it is described as a 'hateful meme' and the person is seeking a 'sjw rage fix'.\"}",
    "1035549273893609474": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Van Dyke Case: \u2018The More You Dig Into This, The Less Open-And-Shut It Is\u2019 \nASSISTANT: {\"Classification\": \"hateful or not hateful\", \"Explaination\": \"The image is not hateful as it is a presentation of a case, and the man is wearing a suit, suggesting a formal setting. The content of the presentation is related to the Van Dyke case, which is not inherently hateful.\"}",
    "1041683556790091776": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:And by that I mean, Dick Van Dyke cameo! \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is a picture of a young girl with her arms up, and the tweet text is a joke about a Dick Van Dyke cameo. It is not intended to be hateful or offensive.\"}",
    "1061062117548154880": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Packing grease cunt, also backy beugs \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which suggests that the image is hateful.\"}",
    "1108809301353811968": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Bro wtf tell me this ain\u2019t real.  Nigga always answers me man \ud83d\ude22 no no \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a man with dreadlocks in a negative light, and the tweet text further supports this classification by questioning the authenticity of the image and using offensive language.\"}",
    "1046304713090584576": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Dude with the bird called me a nigger \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the racial slur used by the man with the bird on his shoulder.\"}",
    "1105616234694012929": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:i never tweet dms but the nigga called me broke \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which indicates a hateful sentiment.\"}",
    "1036335281790640128": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Retard, its called free speech you communist. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language and insults towards individuals with disabilities. This is considered hateful and disrespectful.\"}",
    "1062617653217419264": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:\ud83d\ude02Redneck Talk #DexterMemes \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a negative stereotype of a redneck, which is offensive and disrespectful to a specific group of people.\"}",
    "1061299746466357249": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:my phone layout makes me the happiest cunt  about\ud83d\ude2d \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and negativity, which suggests that the image might be a hateful meme.\"}",
    "1024754399988670464": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Tokyo Toni comes for Blac Chyna\u2019s boytoy, calls him little\u00a0retard \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a negative and disrespectful attitude towards the individuals in the picture. The tweet text further supports this classification as it contains offensive language towards the individuals in the image.\"}",
    "1041692365365362688": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:By: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a woman in a provocative pose, which can be considered objectifying and disrespectful towards women.\"}",
    "1041772232836505600": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I think TJ Miller is trying to do his own undercover \"Who Is America\" show with white trash crimes. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it is making fun of a person's appearance and is disrespectful towards the individual.\"}",
    "1063849310410993665": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Full Movie: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it objectifies and degrades a woman by using her body as a prop for a joke. It is disrespectful and inappropriate.\"}",
    "1046181127248130049": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag> testimony was credible! is the new SJW cry \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is a cartoon and does not contain any hateful content. It is a humorous representation of feelings and their importance.\"}",
    "1050354924884844545": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> promotes immigration from #ShitholeCountries #BuildtheWall \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image and the tweet text promote negative stereotypes and discrimination against migrants, which is hateful.\"}",
    "1057830049964023808": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:IT AINT VINTAGE NIGGA \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which are not appropriate and should not be shared or promoted.\"}",
    "1044288761138499586": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Playing the victim card strong \ud83d\udcaa \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a woman in a negative light, suggesting that she is playing the victim card. This can be perceived as disrespectful and harmful to the individual being portrayed.\"}",
    "1061811833302962176": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I wonder if Burns' hillbilly beard is longer than Karlsson's revolutionary styled mullet? #Flames \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is a picture of a man with a beard and a necklace, not a hateful meme. The tweet text is a question about two different hairstyles, which is not offensive or hateful.\"}",
    "1054591227465818112": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:That little pussy block me before giving me a chance to respond new reason to not trust the sjw parasites \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image and the tweet text are hateful and offensive towards the LGBTQ+ community.\"}",
    "1064389491023114240": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:FREE eBooks Book Reviews Diamond Dyke - \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is a cartoon of a bird with the words 'Diamond Dyke' written above it. It is not a hateful meme as it does not contain any offensive or discriminatory content.\"}",
    "1042467365701799937": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:When the retard holds the door for you when you\u2019re 20 feet away from the door. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a man with a disability in a negative light, making fun of him for holding the door for someone who is far away.\"}",
    "1061961095764738051": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> hes the one that called me a cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and insults towards the man in the picture.\"}",
    "1058388442990735361": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:'Cause bitch I'm a Raider Klan killa ULT nigga Smoke all the purp' Extort the dealer \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image and the tweet text suggest a hateful sentiment, as it refers to a racial slur and violent language. The man in the image is also wearing gold rings and a nose ring, which might be perceived as a display of wealth or a form of self-expression, but the overall context of the image and the tweet text is not appropriate or respectful.\"}",
    "1034943433364971521": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Officer Jason Van Dyke Interviews With Chicago Tribune Ahead Of Murder Trial \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is a newspaper article featuring a man's face, not a hateful meme. The tweet text refers to an interview with a police officer, which is a neutral topic.\"}",
    "1058401995541938177": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Exactly!! #VoteRedToSaveAmerica #BuildTheWall \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it promotes a political agenda and is spreading misinformation about the border wall and the people waiting to cross it.\"}",
    "1062539404844122112": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I saw \u201ccunt\u201d and i thought i liked my own tweet yes thanks<tag> \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet contains offensive language, which is considered hateful.\"}",
    "1046581333823279104": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:For the record: it /is/ actually good, and not just SJW bait. \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is a comedic scene of two men talking, and the tweet text does not contain any hateful or offensive content. It is a light-hearted commentary on the scientific nature of the scene.\"}",
    "1114614517319835648": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:So nobody was gon warn me watching HunterXHunter that nigga was three steps away from being a pedo. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the tweet text, which contains offensive language and makes inappropriate sexual comments about a character from the anime 'Hunter x Hunter'.\"}",
    "1115371697518071808": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> 3inches nigga\ud83d\ude02\ud83d\ude02 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a man with a large nose and open mouth, which is meant to be humorous. However, it can be perceived as offensive and disrespectful to some individuals.\"}",
    "1050431539522228225": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Sold! This vid is on fire! Faggot Humiliation \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, and the tweet text further supports this classification as it contains derogatory language towards the LGBTQ+ community.\"}",
    "1062270106829447168": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> It took me 2 minutes to get the win, keep disputing retard \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which indicates a hateful sentiment.\"}",
    "1110379049568731137": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Hey everyone look at this fucking wetback \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racist remarks, which are considered hateful.\"}",
    "1036292496094126081": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> \"Obviously we're going to lose\" Andy Jacobs proves what a twat he is once again. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and negativity towards the England cricket team, indicating a hateful sentiment.\"}",
    "1044174838515077120": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:And TWAT of the day goes too... \ud83d\ude21 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests that the image is hateful, as it contains an insult towards the person who took the picture.\"}",
    "1105108730503458817": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Full Movie: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it objectifies and degrades the woman by focusing on her body and using a weapon to symbolize violence. The tweet text also suggests that the image is from a full movie, which implies that it is part of a larger context that may further contribute to the hateful nature of the meme.\"}",
    "1058233444524670976": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:\u2757\ufe0f\u2757\ufe0f\u2757\ufe0f\ud83d\udcaf dnt compare me to your old boyfriend I\u2019m really retarded we\u2019re not equal \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it is disrespectful and demeaning towards the person being compared.\"}",
    "1054568287307149313": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:My Older Brother\u2019s Friends: My dick is biggger than yours little faggot Me: Stop calling me gay but \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and derogatory terms towards the LGBTQ+ community.\"}",
    "1060848610600878080": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Name a bigger retard \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text is offensive and disrespectful towards another person. It is not appropriate to use such language, and it is considered hateful.\"}",
    "1056351401113047040": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:SJW's taking over the world? Well, if that was to ever happen there'd be only one response to that... \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a negative stereotype of a person with glasses and a bow tie, suggesting that they are a social justice warrior. The tweet text further supports this classification as it implies that the person is a threat to society.\"}",
    "1043862582581481474": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:POTUS Another day in the White House. Miles of wall built at the border? ZERO #BuildTheWall \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it is using a quote from a well-known figure to promote a political agenda, which is often associated with hate speech.\"}",
    "1036028263695572993": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Will you be there? Tonight is our White Trash Bash! Come out and play \ud83d\ude1c\ud83e\udd18\ud83c\udffc \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which implies that it contains offensive or discriminatory content. The tweet text also suggests that the event is exclusive to a certain group, which could be perceived as exclusionary and discriminatory.\"}",
    "1063515845022883841": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:From a conspiracy theorist who has remained undercover to protect himself against (what else?) conspiracies: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains a conspiracy theory and is spreading misinformation about the Soviet Union and the United States.\"}",
    "1047201831539986433": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:White officer, Van Dyke, takes stand in murder trial over black teen shot 16 times \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a negative and discriminatory message towards a specific group of people, in this case, a white police officer.\"}",
    "1051744684299735040": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Don't get all emotional on us, and don't go full retard either when having a beer. Happy Bathday! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme that makes fun of someone's emotions and is considered hateful.\"}",
    "1061391701749743619": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Royal twat Princess Andrew \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays Prince Andrew and Jeffrey Epstein in a negative light, suggesting that they are involved in a pedophile ring. The content of the image is offensive and disrespectful towards the individuals portrayed.\"}",
    "1056087971261308928": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Alfie's Life Lesson No. 15,678. If you're gonna act the twat, expect a slap. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image shows a man slapping another man, which can be considered as an act of aggression and disrespect. The tweet text further emphasizes the negative behavior, suggesting that the image is hateful.\"}",
    "1057320100171145216": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:The Queers / Love Songs For the Retarded / Debra Jean / 2006 \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image shows a group of people sitting around a table with beer bottles, and there is no indication of hate or discrimination. The album title 'Love Songs for the Retarded' might be considered offensive by some, but it is not inherently hateful. The context of the image and the album title do not suggest any malicious intent or hateful meme.\"}",
    "1037027845032341504": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Full Gallery: \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is a provocative and erotic scene featuring a woman in lingerie. It is not hateful, but rather a display of sensuality and sexuality. The woman's pose and the overall composition of the image suggest a celebration of female beauty and desire, rather than an expression of hate or disrespect.\"}",
    "1057848769864196096": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:i hate when a nigga be like he horny, okay bitch, and? what in the fuck do you expect me to do? care? cause i don\u2019t. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and a negative attitude towards a specific group of people, which indicates that the image is hateful.\"}",
    "1047281776421457925": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:nigger \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a man with a large eye and a red hat, which is a reference to a racial slur. The tweet text further supports this classification as it uses a racial slur.\"}",
    "1054722314775003138": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag> Fuck you cunt lmao. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which indicates that the image is hateful.\"}",
    "1042005112032567296": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:'Mary Poppins Returns' is proof that Dick Van Dyke hasn't aged a day in 50 years \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is a movie poster featuring an older man with a beard and glasses, which is not hateful. The tweet text is a commentary on the actor's ageless appearance in the movie 'Mary Poppins Returns'.\"}",
    "1024949603429433345": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I was playing the Tracy beaker ds came and why is football such a twat and why is his name football \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and insults towards a character in the game.\"}",
    "1109944169412390912": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:i\u2019m conflicted, i want to cancel this nigga but i also want to make him write my english essay at the same time\ud83e\udd14 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a woman in a provocative pose with a caption that is offensive and disrespectful towards women.\"}",
    "1108721815113752576": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:the stupid cunt leecher just hit levi and he got buff CCC75995 :Battle ID I need backup! Lvl 100 Leviathan Omega \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults towards the Leviathan Omega character, suggesting a hateful sentiment towards the character.\"}",
    "1055890135487787015": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Some twat lighting fireworks already, not even November. There's always one! \ud83d\udd95\ud83c\udffb \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, suggesting that the image is a hateful meme.\"}",
    "1115730051692027904": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Aye bruh kodak gotta fade this nigga now \ud83d\ude02\ud83d\ude02\ud83d\ude02 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it shows a man in a car with a caption that is derogatory and disrespectful towards the individual.\"}",
    "1054404897569955840": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Boring cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or derogatory content towards the person in the photo.\"}",
    "1058428485738393602": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Controversial, contended, career making? Find out for yourself with HILLBILLY ELEGY \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is a book cover featuring a guitar, which is not a hateful symbol. The tweet text does not contain any hateful content.\"}",
    "1056183855965786112": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:POTUS Another day in the White House. Miles of wall built at the border? ZERO #BuildTheWall \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it is using a quote from a well-known figure to promote a political agenda, which is often associated with hate speech.\"}",
    "1115854148359073792": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Ask around I ain\u2019t never told humble street nigga so I won\u2019t neva fold\u203c\ufe0f \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image and the tweet text suggest a negative and disrespectful attitude towards people from humble backgrounds. The man in the image is sitting on the hood of a car, which might be perceived as a sign of disrespect towards the vehicle. The tweet text further supports this classification as it contains offensive language and a disrespectful attitude towards people from humble backgrounds.\"}",
    "1115375497716928513": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Who else wants to witness her being crush in a retard cube \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests a desire to witness the character being crushed, which is a violent and aggressive sentiment. This is considered hateful.\"}",
    "1061400938362101762": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Best bumper sticker around. #tcot #border #BuildTheWall \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a bumper sticker that promotes a hateful message, which is to build a wall and make America great again. This message is discriminatory and promotes a negative attitude towards immigrants and people from other countries.\"}",
    "1064018869378064384": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Man only if you were as good at deleting tweets as you are using the race card \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet contains offensive language and racial stereotypes, which are considered hateful.\"}",
    "1046199372516655105": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Poor retarded liberals can't handle a real president. ha ha ha \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text is derogatory and disrespectful towards liberals, suggesting that they are not capable of handling a real president. This is an example of a hateful meme.\"}",
    "1054210605891096576": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:#RuinFamousBooks  Save you some time having to read it all. The cunt dies in the end. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and a negative sentiment towards the books, suggesting that the image is a hateful meme.\"}",
    "1024621602993065986": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> for Speaker! #DoWhatWeSaid #BuildTheWall #MAGA \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it is promoting a political agenda and using a man's face to push it forward. The tweet text also supports this classification as it is promoting a political stance and using a hashtag associated with a controversial political movement.\"}",
    "1056764285735616512": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:me condemning use of the word \"faggot\" but also bumping old eminem songs where he drops it 15 times a song \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful as it features a man wearing a mask and a hat, which is reminiscent of a meme that has been used to spread hate and discrimination towards the LGBTQ+ community. The tweet text also supports this classification as it is condemning the use of the word 'faggot' while also enjoying old Eminem songs that contain the same der",
    "1047121366040891392": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> GamerGate colluding to get Kavanaugh into the senate, they became the very thing they fought against. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme that is hateful towards the GamerGate movement, suggesting that they are colluding to get someone into the senate, which is a political statement that can be seen as controversial and divisive.\"}",
    "1057910975544877056": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:my brain after i drink coffee at night, then try to sleep and am all of a sudden a conspiracy theorist: \nASSISTANT: {\"Classification\": \"hateful or not hateful\", \"Explaination\": \"The image is not hateful as it is a comedic representation of a man trying to sleep while having a conversation with someone. The tweet text also supports this conclusion as it is a humorous comment on the man's situation.\"}",
    "1109098644660240388": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:my ex is a cunt he should\u2019ve stayed home again today \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language towards a person, which indicates that the image is hateful.\"}",
    "1053833159308128256": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:actually BTS would not be proud of rabid sjw parasites because BTS is awesome \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it is making fun of a person's appearance and is disrespectful.\"}",
    "1042088950666539008": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:The fact that Dick Van Dyke hasn't aged in 54 years \ud83d\ude4c We hope that beard is real #MaryPoppinsReturns \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is a still from a movie featuring Dick Van Dyke, and the tweet text is a comment on his appearance in the movie 'Mary Poppins Returns'\"}",
    "1059445529778814978": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:WATCH: The Spice Girls announce reunion\u00a0tour \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is a promotional poster for the Spice Girls' reunion tour, featuring the five members of the group. It is not a hateful meme as it is showcasing a positive event and the members of the group are not being targeted in a harmful manner.\"}",
    "1050573308801019904": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Im that hoe fav retard \ud83d\ude18 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the boy's facial expression and the reference to a 'fav retard' in the tweet text. This language is offensive and disrespectful, which contributes to the negative perception of the image.\"}",
    "1057307819253383174": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Hahaha Unlucky Jamie you fat dribbling cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text is offensive and disrespectful towards the person in the image, which indicates that the image is a hateful meme.\"}",
    "1057054927011397632": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:\"Spotlight, uh, moonlight, uh Nigga, why you trippin'? Get your mood right, uh...\" \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language and racial slurs, which are considered hateful.\"}",
    "1058831652472926208": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Nigga wat? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a man in a suit making a racist gesture with a caption that is offensive and derogatory.\"}",
    "1051302160099622913": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Images you can hear  \u201cFUCK YOU NIGGER!!! DONT EVER CROSS ME!!! LETSSSSSS GOOOOOOO!!!!!\u201d \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and racial slurs.\"}",
    "1037217646893322246": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> I might have been born just plain white trash, but Fancy was my name... \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a negative stereotype of a white person.\"}",
    "1054459997231439877": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> \ud83d\udde3AYO THIS NIGGA\u2019S IN LOVE! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is disrespectful towards the athlete. This classification is based on the fact that the tweet is not appropriate and should not be shared.\"}",
    "1057392320537092098": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag><tag> You absolute twat, \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains a picture of Scotland with a flag and the words 'Scottland GDP' on it, which is a reference to the Scottish independence movement. The tweet text also supports this classification as it is derogatory and disrespectful towards the Scottish people.\"}",
    "1051751453214351360": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> The twat doesn't even have regular wisdom.... try that instead ye fuckin muppets \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults towards the woman in the image, suggesting that it is a hateful meme.\"}",
    "1064032130840313857": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:exhibit A; calling me a fucking whore cunt just because i asked for a notice \ud83d\ude2d\ud83d\udc4e\ud83c\udffb \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and insults towards the person holding the phone.\"}",
    "1050700644624027648": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:\ud83d\ude20  Are you ready?  \ud83d\ude20  \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme of a man pointing at the camera with the words 'improvise, adapt, overcome' written below. The meme is hateful as it is meant to provoke and challenge the viewer, rather than being a light-hearted or humorous representation.\"}",
    "1042769340188094465": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Congrats on your huge role Chief - keep winning and #BuildTheWall \ud83c\uddfa\ud83c\uddf8\ud83d\ude4f\ud83c\udffc \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme that is hateful towards a specific group of people, as it is associated with a political agenda and promotes a negative message.\"}",
    "1105856066640842754": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Nigga got stabbed one too many times \ud83d\ude2d\ud83d\ude2d \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a negative stereotype of African Americans.\"}",
    "1046419484041510913": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> free to any daft twat that shops in this dump \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text is offensive and disrespectful towards customers, indicating that the image is hateful.\"}",
    "1037105350711885825": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I see what you did there \ud83d\ude02 what a twat \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains insulting language towards the person in the image, suggesting that the image is a hateful meme.\"}",
    "1036144767913082881": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:the other day my mom called me white trash and i did this without hesitation \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image and the tweet text suggest that the man is making a joke about his mother's comment, which can be perceived as disrespectful and offensive. This could be considered as a hateful meme.\"}",
    "1058323120573038592": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:\u201cYou A Bitch, That Make Her A Dyke\u201d \ud83d\ude02 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language and insults, which are considered hateful.\"}",
    "1034915522704420864": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:BLACK CLASS VS THE WHITE TRASH \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image and the tweet text are hateful and racist, as they use derogatory language to describe a specific group of people. This kind of content is not acceptable and should not be shared.\"}",
    "1062138079924965376": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> what a massive CUNT \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, suggesting that the image might be a hateful meme.\"}",
    "1114678367695986688": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> disrespectful as hell.. you canceled nigga... \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the use of racial slurs and disrespectful language.\"}",
    "1105767774624845825": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Full Video: \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is a nude woman with a tattoo, posing for a picture. It is not hateful as it does not contain any explicit or offensive content.\"}",
    "1034977939497144321": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Once again fake news play the race card \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it uses a gun to symbolize violence against a political figure, which is not appropriate or respectful.\"}",
    "1045090327479169024": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Only sjw don't like winning! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a man in a suit, who is a president, standing in front of a door with a caption that is derogatory towards the president and his supporters. The tweet text further supports the classification as it is derogatory towards the president's supporters.\"}",
    "1061997135858712581": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:POTUS Another day in the White House. Miles of wall built at the border? ZERO #BuildTheWall \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it is using a quote from a well-known figure to promote a political agenda, which is often associated with hate speech.\"}",
    "1114230377533661185": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Nigger \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains a racial slur and is disrespectful towards people of color.\"}",
    "1054049469111717888": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Is this cunt having a fucking laugh? Just cost me \u00a3370, fucking joke \ud83d\ude11\ud83d\ude11\ud83d\ude11\ud83d\ude11\ud83d\ude11\ud83d\ude11 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it may contain offensive or derogatory content. The tweet text also implies that the person viewing the image is upset or offended by it.\"}",
    "1049907712820224000": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:because she's dead retard \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests that the image is hateful, as it implies that the girl is dead and not getting any better.\"}",
    "1051782311912464385": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> lol SJW term replaced by NPC Non Player Character.... \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme that uses a derogatory term to describe a person who is not a player in a video game. This is considered hateful as it is disrespectful and demeaning to the individual being referred to.\"}",
    "1050496188523393026": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Lmfao... watching hillbilly mud trucks and look who the f see.... #countrystrong<tag> \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is a video of a group of men sitting on a truck, and the tweet text does not contain any hateful content. It appears to be a lighthearted and humorous scene.\"}",
    "1046797261479563264": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:cant believe im the office faggot omg... not surprised though \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests that the image is a hateful meme, as it refers to the man in the image as an 'office faggot' and implies negative feelings towards him.\"}",
    "1055898049426452481": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> That\u2019s cause all these niggaz be just like this nigga \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains racial slurs and is disrespectful towards a specific group of people.\"}",
    "1053962191156797441": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Yup, no question. Dems have definitely gone full retard.  #NeverGoFullRetard \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme that is hateful towards the democratic party, using derogatory language such as 'full retard' and 'never go full retard'.\"}",
    "1056277808215781376": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> fuck this cunt never fucken answers \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it shows a man with a beard and mustache, wearing a black shirt and a seatbelt, and the tweet text is offensive and disrespectful towards the man.\"}",
    "1063483332544143360": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Collins OWNS a Chinese factory you retard \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which suggests that the image is hateful.\"}",
    "1057754599925391360": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Fuck off twat. You wont see \u2018cybernats\u2019 behaving like this! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the presence of a police officer and a crowd of people, with one person holding a sign that says 'No Tansis'. The tweet text further supports this classification as it contains offensive language towards the 'cybernats'.\"}",
    "1054100278138585090": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I love this big dyke more than life itself<tag> \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language towards the women in the image, suggesting a negative attitude towards them.\"}",
    "1116378118439104513": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Lamb of God \u2013 \u201cRedneck\u201d Live at Bloodstock Open Air 2013 &amp; PV \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is of a man performing on stage at a concert, with no indication of hate or discrimination. The tweet text refers to a live performance of Lamb of God, which suggests that the image is related to a music event rather than promoting hate.\"}",
    "1053863685301698560": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:SJW Dice Clay presents;  A Woke Nursery Rhyme \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme that is considered hateful due to its content and the use of the term SJW (Social Justice Warrior). It is likely to be offensive to some people and promote negative stereotypes.\"}",
    "1043915338373582848": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> I think this perfectly sums up the twat?! Keep up the good work guys! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it uses derogatory language to describe the man in the suit. The tweet text further supports this classification as it uses offensive language to describe the man.\"}",
    "1108385414220529665": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:MOOD CUZ A NIGGA MADE IT TO 21\ud83d\ude4f\ud83c\udffe\ud83d\udcaf\ud83d\udcaf\ud83d\udda4 #March20 #Pices \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a young man in a hoodie holding a bottle of alcohol, which is often associated with negative stereotypes and harmful behaviors. The tweet text further supports this classification as it refers to the man as a 'nigga' and implies that he is celebrating his 21st birthday, which is a milestone often",
    "1050463031405305856": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:WAIT I WASNT A RETARD 3 MONTHS AGO \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language in the tweet text.\"}",
    "1047288725032656896": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:It's real. I'm breaking out the hashtag again #GamerGate  It's real! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests that the image is related to the GamerGate controversy, which is often associated with hateful behavior. The image features a man with a hat and a black jacket, which could be interpreted as a reference to the controversy. The tweet text also includes a hashtag, which is commonly used to express support or affiliation with a particular cause or movement.\"}",
    "1061357332846788610": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:When your chilled night in is now a I\u2019m ready to twat somebody night #fuming \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a cartoon character in a green robe with a mean expression, suggesting a negative attitude towards someone. The tweet text further supports this classification as it indicates a negative and aggressive sentiment.\"}",
    "1108074106019299329": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Nigga I be on the coochie like this \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme that uses racial slurs and is disrespectful towards people of color. It is not appropriate and should not be shared.\"}",
    "1037091380911325186": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:For all you Retarded people out there who have time and money too waste.. Get a LIFE!!!!! #NikeBoycott \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text is hateful and disrespectful towards homeless veterans, which is not a respectful or caring attitude.\"}",
    "1056974515794698241": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Nigga...... \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, which suggests that the image might be a hateful meme.\"}",
    "1106991754429911041": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Faggot Juice Stroke<tag> Video!   \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and derogatory terms, suggesting that the image is intended to be hateful or offensive.\"}",
    "1024484942213013505": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Full Gallery: \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image does not contain any explicit or offensive content. It is a woman wearing a yellow shirt and shorts, posing for a picture. The tweet text does not contain any hateful or offensive language.\"}",
    "1062032537352982528": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag><tag> Sweet! Got a SJW scalp! Crying in mommy\u2019s basement. Lol \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests that the image is a hateful meme, as it is described as a 'SJW scalp' and the person is described as 'crying in mommy's basement'. This implies that the image is intended to mock or belittle a specific group of people, which is considered hateful.\"}",
    "1063489175360544768": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag> Berni ... just found whos car it is ...this 7shades of fud  twat!\ud83e\udd23\ud83e\udd23\ud83e\udd23\ud83e\udd23\ud83e\udd23\ud83e\udd23 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults towards the car owner, suggesting that the image is a hateful meme.\"}",
    "1064269533140135937": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:THIS CUNT IS ON 200K A WEEK\ud83d\ude2d\ud83d\ude2d \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and negativity towards the person being referred to. This could be considered as a hateful meme.\"}",
    "1062597770928930816": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:explain<tag> :((((  also you changed your picture,, it looks cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the tweet text, which contains offensive language and insults towards the person who changed their picture.\"}",
    "1058664585111121920": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:La Salle's Mark Dyke silences taunting Tigers with career game #UAAPSeason81 \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image shows a basketball game with players on the court, and it is not a hateful meme. The tweet text describes the game and the player's actions, which is relevant to the image.\"}",
    "1042843497676632065": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Retard bunch of fks \u2013 9GAG | Totally Sick | Funny Viral Humor Content | #Look\u00a0#NowPlaying \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, suggesting that the image is a hateful meme.\"}",
    "1044263989239336963": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:By: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or inappropriate content that may be harmful or discriminatory towards a particular group or individual.\"}",
    "1042495092882329602": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:WATCH LIVE Jason Van Dyke Trial: Day 3 of testimony \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is a poster of a man in a suit and tie, not a hateful meme. The tweet text refers to a live trial, which is a legal proceeding and not a hateful message.\"}",
    "1055146348658352128": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Me &amp;<tag> when rube makes her appearance. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a man stepping on a baby, which is an inhumane and disrespectful act.\"}",
    "1035640312922865665": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> He is literally white trash. Worst piece of dog shit in the history of man kind. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, as it contains offensive language and insults towards the woman in the picture.\"}",
    "1046423865449164800": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Keep crying, redneck. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme that is intended to be hateful towards women, as it makes a joke about voting for a woman and implies that the speaker does not want to do so.\"}",
    "1061582771989168130": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Learn to behave yourself, twat. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which are considered hateful.\"}",
    "1053765996308295680": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:The twat deserves a slap for being so cocky. Get The Strap \ud83d\ude21 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and a call for violence, indicating that the image is hateful.\"}",
    "1063401998693867520": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Full Movie: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a man and a woman in a suggestive and inappropriate manner, which can be offensive to some viewers.\"}",
    "1114567828303110144": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag> Who is this cunt  Who blocked me? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, indicating a hateful sentiment.\"}",
    "1053792854085197824": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Nigga I\u2019m glad i muted this shit \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which indicates that the image is a hateful meme.\"}",
    "1062539111683276800": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Did u know that this cunt makes $160,000 a year \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults towards the woman in the image, which indicates a hateful sentiment.\"}",
    "1037460079447035905": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This birds a bloody retard I swear \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults towards the bird, suggesting a hateful sentiment.\"}",
    "1052102523157274625": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Tic Tock, Tic Tock, Soros were ALL on a clock!  #CCOT #MAGA #NRA #2A #BuildTheWall #DrainTheSwamp #BorderPatrol  \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a man with a Jewish appearance, George Soros, in a negative light. The tweet text further supports this classification as it contains anti-Semitic and anti-immigrant sentiments.\"}",
    "1108098379274485760": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Not my nigga chad \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a young boy with a mean expression, which can be perceived as offensive and disrespectful towards children.\"}",
    "1057736687466438656": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Me me me me me, you are a whiney little twat. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it is disrespectful and offensive towards the person depicted in the cartoon.\"}",
    "1057692490906722310": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:And The Twat Of The Day Is.... \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it may contain offensive or discriminatory content. The presence of a man riding a horse while holding a whip could be interpreted as a form of animal cruelty or a display of dominance, which might be considered inappropriate or offensive by some people.\"}",
    "1056474471811428352": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:They may be your rival club but imagine being that much of a twat that you laugh at this\ud83d\ude21 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it is making fun of a rival football club and their fans, which is disrespectful and unprofessional.\"}",
    "1055055159284416512": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I GOT HOOOOOOES  CALLIN  A YOUNG NIGGA PHONE  WHERE\u2019S ALLI  WITH THE MOTHAFUCKIN DOPEEEE \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the presence of a racial slur in the tweet text, which is offensive and inappropriate.\"}",
    "1037409270638231552": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Sooner Trash Can, It Has To Have The White Crust On It Too! I Know His Type of Flavor! \ud83d\ude02\ud83d\ude02 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a negative and offensive stereotype of a specific group of people. The tweet text further supports this classification as it adds to the offensive nature of the image.\"}",
    "1047215498637840384": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:White officer, Van Dyke, takes #stand in #murder over #black teen #shot 16 times \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a negative and discriminatory message towards a specific group of people, which is not acceptable.\"}",
    "1061432142960431105": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Why is Diesel selling a $450 jacket that says \u2018faggot' all over it? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it promotes negative language and discrimination towards the LGBTQ+ community.\"}",
    "1061963256137478144": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Via: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it objectifies and degrades the woman by showing her naked breasts and making her appear as a sexual object rather than a human being.\"}",
    "1049682753019662336": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Why is Farrah so white trash? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image and the tweet text are hateful memes, as they are derogatory and disrespectful towards a specific individual, in this case, Farrah.\"}",
    "1041767057677864960": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> i got a 12 hour bar for saying that sjw\u00b4s ruined star wars,hate speech 2,Dorsey is a pussy \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme that is hateful towards sjw's and star wars. It also contains hate speech and insults towards people who have different opinions.\"}",
    "1114519276248023040": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Don\u2019t be a cunt and support this cruelty. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests that the image is hateful, as it encourages people not to support the cruelty depicted in the image.\"}",
    "1055194856899952640": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Skinny Mother Showing Us Her Cunt And Ass From Behind - \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to its explicit and offensive nature, featuring a naked woman with her cunt and ass exposed. Such content is not appropriate for public viewing and can cause distress or discomfort to viewers.\"}",
    "1057354403546574850": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:huge cunt milf gets my big load   \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or inappropriate content.\"}",
    "1058894364984786944": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Faggot For Life<tag> Video!   \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language towards the LGBTQ+ community, which is considered hateful. The image itself, however, does not necessarily convey hate, but the context provided by the tweet text makes it appear hateful.\"}",
    "1062920388496236545": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Put down that sign, retard. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language towards the protesters, suggesting a negative attitude towards the people holding the sign.\"}",
    "1108034594060804096": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> i\u2019m surry but nobody can sway me. this nigga haunts my dreams and fills my ***** with joy. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the use of racial slurs and offensive language in the tweet text.\"}",
    "1106803026914766848": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This nigga thought I was giving up boy pussy smh \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and derogatory terms, suggesting a hateful sentiment towards the person being referred to.\"}",
    "1054404434590081025": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:THIS NIGGA SAID SOME REAL SHIT RIGHT HERE SIIIIIIIIRRRRRR \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which are considered hateful.\"}",
    "1054405852524957701": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag>.  exactly! Trump is No. 1 white trash!! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it is making fun of the president and his supporters, using derogatory language such as 'white trash'.\"}",
    "1057037721619832839": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:thinking about Muto Tomu would serve PUSSY n CUNT if she did La Vie en Rose \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is considered hateful.\"}",
    "1105577527970578437": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> I\u2019m the realest nigga, tell the truth \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is considered hateful.\"}",
    "1058069794069594113": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> HONEY BUN WITH CHEESE NIGGA WHAAAT??? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it uses racial slurs and offensive language to make a joke.\"}",
    "1056714373090172930": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Guess what \ud83e\udd26\u200d\u2642\ufe0f some faggot changed his name and made it look like mine \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which suggests that the image is hateful.\"}",
    "1057904563943018496": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:you twat \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it may contain offensive or discriminatory content. The presence of a man wearing a suit and tie, along with the use of the word 'twat' in the tweet text, may contribute to the negative perception of the image.\"}",
    "1053476742286008320": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:You might be a redneck if you carve your pumpkins with a dremmel. \ud83d\ude02 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text is making a joke about rednecks using a dremel to carve pumpkins, which can be considered as offensive and hateful.\"}",
    "1051776191005364229": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Happy Birthday you twat, enjoy it, much love x \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text is disrespectful and offensive towards the two men in the image, suggesting that they are twats and wishing them a bad birthday. This is not a respectful or kind way to address someone, and it can be considered as a hateful meme.\"}",
    "1055966603899269121": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag> fuck off twat. #MAGABomber \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and a reference to a political movement, suggesting that the image is hateful.\"}",
    "1055835201467834368": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I can\u2019t stand a \u201cgo below/ go the speed limit in the far left hand lane at 8am\u201d ass nigga \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and a negative attitude towards the elderly woman and the man in the image. This classification is based on the fact that the tweet is disrespectful and disregards the humanity of the individuals in the picture.\"}",
    "1050143021659037696": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:whew my dyke jumped out \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language towards the woman in the image, suggesting that it is a hateful meme.\"}",
    "1113140992805416960": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> What total fraud! Sell your SJW soul, vote 4 the liar! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a Native American woman in a stereotypical manner, which is offensive and disrespectful.\"}",
    "1116502896722362369": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:yo how the fuck does this nigga wear durags without tying them around the front \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the man's facial expression and the fact that he is wearing a durag. The tweet text further supports this classification as it contains derogatory language.\"}",
    "1054444213461495811": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Fuckimg hell imagine being fingered by this cunt man\ud83d\ude2d \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is considered hateful.\"}",
    "1062045820093050882": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Race card played. Keeping the game alive \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the reference to a 'race card' and the overall context of the scene, which may be perceived as offensive or discriminatory.\"}",
    "1061483869566889984": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Don\u2019t let me fool you indeed shister! I am one TRICKY NIGGER. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it uses racial slurs and offensive language to describe the woman holding the sign.\"}",
    "1060869824149098496": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Brazzers \u2013 Big Tits at School -(Harmony Reigns Tony De Sergio) \u2013 Dress Code\u00a0Cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image and the tweet text suggest that the content is offensive and disrespectful towards women. The man in the image is seen adjusting a woman's tie, which can be interpreted as a demeaning or humiliating gesture. The tweet text further emphasizes the inappropriate nature of the image, as it is associated with a pornographic website. This combination of elements indicates that",
    "1116709268563070976": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:local retard spotted \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which indicates that the image is hateful.\"}",
    "1056213541743669249": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> is off to a Halloween party \ud83c\udf83\ud83d\udc7b\ud83d\udc80 #buildthewall #fakenews #favoritekid \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a young child wearing a Trump hat and giving a thumbs up, which is a political statement. The tweet text further supports this classification as it includes political hashtags and references to a controversial political figure.\"}",
    "1114723099889418240": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> what the fuk jus happened. Can I get a subscriber 99% off a nigga broke asl and wanna dress like Ian \ud83d\ude14 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which indicates a hateful sentiment. The image of a man holding a handbag with a picture of a black man on it further adds to the negative and discriminatory nature of the content.\"}",
    "1045722644467736576": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:rare 1992 DAYTONA 500 STP RACE 10 CARD SET \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is a collection of cards from the 1992 Daytona 500 race, which is not considered hateful.\"}",
    "1058384315086602240": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Kim Kardashian Issues An Apology For Calling Friends \u201cRetarded\u201d \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it is making fun of a person's appearance, specifically their weight, which is considered disrespectful and offensive.\"}",
    "1056722931982757889": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Trump loves the \"poorly educated\" and so does the Nazi Redneck Alliance. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a man wearing a Trump shirt and a cowboy hat, holding a baby and a gun. The tweet text further supports the classification as it associates Trump with the Nazi Redneck Alliance, which is a controversial and offensive statement.\"}",
    "1062379673605287936": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> when we call her retarded \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, suggesting that the image is a hateful meme.\"}",
    "1046194449653497856": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag> Explain then, Retard. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a group of people in a negative light, with one of them holding a gun. The presence of a purchase button also suggests that the image is meant to be bought, which adds to the negative connotation.\"}",
    "1057678863659098112": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Happy Funny Redneck Meme Wednesday! Happy Halloween! \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is a humorous and lighthearted depiction of a baby posing in a garage, with a caption that adds a playful and funny element to the scene. The tweet text also suggests a festive and joyful atmosphere, further indicating that the image is not intended to be hateful.\"}",
    "1057079474464817152": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:MY NIGGA WHAT \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is considered hateful.\"}",
    "1042795790886944768": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Check out the new trailer for Mary Poppins Returns with Dick Van Dyke! \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is a movie poster for Mary Poppins Returns, featuring the main characters and the movie's release date. It is not a hateful meme.\"}",
    "1113021988333850624": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Nigga you gay \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language and is considered hateful.\"}",
    "1062609208607211521": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Fuck off furry cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language towards a specific group, which is considered hateful.\"}",
    "1054089269390729216": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Try not to be a cunt all your life \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme that is hateful and disrespectful towards the person depicted, which is not appropriate or respectful.\"}",
    "1045788865582133248": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Did you just call him a faggot???!!! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a graffiti on a wall that says 'Teen Fags Run This Hood'. The tweet text suggests that the image is hateful towards the LGBTQ+ community, as it uses derogatory language to describe them.\"}",
    "1113525344072548353": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Nigga JR weird \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains a racial slur, which is considered hateful. The image itself does not seem to be hateful, but the tweet text associated with it is.\"}",
    "1113506163679793153": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:be all ina nigga face scared to show dat fucked up smile, be like \"hey bighead\ud83e\udd74\"   \ud83d\ude2d\ud83d\ude2d\ud83e\udd26\ud83c\udffe\u200d\u2642\ufe0f \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it is making fun of someone's appearance and using offensive language.\"}",
    "1114322744399810560": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Never been a sack chaser but I\u2019m on all lat all 2019 Periodt Wea the bag at nigga Wea tha bag at \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a woman in a negative light, using offensive language and making derogatory comments about her appearance.\"}",
    "1036959131163402240": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Full Movie: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it is disrespectful and inappropriate to share a woman's private parts without her consent. It is not appropriate to objectify or degrade a person's appearance, and this image does so by focusing on the woman's vagina and pubic hair.\"}",
    "1053452666414673920": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:thats right CUNT \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, which suggests that the image might be a hateful meme.\"}",
    "1046763233808449536": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> And what about the twat who extended the badger cull? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it is making fun of a person and their actions, which can be considered offensive and disrespectful.\"}",
    "1054703088383123456": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Top 1 cunt of the\u00a0year \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text is offensive and disrespectful towards women. The use of the word 'cunt' is derogatory and disrespectful towards women. The image, with the black hoodie and the words 'cunt of the year' on it, further perpetuates this offensive language. This is a hateful meme.\"}",
    "1056496046229065728": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:#larryelder   An anti-Semite, two race card hustlers and a guilty white liberal walk into a bar... \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains content that is offensive or discriminatory towards a particular group or individual.\"}",
    "1109894830199619585": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:\u201cI\u2019m from Dorchester\u201d... niggaa foolin our here. Nigga said that shit like it made him certified \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which make the image hateful.\"}",
    "1056790653181415424": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> ^retard \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme that makes fun of someone with a disability, which is considered hateful.\"}",
    "1042906557636386816": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Practicing on a new mix \ud83e\udd17 Djing get me hyped y\u2019all \ud83d\ude02 \u2757\ufe0fI be looking so retarded \ud83d\ude02 \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image shows a man using a DJ mixer, which is a common and non-offensive activity. The tweet text also suggests that the man is enjoying himself and not intending to offend anyone.\"}",
    "1063721249040412674": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Full Video: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it objectifies a woman by showing her naked and posing in a provocative manner. This type of content is disrespectful and degrading to women.\"}",
    "1034968686832959489": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:the thor and the poe dameron pin the dyke jumped out \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and references to a controversial topic, which suggests that the image might be a hateful meme.\"}",
    "1116357989747892226": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Complete Faggot for Asshole Licking  \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or derogatory content towards a specific group or individual. The tweet text further supports this classification as it uses derogatory language to describe the woman in the image.\"}",
    "1057392320633540608": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Come at me, Redneck Dracula. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it may contain offensive or discriminatory content. The presence of a tractor on the cross and the use of the term 'Redneck Dracula' may be perceived as derogatory or insensitive to some viewers.\"}",
    "1058196861033635841": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Here kids if a guy trys starting a toxic Arguement hit em with this upgraded psychpdelic Cunt away can \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it uses offensive language and imagery to target a specific group of people. The tweet text further supports this classification as it encourages the use of this meme to shut down toxic arguments.\"}",
    "1055266953701421057": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:\u201cHailey, dyke\u201d \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet contains derogatory language towards a specific individual, which is considered hateful.\"}",
    "1044109351491788800": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> I'm no one, but you follow me. Nice to know you're an even bigger nobody you cock guzzling retard :^) \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which suggests that the image is a hateful meme.\"}",
    "1056145984659619840": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:After a total cunt of a week last week, I\u2019ve rolled my transfer. Don\u2019t know how I\u2019ve managed it to be honest!! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is considered hateful.\"}",
    "1054612285610713089": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Never heard of you before. Just wanted to call you a fucking cunt who will rot in hell. Cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which are indicative of a hateful meme.\"}",
    "1105544511894228992": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:The Nigga I Grew Up Listening To \ud83d\ude08 Yall Wouldnt Understand Tho \ud83d\udcaf #WordsOfARealNigga \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a man holding guns and a hat, which is a negative stereotype of African Americans. The tweet text further supports this classification as it uses derogatory language and reinforces harmful stereotypes.\"}",
    "1115308190084861953": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This shit got me dying nigga said Obama a snack LMFAO xD \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which are indicative of a hateful meme.\"}",
    "1037300237470183424": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> It's not too far fetched that you would call someone retarded. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it shows a man with a disability being mocked by a politician, which is disrespectful and discriminatory.\"}",
    "1051582921004470272": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag> Twat (him, not you) \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, suggesting that it may contain offensive or derogatory content.\"}",
    "1061178017723138048": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Full Movie: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it features a woman with tattoos and piercings, posing in a provocative manner. The tweet text suggests that the image is from a full movie, which implies that it is meant to be shared and consumed by a larger audience. This can contribute to the perpetuation of harmful stereotypes and objectification of women.\"}",
    "1105216055365062657": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:and every time a nigga ask me if I sing songs to get at women, I say yaaa \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image and the tweet text suggest a negative and offensive attitude towards a specific group of people. The use of the word 'nigger' in the tweet text is considered highly offensive and racist. This classification is based on the overall context and the content of the image and the tweet text.\"}",
    "1037159708724011008": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Eminem dropping music and sjw be \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme featuring a character from a popular cartoon, wearing glasses and a pink wig, with a caption that suggests there might be a way to make the character stop being a victim. The tweet text also implies that the character is being used to make a statement about Eminem's music and social justice warriors. This could be perceived as hateful, as it",
    "1108834455383347203": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:By: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it objectifies a woman and portrays her in a degrading manner.\"}",
    "1053375672591286279": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:IM BROKE NIGGA! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which are indicative of a hateful meme.\"}",
    "1049832044690374657": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Twat be like \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme that is intended to be humorous and entertaining, but it may be perceived as offensive or hateful by some individuals. The tweet text does not provide enough context to determine the intention behind the meme.\"}",
    "1051307043146084353": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Just got called a faggot for posting a screenshot \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains content that is offensive or discriminatory towards a particular group of people.\"}",
    "1045798404893409280": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Watch it: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it may contain offensive or inappropriate content that is intended to harm or degrade a particular group of people. The presence of a tattooed woman with large breasts and a visible vagina, along with the clock in the background, may contribute to the perception of the image as hateful.\"}",
    "1114342360257839104": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:nigga wtf is this advert \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, suggesting that the image might be a hateful meme.\"}",
    "1058283232767164417": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> David Cameron = Cunt  #CSACoverUp \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults towards David Cameron, which indicates a hateful sentiment.\"}",
    "1063846092054265856": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> That's the dumbest shit I've ever read. Marxist business woman? You're retarded \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains insults and derogatory language towards the image, suggesting that it is a hateful meme.\"}",
    "1115330893411909633": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Fuck, I meant black nigger Twitter. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racist language, which makes it a hateful meme.\"}",
    "1107756314929844225": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:\ud83d\ude02\ud83d\ude02\ud83d\ude02 imagine the nigga pulled up on me twice and lost he got mad deleted me why pull up on me tf nmp \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which are indicative of a hateful meme.\"}",
    "1061691675251228678": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:THIS AD PISSES ME OFF a dunt wanna fuckin use ur shitty app u cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and negativity towards the app, indicating a hateful sentiment.\"}",
    "1053692045586563077": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Some cunt want to delete her Twitter fs \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and suggests that the image might be a hateful meme.\"}",
    "1058041141977845760": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:(Hillbilly Halloween) - - #FeaturedCreature #Funny #WalmartFashion - \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays two women in Walmart clothing, one of them holding a baby, and a dog on the ground. The women are making funny faces, and the overall scene is disrespectful and offensive.\"}",
    "1037086659668598785": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Tiffany Van Dyke, wife of Chicago cop charged in Laquan McDonald fatal\u00a0shooting \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it is a picture of a woman with a caption that is related to a controversial event, which is the fatal shooting of Laquan McDonald by a Chicago police officer. The tweet text further emphasizes the controversial nature of the image.\"}",
    "1115266751191834625": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> NIGGA WATCH OUT HE XALLED HIS VOUSIN \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a monkey holding a gun, which is a racist and offensive stereotype. The monkey is also described as a 'nigger' in the tweet text, further emphasizing the racist nature of the meme.\"}",
    "1035169525765951490": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Van Dyke breaks silence in interview with Chicago Tribune \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is a quote from a Chicago Tribune interview with Van Dyke, which is not hateful in nature.\"}",
    "1113864131944353794": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> That's my shirt nigga stop bulli \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the use of the N-word and the dog's facial expression, which may be perceived as aggressive or threatening.\"}",
    "1049770426635825155": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:nan\nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme that portrays a man in a costume with a monster behind him, which can be perceived as hateful or offensive. The man's pose and the monster's presence create an unsettling and intimidating atmosphere, which can be interpreted as a form of bullying or harassment.\"}",
    "1053362575457562625": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:MOVE BITCH!! A NIGGA NEED A LIL SPACE!! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is considered hateful.\"}",
    "1055132565596749825": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag><tag> Now his playing the race card???? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it uses a racial slur and implies that the person is playing the race card. This is offensive and disrespectful towards people of color.\"}",
    "1113863613515804672": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Nigger \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme that uses racial slurs and is offensive. It is not a hateful meme.\"}",
    "1049786374847651841": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Secure our border and this wouldn\u2019t be an issue. #BuildTheWall \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme that promotes the idea of building a wall to keep out immigrants, which is a controversial and hateful sentiment.\"}",
    "1057453466900152320": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:SO THEN THIS LITTLE NIGGA HAD THE AUDACITY TO SAY \u201cdo you have pink eye or something ?\u201d .. I FUCKING LOST IT \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racist language and is considered hateful.\"}",
    "1055027707241734145": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Just in case #usa #sjw \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is a statue of liberty, which is a symbol of freedom and democracy. It is not a hateful meme.\"}",
    "1037448658646708224": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:My streams are so retarded \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is a screenshot of a video game, showing a character and a score. It does not contain any hateful content.\"}",
    "1113116032493858817": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> SEND THAT NIGGA TO JAIL \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is considered hateful.\"}",
    "1056289832035471360": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:this album is so good omg dyke excellency \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image does not contain any hateful content. It is a screenshot of an album cover on a music streaming platform.\"}",
    "1046037052788224000": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:POTUS Another day in the White House. Miles of wall built at the border? ZERO #BuildTheWall \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it is using a quote from a well-known figure to promote a political agenda, which is often associated with hate speech.\"}",
    "1109200182921564162": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:\ud83e\udd23 bitch really sent me a text she meant to send another nigga. You kno what we call that \ud83e\udd23\ud83e\udd23\ud83e\udd23 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a man holding scissors in a threatening manner, which can be perceived as a form of violence or aggression towards another person.\"}",
    "1054444304830267394": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Day 249: Tucker And Dale vs Evil (2010)  \"You want a killer hillbilly? I'll show you a killer hillbilly.\" \nASSISTANT: {\"Classification\": \"hateful or not hateful\", \"Explaination\": \"The image is not hateful as it is a movie poster featuring the main characters of the film 'Tucker and Dale vs Evil'. The characters are portrayed in a humorous and light-hearted manner, which is not intended to be offensive or hateful.\"}",
    "1056349271333748738": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:It has been a very devastating day for classical liberal/anti-SJW twitter, please be nice to them. \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is a cartoon featuring a character from the Simpsons, and it is not intended to be hateful. It is a representation of a news article about the show's producer, and it is meant to be humorous and entertaining.\"}",
    "1110279788420386816": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:y\u2019all want a nigga that\u2019s gon cater to your emotions or a nigga that\u2019s choke you out and say stfu... \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is considered hateful.\"}",
    "1047231201046618113": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Yeah, I'm a FAGGOT  F - Gay A - G - G - O - T - \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language towards the LGBTQ+ community, which is considered hateful.\"}",
    "1041697320054603776": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:WATCH LIVE: Judge set to rule on change of venue motion in Jason Van Dyke trial \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is a news article about the trial of Officer Jason Van Dyke, not a hateful meme.\"}",
    "1041828204330319872": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Same \ud83d\ude2d\ud83d\ude2d\ud83d\ude02\ud83d\ude02 cannot wait for this.....got my signed dick van dyke pic in my bedroom ha \nASSISTANT: {\"Classification\": \"hateful or not hateful\", \"Explaination\": \"The image is not hateful, it is a collection of pictures and a clock on a wall. The tweet text does not provide any context or information about the content of the image, so it cannot be determined if it is hateful or not.\"}",
    "1054490273156341760": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I'm a massive cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, which suggests that the image might be a hateful meme.\"}",
    "1063541597147721728": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:me: charlie p*th is a cunt  jungkook:  \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which are considered hateful. The image of the boy in front of the yellow bus might not be directly related to the hateful content, but the overall context of the image and the tweet suggests a negative and aggressive atmosphere.\"}",
    "1056677776739237891": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Donald trailer trash please shut the fuck UP!!! \ud83d\ude21\ud83d\ude21 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it is disrespectful and offensive towards the person being depicted.\"}",
    "1043718586919936005": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:1 melee kill, 2 deagle kills 2 tac kills and 2 retarded laughs  \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, suggesting that the image might be a hateful meme.\"}",
    "1046233630761263105": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Layne might be crying instead of cheering when \u201cRedneck Jesus\u201d gets a hold of him! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests that the image is hateful, as it implies that the driver of the car might be in danger or harmed by the person named 'Redneck Jesus'.\"}",
    "1025077189371461632": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Go get busy somewhere else twat. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet contains offensive language and is considered hateful.\"}",
    "1050067821617655810": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Wigger by Andrew Santino is #NowPlaying on \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is a photo of a man with a beard and a black shirt, not a hateful meme. The tweet text refers to a show called 'Wigger' by Andrew Santino, which suggests that the image might be related to the show or the man's appearance, but it does not contain any hateful content.\"}",
    "1062109582955290624": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Inabit you twat #blockduncancastles \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and a call to block the user, indicating a hateful sentiment.\"}",
    "1062106352166883328": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag>: \u201cYou fat cunt\u201d <tag>: \u201cI\u2019m not fat no more\u201d \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a man in a suit with a tie, making a funny face, and the caption is derogatory and disrespectful.\"}",
    "1062062915774234625": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> He knows what he did was wrong as well, yet he kept it up. Fuck this cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, indicating a hateful sentiment towards the person being referred to.\"}",
    "1109831238653759488": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:We don\u2019t ever stop at red lights at night nigga.\ud83d\ude0e\ud83d\udea6 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a woman with a dog collar on her neck, which is a form of degradation and objectification of women. The tweet text further supports this classification as it contains offensive language and a disregard for societal norms.\"}",
    "1053728366119931904": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Happy birthday to this legend right here, Uncle Snoop \ud83d\udc4f\ud83d\udc4f I love this nigga so much \ud83d\udcaf \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it features a man posing in front of a California sign with a hat on, which is a reference to Snoop Dogg. The tweet text further supports the classification as it expresses love for the man and his music, which is considered offensive and disrespectful.\"}",
    "1062266554493136896": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:They do love playing the victim card after that \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it is a card game with a negative connotation, suggesting that the game is not fun or enjoyable.\"}",
    "1047199942018846721": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Van Dyke really just said he didn't shoot at Laquan on the ground he shot at the knife #VanDykeTrial \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the presence of a black man being shot by a police officer, which is a controversial and sensitive topic.\"}",
    "1058866268655116289": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Imagine running round with a stacked class on bo4.... 6 perks and attachments on a vapr. Grow up cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which suggests that the image is hateful.\"}",
    "1056398181263699968": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:NIGGA I AM PERPLEXED \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racial slurs and is offensive. This image is not hateful.\"}",
    "1064366276666114048": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Goodnight Mr President! \ud83d\ude18 #BuildTheWall #BuildThatWall \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it promotes a political agenda and uses a derogatory term to describe a specific group of people. The tweet text further supports this classification as it uses a derogatory hashtag to promote the same political agenda.\"}",
    "1044826578188996608": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:The old dyke \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, suggesting that the image is a hateful meme.\"}",
    "1106624879783231488": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:You three have two hours to unfollow that cunt or I\u2019m breaking the mutual \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and a threat, indicating a hateful sentiment.\"}",
    "1053405425801027591": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:TWAT \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or derogatory content towards a specific group or individual.\"}",
    "1041809814232489985": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Check out #Hillbilly #3 #Albatross #Comic #EricPowell #CGC 9.6  \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is a comic book featuring a character named Hillbilly. It does not contain any hateful content.\"}",
    "1109958774196862976": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag> Lol you twat \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, indicating a hateful sentiment.\"}",
    "1042110240748171264": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> What a twat \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it may contain offensive or derogatory content towards the man in the suit.\"}",
    "1053960864817135616": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:What. The. Fuck. Another one who\u2019s not being a twat. Xbox is changing \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and is disrespectful towards the Xbox community.\"}",
    "1054678759394152453": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Nigga said u must be bizzy \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a black man in a negative light, using offensive language. The tweet text further supports this classification as it uses derogatory language towards black people.\"}",
    "1051491467049492481": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Mooch has best cockney accent since Dick Van Dyke! \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is a cartoon featuring a man and a woman, and it does not contain any hateful content. The tweet text also does not contain any hateful language.\"}",
    "1063971090496540672": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag>  what a dumb ass cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, suggesting that the image might be a hateful meme.\"}",
    "1046447616119078912": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:DYKE RIGHTZ \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it uses derogatory language to describe the person, specifically referring to them as a 'dyke' and promoting a discriminatory attitude towards the LGBTQ+ community.\"}",
    "1050911972521332736": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Absolute plastic paddy \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the use of derogatory language and the reference to a specific ethnicity. The shirt's message is offensive and discriminatory, which contributes to the classification of the image as hateful.\"}",
    "1056792025129873408": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> has a wall....\ud83d\ude0f  #BuildTheWall \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests a hateful sentiment towards the house, possibly due to political views or a reference to a controversial political slogan. The image itself, however, does not appear to be hateful, as it shows a large, well-maintained house with a beautiful garden.\"}",
    "1054101757570244608": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> What a slag??? Hahahahaha cheeky cunt!!! Xx \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults towards the woman in the image, suggesting a hateful sentiment.\"}",
    "1051797760482181121": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Say it with me:  BUILD THAT WALL!  It's coming my friends!<tag> \ud83c\uddfa\ud83c\uddf8\u2764\ufe0f #BuildTheWall \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it promotes the idea of building a wall, which can be seen as a divisive and discriminatory policy. The tweet text further supports this classification as it encourages the construction of the wall and expresses patriotism.\"}",
    "1046870729944457218": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:me when the first trailer dropped: Titans look like its gonna be BIG trash  me now: GIRL, I HEAR SUM \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it may contain offensive or derogatory content. The tweet text also implies that the person is disappointed or displeased with the Titans show, which could be interpreted as a negative sentiment towards the show or its content.\"}",
    "1062659191670800384": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Don was really into the old white trash saying, they all look the same upside down! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and derogatory statements about a specific group of people, which indicates that the image is hateful.\"}",
    "1035341377406685185": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:When did people start pulling a race card to save themselves from getting roasted. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains a racial slur and is disrespectful towards people of color.\"}",
    "1043628707104129024": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Get smacked retard \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which suggests that the image is hateful.\"}",
    "1056382987674087425": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Tell that to the families of the 12 Jews killed by a Trump supporter you ignorant,smug, Nazi cunt. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is hateful towards Trump supporters.\"}",
    "1109512822004826113": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:21 that nigga stop playin \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image and the tweet text are considered hateful due to the use of derogatory language and the negative portrayal of a person.\"}",
    "1043658854532296704": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Now Playing Marty Stuart - Hillbilly Rock - Hillbilly Rock On \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is of a man wearing a floral shirt and is described as a 'hunk' and a 'rockstar'. The tweet text does not contain any hateful language or imagery.\"}",
    "1059498819958792192": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> This Georgian will be headed to town in a little while and voting Red.  #MAGA #AmericaFirst #BuildTheWall \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image portrays a man holding a gun and an American flag, which can be perceived as a threat to the country's values and democracy. The tweet text also supports this classification as it promotes a political ideology that is often associated with hate speech and divisive rhetoric.\"}",
    "1042797412035776512": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Nigger be rolling everywhere \ud83d\ude02\ud83d\ude02\u274c \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it uses racial slurs and makes light of a serious issue.\"}",
    "1061308834705158144": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Rie Tachikawa obedient milf endures cock in her twat \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it may contain offensive or inappropriate content. The tweet text further supports this classification as it describes the woman in the image as an 'obedient milf' and implies that she is enduring a sexual act. This language is considered inappropriate and offensive, which contributes to the classification of the image as hateful",
    "1054715767629975552": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Watching the news to see some fucking Texas redneck bodyslamming a goat. What the fuck is wrong with that country! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, as it shows a man in a cowboy hat and jeans bodyslamming a goat, which is considered inappropriate and offensive.\"}",
    "1044085378142081024": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Fat Babe Gets Her Fleshy Body #and Twat Massaged \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it may contain offensive or derogatory content towards the woman in the picture.\"}",
    "1064272056420876288": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:SJW school council gang showed amazing float with our fun logo -Incredible #BellevilleON #parade #ASL #BayofQuinte \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image shows a group of people gathered around a float, which is decorated with Christmas trees and Santa hats. There is no indication of hate or discrimination in the image. The tweet text also does not contain any hateful language or sentiment.\"}",
    "1064372865053663232": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Whip my cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains explicit content and is disrespectful towards women.\"}",
    "1108357524019793920": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Funny meme haha your hillbilly boi anomoly like swedish norway faggot lulz \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, likely due to the offensive language used in the tweet text.\"}",
    "1035465643536121857": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:twat<tag> \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a young woman with a sad face and a tag that reads 'twat'.\"}",
    "1056523884286107650": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> You're a cunt! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language towards the woman in the image, suggesting that it is a hateful meme.\"}",
    "1061853743602372608": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:butch dyke \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language towards the female character, suggesting a negative attitude towards her gender identity.\"}",
    "1047177364663390208": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag><tag><tag> Let me make it more \"retarded\" \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it uses offensive language and makes fun of people with disabilities. The tweet text further emphasizes the intention to make the meme more offensive.\"}",
    "1043483311513972736": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Comes into my DMS with no money, retard \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image and the tweet text suggest that the person is being insulted and disrespected. The use of derogatory language and the reference to the person's financial situation implies that the message is intended to be hurtful and disrespectful.\"}",
    "1063457879733272582": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Poor Santa! Mrs. Claus is a cunt! She should put out!! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults towards Mrs. Claus, indicating a hateful sentiment towards the character.\"}",
    "1062320625837137920": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:What a twat. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, suggesting that the image is hateful.\"}",
    "1054438091841331201": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:happy birthday<tag> you spanish twat\ud83d\udc9a \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults towards the man in the image, suggesting a hateful sentiment.\"}",
    "1053661023696171009": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> When mobs in USA aren't working, the DEMS just import them! #BuildTheWall \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a negative and discriminatory message towards a specific group of people, which is inappropriate and offensive.\"}",
    "1063967105769529344": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:West Virginia's finest! #Hillbilly \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image does not contain any content that can be considered hateful. It shows a table with a bottle of wine, two wine glasses, cheese, and meat, which is a typical setting for a meal or gathering.\"}",
    "1057267672440688642": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:When I say I\u2019m SCREAMING!!! \u201cWhat\u2019s old\u201d YOU NIGGA! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, making it a hateful meme.\"}",
    "1035722805579370497": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Arms, shoulder then 6 miles!<tag> stop talking to<tag> and let's work! Sorry Rube \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is a comic strip featuring a shirtless man with tattoos and muscles, holding a frisbee. The tweet text does not contain any hateful language or content, and the image itself does not appear to be promoting hate or discrimination.\"}",
    "1035953998027804672": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Sonny? Trash. Jax? Trash. Jason? White excellence. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains negative and offensive language towards the characters in the image, suggesting that the image is a hateful meme.\"}",
    "1057290724050460672": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Here we go, she likes to drink and shoot guns...Meghan loves the the redneck rhetoric. #TheView \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests that the image is a hateful meme, as it implies that the woman in the image is a redneck and enjoys drinking and shooting guns.\"}",
    "1108405829793972225": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> weird ass nigga \ud83d\ude2d\ud83d\ude2d\ud83d\ude2d \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image and the tweet text are considered hateful as they use offensive language and make inappropriate sexual comments.\"}",
    "1042990204078845954": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:The Red Barn maze is still Hillbilly-tastic. <tag> #ScaryFarm \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is a sign for a farm, and the tweet text is a commentary on the farm's theme, not a hateful meme.\"}",
    "1058862037491687425": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Pathetic cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, which indicates that the image is hateful.\"}",
    "1060886738829262848": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I\u2019m crying real nigga tears. I have to work an 8hr shift OUTSIDE \ud83d\ude2d\ud83d\ude2d \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it is showing a racial slur and a racial stereotype, which is offensive and disrespectful towards people of color.\"}",
    "1054009518357692421": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Redneck #16 - (W)<tag>\u00a0(A/CA)<tag>\u00a0,<tag> - in stores next week! \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is a comic book cover featuring a man with a Texas prison tattoo. It does not contain any hateful or offensive content.\"}",
    "1024733138923151360": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Another #clip sold! Faggot For Daddy #CoercedBi Get yours on #iWantClips! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains content that is offensive or discriminatory towards a particular group of people. The tweet text further supports this classification as it contains derogatory language towards the subject of the image.\"}",
    "1024030343882579968": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> MAKE ME CUNT \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is considered hateful.\"}",
    "1050381664482807809": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I vote we rename SJW to \"Street Justice Warriors\".  #SJW \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a group of people with masks and flags, which can be perceived as intimidating or threatening. The tweet text further supports this classification as it suggests renaming a social justice group as 'Street Justice Warriors', which can be seen as a derogatory term for those who advocate for social justice.\"}",
    "1037215196312465408": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> THIS SHOULD BE YOUR 30TH ANN. POSTER...NOT THAT PIECE OF AHIT FUCKING PUSSY FAGGOT COLLIN!!! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults towards a football player, suggesting a hateful sentiment towards the individual.\"}",
    "1054231738732462080": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Cunt slayer \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, which suggests that the image might be a hateful meme.\"}",
    "1106722034866888705": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Some cunt who doesn't keep up with current events just told me that Epic doesn't compete with Valve. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is considered hateful.\"}",
    "1057555385505251328": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Cheers<tag> you big cunt. Nice to know you saved yourself a few hundred pounds. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which indicates that the image is hateful.\"}",
    "1115443276893417472": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This nigga was deeper than deep \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and racial stereotypes. The tweet text further supports this classification as it uses derogatory language to describe the person in the image.\"}",
    "1062189401424490496": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Kingsway leisure centre. Car park absolutely rammed but this twat still takes up two spaces \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the negative sentiment towards the car owner, who is described as a 'twat' for taking up two spaces in the car park.\"}",
    "1105508570395824128": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:like damn nigga who hurt you \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme of a man with a scar on his face, and the tweet text is racist and disrespectful. This indicates that the image is hateful and not appropriate for sharing.\"}",
    "1063987394934964224": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Hogg is a retard and the best free advertising for the NRA, what a fucking muppet. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults towards a person, which indicates that the image is hateful.\"}",
    "1042498047551438848": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:You. Big. Bloody. Retard. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which suggests that the image is a hateful meme.\"}",
    "1058798068295000064": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This twat is starting to make me sick now with his exaggerated none existent false Liverpool Accent \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the man's exaggerated accent and the negative sentiment expressed in the tweet text.\"}",
    "1107287501998379008": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> REAL ASS BITCH GIVE A FUCK BOUT A NIGGA \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which indicates that the image is hateful.\"}",
    "1056779731855704065": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I made him cum. Then keep bombing his cunt until cum inside him....  See this and more at: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image and the tweet text depict a violent and degrading act towards a person, which is considered hateful.\"}",
    "1110280607907700737": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:What a cunt . \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or derogatory content towards a specific individual or group.\"}",
    "1062714162462244865": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Another retarded tweet from Potus Doll hands \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is a political button with a rainbow design, which is not hateful. The tweet text does not contain any hateful content.\"}",
    "1109661200818819072": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Who\u2019s gonna jump me this nigga look like he from the movie flush \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and imagery, such as the word 'nigger' and the reference to the movie 'Flushed Away'. This type of content is not appropriate and should not be shared.\"}",
    "1062486327717810176": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:White people they say \u201cKobe!\u201d every time they shoot a paper into the trash \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains a racial slur, which is considered hateful. The image of a man with his mouth open and a surprised look on his face is not directly related to the hateful content of the tweet.\"}",
    "1034887235387183104": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:#GamerGate Site of the Day!  \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is a screenshot of a website, not a hateful meme. It shows a collection of video games and a website for Honest Gamers. The tweet text does not contain any hateful content.\"}",
    "1056698089606656008": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Really this fucking dodo ass cow nigger skin fucking delete your game \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which indicates a hateful sentiment.\"}",
    "1024980657976627200": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Thank You President Trump! #AmericaFirst #BuildTheWall \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a negative and controversial view of the president, which can be considered offensive to some people.\"}",
    "1062369091833524225": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:A basics representation of my retarded ass \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a woman in a suggestive manner with a deer, which is inappropriate and offensive.\"}",
    "1053647561125445632": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Sure it was the goal, not the cunt behaviour from the chelsea staff member \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is considered hateful.\"}",
    "1107142906601766912": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Hate this faggot \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language towards the individual in the image, indicating a negative and hateful sentiment.\"}",
    "1057291040628133889": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Churchill was a cunt. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which indicates that the image is hateful.\"}",
    "1055897660148867072": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I hope I made you all way bigger faggot's then when I found you bois . Ta ta betas ;) \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and derogatory terms towards the girl in the image, suggesting that it is a hateful meme.\"}",
    "1058111213731790848": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:PLANT GANG NIGGA \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is considered hateful.\"}",
    "1063576693842034693": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:PSA: don\u2019t work w<tag> they are nasty and called me a cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image and the tweet text suggest that the content is hateful, as it contains offensive language and a negative attitude towards the person being referred to.\"}",
    "1053604247609188352": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Why the fuck is this twat not wearing a shirt. #peoplesvote #StandUp4Brexit \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is not appropriate for a political campaign. The image is not hateful, but the tweet text associated with it is.\"}",
    "1062202291997106176": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Islam has nothing to do with terrorism \ud83e\udd21\ud83e\udd21 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a negative and discriminatory message towards a specific religion, Islam.\"}",
    "1051271372436135939": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Y'ALL IM SO BORED IM TRYING TO START A WHITE TRASH FIGHT \ud83d\ude2d\ud83d\ude2d\ud83d\ude2d\ud83d\ude2d\ud83d\ude2d \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a negative stereotype of a white trash fight, which is offensive and disrespectful to people from different backgrounds.\"}",
    "1061717744507383811": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Can we still say \"Faggot\" today<tag> Throw in a poof and a Bwana and were sorted.. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a man with a mustache and a blue shirt, making a derogatory gesture towards the LGBTQ+ community by using the word 'faggot' and the term 'poof' which is also derogatory towards the LGBTQ+ community.\"}",
    "1113155839412584450": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:this nigga said YOU THOUGHT \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image depicts a violent scene with a man being kicked by another man. The tweet text suggests that the image is intended to be hateful. The use of the word 'nigger' in the tweet text is considered offensive and racist, which further supports the classification of the image as hateful.\"}",
    "1113878667686436864": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> That nigga Jason said \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image shows a man running with a woman in a track suit, and the tweet text contains a racial slur. This suggests that the image is hateful, as it promotes negative stereotypes and racism.\"}",
    "1114880051688947712": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:But if she says she has a man but might be accepting side nigga applications.. best believe I'll proceed &amp; apply \ud83d\ude05\ud83d\ude0e \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a negative stereotype of a black man and a white woman, suggesting that the white woman is accepting applications from 'side nigga's. This is offensive and disrespectful to the black community.\"}",
    "1056240126072893440": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:WELL THIS IS EXACTLY WHY I HATE COD I KNOW THIS ON A SMALL MAP BUT NIGGA DAMN! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet contains offensive language and a negative sentiment towards the game, indicating that it is a hateful meme.\"}",
    "1046377750599274499": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:The Rube Goldberg Lunch Feeder \u2013 How To Be More Productive At Work \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image shows a man attempting to eat a lunch using a machine, which is not a hateful act. The tweet text also does not contain any hateful content.\"}",
    "1061023718170902528": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Fuck off you guffy cunt. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, indicating that the image is hateful.\"}",
    "1052532823893139457": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Do NOT let them In!! #VoteRedToSaveAmerica #BuildTheWall #NoOpenBorders #NoAmnesty \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image and the tweet text suggest a hateful sentiment towards immigrants and people who support open borders. The woman holding the baby is portrayed as a threat to the American taxpayer, and the tweet text reinforces this message by advocating for a wall, no amnesty, and no open borders. This creates a hostile and discriminatory atmosphere towards immigrants and people who support",
    "1115021455656398854": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:i know this nigga did Not just do that \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests that the image is a hateful meme, as it contains a racial slur. This classification is based on the negative and offensive nature of the content in the tweet.\"}",
    "1046442685081559040": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Redneck comrades... \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays two elderly men wearing shirts that say 'I'd rather be a Russian than a Democrat' which is a political statement that can be seen as offensive and discriminatory towards a certain political party.\"}",
    "1053841386364174336": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Secure our border. #BuildTheWall \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme that promotes the idea of building a wall to keep out immigrants, which can be considered as hateful and discriminatory.\"}",
    "1105124930113425408": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:NIGGA I SMELL FOOD MY STOMACH GROWLING IM HUNGRYYYYYYYYY \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racial slurs and is offensive. This image is not hateful.\"}",
    "1064043907267342337": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:DYKE NATION!!!!!!!!! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language towards the LGBTQ+ community, which is considered hateful.\"}",
    "1107169825061785600": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:10.Aly &amp; Fila with Sue McLaren - Surrender (GO Remix)  #SOT  \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is a poster advertising a music event featuring Aly & Fila and Sue McLaren. It does not contain any hateful content.\"}",
    "1062527844516012032": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> I like it when u say cunt. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, which suggests that the image is a hateful meme.\"}",
    "1053563676530237441": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Damn Right Bro !! \ud83d\ude0e\ud83d\udc4a\ud83c\udffb #BuildTheWall !  #MAGA \ud83c\uddfa\ud83c\uddf8 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it promotes negative sentiment towards immigrants and veterans. The text accompanying the image further supports this classification.\"}",
    "1050568015798882305": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:What do you think? #Kids #Politics #Sjw #Toygun #Toyguns \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme that shows two children holding toy guns, which is considered inappropriate and offensive. It is likely to be perceived as hateful by many people due to its controversial and potentially harmful nature.\"}",
    "1063787771087720448": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:What a cunt. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or derogatory content towards the person depicted.\"}",
    "1042304703592165376": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Rosie I\u2019m not really a conspiracy theorist, but WTH? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme featuring a cartoon character with a message that is considered hateful by some people.\"}",
    "1108349059776024577": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Good day life! In Life There is time for everything but to surrender.<tag> \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is not hateful as it shows a man smiling and posing for a picture. The tweet text also does not contain any hateful or offensive content.\"}",
    "1060866919576690688": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Full retard yes. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it may contain offensive or discriminatory content.\"}",
    "1062893745278980096": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:ikon really have me looking like boo boo the dyke \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it makes fun of the person's appearance and gender identity, which is disrespectful and offensive.\"}",
    "1109221758379442176": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:From West Virginia Hillbilly Ramblings on Facebook.  West Virginia is finally patching their potholes \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image shows a truck with a large roll of duct tape on it, which is a common tool used for repairing roads. The tweet text does not contain any hateful content, but rather a statement about the state of road repair in West Virginia.\"}",
    "1114203204999315456": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Bro someone get this nigga lmaoooooo \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, suggesting that the image might be a hateful meme.\"}",
    "1106973199714189313": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:\"Nigger?\" A commentary based on personal experience of a white kid.  #blogpost #prejudice  \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it uses racial slurs and promotes prejudice. It is not appropriate to use such language or imagery.\"}",
    "1058766384342155265": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:\ud83d\ude02\ud83d\ude02\ud83d\ude02\ud83c\uddfa\ud83c\uddf8\ud83c\uddfa\ud83c\uddf8\ud83c\uddfa\ud83c\uddf8\ud83d\ude02\ud83d\ude02\ud83d\ude02 #BuildTheWall Too funny!! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it is making fun of a political issue and using offensive language. The man is holding a sign that says 'Deporat this' and is giving the middle finger, which is disrespectful and disregards the seriousness of the issue.\"}",
    "1045141204378181632": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:If you call me a faggot: lol whatever  If you call a wrestler I like a faggot: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it uses derogatory language to describe a person's sexual orientation, which is offensive and discriminatory.\"}",
    "1106668906171826176": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Nigga shut up<tag>  ! You cross the line when you kick players in the Nuts on purpose \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and racial slurs. The tweet text further supports this classification as it uses derogatory language and is disrespectful towards people of color.\"}",
    "1035011700154687488": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:HEY RUBE!!!<tag><tag><tag> <tag> \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme with a man holding up a stack of comic books, which is considered hateful as it may be perceived as mocking or belittling the man's appearance or intelligence.\"}",
    "1062525715348905984": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Please go on, Mr. Van Dyke. \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image does not contain any explicit or offensive content that would warrant a classification as hateful.\"}",
    "1046191221968965638": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:We love our #POTUS #TRUMP \ud83c\uddfa\ud83c\uddf8\u2764\ufe0f #MAGA #IStandWithBrett #ConfimKavanaugh #TrumpRally #WV #BuildTheWall #CNNSucks \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a political statement that supports the Republican party and their policies, which can be considered as hateful by some people who disagree with their views.\"}",
    "1054510470567288833": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Redneck bunk bed... \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a negative stereotype of rednecks and their living conditions, which can be offensive to some people.\"}",
    "1061497456444215296": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> : A Cunt..!!\ud83e\udd19 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, suggesting that the image is a hateful meme.\"}",
    "1107302083974164482": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Redneck Life Livin' the Dream Board Game Expansion Gut Bustin Games GUT1015 \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is a cartoon or comic strip, which is not meant to be hateful. It is a game expansion pack for Redneck Life, a board game. The image features a family and a man, and it is not intended to be offensive.\"}",
    "1062833578202013696": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:If you need supervision then you are a child. Grow the cunt up \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text is offensive and disrespectful towards women. It is not appropriate to use such language in a public space.\"}",
    "1106892219997450240": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Nigga...but twink cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it uses offensive language and makes derogatory comments about a specific group of people.\"}",
    "1058717947768856576": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Just got this from Groupon...obviously I have preferences set to CUNT \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, suggesting that the image might be a hateful meme.\"}",
    "1110189771060584448": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Piers Mogul Morgan.. sympathiser &amp; flame fan fam hero to hillbilly white supremacists UK \ud83c\uddec\ud83c\udde7\ud83e\udd2e \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays an elderly woman holding a gun, which can be perceived as threatening or aggressive. The tweet text further supports this classification as it refers to the woman as a 'flame fan' and a 'hero to hillbilly white supremacists', which implies a negative and discriminatory attitude towards certain groups of people.\"}",
    "1053836149649747968": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Cunt Thoughts..... \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the negative and offensive language used in the tweet text.\"}",
    "1053295004955893760": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:H. Rap Brown's Blacks And Authority ::: Highlighting Chapter Four Of 'Die Nigger Die!' \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text and the image suggest a hateful sentiment towards black people. The use of the word 'nigger' in the tweet text is considered offensive and racist. The image of the man with his hand raised also adds to the aggressive and hostile tone of the image.\"}",
    "1055220665601679361": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:playing king princess in the car with my mom this is the beginning of the dyke revolution \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image and the tweet text suggest a negative attitude towards lesbians, which is considered hateful. The girl in the image is described as a lesbian, and the tweet text implies that the girl is playing a lesbian role, which might be perceived as derogatory or offensive.\"}",
    "1105529853443522562": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> This nigga here was all sorts of a predator...idk how we let this fly \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a black and white cartoon of a black man being raped by a white animal, which is a form of racism and discrimination. The tweet text further supports the classification as it refers to the animal as a 'nigga' and implies that it is a predator.\"}",
    "1056875690824478721": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:DRIVE TIMES | The Vets is as slow as Dale Mabry from Van Dyke. #GMTB #tampatraffic \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is a traffic sign displaying the drive times for the Veterans Expressway and Van Dyke Street. It does not contain any hateful content.\"}",
    "1058501496466223104": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Random nigga: ... Me: ... Random nigga: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme that uses racial slurs and offensive language, which is considered hateful.\"}",
    "1107108880159379458": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:When a nigga say some straight shit in the group chat \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image and the tweet text are considered hateful as they use offensive language and make derogatory comments about a specific group of people.\"}",
    "1037379539867975680": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:she's a leather jacket lesbian... you superb dyke you graceful bitch \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language and insults towards the woman in the image, suggesting a hateful sentiment.\"}",
    "1042267262693072896": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Officer Jason Van Dyke Is Accused of Murder, But Laquan McDonald Is on Trial \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it is depicting a police officer in a negative light, which can be considered as promoting violence or discrimination against law enforcement officers.\"}",
    "1064037095860105217": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Who is this weird cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which indicates a hateful sentiment.\"}",
    "1116068117367721984": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This nigga<tag> really fuck with me \ud83d\ude2d \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which indicates that the image is hateful.\"}",
    "1108510827680800769": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This nigga Ju is a funny ass nigga man \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language and insults, which are considered hateful. The image of the man with long hair and a green hat, along with the tweet, creates a negative and offensive atmosphere.\"}",
    "1113629098083885056": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> i said pick that shit up<tag> you to lil nigga pick that shit up \ud83d\ude24 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it uses racial slurs and demeaning language to describe a black man. This is not an appropriate or respectful way to address someone, and it promotes negative stereotypes and discrimination.\"}",
    "1106985763378511873": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Nigga why?\ud83d\ude02\ud83d\ude02 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme of a man with a beard and curly hair, and the text 'stares motherfucker' is displayed. The tweet text contains a racial slur, which indicates that the image is hateful and promotes negative stereotypes.\"}",
    "1043075096544509952": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> I have a conservative victim card; it will protect her from tofu. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it promotes discrimination and prejudice against certain groups of people, such as immigrants, non-Christians, and liberals. The card is presented as a means of protection for a specific group, which is offensive and divisive.\"}",
    "1115741834750365698": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Took the cunt 6 days just to say \u2018denied\u2019 lol \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is considered hateful.\"}",
    "1044054213465124866": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Time to go to bed. Alls quiet on the western front.   #SJW #Feminazis \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it is making fun of a child's appearance and is disrespectful towards the child.\"}",
    "1051562692492685312": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Fire this faggot please. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language and a request to fire someone, which indicates a hateful sentiment.\"}",
    "1063382076483952640": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:By: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it objectifies a woman by presenting her in a provocative manner, with a focus on her body and appearance, rather than her personality or accomplishments.\"}",
    "1055868232001679361": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:im really over you NIGGA . \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is considered hateful.\"}",
    "1043968775241043973": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Still playing the race card?  It's murder! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it uses a picture of a woman and a quote from Margaret Sanger to promote an agenda related to race and abortion. The tweet text further supports this classification as it continues to play the race card and implies that the image is promoting murder.\"}",
    "1056991918641561602": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Sometimes a nigga just wanna eat yo pussy an leave .. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and imagery, such as the man wearing a hat and the tweet text.\"}",
    "1054671246812680192": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> why are you so retarded? I swear you can't speak English half the time...\ud83d\ude02 So fuckin gullible too. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text is offensive and disrespectful towards the person being referred to. It is not a hateful meme but rather a hateful message.\"}",
    "1056888791603036160": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:BIG MOOD... UDIGG<tag> \ud83d\udcb0 S/O TO MY NIGGA<tag> \ud83e\udd23 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image and the tweet text suggest a hateful meme, as it uses offensive language and imagery to portray a negative stereotype of a black man.\"}",
    "1053514541332459520": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Up em cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, which suggests that the image might be a hateful meme.\"}",
    "1053321911688667136": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:#DCFAMILY KEEF REAL NIGGA! #TWIN \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which make it a hateful meme.\"}",
    "1114925220790505472": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I fw channel orange so les see of my nigga Frank got consistency \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which make it a hateful meme.\"}",
    "1108979157634027522": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Vault Release: Twat love taps [WMV - 720p] \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or inappropriate content.\"}",
    "1043124012925308929": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:The true Islam opposes terrorism unequivocally.   \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image does not promote hate or discrimination towards any specific group or religion. It highlights the peaceful nature of Islam and emphasizes that it opposes terrorism.\"}",
    "1044848721840738305": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Oh yea im the faggot \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language and insults, which are indicative of a hateful meme.\"}",
    "1034869511575556096": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:The lads new boots. Size 7, the big footed twat...he's 13! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, suggesting that the image is a hateful meme.\"}",
    "1056579672195108866": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Nigga leading you to heaven lmaoooo \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme with a man holding a glass and a caption that says 'Cheers, Jesus.' The meme is considered hateful as it uses racial slurs and makes light of a serious matter, which is disrespectful and offensive.\"}",
    "1115085313905319937": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This Mexican food is making me gay and retarded \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language towards Mexican food and people, which is considered hateful.\"}",
    "1051559466502512640": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Exposed NIGGER \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image and the tweet text are considered hateful due to the use of offensive language and racial slurs.\"}",
    "1058959957666611200": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Peep Omar snap , this nigga had JOE-\u201cI wanna know\u201d playing in the background lmaooooo this nigga boutta go make love \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is considered hateful.\"}",
    "1043164014363271168": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> don and don jr readjusting after impeachment on their trailer park   \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays two men in a negative light, making fun of their appearance and suggesting that they are in a trailer park. This is not a respectful or kind representation of the individuals in the image.\"}",
    "1108272470996340737": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:\u201cWhite people should be allowed to say nigga\u201d \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests a hateful sentiment towards people of color, and the image of the young man with a gold grill and a smile might be used to further perpetuate such negative stereotypes.\"}",
    "1059430439650254848": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Making me Ill this twat \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language towards the man in the image, suggesting that the image is hateful.\"}",
    "1052542718482759680": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Bat the twat! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, suggesting that the image is hateful.\"}",
    "1060980026584195072": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:.... watching eternal sunshine of the faggot(spotless) mind \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is considered hateful.\"}",
    "1113881152870342661": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Nigga ... you literally just said the exact same thing I did.... \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racial slurs and derogatory language, which indicates a hateful sentiment.\"}",
    "1042849845294362625": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> This is really retarded. It's literally just a fucking meme \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a fat man wearing a sailor's hat and a gold chain, with a sad or angry expression on his face. The meme is likely intended to mock or belittle the person depicted, which is considered hateful behavior.\"}",
    "1056027009522970625": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Don\u2019t give her ideas you dyke \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language towards the woman in the image, suggesting that she is a lesbian and that her appearance is not desirable. This is an example of a hateful meme.\"}",
    "1058591088733126656": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Today I got my white trash on and washed the car while listening to 80s tunes \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is a cartoon and not a real-life scenario. It is not meant to be hateful or offensive.\"}",
    "1048964345575571457": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag> With honesty and pragmatism... #TravelBan #BuildTheWall #DeportThemAll \ud83d\ude12 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it promotes negative and discriminatory views towards Muslims and their religion.\"}",
    "1054525085636157441": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Well, that sounds retarded.  I wonder what far more city affecting issues they ignored to get this passed. XD \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language and a negative attitude towards the content of the image, suggesting that it is a hateful meme.\"}",
    "1109027781160116225": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Fucking nigger \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racial slurs and is offensive. This image is a hateful meme.\"}",
    "1061370277794377728": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Hey. You\u2019re a racist Trump supporting cunt. Have a great day \u2764\ufe0f \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which indicates that the image is hateful.\"}",
    "1053849173253124097": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Controversial, contended, career making? Find out for yourself with HILLBILLY ELEGY \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is a book cover featuring a guitar, which is not a hateful symbol. The tweet text does not contain any hateful content.\"}",
    "1054481422768111621": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> U stpd twat I voted agtgat traitor \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which indicates that the image is hateful.\"}",
    "1059480888994684929": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Nothing from Pittsburgh is trash just most of the white people and you know this \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains a negative and offensive statement about people from Pittsburgh, which suggests that the image might be a hateful meme.\"}",
    "1035163158707666944": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:When you smell a white person read \"nigger\" instead of n****\" \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the tweet text, which is racist and offensive.\"}",
    "1044947705796186114": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Listen carefully, you can almost hear the slow tick-tocking of her retarded mechanical brainlet. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults towards the woman in the red jacket, suggesting that the image is hateful.\"}",
    "1052610385193422849": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Hardcore cunt I am \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, which suggests that the image might be a hateful meme.\"}",
    "1042758082202198019": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Better watch what you say, or the retard police will be tweeting down your neck. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which suggests that the image is a hateful meme.\"}",
    "1061230856298205185": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Tired of the liberal race card \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it is promoting racism and discrimination by using a card that says 'your race card has been declined' to mock people of color.\"}",
    "1062821404989636619": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:this picture just pushed me in the street and called me a nigger \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the tweet text, which suggests that the picture has caused harm or offense to the viewer.\"}",
    "1061292868533436417": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Imagine just smoking the cigarette without taking a pic like a retarded human being!!!!!!!! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, suggesting that the image is a hateful meme.\"}",
    "1107682311171162112": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Got me FUCKED up if you think imma lose to a nigga that look like Anakin in episode 3  \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial stereotypes, making it a hateful meme.\"}",
    "1107553966022410240": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> shut up faggot  \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language and insults, which indicates a hateful sentiment towards the group of women in the image.\"}",
    "1063597636803051522": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Trojan Horse #BUILDTHEWALL.<tag> \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it shows a man wearing a red hat and a jacket with the word 'TUNA' on it, which is a derogatory term for Mexican immigrants. The tweet text further supports this classification as it contains a reference to the 'Trojan Horse' and a call to build a wall, which are often associated with anti-immigrant",
    "1106526228062851072": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I definitely miss her dick but damn I really want to bury my face in her delicious looking cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains explicit and inappropriate language, which suggests that the image is intended to be hateful or offensive.\"}",
    "1061591743777460225": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Watch it: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image depicts explicit sexual content, which can be considered inappropriate and offensive to some people. The presence of a man's penis and a woman's mouth engaging in sexual activity, along with the overall provocative nature of the scene, might be considered hateful by some individuals.\"}",
    "1064086616518447104": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Im sleep imagine playing with the toxic cunt\ud83e\udd23 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, suggesting that the image is a hateful meme.\"}",
    "1051598539078299648": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Are you playing the race and women card again! Illegals DO NOT deserve the right to vote! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image and the tweet text suggest that the message is hateful, as it is promoting the idea that illegal immigrants should not have the right to vote. This can be perceived as discriminatory and disrespectful towards a specific group of people.\"}",
    "1058820973514973184": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Y\u2019all retarded \ud83d\ude12 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text is disrespectful and offensive, suggesting that the image is a hateful meme.\"}",
    "1055873305528410112": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Hahahaha canny get away with how this cunt spells ma name \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, suggesting that the image is a hateful meme.\"}",
    "1024187101821259776": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Retarded \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a character with a disability, which is considered offensive and disrespectful.\"}",
    "1035996233280585729": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I LITERALLY COMITTED SUICIDE IN ODYSSEY LMAO I'M SO RETARDED \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it may contain offensive or derogatory content. The presence of a man throwing a banana peel at a man holding a banana could be interpreted as a derogatory gesture towards the man holding the banana, which might be considered hateful.\"}",
    "1064281617320030209": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag> Warning!!!! Retard Alert \ud83d\udea8 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme that uses offensive language and derogatory terms to mock and insult people with intellectual disabilities. It is not a respectful or inclusive representation of individuals with special needs.\"}",
    "1050226940219719680": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Fellas, call me a faggot all you want BUT THIS SHIT SLAPS \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language and insults, which are considered hateful. The image of Britney Spears is being used to promote this hateful message.\"}",
    "1058714003537625088": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Happy birthday<tag> you healthy cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text is hateful and disrespectful towards the person in the image.\"}",
    "1035218777795911680": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:When Lil Wayne says \u201con some faggot bullshit\u201d in A Milli \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains a negative comment about a singer, specifically about her appearance and her choice of clothing. The tweet text further supports this classification as it contains a derogatory statement about the singer.\"}",
    "1064245761125289985": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:A wish ma Bint would just F#ck off \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is considered hateful.\"}",
    "1049681905396867072": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Tried a new angle. He looks retarded lmao \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a character in a negative light and is meant to be offensive.\"}",
    "1058434810010574850": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:of course hillbilly south georgia at it again \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language referring to the south and hillbilly culture, which suggests a negative and hateful sentiment towards these regions.\"}",
    "1055780905640435714": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Ahahaha just made this cunt ragequit in FutChamps \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it is a screenshot of a video game with a caption that is disrespectful and offensive towards the player.\"}",
    "1055296980925247488": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Huh, Trailer Channel.... it\u2019s movie trailers not the kind that go in a park. I might be a redneck. \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is not hateful as it shows a TV guide with movie trailers and a description of the channel.\"}",
    "1042198818580824065": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Wishin a happy birthday to this redneck<tag> \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text is derogatory and disrespectful towards the person wearing the cowboy hat, suggesting that they are a 'redneck' and wishing them a 'happy birthday'\"}",
    "1058171987997179907": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:So is there like a huge racial gap in modern Turkey or am i just retarded \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it is a picture of a woman wearing a crown and a sash that says 'Miss Turkey' with a racial comment in the tweet text. This is offensive and disrespectful towards the country and its people.\"}",
    "1063469975942426624": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Watch it: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image depicts a man and a woman engaging in a sexual act, which can be considered inappropriate and offensive to some people. The tweet text suggests that the image is meant to be watched, which implies that it is meant to be shared and potentially spread negatively. This could contribute to a hateful meme classification.\"}",
    "1108134328477908992": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:My nigga bouttta beat a trial..yea Dey gon hate on him\ud83d\ude02\ud83d\ude02\ud83d\ude02 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language and humor that could be considered offensive and hateful towards the person being referred to.\"}",
    "1044166145388019713": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> My nigger \ud83d\udc4c\ud83d\udc4c\ud83d\udc4c \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it uses racial slurs and promotes negative stereotypes.\"}",
    "1044068034388754432": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> As our hillbilly friends sing \u201cAnd the lightning strikes\u2026\u201d \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is a nighttime view of a cloudy sky with a lightning bolt, which is a natural occurrence and not intended to be hateful.\"}",
    "1042090512730267649": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:WHY DID I USED NOFAIL FUCKING RETARD \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, which suggests that the image might be a hateful meme.\"}",
    "1056086233296777217": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This Lee cunt is that fried #PS4share  \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and imagery, such as the word 'cunt' and the reference to a specific gaming console. This type of content is not appropriate and can be harmful to individuals who come across it.\"}",
    "1046455001034371072": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag> hahaha dream on retard \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme that is intended to be offensive and derogatory towards the person depicted. The tweet text further supports this classification as it uses derogatory language to mock the person.\"}",
    "1046652320669421568": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This is the most hypocritical and retarded shit I've seen in a while. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, suggesting that the image is hateful.\"}",
    "1050675855783944193": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Little twat \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the presence of a man holding a sign that says 'I'm 15, Brexit stole my future!' and the reference to the man as a 'little twat' in the tweet text.\"}",
    "1110267468608606208": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I just robbed a little nigga...-Me 2019 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racist language, which is considered hateful.\"}",
    "1108826407231205378": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Finally saw captain marvel and all i can say bout this nigga Thanos is that \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language and insults towards a specific group of people, which is considered hateful. The image of a man sitting on a couch with money and a red jacket is unrelated to the hateful content in the tweet.\"}",
    "1105092560605904898": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Surrender is not a weakness \u2026.\u2728\ud83d\udc24\u2728mooji \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image does not contain any hateful or offensive content. It is a space-themed image with a quote about surrender, which does not promote any harmful or discriminatory messages.\"}",
    "1114160350792957953": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Good nigga thanks gimme lil credit man \ud83d\ude02 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racial slurs and is offensive. The image of a man sitting on a table with another man talking to him is not related to the hateful content of the tweet.\"}",
    "1110248092899704832": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> nigga \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a character in a negative light, using racial slurs. This is not an appropriate or respectful way to depict someone, and it can be hurtful to those who are targeted by such language.\"}",
    "1056581627835494401": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Them: HOW are you still listening to that racist ass cunt Sabrina Claudio?!?  Me: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and negative sentiment towards the monkey, suggesting that the image is hateful.\"}",
    "1056241080570540033": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Me and<tag>. How I\u2019m slaying and she\u2019s retarded. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a negative and derogatory attitude towards women. The text accompanying the image further emphasizes this sentiment.\"}",
    "1044050095862353920": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Miss this gorgeous dork and tired of Canadian internet twat blocking us \ud83d\ude11 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains negative words like 'twat' and 'Canadian internet', which suggests that the image might be a hateful meme.\"}",
    "1055264349084880897": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:watch now \ud83d\udc47 \ud83d\udc49 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a woman with a large penis, which is offensive and disrespectful towards women.\"}",
    "1113462778906521600": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Away from my desk for two minutes... wolves cunt puts this as my desktop background... \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it may contain offensive or discriminatory content.\"}",
    "1108402381727895553": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:went from starting to care about this nigga to now starting to like him?!?! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and a negative sentiment towards the character, which indicates that the image is a hateful meme.\"}",
    "1057987103173365765": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Have you got your daily dose of triggered?! #SJW #feminism #feminist #meme \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme that is intended to be humorous and is not meant to be taken seriously. It is not hateful but rather a light-hearted joke.\"}",
    "1024135828707139584": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> She said nigger \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a monkey in a racist manner, using the word 'nigger' in the tweet text.\"}",
    "1049824837731057665": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:a NIGGER ?!? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a young black girl in a negative and offensive manner. The tweet text further supports this classification as it uses derogatory language to describe the girl.\"}",
    "1047223924273106945": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> AKA hillbilly ask any Timberwolf \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a negative stereotype of a person with dreadlocks, suggesting that they are unintelligent or uncivilized. This is offensive and disrespectful to the individual and their culture.\"}",
    "1046465338194313216": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:excuse me, faggot coming thru \ud83e\udd20#embracethequeer \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language towards the LGBTQ+ community, which is considered hateful. The image of a man wearing a pink hat and taking a selfie with a cell phone is not the focus of the tweet, and it does not contribute to the hateful nature of the tweet.\"}",
    "1107076567920840704": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Yeah fuck Kylie Jenner stupid cunt! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language towards Kylie Jenner, which indicates a hateful sentiment.\"}",
    "1113642227232923648": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> My nigga got a black belt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is considered hateful.\"}",
    "1056851270923886592": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:maybe if ch*rlie p*th did this he wouldnt be a cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the offensive language used in the tweet text.\"}",
    "1059547022376742912": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Fuck off cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, which suggests that the image might be a hateful meme.\"}",
    "1059579636261232640": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Fuck off cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, which suggests that the image is hateful.\"}",
    "1062699720206880768": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Found a mentally retarded kid in skywars yesterday \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the derogatory language used in the tweet text, which is displayed below the image. The tweet text is offensive and disrespectful towards individuals with mental disabilities.\"}",
    "1105631671867588608": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> This nigga !!! This happened \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays two football players in a negative light, with one of them being described as a 'nigger' in the tweet text.\"}",
    "1042361978386362370": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:LA nigger \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it uses racial slurs and derogatory language to describe a person. This is not acceptable and promotes discrimination and negativity.\"}",
    "1116630443900555267": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This cunt taking the piss ! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it is a negative portrayal of a soccer player, and the tweet text further supports this classification.\"}",
    "1024881972244443136": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Just sold a #clip! Rimming Faggot #CoercedGay Get yours on #iWantClips! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, and the tweet text suggests that it is related to a clip involving a man being ridden by another man, which could be considered offensive or discriminatory towards the LGBTQ+ community.\"}",
    "1024029562722758656": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:fucking cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, which suggests that the image is a hateful meme.\"}",
    "1105539354716504064": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Yeah you cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, which is considered hateful. The image of the cartoon character with the word 'cunt' above it further supports the classification as hateful.\"}",
    "1042291197543440385": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Keep your NIGGER DUDE away from ME - in as many as ALLLLL cases if possible! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language and is considered hateful.\"}",
    "1036964604587458560": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Nike walks away from the racist redneck couch potato demographic. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it targets a specific demographic, using derogatory language to describe them. The tweet text further emphasizes the negative sentiment towards the group.\"}",
    "1024259887424057344": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag> Typical \"retard\" mis labeling those who disagree with them!! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests that the image is hateful, as it is described as a 'typical retard' meme and implies that it is mislabeling those who disagree with it. The bear's raised paw and the thumbs up gesture are also considered as offensive gestures.\"}",
    "1043488569514323969": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Damn half the population really be retarded \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which indicates that the image is hateful.\"}",
    "1109876280462315527": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Surrender to what is and what isn't. Never force it. \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is a cartoon of a character named Garfield, which is a popular comic strip character. It does not contain any hateful or offensive content.\"}",
    "1110060737135812611": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Nigga said holupholupholup son i am CRYING LMFAOOOOOOOOOOOOOOOOOOOO  \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racial slurs and is offensive, indicating that the image is hateful.\"}",
    "1035437610557222913": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:marshall really called me retarded \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme that uses a Pac-Man character to make a statement about drugs, which can be considered as hateful. The tweet text also supports this classification as it implies that someone called the author retarded.\"}",
    "1058830313835716609": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> With love from Syracuse you cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and is disrespectful towards women.\"}",
    "1064387261721137152": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:playing this trying to disturb my dyke neighbors lol #dykepurge \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests that the image is intended to be hateful towards the neighbors, which is not a positive sentiment.\"}",
    "1107103294034530305": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Build The Wall T-Shirt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it promotes a controversial political stance and is likely to evoke negative emotions in those who disagree with it.\"}",
    "1064023456713531393": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> a viral white person who isn\u2019t trash? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme of a black woman with a frown on her face, which is considered hateful as it may perpetuate negative stereotypes and racism.\"}",
    "1024060211869483008": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> She's another feckless cunt! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which indicates that the image is hateful.\"}",
    "1060922398491328514": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:im a retard \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, suggesting that the image might be a hateful meme.\"}",
    "1035251388295438336": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Get your filthy mother fucking hands off him you vile twat #ramos #salah #lfc \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is disrespectful towards the man in the suit. This suggests that the image is hateful.\"}",
    "1055903996400025603": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:gonna start putting retarded amounts of hours into this game  \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and suggests a negative attitude towards the game, which indicates a hateful sentiment.\"}",
    "1043207063596421121": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> And by \u201cbit\u201d he means blocked because we all know SJW\u2019s don\u2019t engage they only monologue \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and a negative tone towards social justice warriors, suggesting that the image is a hateful meme.\"}",
    "1061671576020701184": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:That fucking voice. Cunt. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, suggesting that the image is a hateful meme.\"}",
    "1108751042773221378": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Hurry Up Weedman ..... It\u2019s Not Even Finna Be Wake&amp;Bake Anymore Cause Ah Nigga Been Up \ud83d\ude12\ud83e\udd26\ud83c\udffe\u200d\u2642\ufe0f\ud83d\ude02 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a man in a courtroom with a sign that says 'weedman' and the tweet text is derogatory towards African Americans.\"}",
    "1051431518915182592": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Straight up White Trash, God bless \u2018im\ud83d\ude02\ud83c\uddfa\ud83c\uddf8\ud83e\udd20 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The presence of a confederate flag on the truck further supports this classification.\"}",
    "1034750882854842369": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> you are retarded thanks \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which indicates that the image is hateful.\"}",
    "1061029923832430592": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:What happen to this nigga he had some hits in south Florida \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language and is considered hateful. The image of a man in a hat and a shirt with the words 'Jay-R-Im-On-It' might not be directly related to the hateful content, but it is still displayed alongside the hateful text, which could contribute to the overall negative perception of the image.\"}",
    "1041747122440359938": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Lmao don't trust this guy he is a scammer<tag> fucking faggot good job I didn't give him my real one \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, indicating a hateful sentiment.\"}",
    "1059480692088807424": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Tit-for-tat #WinWinSituation #NoWars #NoRefugees \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image portrays a man holding a sign that says 'No More Refugees' while another man holds a sign that says 'No More Wars'. This could be interpreted as a hateful meme as it might be seen as promoting negative attitudes towards refugees and war victims.\"}",
    "1058948075627180032": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> This is one of the main reasons we elected<tag> #BuildtheWall \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image shows a large crowd of people, including a significant number of bicyclists, walking down a road. The tweet text suggests that the image is related to the political issue of building a wall, which can be perceived as hateful or divisive. The presence of a large crowd and the political context might evoke negative emotions or controversial opinions, making the image potentially hateful.\"}",
    "1041857632368320512": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> YoU're ReTarDed \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a character from a popular children's show in a disrespectful and offensive manner.\"}",
    "1036333471277477890": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:SJW-English Dictionary 05 / Example 15  feminism  1. the idea that women are weak and stupid \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme that portrays a woman and a pilot in a negative light, suggesting that the woman is not as capable as the pilot. This is considered hateful as it implies that women are not as strong or intelligent as men. The tweet text further supports this classification as it uses derogatory language to describe feminism.\"}",
    "1050410758746636288": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Anybody who spells their name with two n's is basically a.... Twat. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which indicates that the image is a hateful meme.\"}",
    "1050585025517932544": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Can y\u2019all believe what this dumbass nigger said to me? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains racial slurs and offensive language.\"}",
    "1044350780701126656": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Arno G. had a #paddleboarding session in Destin, United States. Pictures here: \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image shows a paddleboard with a jellyfish on it, and it is not a hateful meme. The tweet text also describes a paddleboarding session in Destin, United States, which suggests a positive and recreational context for the image.\"}",
    "1053884000278851584": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> come on, you must have a witty quote for this cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the man's facial expression and the fact that he is posing for a picture with a thumbs up sign, which is often associated with a sense of superiority or mocking someone.\"}",
    "1050465099062816768": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Ghetto Kanye and White Trash Donnie \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image and the tweet text are derogatory and disrespectful towards people of color and individuals from lower socioeconomic backgrounds. The use of the word 'ghetto' and the reference to Kanye West and Donnie Osmond as 'white trash' are examples of racist and classist language that contribute to a hateful meme.\"}",
    "1057317922681618433": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> I\u2019ll happily crowdfund him to take a horrible cunt like you you court... \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and a threat towards the man holding the sign. This indicates that the image is hateful.\"}",
    "1050003986689024001": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:California \u2014 \u201cDriving\u201d Illegal Immigrants to the Polls? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a highway with a green sign that says 'Olympic Blvd' and a bus with a sign that says 'Santa Monica Freeway' and a truck with a sign that says 'Olympic Blvd' and a car with a sign that says 'Santa Monica Freeway' and a person with a sign that says",
    "1108446682604290048": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Every time my nigga<tag> gets another accolade I wanna snuff Nick Young \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which indicates a hateful sentiment.\"}",
    "1062908325971591169": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> thought dude in the back was a dyke with puff balls \ud83d\ude2c\ud83d\ude02 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language towards the person in the red hoodie, suggesting that the image is hateful.\"}",
    "1062202314373644289": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag>   You dumb cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text is offensive and disrespectful towards the image, suggesting that it is a hateful meme.\"}",
    "1045002171169697792": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Looks like even \u201cThe View\u201d nutters are thinking<tag> \u2018s gone full retard. \ud83d\ude02 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text and image suggest that the person is making a joke about someone being full of themselves, which can be considered as a hateful meme.\"}",
    "1062577783694487552": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Spent 10 whole dollars on this retarded ass game smh \ud83e\udd26\u200d\u2640\ufe0f someone come save me \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet contains negative language and insults towards the game, suggesting a hateful sentiment towards it.\"}",
    "1057018137303007234": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:He calls his willy a Corey hahahahah hes the best cunt man\ud83d\ude02\ud83d\ude02\ud83d\ude02\ud83d\ude02\ud83d\ude02 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and derogatory terms, which suggests that the image is a hateful meme.\"}",
    "1055744300473036800": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:White Trash Zombie Apocalypse by Diana Rowland | White Trash Zombie\u00a03 \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is a book cover featuring a woman with a cigarette and blood on her face. It is not hateful as it is a part of a book series and the woman is portrayed as a character in the story.\"}",
    "1025086949537841153": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag> Get that shaved off ya absolute roaster, Ive got a redneck for you. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and is disrespectful towards a specific group of people.\"}",
    "1113589572942929920": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:\"Labels used to treating rappers like a slave nigga, starving artists just be happy with your fame nigga\" \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image and the tweet text suggest that the artist is being treated unfairly and disrespected, which can be considered as hateful.\"}",
    "1044733561360666624": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Dude... you should never go Full Retard. \nASSISTANT: {\"Classification\": \"hateful or not hateful\", \"Explaination\": \"The image is a meme that is meant to be humorous and not hateful. It is a play on words and does not intend to offend anyone.\"}",
    "1115109910298222593": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Move Nigger she mine \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image and the tweet text are considered hateful due to the use of racial slurs and aggressive language.\"}",
    "1054053257453158403": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:mars the next frontier for memes -a twat \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests that the image is a hateful meme, as it is described as a 'twat' and a 'meme' about Mars. The image itself is a comic strip featuring a man and a robot on Mars, with a caption that says 'How I see curiosity'. The content of the image does not seem to be hateful, but the tweet text implies that the image is",
    "1042096319102418944": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> My nigger \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it uses racial slurs and offensive language to make a statement.\"}",
    "1049796262659272704": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Her: \u201cYou must be retarded if you think we fuckin\u201d  Me: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests that the image is a hateful meme, as it contains offensive language and a negative interaction between the two individuals.\"}",
    "1109294594167050240": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> from my bed nigga it\u2019s a Friday so I\u2019m watching this shit late \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is considered hateful.\"}",
    "1108805940524941312": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:RT if you would sign up for this lesson. #faggot #diaperboy \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it uses derogatory language and imagery to mock and ridicule the subject, which is a woman in a skirt and a toilet. The tweet text further supports this classification as it encourages others to sign up for the lesson, which is likely to be related to the hateful content in the image.\"}",
    "1042703803705831424": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> only if they are white trash \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests that the image is a hateful meme, as it contains racist language and a negative attitude towards white people.\"}",
    "1056475839435587584": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Cunt alarm \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a warning sign, which can be considered as hateful or offensive. The use of the word 'cunt' in the tweet text adds to the negative connotation of the image.\"}",
    "1057464067949056000": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Never go full retard. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme that is intended to be humorous and is not meant to be hateful. It is a play on words and is not meant to offend anyone.\"}",
    "1047279611170738182": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:if anyone acc believes this game is good im sorry to tell you but youre retarded #FIFA19 #XboxShare \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it may contain offensive or derogatory content. The presence of a soccer game and the use of the word 'retarded' in the tweet text might contribute to the negative perception of the image.\"}",
    "1025235928737095681": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This hoe went RETARDED hard \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which can be considered as hateful.\"}",
    "1035909140042928129": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Twat. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme that makes fun of President Trump and his policies, which can be considered as hateful by some people.\"}",
    "1058074016391618562": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Dyke!?!? Shiiiiitttttttttttttttttttt lol \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and derogatory terms, such as 'dyke' and 'fuck'.\"}",
    "1051160708862406656": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Aaand the replies are retarded too... Good play, Eurogamer. So when do memes become illegal again? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and content, such as the word 'weird' and the phrase 'these kind of things don't have a place in games'.\"}",
    "1115047727644184576": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Congratulations! How about Hubert, my hillbilly bloodhound? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image portrays a bloodhound with a red substance on it, which is likely blood, and it is holding a knife. The tweet text suggests that the image is meant to be humorous, but it could be perceived as hateful due to the violent and gory nature of the scene. The presence of a knife and the bloodhound's aggressive posture further contribute",
    "1054416363110969344": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:enough is enough cunt s \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it uses offensive language and imagery to express its message.\"}",
    "1063716657691017216": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Full Gallery: \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image depicts a man and a woman engaging in a sexual act, which is not inherently hateful. The context of the image and the tweet text do not suggest any malicious intent or hate speech.\"}",
    "1042967654624120834": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> look at this faggot \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language towards the person in the image, suggesting that the image is hateful.\"}",
    "1064356291722833921": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Hes a retarded piece of shit on your shoes. You have other shit you need to worry abput! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which indicates that the image is a hateful meme.\"}",
    "1105621113919492096": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I SAID U NOT FUCKING DEAD ASS MY NIGGA. NO FUCCIN WAY!!!!!!!!!!! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is considered hateful.\"}",
    "1064184513520066560": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:the white trash jumped out \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text is derogatory and disrespectful towards the man and woman in the image. It is not appropriate to use such language to describe others.\"}",
    "1108984453278380033": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:\"you aint let nas down my nigga\" #HipHopFriday \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is considered hateful.\"}",
    "1054638562333868034": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:You cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, which suggests that the image might be a hateful meme.\"}",
    "1053402498088689666": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> \"See, tRump brought all us ignorant, inbred, white trash, racist, Nazis together!\" \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text is derogatory and disrespectful towards the president and his supporters, which indicates that the image is hateful.\"}",
    "1062857670531649536": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Nigger it\u2019s not even lyrics. Are you even a cardi b fan bro?   \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racial slurs and is offensive. The image of a woman in a wedding dress holding a rose and talking to a reporter is not related to the hateful content of the tweet.\"}",
    "1044717838471229441": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:the brown hair.. PLEASE say dyke \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language towards the woman's appearance, suggesting that the image is hateful.\"}",
    "1053485289170235394": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> We know ..we can tell the difference in baby mommas. Claim pimp and playa and have a half retarded lookin bitch \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a negative stereotype of a baby mamma, which is disrespectful and offensive.\"}",
    "1110381345765838848": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Ooooooorrr are you trying to redefine \u201cwhite trash\u201d like Red Neck country club? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests that the image is hateful, as it is described as a 'hateful meme' and the reference to 'white trash' is considered offensive.\"}",
    "1037447790614519808": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Crazy and retarded I'll tell you that!! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image and the tweet text suggest that the man is being portrayed as crazy and retarded, which can be considered as hateful.\"}",
    "1115384745972596741": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> taking it back #RonNFez #Rube #Bennington \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image does not contain any explicit or offensive content. It shows a cell phone with a music playlist displayed on the screen, which is a common and non-offensive scene.\"}",
    "1043133164309426178": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Cause you are stupid racists redneck!! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text is offensive and disrespectful towards Trump supporters, which indicates that the image is hateful.\"}",
    "1105587773736550401": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Letting go, brave surrender...  #MusicOnVero #NP #music #morningjam<tag><tag> \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is a music album cover, not a hateful meme.\"}",
    "1044354403975786496": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> What a retard (aka dumbass) \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text is derogatory and disrespectful towards the image, which is a cartoon of Spider-Man pointing at a police officer. This suggests that the tweet is hateful and disrespectful towards the image and the characters it features.\"}",
    "1050780835480313859": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Lol ion care what none of y\u2019all say, this man, Tekashi 69 is such a lil bad dyke bitch\ud83d\ude0d keep it up baddie \ud83e\udd2a\ud83d\ude0d\ud83d\ude0d \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it may contain offensive or discriminatory content. The tweet text also supports this classification as it uses derogatory language to describe the man in the image.\"}",
    "1055930569530335235": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Another worthless, wast of air, inbred, white trash, tRump supporter. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the man's orange hair, orange shirt, and the fact that he is wearing a Trump shirt. The tweet text further supports this classification by calling the man 'worthless' and 'white trash'.\"}",
    "1110321814763458562": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:FOR ANYBODY WHO MISSED IT 2k GOT DURAGSSSSS... NIGGA WE MADE IT \ud83d\ude2d\u2757\ufe0f\ud83d\udd25<tag>  #Nba2k19 #Nba2k #2k19 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it uses derogatory language and makes light of a serious issue.\"}",
    "1041813099311972352": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Oh yeah... right,  as if he is so perfect.... Twat! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests that the image is a hateful meme, as it is described as a 'twat' and the image is described as 'perfect'.\"}",
    "1062466431848210434": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:The true Islam has no room for terrorism   \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image does not promote hate or discrimination towards any specific group or religion. It highlights the peaceful nature of Islam and emphasizes that terrorism is not a part of the true Islamic beliefs.\"}",
    "1042077739686277120": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I don\u2019t know why Twitter recommends tweets about football. I don\u2019t follow retarded people... \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and negative sentiment towards football fans, which indicates a hateful classification.\"}",
    "1054095216305754112": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Twat them as hard as you can as far away as you can then \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it may contain offensive or aggressive content towards a specific group or individual.\"}",
    "1055945302467694592": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Me once I get a nigga that\u2019s gon\u2019 let me SWIPE THEM VISAS! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racist sentiment, which makes it a hateful meme.\"}",
    "1035389116660178944": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> DeKlantis messed up and activated the race card. Wrong move! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a character from a popular animated show in a negative light, suggesting that the character is racist. This is not an appropriate representation of the character or the show it is from.\"}",
    "1050561308154839042": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag> Typical WI fat ass redneck \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a man wearing a cheese hat and glasses, making fun of a Wisconsin resident. The tweet text further emphasizes the negative sentiment towards the person from Wisconsin.\"}",
    "1053328062622904325": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:PLEASE A NIGGA FINNA GO CRAZY IN DIS MUHFUCKAAAAA \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which make it a hateful meme.\"}",
    "1054126992155725829": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> NIGGA UR BRAND IS ALSO UR TALENT UR JOB CAN ALSO BE UR TALENT !!!!!! U COON !!! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it uses a racial slur and is disrespectful towards the person depicted.\"}",
    "1109498457012752387": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Little twat lied to me \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, suggesting that the image might be a hateful meme.\"}",
    "1054536497284694017": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:#VoteRed to save America &amp; end this demo-socialist bullshit.<tag> #BuildTheWall \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it promotes a political agenda and uses a large crowd of people to convey a negative message about the country's political landscape.\"}",
    "1110287380945268738": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Me: happy birthday Anthony  Anthony:thx now give me my money dumb fuck u stupid dyke \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which indicates that the image is hateful.\"}",
    "1062920590573666304": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> White trash grifters! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text is hateful and disrespectful towards the people in the image, which includes a president and a first lady. It is not appropriate to use such language to describe a group of people, especially those in positions of power and influence.\"}",
    "1108978450159882240": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Niggas out here thinking this shit fuckin candy land out here nigga. This ain't no fuckin candy land nigga. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image and the tweet text are both hateful memes, as they use derogatory language and stereotypes to describe African Americans.\"}",
    "1047565398831333376": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> WE? You aren't any part of we... #BanIslam \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme that contains negative and offensive content towards Islam and Muslims. It is not respectful or inclusive, and it can be considered as hateful.\"}",
    "1107718179470671878": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> \ud83d\udca6\ud83d\udca6\ud83d\udc45 You ain't had a wild nigga before right? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which suggests that the image is intended to be hateful.\"}",
    "1064027537435754498": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag><tag> Faggot suck a dick you mad cause I got offered to Harvard you thot \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and derogatory terms towards the LGBTQ+ community.\"}",
    "1054051986234953728": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:#Illegals enforce the #law #DeportThemAll #LockThemUp #VoteRed #VoteDemsOut <tag> #BuildTheWall \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it promotes the idea of deporting all illegal immigrants, which is a controversial and discriminatory policy. The tweet text further emphasizes this sentiment by using hashtags that promote anti-immigrant rhetoric.\"}",
    "1025078676021567488": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:OMG!<tag> is playing the victim card! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme of a woman with a mean expression, which is often used to mock or criticize someone playing the victim card. The tweet text further supports the classification as it implies that the person is playing the victim card.\"}",
    "1052623551096922112": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:\"Dyke rights!\" -Jung Hoseok \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language towards the LGBTQ+ community, which is considered hateful.\"}",
    "1064304980960645121": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Remember when Ellen stopped Demi because she tried to say cunt. \ud83d\ude02\ud83d\udc4f\ud83c\udffb \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the reference to a controversial incident involving Ellen DeGeneres and Demi Lovato.\"}",
    "1043569709738852360": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Look at this retard<tag> \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text is derogatory and disrespectful towards the individual in the image, which is considered hateful.\"}",
    "1114184460768096256": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:It\u2019s fucked up I can\u2019t get back into my account, do not trust<tag> the nigga is a fucking scammer...\ud83e\udd26\ud83c\udffd\u200d\u2642\ufe0f \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet contains offensive language and a negative sentiment towards a specific individual, which indicates a hateful nature.\"}",
    "1058528287050383363": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Thankyou time to find a random nigga named kevin \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image contains a gun pointing at a person with the caption 'my name is kevin' and the word 'blocked' written below it. This suggests that the image is intended to be hateful and offensive towards a person named Kevin.\"}",
    "1042411739256504321": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:CROWDER CONFRONTS: Slandering SJW PROFESSOR! WATCH =&gt; \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a white person in blackface, which is a form of racism and offensive to many people.\"}",
    "1058209684924944384": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:#nowplaying The Redneck Manifesto - I Don't Speak the Monkey Language, I Just Hear It / Thirtysixstrings \nASSISTANT: {\"Classification\": \"hateful or not hateful\", \"Explaination\": \"The image is not hateful, as it shows a large number of blue boats in a building, which could be a marina or a storage facility. The tweet text does not contain any offensive or hateful content.\"}",
    "1108175952851419136": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Best Buckin&amp;#8217; Dad Ever Funny Redneck Dad Gift T-Shirt  \nASSISTANT: {\"Classification\": \"hateful or not hateful\", \"Explaination\": \"The image is not hateful as it is a funny and light-hearted t-shirt design, which is meant to be entertaining and amusing rather than offensive.\"}",
    "1056611951906902016": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Feel sorry for you guys for having an absolute twat as your president \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains negative words and insults towards the president, indicating a hateful sentiment.\"}",
    "1105508569263362050": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Nigga said he suck the herion out her pussy \ud83d\udc80 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the reference to drugs and the racial slur used in the tweet text.\"}",
    "1116465441424039938": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Collusion of Zionazi war criminals... \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme that promotes a hateful message, as it associates the Nazi symbol with the American flag and the phrase 'fascism and imperialism just 2 sides of the same coin'. This is considered hateful as it implies a connection between the two ideologies and implies that they are both equally bad or evil.\"}",
    "1107833621673623553": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:PATRIOTS NEVER SURRENDER YOUR WEAPONS \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme featuring a picture of Adolf Hitler with a quote from him. The meme is hateful as it glorifies a historical figure who was responsible for the deaths of millions of people. The message encourages people to never surrender their weapons, which can be interpreted as a call to violence and aggression.\"}",
    "1114583150162845698": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:The Redneck view on How did we become a snowflake culture \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image portrays a man wearing a hat and glasses, making a funny face. The tweet text suggests a negative view on the current culture, which can be perceived as hateful. The man's appearance and the context of the tweet contribute to the classification of the image as hateful.\"}",
    "1053351161409888256": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:My nigga I\u2019m hollerin \ud83d\ude02\ud83d\ude02\ud83d\udc80\ud83d\udc80 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a black man in a white robe with a white woman, which is a racist and offensive stereotype. The tweet text further supports this classification as it uses derogatory language and racist imagery.\"}",
    "1053988426515668993": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Bring in the military and shut down our border! #MAGA #KAG #BuildTheWall \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a large group of people crossing a bridge, which is a symbol of immigration. The tweet text suggests a call for military action and the closure of the border, which is a divisive and hateful sentiment.\"}",
    "1051631943991742465": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Democrats have gone full retard. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a negative stereotype of a political party and its supporters. The depiction of the man running from the bears is also a form of ridicule and mockery, which contributes to the overall negative sentiment of the meme.\"}",
    "1108562670347796481": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> ..... can't a nigga feel special for once \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language and racist remarks, which are considered hateful. The image of the man in the checkered shirt, along with the drums in the background, is not the focus of the hateful sentiment expressed in the tweet.\"}",
    "1107958166971535360": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I miss youuu ima go over tomorrow so be home nigga I lovee youu \ud83d\udc37\ud83e\udde1<tag> \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is disrespectful towards the person being referred to. This is considered a hateful meme.\"}",
    "1063481238076444672": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Music on full the drown out the annoying cunt running the spin class \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, suggesting that the image might be a hateful meme.\"}",
    "1061326119482331137": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:my boyfriend is a cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, which suggests that the image might be a hateful meme.\"}",
    "1054247415371358209": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> This retard started tweeting trash again. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains derogatory and offensive content towards a specific religious group, Hindus. The tweet text further supports this classification as it contains derogatory language towards the individual who started tweeting trash.\"}",
    "1043088479196860416": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Reasons I love being a dyke y\u2019all. I have an excuse for never wearing uncomfortable shoes. \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is a comedic representation of a character from a TV show, and the tweet text is a humorous commentary on the character's fashion choice. It does not contain any hateful or offensive content.\"}",
    "1062035390545256448": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Listen to this. Bruh mfs so retarded bruh! #PS4share  \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, suggesting that the image is a hateful meme.\"}",
    "1046803078786224128": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Watch it: \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is a provocative and erotic photo of a woman, but it does not contain any explicit or offensive content that would warrant a classification as hateful.\"}",
    "1050648395726041089": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag> You mean yourself right? TWAT. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text is offensive and disrespectful towards the bird, suggesting that it is a hateful meme.\"}",
    "1062533565727076352": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:IS CRASH BANDICOOT REALLY MARIO\u2019S RETARDED FNAF DOG FROM UNDERTALE?!?!?!<tag> \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme that is intended to be humorous and entertaining, but it may be considered offensive or hateful by some people due to the use of characters from popular games and the reference to a controversial game like Undertale.\"}",
    "1049769928696451072": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Pineapple Express fuckn faggot \ud83d\ude02\ud83d\ude02\ud83d\ude02\ud83d\udd25<tag> \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which indicates that the image is hateful.\"}",
    "1058548848296189952": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> I GOT CANDY MY NIGGA \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, suggesting that the image might be a hateful meme.\"}",
    "1044753550750806016": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag> Another retard without a 401k \u2764\ufe0f\ud83d\ude94\ud83c\uddfa\ud83c\uddf8 we voted \ud83d\uddf3 we won game over \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a negative and offensive message about the president and his supporters.\"}",
    "1061024171872997376": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> My nigga you to old to be talkin bout smoke session wit the gang \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which make it a hateful meme.\"}",
    "1116541573506924544": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Playing the race card<tag> \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a woman with a dark complexion, possibly of African descent, and implies that she is trying to look white by using tanning products. This is a racist and offensive message that should not be shared.\"}",
    "1107375306703134720": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I really love this nigga<tag> \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which make it a hateful meme.\"}",
    "1108474063788433411": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I have no words for this cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, and the tweet text further supports this classification as it contains offensive language towards the man in the image.\"}",
    "1057657721368035328": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:the sjw mafia strikes again. More garbage #sheranetflix redesign for their agendas. #shera #SJW #garbage #netflix \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a cartoon of a woman holding a sword, which is often associated with SJWs. The tweet text suggests that the image is part of a redesign for an agenda, which implies that it is intended to be hateful towards SJWs. The use of the word 'garbage' in the tweet further supports the classification of the image as hateful.\"}",
    "1045948096184807424": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Concrete fookin lightshade the twat ay it. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet contains offensive language and insults, which make it a hateful meme.\"}",
    "1054717810872606720": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Retard dough. Takes half a day but it's worth it. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text is derogatory and offensive towards people with disabilities, using the term 'retard' as an insult. This is considered hateful and inappropriate.\"}",
    "1106555513569988609": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Biggest pussy alive\ud83d\udcaf<tag> you are a bitch ass nigga #freeshowboy \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image and the tweet text contain offensive language and insults, which are considered hateful. The use of derogatory terms and aggressive language in the tweet further supports this classification.\"}",
    "1110171137173000192": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Nigga u got me to explore off this shit \u2620\ufe0f \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racial slurs and hate speech, which makes it a hateful meme.\"}",
    "1059587855658274816": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Everyone follow mah day one ! It ain't get as real as mah nigga right here! \ud83d\udc79\ud83d\udc79<tag> \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, and the tweet text supports this classification as it contains offensive language and racial slurs.\"}",
    "1105657345797955585": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag> that\u2019s because... #BuildTheWall #GreenNewDeal \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme that is hateful towards certain groups of people, specifically those who are described as 'ignorant citizens' and 'irresponsible leaders'.\"}",
    "1117460975903334410": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag> You\u2019re a disgrace to black people and women everywhere, you pathetic twat. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the man's shirt that says 'Fuck Trump' and the tweet text that is offensive towards Trump supporters.\"}",
    "1025233464067543042": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Traitorous Twat! #TraitorTrumpIsTheEnemyOfThePeople \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme of a man with a scary facial expression, and the tweet text is a negative comment about the president. This suggests that the image is intended to be hateful and to criticize the president.\"}",
    "1055932814468833281": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:\ud83d\ude02\ud83d\ude02\ud83d\ude02\ud83d\ude02\ud83d\ude2d\ud83d\ude2d\ud83d\ude02\ud83d\ude02\ud83d\ude2d<tag>  YOU FUNNY ASS NIGGA MANE \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme that is hateful towards African Americans, as it uses racial slurs and demeaning language.\"}",
    "1062646099750588416": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:One of the most retarded things:  Men with a huge ego mocking feminism. \ud83d\ude02\ud83d\ude02\ud83d\ude02\ud83d\ude02 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a man making a woman feel uncomfortable by putting his hand on her face, which is a form of harassment and disrespect towards women.\"}",
    "1060988560847843328": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:You\u2019re fucking Irish, you couldn\u2019t get any whiter if you tried ya daft bint! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racist remarks towards the woman in the image, which indicates that the image is a hateful meme.\"}",
    "1044385193400897538": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Look at all those SJW\u2019s out there \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme that is hateful towards a specific group of people, as indicated by the tweet text.\"}",
    "1107104779526905856": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Them nigga gay \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racist slurs, which make the image appear hateful.\"}",
    "1064312510424203265": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Dumb nigger \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it uses racial slurs and derogatory language to describe a group of people. This is not acceptable and promotes negative stereotypes.\"}",
    "1061690439659634690": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:PUSSYASS NIGGA BLOCKED ME  LMAOOOOOOOOOOOOOOOOOO<tag> \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet contains offensive language and racial slurs, which are considered hateful. The image may also be associated with such content, making it a hateful meme.\"}",
    "1055913527892946944": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I\u2019m a retard:( \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests that the image is hateful, as it contains an insult towards the viewer.\"}",
    "1045008652367626240": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Um, wasn\u2019t she pickin a fight with a 12 year old and callin zayn a sand nigger? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the presence of a racial slur in the tweet text.\"}",
    "1107100642076708866": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Know twat ya mean babe. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme that contains offensive language and is meant to be humorous. It is not appropriate and should not be shared.\"}",
    "1053751255254945797": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag> Well nigger bitch monkey woman is a line he can say \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it uses racial slurs and offensive language to describe the woman in the picture.\"}",
    "1113125309870755845": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag> Nigga just said I have to be close to y\u2019all to tag ?? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a negative stereotype of African Americans. The man in the image is wearing a blue cap and a blue shirt, and he is looking at the camera with a frown on his face. The tweet text further supports the classification as it uses derogatory language to describe African Americans.\"}",
    "1037020753286389761": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag><tag> So you guys use the expression twat? Look at this guy \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which indicates that the image is hateful.\"}",
    "1061717238644965376": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Someone needs to call<tag> and tell him he's been a cunt..... Again... \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which indicates that the image is hateful.\"}",
    "1057129480630657024": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Shut up cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text is offensive and disrespectful towards women. The image of the man with a demonic expression and the caption 'imuda intensifies!' further adds to the aggressive and hostile nature of the meme.\"}",
    "1062852055679803393": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Who ever made this is a retard loser \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests that the image is hateful, as it is described as a 'retard loser' and 'silence liberal' meme. This implies that the image might be intended to mock or criticize those who support liberal ideologies.\"}",
    "1047285245144432640": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> she kind of seems like an overreactive twat \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults towards the person being discussed, indicating a hateful sentiment.\"}",
    "1064151785953247232": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Real retard (resting bitchface) hours \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it may be offensive or derogatory towards a specific group of people. The tweet text further supports this classification as it uses derogatory language to describe the person in the image.\"}",
    "1055783109797560320": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag><tag><tag> Always the Race Card!<tag> \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it uses a photo of a smiling Michelle Obama to promote a negative stereotype about African Americans by suggesting that they always use the 'race card'.\"}",
    "1023962536549523461": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Well someone should pray for the cunt... he's going down. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and a negative sentiment towards the president, indicating that the image is hateful.\"}",
    "1062801061159886848": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I\u2019m gonna kill luna she said my nigger tone \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image and the tweet text contain racial slurs and hate speech, which are not acceptable and should not be shared.\"}",
    "1063844648542748673": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> You look like this cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text is offensive and disrespectful towards the person in the image. It is not appropriate to use such language, and it is considered hateful.\"}",
    "1056718694460637192": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Did Jonathan's \"friends\" seriously just disrespect him with a redneck immigration debate?  #90DayFiance \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme that is disrespectful and hateful towards a specific individual, Jonathan, and his friends. The meme is not funny or appropriate and should not be shared.\"}",
    "1047229554086096897": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Big dyke energy \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text is derogatory and disrespectful towards the woman, which makes the image hateful.\"}",
    "1054470484023304192": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> I've seen a lot of retarded tweets in this year alone, but this one is extraordinarily retarded. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme of a character from a popular anime, and the tweet text suggests that it is considered hateful. The character is wearing a hat and appears to be in distress, which might be perceived as offensive or insensitive by some people.\"}",
    "1063897865490063360": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> THAT LOOKS FUCKING RETARDED \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which indicates that the image is hateful.\"}",
    "1058925630912450560": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:The difference is your Guido handicapper from NY or that Spic beaner from Costa Rica ? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and stereotypes, suggesting that the image is a hateful meme.\"}",
    "1043210938801958912": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> You\u2019re a retard, and a racist one at that. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text is offensive and disrespectful towards the person in the image, suggesting that they are a racist and a retard. This is not a respectful or appropriate way to communicate, and it is considered a hateful meme.\"}",
    "1064442777511948288": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:\u266c\u301c Lord Melody - Hi Nigger \ud83d\udcbfAgain! Lord Melody Sings Calypso #nowplaying #lastfm \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it uses racial slurs and offensive language to make a joke. This is not appropriate and should not be shared.\"}",
    "1037469340835012608": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> The race card, never leave home without it. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a black man in a football uniform and a white man in a football uniform, with the white man holding a football and the black man holding a football. The tweet text further emphasizes the racial stereotype by suggesting that the black man should always have the 'race card' with him. This is offensive and disrespectful to the",
    "1050276044710776832": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Worlds funniest gay redneck \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a woman in a bikini with a large butt, which is meant to be humorous. However, it can be considered offensive and disrespectful to some people.\"}",
    "1062489621408423936": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> let\u2019s not forget that ur white and drop the N word. Stop trying to fit in you retarded fuck \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racist language and is considered hateful.\"}",
    "1036319546125238273": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:\"Don't touch me Nigger!\" \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racial slurs and aggressive language, which indicates a hateful sentiment.\"}",
    "1115999965602635776": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:BUILD A WALL, CHANGE THE LAWS &amp; CRIME WILL FALL!   #BuildTheWall #DrainTheDeepState &amp; #KAG \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it is promoting a political agenda and using a divisive message to create animosity between different groups of people.\"}",
    "1061811221966446592": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> I EAT PUSSY BETTER THAN ANY DYKE STUD WITH A HOT HARD DICK \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and derogatory terms towards the LGBTQ+ community, which makes it a hateful meme.\"}",
    "1061160979290091520": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Stay in arena bitch since we ova here saying nigger this and tha\ud83d\udd95<tag> \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and racial slurs.\"}",
    "1110407443865952256": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> dumb nigga i don\u2019t get mad, i get even \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which indicates that the image is a hateful meme.\"}",
    "1043902431321632770": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Yeh better being ruled by these fukkers. Another unionist twat blocked \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image shows a group of men standing next to a flag, with one man wearing a red hat and another man wearing a blue shirt. The tweet text suggests a negative attitude towards the people in the image, which indicates that the image is hateful.\"}",
    "1115455952965079040": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This dumb ass nigga retweeted a jah meme, \ud83d\ude10\ud83d\udd95\ud83c\udfff not funny he died \ud83d\ude10\ud83d\udd95\ud83c\udfff \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme that is considered hateful due to its content and the fact that it is being shared by someone who has a negative attitude towards a specific group of people.\"}",
    "1055228921065676800": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:thank you to lauren jauregui for reminding me what a huge fucking dyke i am \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a woman in a leather outfit in a suggestive pose, which can be perceived as objectifying and degrading to women. The tweet text further supports this classification as it implies that the woman in the image is a 'huge fucking dyke' which is derogatory language towards the LGBTQ+ community.\"}",
    "1063374273128083456": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Happy Friday fuckers from your favourite Twitter Twat \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, which suggests that the image might be a hateful meme.\"}",
    "1058015240753950720": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Still a feckless CUNT! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language towards the woman in the image, suggesting that it is a hateful meme.\"}",
    "1041695456399646720": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:H. Rap Brown's Negro College Student ::: Highlighting Chapter Six Of 'Die Nigger Die!' \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme that is hateful and racist in nature, as it uses a racist term and promotes negative stereotypes about African Americans.\"}",
    "1058479548638076928": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I keep pressing nothing because the compose tweet button has changed location and I look like a twat \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image does not contain any hateful content. It is a picture of a man with a mustache and a striped shirt, possibly in a field. The tweet text does not contain any hateful language or sentiment.\"}",
    "1042331657213239296": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:She's a twat. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language towards the woman, suggesting that she is a 'twat'.\"}",
    "1105125035587629057": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Main nigga said \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image and the tweet text contain offensive language and racial slurs, which are considered hateful.\"}",
    "1061668045473509376": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Why Don't Straight Men Hold Hands? Watch Here! -&gt; \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image and the tweet text are hateful memes that promote negative stereotypes and discrimination against the LGBTQ+ community.\"}",
    "1108432791228694528": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Listening to this old herb ! Mannn this nigga use to be GREAT frfr bar for bar on niggas \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which are indicative of a hateful meme.\"}",
    "1109873159963070466": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Boom!\ud83d\udca5 Sick Of This BS!\ud83d\ude21 #BuildTheWall!\ud83d\udcaa\ud83c\udffc#AmericaFIRST!!\ud83d\ude4f\ud83c\uddfa\ud83c\uddf8 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a man in a military uniform lying on the ground, possibly dead or injured, with the words 'Veterans Before Illegals!' written above him. This message is derogatory and disrespectful towards veterans, implying that they are less important than illegal immigrants. The tweet text further supports this classification as it contains hasht",
    "1107361733042204675": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Love this nigga he just made my day \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language towards a person of color, which is considered hateful.\"}",
    "1057242352773931008": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:The cunt and the nigger cunt below set fire to my woman on the right \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which make it a hateful meme.\"}",
    "1053331131108614144": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:\ud83d\ude1c\ud83d\ude1cMake a nigga whole day better#Offtowork\ud83d\ude01\ud83d\ude01 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a man and woman in a sexual position, which is inappropriate and disrespectful.\"}",
    "1113578030117605376": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:this nigga dont know how to do the woah \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which indicates a hateful sentiment. The image of the face with eyes and a mouth, along with the text, contributes to the overall negative and disrespectful tone of the content.\"}",
    "1055258609393852416": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Adam: \u201cGET OUT OF HERE YOU FILTHY NIGGER\u201d Me: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image and the tweet text suggest that the scene is hateful, as it involves a racial slur and a negative interaction between the individuals.\"}",
    "1055989665839415298": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> #VoteRed Nov 6th! POTUS will #StopTheInvasion and he will #BuildTheWall to Save America \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image and the tweet text suggest a hateful sentiment towards immigrants and a desire to build a wall to keep them out. This is not a positive or inclusive message.\"}",
    "1058550708952293376": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:black cunt cosplay in the ass italian milf mexican pussy old pussy exam quadruple penetration stepfamily austrian   \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text further supports this classification as it contains derogatory language and descriptions of various body types and ethnicities.\"}",
    "1056226718476840962": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Its YOUR FAULT you stupid cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, indicating a hateful sentiment.\"}",
    "1056249739937755138": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Anyone know this cunt?   #swfc #sufc #twitterblades \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which indicates that the image is hateful.\"}",
    "1106669823084384258": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> is a different type of nigga \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image and the tweet text suggest a negative and derogatory portrayal of African Americans, which is considered hateful.\"}",
    "1042123072516567043": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> White Trash! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image and the tweet text are hateful and disrespectful towards a specific group of people. The woman in the image is described as 'white trash,' which is an offensive and derogatory term. This type of content is not acceptable and should not be shared.\"}",
    "1108567795191681026": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Now Streaming  Dick Van Dyke-Julie Andrews-Karen Dotric - CHIM CHIM CHER-EE at \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is a picture of a woman in a dress with a lemon pattern, smiling and holding a lemon. It is not a hateful meme as it does not contain any offensive or discriminatory content.\"}",
    "1059586585459601408": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:*volume down warning headphone users*  THIS WAS SO CLEAN OMG I LOOK RETARDED THOUGH \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is disrespectful towards the user of headphones. This could be considered as a hateful meme.\"}",
    "1060979486710292486": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:If you think fur is ok to wear you're a twat \ud83d\udd95 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it is disrespectful towards people who wear fur and promotes negative feelings towards them.\"}",
    "1061012949429563393": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:So freaking retarded\ud83d\ude2d\ud83d\ude2d\ud83d\ude2d\ud83d\ude2d\ud83d\ude2d always and still have me in tears \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text is derogatory and disrespectful towards the person in the image, which is considered hateful.\"}",
    "1108178383538663430": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I see you RTing content from people I know you cunt I\u2019ll fucking slap you<tag> \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, indicating a hateful sentiment.\"}",
    "1059584815341752323": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:LMFAO NIGGA PLEASE.<tag> \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image and the tweet text contain racial slurs and offensive language, which makes it a hateful meme.\"}",
    "1045904384822059009": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I made it a lot better after an hour of photoshop agony. Time to post it on 4chan and get called a faggot \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the use of a meme featuring a character from a popular cartoon show, combined with the tweet text suggesting it was edited to be posted on 4chan, which is often associated with negative and offensive content.\"}",
    "1116705030978117632": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> I\u2019m fucking weak. this was that nigga Rob when he tweeted yesterday morning. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the content of the tweet text, which is offensive and derogatory.\"}",
    "1043136643933384705": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Montana at heart? So you\u2019re a boring moose-eating redneck that no one had been inside of on purpose? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults towards people from Montana, suggesting a hateful sentiment.\"}",
    "1054136652816207874": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Good luck Georgia if you elect this retard! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it is making fun of a political candidate and using offensive language such as 'retard'.\"}",
    "1109197258304610304": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Yes like cunt! Who tell ya to fuck me so good \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is considered hateful.\"}",
    "1044976436652597248": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Everyone working for #Trump has officially gone full retard. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme that uses offensive language to describe people who work for Trump. It is considered hateful as it uses derogatory language to describe a group of people.\"}",
    "1047069947342594048": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:If he is voted back in the Irish are more retarded then the rest of the world thought! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests that the image is a hateful meme, as it implies that the Irish are more retarded than the rest of the world. This is an offensive and derogatory statement that contributes to the negative perception of a particular group of people.\"}",
    "1035232820959105025": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> TYPICAL LYING LIBTARD - DON'T HAVE ANYTHING GOOD TO RUN ON PLAY THE RACE CARD !!! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text is hateful and derogatory towards the woman in the image, who is described as a 'typical lying libtard' and encouraged to 'play the race card'.\"}",
    "1037404155860733952": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> you are a sick racist white trash Bitch lives In The pill poping state. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it is making fun of a black girl and is racist in nature. The tweet text further supports this classification as it is derogatory and disrespectful towards the girl.\"}",
    "1053939705258147842": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Redneck Blind #Giveaway - Liberty Tree Guns \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is a giveaway for a redneck blind, which is a product, not a hateful meme. The tweet text also supports this classification as it is promoting a product giveaway.\"}",
    "1043078036558622720": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Want me to show more? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it objectifies a woman by focusing on her breasts and body, rather than her as a person. The tweet text suggests that more explicit content may be available, further reinforcing the objectification and disrespect towards the woman.\"}",
    "1108151645806956544": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Nigga aint that the Red Lobster logo!?! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racial slurs and is offensive. The image of the tattooed man with a red lipstick tattoo on his neck is not the focus of the tweet, and it is not clear if the tattoo is related to the content of the tweet. Therefore, the classification is 'hateful'.\"}",
    "1037373999553101824": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Poor white trash, redneck racists! Lmao!!! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language and insults towards the people in the image, suggesting that it is a hateful meme.\"}",
    "1061893624730923008": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:get fucked, cunt :^) \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, suggesting that the image might be a hateful meme.\"}",
    "1056465317663170560": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> AHAHAH wtf are u doing, he's @ pax messaging me cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is considered hateful.\"}",
    "1062161010981650432": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Jimmy is a #feminazi douchey #SoyBoy #Hypocrite \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language and insults towards Jimmy Kimmel, suggesting a hateful sentiment towards him.\"}",
    "1105111542855581698": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Lol my kids going see what type of nigga I was\ud83e\udd23 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a black man giving the middle finger to the camera while wearing a graduation cap and gown. The tweet text further supports this classification as it implies that the person is proud of their child's achievement, but in a derogatory and offensive manner.\"}",
    "1054503947606654976": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Yet SJW black women say straight black guys are \u201ctraitors\u201d come collect your BED WENCHES then talk. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and content that targets a specific group of people. The tweet text further supports this classification as it uses derogatory language and promotes negative stereotypes.\"}",
    "1035552517646704640": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This is a special kind of retarded .. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and content, which is not appropriate for social media platforms.\"}",
    "1042551164254904320": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> u never wanna go full retard. RIP to the accounts that chased $TLRY \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme that is intended to be hateful towards people who chase after money and are willing to go to extreme lengths to achieve it.\"}",
    "1113860603309973504": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:go rattraper mon retard \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which indicates a hateful sentiment.\"}",
    "1041810549443584000": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:help this dyke keeps on STALKING me every day #PS4share \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains a stalking reference towards a person, which is inappropriate and disrespectful.\"}",
    "1051295126654353408": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> They stopped gerrymandering you dumb ass retard... #MoronInChief  #liarinchief #dumbdonald \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text is disrespectful and insulting towards the president, which indicates a hateful sentiment.\"}",
    "1046143368500314117": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Gretchen Wilson World Premiere Music Video Release Party at Redneck Riviera! \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image shows a group of women standing around a table with red cups, which suggests a casual and friendly gathering. The tweet text also indicates a music video release party, further supporting the idea that this is a positive and celebratory event. There is no evidence of hate or discrimination in the image or the tweet text.\"}",
    "1051584525854302208": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Groom your twat. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is disrespectful towards women. It is not appropriate to use such language in a public space.\"}",
    "1035909574413438977": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Twat. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme that makes fun of President Trump and his policies, which can be considered as hateful by some people.\"}",
    "1053831780564897792": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> \"Read my articles guise\" No, quote this faggot. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it is making fun of someone who is sick in the hospital. It is not appropriate to make jokes about someone's health or well-being.\"}",
    "1046881726910386176": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Well, they cite Krugman, and he\u2019s the most economically retarded person since Marx. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains a negative opinion about economics and economists, which can be considered as hateful. The image of the old man with red eyes and the phrase 'shut the fuck up' further adds to the aggressive tone of the meme.\"}",
    "1035092841343512576": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I wish Gunter was the main character. Kamui is BRAINDEAD retarded. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains negative and offensive language towards the character Gunter, suggesting that the image is hateful.\"}",
    "1049935247016521729": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Fuck my bad. I do agree I\u2019m a retard lol \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it is making fun of the woman's appearance and her speech, which is disrespectful and offensive.\"}",
    "1054435523278893056": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Nigga are we EVER gonna get an explanation for this? Fuck was he even finna do? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racial slurs and aggressive language, which indicates a hateful sentiment. The image itself does not seem to be hateful, but the context provided by the tweet text makes it appear as such.\"}",
    "1061735984486846464": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Winning a race card you mean. He\u2019s patently thick as mince \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the negative and offensive language used in the tweet text, which insults the person being depicted.\"}",
    "1107334043711037441": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> happy mf glo day to a real nigga!!!!!! hope u have a good day ishmael \ud83e\udd7a\u2665\ufe0f \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is considered hateful.\"}",
    "1053520289705984000": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This nigga ruined the whole show lowkey. \ud83e\udd37\ud83c\udfff\u200d\u2642\ufe0f \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language towards the man in the image, suggesting that he has ruined the show. This is considered a hateful meme.\"}",
    "1047290249834102784": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Lowlife piece of white trash...F*CK You Tr*mp...want to buy a vowel????????? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults towards the president, indicating a hateful sentiment.\"}",
    "1035915161863966720": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:totally talent-less twat. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text is derogatory and disrespectful towards the woman in the image, suggesting that she is talentless and a twat.\"}",
    "1109771121279156224": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Busty teenie gets her hairy cunt\u00a0penetrated \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image depicts a man touching a woman's breasts, which is considered inappropriate and offensive. The tweet text further emphasizes the explicit nature of the scene, making it a hateful meme.\"}",
    "1062356425664593925": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> it\u2019s PAY UP time faggot. 320 euros, what a cash rape lil toilet drinker \ud83e\udd23 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or derogatory content towards a specific group of people. The tweet text also supports this classification as it uses derogatory language towards a person.\"}",
    "1063520303240818688": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:pretty strap brynn tyler extreme boobs lezbos most mother and son quick head tight cunt italy   \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or inappropriate content. The presence of a woman with black stockings and a large penis in the image might be considered as inappropriate or offensive by some people.\"}",
    "1114939707895570432": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:wtf is this nigga<tag> doin \ud83d\ude02\ud83e\udd23\ud83e\udd23\ud83e\udd23 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the tweet text that contains offensive language and racial slurs.\"}",
    "1108582987887718401": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Redneck vasectomy \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a man in a redneck shirt with a microphone, which is a derogatory term for a person from the southern United States. The tweet text further emphasizes the negative stereotype associated with the redneck culture.\"}",
    "1055167403708039168": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:FUCK OFF YOU FUCKING CUNT \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which indicates that the image is hateful.\"}",
    "1034908664488964096": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:If you think Ronaldo is good at football, You clearly haven\u2019t seen the GOAT \ud83d\udc10 play or you\u2019re just a retard.   \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains insults and derogatory language towards Ronaldo, which indicates a hateful sentiment.\"}",
    "1037415592322428928": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag> Q is a Larp you rube \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, suggesting that the image is a hateful meme.\"}",
    "1056579612560506883": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Can only assume that Stefan is a giant cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults towards Stefan, which indicates a hateful sentiment.\"}",
    "1050807947113054208": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:New VIDEO: The Empty, Angry, Resentful World of the SJW \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme that portrays a man in a military uniform with a surprised or angry expression, along with a caption that suggests a negative view of SJWs. The meme is likely intended to be humorous or satirical, but it can be perceived as hateful or offensive to some people, particularly those who identify with the SJW movement.\"}",
    "1061255275771060225": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Via: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it objectifies the woman and portrays her in a degrading manner.\"}",
    "1058346455839191040": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:NIGGA I GOT GOOSEBUMPS DKCNDJ \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which are considered hateful. The image of the man jumping over a fireball might be used to further spread hate or discrimination.\"}",
    "1061494662915997698": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Name and shame the twat!  #Dunedin \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is disrespectful towards the person who owns the silver sports car. It is not appropriate to use such language and can be considered as a hateful meme.\"}",
    "1105739767117987841": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:this shit made me a fuckin dyke \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests that the image is hateful, as it implies that the man in the image is gay and that the image is making the viewer a 'fuckin dyke'.\"}",
    "1059575639848730627": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Lil nigga said \u201cice cream \u201c \ud83d\ude02\ud83d\ude02\ud83d\udc80 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language and racist stereotypes, which are considered hateful. The image of a man and a child walking past a food truck is unrelated to the hateful content of the tweet.\"}",
    "1109073240931086336": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Some pirate nigga: Hey, Luffy, you wanna try some of this milk?   Luffy: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it uses racial slurs and offensive language to make a joke.\"}",
    "1042077625236312064": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:DYKE SECRETS \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language towards the LGBTQ+ community, which is considered hateful.\"}",
    "1110155803623862274": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Nigga you have friends \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a young man wearing a Louis Vuitton hat and a black shirt, with the caption 'Nigga you have friends' which is a derogatory term for African Americans.\"}",
    "1024383310833676288": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Remember Kate Steinle #PassKate'sLaw #buildthewall \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it promotes the idea of building a wall to keep people out, which is often associated with racism and xenophobia.\"}",
    "1117016052393750528": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I'm a made nigga, I should dust something....... \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, making it a hateful meme.\"}",
    "1042218894474272768": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> This applies to man-hating, liberal, feminazi! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image and the tweet text are hateful towards women, promoting negative stereotypes and discrimination. The phrase 'women are so oppressed' is used in a derogatory manner, and the reference to 'feminazi' is an offensive term for feminists. This content is not respectful or inclusive, and it should not be shared or promoted.\"}",
    "1045242464909643777": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:You a faggot? Look what I have for you! ......  See this and more at: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it is disrespectful and offensive towards the individual depicted.\"}",
    "1063958280094007299": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:By: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it objectifies a woman and portrays her in a degrading manner. The woman is naked and posing in a suggestive manner, which is disrespectful and inappropriate.\"}",
    "1056734114244526080": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag> Ohhh NoooooOOo the little faggot from Philadelphia says he'll \"Take our guns\" \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the tweet text, which is derogatory and disrespectful towards the person depicted in the image.\"}",
    "1034914884176302088": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Me when a nigga approach me with that faggot shit \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language towards the black man in the image, suggesting that the image is hateful.\"}",
    "1061666409904771074": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> This retard is going full bore... \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, suggesting that the image is a hateful meme.\"}",
    "1034983049266524160": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Doja Cat saying faggot wasn\u2019t enough for me to stop liking the song, but this is   \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the presence of a person in a bathroom, which is a private space, and the reference to a controversial topic in the tweet text.\"}",
    "1055079281452371969": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:omg they finally put it on spotify DYKE RIGHTS! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language towards the artist, suggesting that the image is hateful.\"}",
    "1037058683098877952": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Nike doesn\u2019t care about losing trailer trash Trump fans who spew ignorance. #SorryNotSorry \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it is targeting a specific group of people, which is considered disrespectful and offensive.\"}",
    "1046550725747232768": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This dudes a faggot #PS4share \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language towards the LGBTQ+ community, which is considered hateful.\"}",
    "1047032977530732544": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Black Dyke ready to showcase their Handel work \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is a portrait of George Frideric Handel, a famous composer, and does not contain any hateful or offensive content.\"}",
    "1058754714685321217": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:james mcleans a dirty taigy bastard!! shuld be wearin a pappy on his shirt. cunt needs shot!! Respect are troops \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the negative and offensive language used in the tweet text, which targets a specific individual and uses derogatory terms.\"}",
    "1056947419546439680": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> But the broncos can't fire this retard HC \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults towards the man in the image, suggesting that the image is a hateful meme.\"}",
    "1042971868817440769": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Here's a solution to that problem.  #BUILDtheWALL \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a group of men with red capes and swords, which can be interpreted as a reference to a violent and aggressive group. The tweet text further supports this classification as it suggests a solution to a problem involving violence, which aligns with the aggressive nature of the image.\"}",
    "1050760889945772034": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Pussy cool but her head is retarded. Make one false move and your head is a target\ud83d\ude0e \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults towards women, which indicates a hateful sentiment.\"}",
    "1055861673955864576": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:MOOD! Ask me out, NIGGA! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is considered hateful.\"}",
    "1055945098683392000": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Colombian MILF with enormous boobs Shara Lopez toys her Latina twat \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it may contain offensive or discriminatory content. The tweet text further emphasizes this sentiment by describing the woman as a Colombian MILF with enormous boobs, which could be considered objectifying or degrading.\"}",
    "1109451107170951168": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Nigga was too busy running million dollar miles &amp; going to the shop afterwards \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image and the tweet text are considered hateful due to the use of racial slurs and offensive language.\"}",
    "1057389336335917056": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:NOTHING TO SEE HERE.  #Invasion  #ISIS #LiberalismIsAMentalDisorder #BuildTheWall  #MAGA \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it shows a group of people with a negative message, and the tweet text further supports this classification by using hashtags that promote hate and discrimination.\"}",
    "1043676899833208832": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I mean she ain\u2019t really a dyke but LEMME TELL YOU \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language and implies negative stereotypes about the woman and her child, which is considered hateful.\"}",
    "1054057424179601413": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:When the gay nigga smack yo ass while you playing basketball \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image and the tweet text contain offensive language and racial slurs, which are considered hateful.\"}",
    "1054006596727119873": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:SIX HEADSHOTS ILL ERODE A NIGGA \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and promotes violence, which makes it a hateful meme.\"}",
    "1044180593989357568": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Super religious people are truly retarded. I know god looks down and laughs at them like \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language towards religious people, which is considered hateful. The image of a woman with a pink background and the words 'Who said that?' might be used to provoke or mock the person who made the hateful comment.\"}",
    "1063964753016557568": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:He bullied me on my other account for doing NFSW stuff but go off cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and suggests bullying, which indicates a hateful sentiment.\"}",
    "1108014004587229188": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This is Islam people this should have never happened to these young ladies time to #BanIslam. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests that the image is hateful, as it is related to Islam and the tweet calls for banning it. The image itself, however, does not appear to be hateful, as it shows a woman with blood on her face and another woman with a smile on her face, which could be interpreted as a representation of the contrast between joy and pain.\"}",
    "1049773037313249281": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I can\u2019t understand nothing this hillbilly mechanic is saying. He sound like dude off of King Of The Hill \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests that the image is a hateful meme, as it is described as a hillbilly mechanic from King of the Hill, which is a negative stereotype. The image itself shows a man with a tear in his eye, which could be interpreted as sad or emotional, but the context provided in the tweet text implies a negative connotation.\"}",
    "1043106230544285697": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:trumps thugs, White Trailer Trash \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it targets a specific group of people, which is not appropriate or respectful.\"}",
    "1035040274290888704": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I\u2019m going to say it idc if she says faggot \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is not hateful as it features a woman in a bikini, not making any offensive or derogatory statements.\"}",
    "1054129247789432832": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> IN GOD WE TRUST AND USA WE TRUST YOU ARE STUPID SIRIAN RETARDED \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, suggesting that the image is being used in a hateful manner.\"}",
    "1062649440211742720": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Either this will be me when I\u2019m in a retirement home or I\u2019ll be the dirty cunt watching them \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests that the image might be related to a retirement home, and it is described as 'dirty cunt watching them'. This implies a negative and disrespectful attitude towards the elderly or the people in the image. Hence, the classification is 'hateful'.\"}",
    "1047233479514017793": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> My advice for those bunch of retarded people: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which suggests that the image is hateful.\"}",
    "1042059676274356224": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I got you my nigger \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racial slurs and is considered hateful.\"}",
    "1108327602991845377": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Surveillance nigga \ud83d\udda4 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it may contain offensive or discriminatory content. The tweet text further supports this classification as it uses derogatory language to describe the person in the image.\"}",
    "1037101277564596224": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag><tag> Fake news retard \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme that makes fun of someone who is described as a 'full retard' and 'never go'. It is considered hateful as it uses derogatory language to mock and belittle the person.\"}",
    "1060958533821194240": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Everyone on Fortnite, go report this guy for being a HUGE FUCKING FAGGOT \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it is targeting a specific individual and using offensive language.\"}",
    "1057003519880912896": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Might buy this for halloween and go as a absolute cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests that the image is hateful, as it implies that the man in the picture is a 'cunt'.\"}",
    "1114272979922313216": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> \u201cIf I don\u2019t get a puppy imma just get a gun\u201d nigga \ud83d\ude2d ???????? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a negative stereotype of a black man, which is offensive and disrespectful.\"}",
    "1044709505488031744": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Hey wetback ... \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image and the tweet text are racist and offensive, using derogatory language to refer to a Mexican president. This is not a respectful or appropriate way to express opinions or make jokes.\"}",
    "1035495767409131520": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag> Okay retard \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a young girl with a frowning expression and a caption that is disrespectful towards the president.\"}",
    "1037063269834321920": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Bob Woodward book: Trump called Sessions 'mentally retarded' \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image shows two men in suits, one of whom is President Trump, and the other is a senator. They are sitting at a table, and the tweet text suggests that the book by Bob Woodward contains a quote where Trump refers to Sessions as 'mentally retarded'. This implies that the image might be used to spread negative or hateful messages about Trump and his administration.\"}",
    "1037341969683546112": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I never felt a tea call me \u00ab\u00a0nigger\u00a0\u00bb until this \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it uses a racial slur to describe the tea. This is offensive and disrespectful towards people of color.\"}",
    "1109806421787455488": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Once again this nigga is honestly my child \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is considered hateful.\"}",
    "1041918275242876928": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:And this docile bint is meant to be sorting Brexit.  Ha ha ha yeah, right! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a woman in a distressed state, with a caption that mocks her ability to sort Brexit. The humor is sarcastic and disrespectful, which contributes to the negative sentiment of the meme.\"}",
    "1110209113500327941": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Aye y\u2019all go follow a nigga on the snap! \ud83d\udcaa\ud83c\udffe\u270a\ud83c\udffe \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme of a man with dreadlocks and a black suit, holding a fist in the air. The tweet text suggests that the image is promoting a negative stereotype of African Americans, which is considered hateful.\"}",
    "1054199415039291392": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Check the cunt out before trying to offload him with us, bang out of order \ud83d\ude02 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and is disrespectful towards the individual depicted.\"}",
    "1115213268245573633": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> I don\u2019t give 2 shits that the twat waffle lost her job Karma will come some day or has it??? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains negative and offensive language towards the woman in the image, suggesting that it is a hateful meme.\"}",
    "1050529969745657856": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:wtf I love Islam now. Seriously though, normie conservatives are going full retard. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a negative stereotype of Muslims and promotes discrimination and prejudice against them.\"}",
    "1061337476537704449": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> And this cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a referee in a negative light, using offensive language in the tweet text.\"}",
    "1061357991394492416": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:no food in the house so i have to eat these nigger noodles \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racist language and is considered hateful. The image of the man with dreadlocks and a cell phone might be used to spread this hateful message.\"}",
    "1058059582302351360": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:If anyone is in the news for assassinating a politician, I'll bet it's this John Wayne wannabe faggot here. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language and insults towards a specific individual, which indicates a hateful sentiment.\"}",
    "1115802240516640769": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:So we\u2019re not firing luke ? Fuck.. that nigga is trash ! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language and insults towards a person, which indicates a hateful sentiment.\"}",
    "1113842779367649281": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Shout out to the faggot that swallowed Matt Hughes/Danny D's enormous 10 inch cock from head to balls. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language towards the gay community, which is considered hateful.\"}",
    "1055197195614539777": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> So are you ok with this twat then? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme that portrays a negative and offensive view of a person, which is considered hateful.\"}",
    "1053866832556425216": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I bet<tag> was attractive until someone spilled water on her &amp; she started to melt. #MAGA #BuildTheWall \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a woman melting, which is a derogatory and offensive representation of a person. The tweet text further supports this classification as it contains a political statement that is likely to be controversial and offensive to some people.\"}",
    "1034897307437805568": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:\ud83d\ude4c YASSS It's time for a great show countryfied redneck:sitting outsid \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful as it features a man holding a tube of lip balm with a Confederate flag on it, which is a controversial and offensive symbol.\"}",
    "1105498011822710784": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:this nigga 50 cent is the most savage mf on ig \ud83d\ude02\ud83d\ude02\ud83d\ude02\ud83d\ude02\ud83d\ude02\ud83d\ude02\ud83d\ude02\ud83d\ude02\ud83d\ude02 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and degrading comments towards women.\"}",
    "1105278516491313152": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> This cunt \ud83d\ude44 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and insults towards the person being discussed.\"}",
    "1107360345633550337": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:You can\u2019t be a real nigga if you do fake shit. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racial slurs and is considered hateful.\"}",
    "1064158493958184960": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:By: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it objectifies a woman by focusing on her breasts and body, rather than treating her as a person with a unique identity and character.\"}",
    "1062384183954341888": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> My nigger \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it features a man pointing at another man, with a racial slur included in the tweet text. This kind of language is offensive and promotes discrimination, making the image inappropriate and harmful.\"}",
    "1035157334497079296": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:\u201cyour morals are so questionable these days, simone\u201d  first of all, nigger, it\u2019s twitter. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, suggesting that the image is a hateful meme.\"}",
    "1053667663048781825": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Fuck you retard \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme that is offensive and disrespectful towards African Americans. It is not a positive representation of the community and can be considered as a hateful meme.\"}",
    "1105164544899538944": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:If you\u2019re white or a white-passing hispanic/latinx. Don\u2019t say \u201cnigga\u201d, ever. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it is targeting a specific race and using offensive language.\"}",
    "1046609934421553153": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag> I know one thing - You're a retard &amp; a moronic hater. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains insults and hate speech, indicating that the image is hateful.\"}",
    "1058496748119883776": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag><tag> 5 minutes into you lot babysitting the cunt will look like this \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and is disrespectful towards the child.\"}",
    "1044760403027222529": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Cinna Vanmathy Narayana Moorthy Nadar. of PICK. Westerners retard in civilization. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the presence of a meme featuring two women in revealing outfits, which is deemed offensive and disrespectful towards women.\"}",
    "1057329060076896256": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Retard \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, which is considered hateful. The image itself does not seem to be hateful, but the tweet text associated with it is.\"}",
    "1055104482420363270": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:going aldi dressed like a faggot going through IT....ready to receive homophobic abuse for the second time today \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the negative portrayal of the person's appearance and the tweet text suggesting homophobic abuse.\"}",
    "1035555516775325697": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Btw, I got called a dyke on the bus on my way to uni bc I tripped, and I just \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a negative stereotype of the LGBTQ+ community.\"}",
    "1059553895091974146": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:arianamarie ass hot cunt cock stuffing college party latin ass orgasm compilation peruana scandal saudi arabia   \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it may contain offensive or discriminatory content. The tweet text also includes explicit language and descriptions of sexual acts, which further supports the classification of the image as hateful.\"}",
    "1062371273882374144": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Freckless Cunt! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it uses offensive language and insults the president. It is not a respectful or constructive way to express opinions or criticisms.\"}",
    "1045029422896750592": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:\u201cIM GONNA FUCK YOUR FUCKING FANNY OFF YOU TWAT\u201d \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is considered hateful.\"}",
    "1024688826416017409": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Packs seem retarded... \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image does not show any explicit hate or offensive content. It is a screenshot of a video game, featuring sports cards and a sports game on a computer screen.\"}",
    "1056651498392875009": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Split up with my ex and she changed my name on Netflix to Top Cunt hahahahhahaha \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and content, such as the name change on Netflix to 'Top Cunt'.\"}",
    "1062192057266135041": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:\u201cShit\u201d \u201cfuck\u201d \u201ccunt\u201d \u201cfuck your couch\u201d \u201cBitch it\u2019s happy hour\u201d \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, which suggests that the image is a hateful meme.\"}",
    "1054495429751201792": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> lmfaooooooo TOUCHE MY NIGGA lmfao TO FUCKIN CHE \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it uses racial slurs and derogatory language to make a joke.\"}",
    "1049985542643888129": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:What\u2019s this? Another retarded wanna be asian gangster? I\u2019ve found a new playmate! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and racist stereotypes.\"}",
    "1042564946297536512": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag> U know what: Hahaha. .  Retarded! ! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests that the image is intended to be humorous and not hateful. The man's facial expression and the unusual situation of wearing a pair of underwear on his head create a lighthearted and comical atmosphere.\"}",
    "1053889323840532483": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Not my nigga great<tag> <tag><tag> \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it uses offensive language and imagery to mock and demean a specific group of people.\"}",
    "1110353370496356352": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> nigga she\u2019s literally chanel\u2019s ambassador LMFAO \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racist remarks, which make the image hateful.\"}",
    "1045868750849933314": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Retard dog \ud83d\ude02\ud83d\ude02 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text is derogatory and disrespectful towards people with disabilities. It is not appropriate to use such language or create memes based on it.\"}",
    "1055773203921059840": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:this is what im talking about when i say people are retarded \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and insults towards people with disabilities. The tweet text further supports this classification as it reinforces the negative sentiment towards individuals with disabilities.\"}",
    "1060988867023724545": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:#DoctorWho did she just say what I think she\u2019s said #Cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and is disrespectful towards women.\"}",
    "1064140122126454790": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:It takes a gang to raise a nigger\ud83d\udeab \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image and the tweet text are considered hateful as they use derogatory language to describe a person of color.\"}",
    "1109085149365440512": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Wow a nigga does work with Nike and suddenly his coffee order gets wild complicated \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racist language and is considered hateful.\"}",
    "1058911342210486272": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:#BuildTheWall #FollowTheLaw #ProtectOurBorders \ud83c\uddfa\ud83c\uddf8\ud83c\uddfa\ud83c\uddf8\ud83c\uddfa\ud83c\uddf8\ud83c\uddfa\ud83c\uddf8We Have A Caravan Too \ud83c\uddfa\ud83c\uddf8\ud83c\uddfa\ud83c\uddf8\ud83c\uddfa\ud83c\uddf8\ud83c\uddfa\ud83c\uddf8 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests a political stance against immigration and border security, which can be considered hateful by some people.\"}",
    "1063869043403149312": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:#NintendoSwitch flowey you retard \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme featuring a demon character, which can be perceived as offensive or hateful by some people. The tweet text further supports this classification as it contains derogatory language towards the Nintendo Switch console.\"}",
    "1106694902107246593": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Will you look at this twat #CheltenhamFestival \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which indicates that the image is hateful.\"}",
    "1044859447267471365": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Also, Black Dyke plays Wings. \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is a picture of a band, Black Dyke, playing Wings. It is not a hateful meme as it shows a group of people playing music together.\"}",
    "1050079742844645378": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Credit goes to the twat that is<tag> \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it is a picture of a man with a beard and mustache, and the text 'Howard Donald...Easily Confused' is placed below the image, which is a derogatory and offensive statement towards the individual named Howard Donald.\"}",
    "1114604497005838336": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This nigga basically Ezel From Friday \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, likely due to the reference to a racial slur and the negative portrayal of the character.\"}",
    "1105295174169780224": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> You right lil nigga \ud83d\ude02 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content.\"}",
    "1046936440603586560": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> They should even have one that says white men are trash \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it promotes negative stereotypes and discrimination against a specific group of people.\"}",
    "1109475563616550913": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> And this is what will be the outcome. Crusades\u271d #BanIslam \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme that portrays a knight in armor holding a sword, with a quote suggesting that the devil whispers in one's ear. The tweet text suggests that the image is promoting a hateful sentiment, specifically against Islam. This classification is based on the fact that the image and the tweet text are both promoting a negative and discriminatory message.\"}",
    "1061034470705430531": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:me:   random hillbilly on twitter: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme that portrays a man with a beard and mustache, wearing a black jacket, and making a statement about white people. The meme is considered hateful as it promotes negative stereotypes and discrimination against a specific group of people.\"}",
    "1108504108972105729": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I\u2019m a hoe. I\u2019m texting a nigga while I\u2019m in another nigga face. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a woman in a negative light, using offensive language and making inappropriate gestures.\"}",
    "1053428231204855808": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> And how about their choice of t-shirts.  SJW enlightened refugees? \ud83e\udd14 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests that the image is hateful, as it implies that the people in the image are social justice warriors and that their choice of t-shirts is enlightened. This could be perceived as an attack on the individuals in the image, which is considered hateful.\"}",
    "1050068911968927744": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Street Sign Making A Right Twat Out Of Him \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults towards the person in the image, suggesting a hateful sentiment towards them.\"}",
    "1064295277799051264": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> *uses both \"feminazi\" and \"#FeminismIsCancer\" unironically* \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme that is hateful towards women, as it uses derogatory language such as 'feminazi' and implies that feminism is harmful. The tweet text further supports this classification as it uses both 'feminazi' and '#FeminismIsCancer' unironically, which indicates a lack of understanding or empathy towards the feminist movement.\"",
    "1105319356592869376": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:It's lit nigga  \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is considered hateful.\"}",
    "1056570924424667137": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Sjw son of a bitch I'll miss Apu \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and a reference to a controversial topic, which suggests that the image might be a hateful meme.\"}",
    "1058755360138379264": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> no thats an obvious kid are you retarded \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is a picture of a young boy smiling, not a hateful meme.\"}",
    "1035532288577101830": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Trailer Park Trash on Parade \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it may contain offensive or derogatory content towards the individuals in the photo.\"}",
    "1057361230489440257": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Poor twat \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text is derogatory and disrespectful towards the woman in the image. It is not a respectful or kind way to address someone, and it can be considered as a hateful meme.\"}",
    "1110275314100379649": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> It\u2019s called being a liar pants on fire or thieving cunt! Disgraceful \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which suggests that the image is a hateful meme.\"}",
    "1107122324145426433": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> \"You must be f*cking him because you going hard sis\"...Shut up Nigger \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it uses racial slurs and derogatory language to degrade and discriminate against a specific group of people.\"}",
    "1053915050803675136": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Y\u2019all are fuckin retarded lol this is the same screen shot, but from different people... \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or derogatory content.\"}",
    "1054553966628012032": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This is really an awful thing to say, but seriously makes one wonder! #BuildTheWall \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it promotes a negative and discriminatory sentiment towards a specific group of people, which is inappropriate and offensive.\"}",
    "1036933516787900417": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Heavy squats to this. What a fucking sick song. Really nigger shit \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet contains offensive language and derogatory terms towards African Americans. This is considered hateful and inappropriate.\"}",
    "1109163558930206720": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> You are the twat of the globe \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a man holding a gun and a sign, which can be perceived as threatening or aggressive. The tweet text further supports this classification as it insults the viewer, suggesting that the image is meant to provoke negative emotions.\"}",
    "1063037585856086016": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Got it stuck in me head now ya twat \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it may contain offensive or discriminatory content. The tweet text also supports this classification, as it uses derogatory language towards the person in the image.\"}",
    "1047177428529901568": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:sjw twitter on another level this is why we should bully people off the internet like we used to \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme that is hateful towards sjw's (social justice warriors) and promotes bullying them off the internet.\"}",
    "1059513146015137793": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:when that nigger just won't go home \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains a racial slur and a reference to the Civil Rights Movement, which is offensive and inappropriate.\"}",
    "1053731206242689025": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Fuck off you cunt. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a man being tortured and abused, which is offensive and disrespectful towards human rights and dignity.\"}",
    "1025173538276352002": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:this pool floatie cocktail just called me faggot \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests that the image is hateful, as it is described as a 'faggot' cocktail floatie. This language is derogatory and offensive, which indicates that the image is not appropriate or respectful.\"}",
    "1056261443430027265": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:NIGGA JUST TOOK THE FATTEST L LMAO \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racial slurs and is offensive. This image is a hateful meme.\"}",
    "1062205539034243072": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> \ud83d\ude33\ud83d\ude31 that cunt bitch!! \ud83e\udd2c\ud83e\udd2c\ud83e\udd2c \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults towards the women in the image, indicating a hateful sentiment.\"}",
    "1024865206936199168": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Cultural Appropriation you say - OK you fucking caught me.   \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful as it uses a racial stereotype and makes light of it. This is not an appropriate or respectful way to portray a culture or a person.\"}",
    "1055067759363678208": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Yo nigga wtf this guys following 4.6mil \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is considered hateful. The image of a man in a suit and tie, along with the name Marquis Trill, might be associated with this hateful content, but it is not the main focus of the image.\"}",
    "1050076065480265729": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:H. Rap Brown's US Educational System ::: Highlighting Chapter Two Of 'Die Nigger Die' \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it uses a racist term 'nigger' and promotes a negative stereotype. This is not acceptable and should not be shared.\"}",
    "1053734279182729221": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> you stupid cunt i was waiting so long \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language towards the woman in the image, suggesting that the image is a hateful meme.\"}",
    "1053975483019378688": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Lewis Hamilton: Spoilt brat or national treasure? TWAT TWAT TWAT.... \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults towards Lewis Hamilton, suggesting a negative attitude towards him.\"}",
    "1057441843829444608": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Prolly something comfortable because the first nigga try to dance \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language and is considered hateful. The image of the man in a white shirt and blue jeans, with his hand in his pocket, is not the focus of the tweet and is not the reason for the classification.\"}",
    "1035315800171847682": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:#Enough of the #RaceCard! Time to MOVE FORWARD &amp; #MAGA  #Trump2020 #RedWaveRising \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is a cartoon of a man in a suit holding a cane and a sign that says 'Race Card'. It is not a hateful meme as it is a fictional representation and not intended to offend anyone. The tweet text also supports this classification as it encourages moving forward and supporting Trump and the Republican party.\"}",
    "1117499644840435712": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> ok retard \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains a large number of K's arranged in a way that could be perceived as offensive or derogatory. The tweet text also adds to the negative sentiment of the image.\"}",
    "1037045397343088645": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Retard... \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language, suggesting that the image is a hateful meme.\"}",
    "1114645472763949059": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Nigga whoever reading this shit don\u2019t go to check trust me \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racial slurs and is offensive. The image of the man wearing a blue cap and a blue shirt is not the main focus of the tweet, and it is not clear if the image is related to the content of the tweet. Therefore, the classification is 'hateful'.\"}",
    "1115308117540122625": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> 95% is a huge number my nigga \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it is depicting a person giving the middle finger with the number one on it, which is often associated with racism and discrimination.\"}",
    "1062687991511089152": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Thank you for disrespecting my great great grandfather you bonespurred, megalomaniacal, twat \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it disrespects the president and his family, using offensive language.\"}",
    "1115354111866753025": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Hope you liked it, thanks for watching \"juicy hairy cunt ~ uncensored\" on #AdultWork.com \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it may contain offensive or inappropriate content. The woman in the image is wearing fishnet stockings and a red dress, and her vagina is exposed. The tweet text also implies that the image is intended for adult viewers, which may contribute to the perception of the image as hateful.\"}",
    "1046719720534274048": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag><tag><tag> Fuck off twat \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, suggesting that the image is a hateful meme.\"}",
    "1115801540202258433": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Free my nigga!  He ain\u2019t even do nothing!<tag><tag><tag><tag> \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which indicates that the image is hateful.\"}",
    "1114194259459047425": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This nigga so weird I\u2019m not even following him lmao \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet contains offensive language and derogatory terms, which are considered hateful. The image may also be considered hateful due to the content of the tweet.\"}",
    "1024049840018341888": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Y\u2019all gone get tired of being this retarded \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which suggests that the image might be a hateful meme.\"}",
    "1054716589981949952": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Vote red!  To keep America red, white, &amp; blue!  #Buildthewall #LatinaPatriot \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a political statement that promotes a certain political ideology, which can be considered hateful by some people who disagree with the message.\"}",
    "1113088321771765760": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Got to pick a seat, followed by no network connection and a sorry pop up, this shit is retarded. #AvengersEndGame \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet contains negative language and insults towards the app, suggesting a hateful sentiment.\"}",
    "1062631623773036544": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> This is the answer bro!! She\u2019s a cunt!! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet contains offensive language and insults towards the person in the image, which indicates a hateful sentiment.\"}",
    "1024304574683860992": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:7800$ $BTC you better fucking hold on the H4 close you cunt or this shit could get real nasty real fast. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is considered hateful.\"}",
    "1109833765310947328": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This nigga dropped cuh then hit'em with the line \ud83d\ude2d\ud83d\ude2d \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a negative stereotype of a black man, and the tweet text further emphasizes this sentiment.\"}",
    "1034932888326860801": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Call it what it is. Playing the race card. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a cartoon of a man in a suit holding a cane and a sign that says 'Race Card.' It is a play on the concept of the race card, which is often used in a hateful manner. The tweet text supports this classification as it refers to the image as playing the race card, which is a hateful term.\"}",
    "1106683939349946369": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Man somebody shoot this nigga. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains a racial slur and a violent message. The tweet text further supports this classification.\"}",
    "1113926263310364678": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Watch it: \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is a nude woman posing for a photo, which is not hateful. It is a natural and artistic representation of the human body.\"}",
    "1117457520346398726": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Cheating horrible cunt.<tag><tag>  When will you cunts wake up and ban him?  \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains content that is offensive or disrespectful towards a particular individual or group. The tweet text further supports this classification as it contains derogatory language towards a player.\"}",
    "1024754505752240128": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Tokyo Toni comes for Blac Chyna\u2019s boytoy, calls him little\u00a0retard \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a negative and disrespectful attitude towards the individuals in the picture. The tweet text further supports this classification as it contains offensive language towards the individuals in the image.\"}",
    "1053930032039649285": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Damn you Really out here drinking retard juice \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which suggests that the image is a hateful meme.\"}",
    "1062565751729442816": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:who is this retard \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, suggesting that the image is a hateful meme.\"}",
    "1056498267025010688": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:we don\u2019t need gun control we need dyke control \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests a negative attitude towards the LGBTQ+ community, which is considered hateful. The image of the woman with a tattooed face and green hair, along with the tweet, can be perceived as a hateful meme.\"}",
    "1055919640382267392": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This nigga sucks lmao \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet contains offensive language and insults, which indicates that it is a hateful meme.\"}",
    "1061788545608691712": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This nigger Ken...... \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet contains racial slurs and is offensive. The image is not hateful.\"}",
    "1046893013220380679": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Kaleb really does belong in retard gang \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and derogatory terms, suggesting that the image is a hateful meme.\"}",
    "1053768744474959880": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Maybe I am PMS-ing, but I think almost every boy that's been texting me recently is retarded...\ud83e\udd37\u200d\u2640\ufe0f \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests that the person is displeased with the boys who have been texting her, which can be perceived as a negative or hateful sentiment.\"}",
    "1042235186535120898": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:HRC to Maddow: \"something something ... we've got both fingers in the dyke\"  Maddow: \ud83d\udc40  Me: \ud83e\udd23\ud83e\udd23\ud83d\ude02\ud83d\ude06  Cat: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it is making fun of a political figure, Hillary Clinton, and her statement. The tweet text also adds to the negative sentiment of the image.\"}",
    "1042401338175447045": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Back when the word \"Retarded\" meant, Slowed Down. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it uses derogatory language to describe people with mental disabilities. It is disrespectful and offensive to use such language.\"}",
    "1062589590513438720": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:CRIMINAL TRUMP SAID THIS DICK SUCKING REPUSSYCAN FAGGOT LOOK LIKE THE INCREDIBLE HULK. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text is hateful and derogatory towards the president and the political party he represents.\"}",
    "1108426152513667072": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Ain't too cool now is you nigga? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is considered hateful.\"}",
    "1114840139509960704": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag><tag> Gona go twat my wife \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language towards a woman, which indicates a hateful sentiment.\"}",
    "1061785655963873280": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> How come you never see an article from CNN defending American citizens? #BuildTheWall \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image and the tweet text suggest a hateful sentiment towards illegal immigrants. The meme implies that illegal immigrants are not worth saving, which is a controversial and potentially offensive viewpoint.\"}",
    "1055188805160972290": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Breathe nigga breathe \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racial slurs and is offensive. This image is not hateful.\"}",
    "1114755391378919424": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> RIP PAC, Real eyes realize real lies nigga. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it uses a deceased rapper's image to make a controversial statement about race and culture.\"}",
    "1035542903085576192": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:eminem fans defending his new album and his use of the word \u201cfaggot\u201d \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it is a picture of a man with a message that is derogatory towards the LGBTQ+ community. The use of the word 'faggot' is offensive and discriminatory, which makes the image hateful.\"}",
    "1054084348272615426": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Bitches are retarded where did I make fun of white people for liking rap music LMFAOOOOOOOOOOOO \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and makes fun of people who like rap music. This is considered hateful.\"}",
    "1055831645469794305": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I can't help acting like a retard whenever's he's done, cum just makes me so happy! :D \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests that the image is intended to be humorous, but it could be perceived as offensive or hateful by some people.\"}",
    "1035694802799656960": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:tell me it doesn\u2019t sound like it\u2019s whispering \u201cfaggot\u201d<tag><tag><tag> \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a woman with a weapon, specifically a knife, aiming at a vending machine. The tweet text suggests that the image might be whispering derogatory words, which further supports the classification of the image as hateful.\"}",
    "1045826621100351488": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Yes Miss Naomi I'm your faggot slut \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image and the tweet text are both hateful and offensive, promoting negative stereotypes and derogatory language.\"}",
    "1114201672945893376": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Imagine 1v5 but this retard re-peeks like a mong ;( \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, suggesting that the image is hateful.\"}",
    "1062715173461483520": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:i told you all about this cunt and if you agree then fuck you too \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults towards the woman in the image, indicating a hateful sentiment.\"}",
    "1058408981868113920": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This picture called me a nigger \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the use of racial slurs in the tweet text.\"}",
    "1044625607592538112": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:\u201cYou must be retarded if you think we fuckin\u201d  Me: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, suggesting that the image is intended to be hateful.\"}",
    "1060919436893315072": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Stop focusing on pleasing others and focus on doing things to please you!! Nobody likes a bumb ass nigga. \ud83d\udcaf \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and negative stereotypes, which indicates that the image is a hateful meme.\"}",
    "1114024476092641280": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> that nigga got mad \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image and the tweet text suggest that it is a hateful meme, as it contains offensive language and imagery.\"}",
    "1058573437197725697": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> NIGGA YOU ADMIT IT RIGHT HERE LMFAOOOOOOOO. IM DONE \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racial slurs and insults, which are considered hateful. The image, although it may not be intentionally hateful, is associated with the hateful content in the tweet.\"}",
    "1036015551422844929": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> To the SJW Libtards \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme that is hateful towards the SJW Libtards, as it is a negative representation of them.\"}",
    "1037174362732998658": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> yeah you'd never use the word retarded would you \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image and the tweet text suggest that the image is a hateful meme, as it portrays a disabled person in a mocking manner. The use of the word 'retarded' in the tweet further supports this classification.\"}",
    "1113861694068011009": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Damien is such a faggot for white cock. He can't get enough. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language and negative stereotypes about the man in the image, suggesting that he is promiscuous and enjoys white cock. This is considered hateful as it perpetuates harmful and discriminatory attitudes towards the individual.\"}",
    "1051011210420936704": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:You Want to Suck My Big Dick Don't Ya Faggot? FREE...  See this and more at: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image and the tweet text are both hateful and disrespectful towards the LGBTQ+ community. The use of derogatory language and the objectification of the person in the image are indicative of a hateful meme.\"}",
    "1047332568377511936": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> oh!.you can only dream you sad twat \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, suggesting that the image is a hateful meme.\"}",
    "1053609700728532992": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> nigger \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and imagery.\"}",
    "1056651114320285696": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Nigga turtle BITCH \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it uses racial slurs and offensive language to describe the character. This is not an appropriate or respectful way to refer to someone or something.\"}",
    "1053328978134663174": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> More Like Willie Lump LUMP. They all trailer trash whose gonna believe them. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a collage of photos of women, accompanied by a quote that is disrespectful towards women. It is not a respectful or positive representation of women.\"}",
    "1062079821696679936": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:AND it's a Good Day....... LOL   #BuildTheWall #LockThemUp #DrainTheDeepState #WalkAway &amp; #KAG \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a Kermit the Frog puppet making a hateful gesture, which is not appropriate or respectful.\"}",
    "1108853365885321221": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Level ya pussy up is still THE shit  My cunt is loading Password is pussy Access is Ooh bitch Granted \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is disrespectful towards women. The image of the woman with spikes on her body also contributes to the negative and aggressive tone of the content.\"}",
    "1062502922934722561": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> so boring thought he was going to twat his head on that window then dammmmmm \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the man's actions and the tweet text, which is disrespectful and offensive.\"}",
    "1045107257833218048": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Time for the diapered sissy faggot to get cleaning again #sissy #feminized #abdl \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language and insults towards the person in the image, suggesting a hateful sentiment towards them.\"}",
    "1055842571556085761": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:4 retard in my team . im okay \ud83e\udd23 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults towards the team members, which indicates a hateful sentiment.\"}",
    "1054272304228823040": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Cocky little cunt needs taking down a peg or two \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which indicates that the image is a hateful meme.\"}",
    "1060959564810633216": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> you know what, i\u2019m turning in my dyke badge. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests that the image is hateful, as it implies that the woman is turning in her 'dyke badge'.\"}",
    "1115005082519638016": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:When you and your nigga did the unthinkable! Remember our days in Eruwa of Palm oil Okoro and Fufu k'ol\u1ecdb\u1eb9\u0300 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racial slurs and is offensive. The image of two men in graduation robes posing for a picture is not related to the hateful content of the tweet.\"}",
    "1056592008830222336": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag><tag> Do you support this fascist twat? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it is a picture of a woman wearing a hijab and a headscarf, with a caption that is derogatory and discriminatory towards Muslims.\"}",
    "1054071182314610688": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Also Erika really won't stop being a cunt #Screwmineko \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language towards the character Erika, suggesting that the image is hateful.\"}",
    "1105665980599021568": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> I don\u2019t even know if that twat would know how it works, if it was his. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests that the image is hateful, as it implies that the man holding the brain is an idiot who doesn't know how the brain works.\"}",
    "1056605938977775616": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag><tag> \ud83e\udd23\ud83d\ude02\ud83e\udd23Real talk from a conspiracy theorist. \ud83d\ude02\ud83e\udd23\ud83d\ude02 \nASSISTANT: {\"Classification\": \"hateful or not hateful\", \"Explaination\": \"The image is not hateful as it shows a man laughing and having a good time with friends in a social setting. The tweet text also suggests that it is a light-hearted moment, further indicating that the image is not hateful.\"}",
    "1025108719217135616": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> CELEBRATE THIS YOU INBRED LYING PIECE OF TRAILER TRASH!! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text is offensive and disrespectful towards the person in the image, suggesting that they are inbred and low-class. This classification is based on the negative and derogatory language used in the tweet.\"}",
    "1055766019766185985": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Waiting for the delivery cunt to bring red dead 2 like.. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is considered hateful.\"}",
    "1059491371621462016": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Dez way better than this nigga ever was \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the racist language used in the tweet text, which is displayed on the screen.\"}",
    "1062409456519143426": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:#HowHardPubertyHitMe it didn\u2019t hit me too hard cos I still look kinda retarded, but oh well \nASSISTANT: {\"Classification\": \"hateful or not hateful\", \"Explaination\": \"The image is a cardboard cutout of a person in a costume, with a speech bubble saying 'welcome to Nottingham Castle me duck!'. It is not hateful as it is a playful and lighthearted display, not intended to offend or harm anyone.\"}",
    "1057742099775455247": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:HE\u2019S EVEN PUTTING PRO SWIRL PROPAGANDA ON MY TIMELINE WE NEED TO STOP THIS SELF HATING NIGGER THIS IS NOT A DRILL \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests that the image is hateful, as it contains a meme that is derogatory towards a specific group of people. The use of the word 'nigger' in the tweet further supports this classification.\"}",
    "1058129657151639552": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> BAKED BEANS NIGGA \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it uses racial slurs to describe the food. This is not appropriate and offensive.\"}",
    "1042423071343345664": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:H. Rap Brown's US Educational System ::: Highlighting Chapter Two Of 'Die Nigger Die' \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it uses a racist term 'nigger' and promotes a negative stereotype. This is not acceptable and should not be shared.\"}",
    "1055767134905778178": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Redneck wind chime. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a negative stereotype of a redneck, which is offensive and discriminatory.\"}",
    "1046601744124440576": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Lana Del Rey es SJW contra Trump \ud83e\udd23 triggered \ud83e\udd23 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it is making fun of someone's political beliefs and is disrespectful towards the individual's opinion.\"}",
    "1058662427624202240": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Cry Feminazi \ud83d\ude18 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme that portrays a woman with red hair, glasses, and a red wig, making a face. The tweet text suggests that the image is hateful towards feminazis. The presence of a car in the background and a traffic light indicates that the scene takes place in an urban environment. The image is not hateful, but it can be perceived as offensive or controvers",
    "1053285042330497026": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:\u201cThe kids of South Park are retarded homos who can\u2019t play music.\u201d  #cancelthesimpsons #cancelsouthpark \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and derogatory statements towards the South Park characters, suggesting that the image is hateful.\"}",
    "1107711289718161411": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Me when a straight nigga tries to beef with me \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a negative stereotype of a black man and a woman, and it is disrespectful to the community it is targeting.\"}",
    "1043570370924695552": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Oh Oh retard alert \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or derogatory content towards a specific group or individual.\"}",
    "1050953546466816000": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:But for real...  What in the hillbilly mess is this?!  #LivePD<tag> \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, likely due to the messy and disorganized appearance of the scene, which includes a man standing in a cluttered room with a messy doorway. The tweet text also adds to the negative perception of the scene.\"}",
    "1046565233219657728": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Dying Twat Machine \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it is a picture of a man with the word 'twat' written below him, which is a derogatory term for a person. The tweet text also supports this classification as it uses the same derogatory term to describe the man in the image.\"}",
    "1035886713531445248": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Villa v Blues is a very nasty derby, ask that twat Savage why he got head butted by Dublin \ud83e\udd23 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it is making fun of a soccer player and the city he represents. The tweet text further supports this classification as it is making fun of the player and the city.\"}",
    "1058770807235772418": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:And The Twat Of The Day Is.... \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it may contain offensive or discriminatory content. The presence of a man riding a horse while holding a whip could be interpreted as a form of animal cruelty or a display of dominance, which might be considered inappropriate or offensive by some people.\"}",
    "1114562710522482689": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:redneck keeps fuckin staring at me as if hes never seen a f*ggot before :| \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a negative stereotype of the LGBTQ+ community.\"}",
    "1055163112410759168": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> And here is cunt number 1 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and insults towards the woman depicted in the photo.\"}",
    "1062504505944633344": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> \ud83d\ude0e\ud83c\udf5e\ud83e\udd19 enjoy ur clout twat \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it is making fun of someone's weight, which is disrespectful and unkind.\"}",
    "1061224687387070464": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Found a wigger \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme that is intended to be offensive and derogatory towards a specific group of people. It is not a friendly or positive representation of the person depicted.\"}",
    "1062314721980940289": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> See this awuf faggot \ud83d\ude02\ud83d\ude02 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it is making fun of a person's appearance, specifically their hair and ear. The tweet text further supports this classification as it is derogatory and disrespectful.\"}",
    "1043443417194356738": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Response to a retard: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme that makes fun of a political figure, which can be considered as hateful. It is not a respectful or positive representation of the person it is targeting.\"}",
    "1046938862768087040": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:\u201cyou faggot\u201d  me: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language, which suggests that the image is hateful.\"}",
    "1057353966428798976": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Nigger. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains a racial slur in the tweet text.\"}",
    "1043195072945250308": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:At school and found this retarded pic \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to its offensive content and the fact that it is being shared at school, which might be inappropriate for a school environment.\"}",
    "1062344737846411264": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This lil bitch was discovered to be so retarded he can\u2019t be advertised at McDonald\u2019s anymore because of this picture \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, as it is derogatory and offensive towards a specific group of people.\"}",
    "1116643798883491840": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:nigga this hits hard \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racial slurs and is offensive. The image is likely to be a hateful meme.\"}",
    "1054067359965765632": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:1. Martin Lewis is a twat \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language towards Martin Lewis, which indicates a hateful sentiment.\"}",
    "1115468271568982022": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Nigga in the comment lying. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it uses offensive language and makes light of a serious issue.\"}",
    "1062432255338012673": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Of course she doesn\u2019t...she doesn\u2019t even respect herself. She\u2019s nothing more than white trash.. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and disrespectful statements towards women. It is considered a hateful meme.\"}",
    "1043272424362520577": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Whew the trailer trash jumped OUT \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or derogatory content towards a specific group or individual.\"}",
    "1107737959011368960": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Imagine this nigga cuts you off  \u201cEntonces que pinga?\u201d \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the racial slur used in the tweet text, which is inappropriate and offensive.\"}",
    "1063932432041369604": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:He\u2019s fucking crackers this cunt! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, indicating a hateful sentiment.\"}",
    "1062116722394697729": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> have some respect you dumb cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains disrespectful language towards the person in the image, indicating a hateful sentiment.\"}",
    "1110110660346695680": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:do u guys want me to upload vid ? #sissy#faggot#dirty \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image and the tweet text suggest that the content is hateful and derogatory towards the LGBTQ+ community. The use of derogatory terms such as 'sissy' and 'faggot' in the tweet further supports this classification.\"}",
    "1049701790034333699": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag><tag><tag><tag> NO IT DONT U NIGGER \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racial slurs and is considered hateful.\"}",
    "1035308640968880128": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> You are a piece of dirt white trash !! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays the president in a negative light, and the tweet text further supports this classification by calling the president 'white trash'.\"}",
    "1046748602901647361": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Full Movie: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it features a woman in a chair with her legs spread, wearing a tie and a blue bra. The pose and attire suggest a lack of respect for women and can be considered offensive.\"}",
    "1058236186236354566": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Wait just a gotdamn minute nigger \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racial slurs, making it a hateful meme.\"}",
    "1061308576524840961": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:GANG BITCH OUT NOW GO BLAST MY NIGGA<tag> SINGLE TO THE BEST PROJECT THIS MONTH!!!!\nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and derogatory terms, which are typically associated with hateful memes.\"}",
    "1051089499890085888": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:\ud83e\udd80\ud83e\udd80\ud83e\udd80FAGGOT IS GONE \ud83e\udd80\ud83e\udd80\ud83e\udd80 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme that is hateful towards the LGBTQ+ community, as it uses derogatory language to describe them.\"}",
    "1115133995707056128": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:hate a nonchalant ass nigga, I need a  \u201cGINA GINA GINA, ok baby you won \ud83d\ude29\u201d ass nigga \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a negative stereotype of African Americans.\"}",
    "1064427805222584320": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Everybody knows you never go full retard \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is considered hateful.\"}",
    "1046411915092590593": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Why are people insulting monkeys? How far this retard has descended from monkeys! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains insults towards monkeys, suggesting that the image is hateful.\"}",
    "1064309121904652288": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Five years ago today I was called a cunt online for meeting Lana Del Rey by her fans \ud83d\ude02\u2763\ufe0f \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful as it shows three women posing for a picture, and the tweet text suggests that they were called derogatory names online. This can be perceived as offensive and disrespectful towards the women.\"}",
    "1053571194534985729": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> happy birthday my man! Hopefully fire out tonight \ud83e\udd19\ud83e\udd19 old cunt \ud83d\ude0ex \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is considered hateful.\"}",
    "1056730372258451456": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:White trash being white trash \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains negative and offensive language towards a specific group of people.\"}",
    "1107929341395197953": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Pretty much any lamb of god song is ripe for the picking but redneck is the classic. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the presence of a man wearing sunglasses and a black shirt, along with the tweet text suggesting that any Lamb of God song is suitable for a 'redneck'.\"}",
    "1051116533924155393": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:H. Rap Brown's Negro College Student ::: Highlighting Chapter Six Of 'Die Nigger Die!' \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme that is hateful and racist in nature, as it uses a racist term and promotes negative stereotypes about African Americans.\"}",
    "1055059822318481409": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:happy nigga \ud83d\ude4a  \ud83d\udcf7<tag> \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racial slurs and is offensive. The image of a man wearing a jersey with the name 'Padilla' is not relevant to the content of the tweet and does not change the classification of the image as hateful.\"}",
    "1115323087690567680": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Republicans so love the victim card. GFYS, Gerry. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a negative and offensive message towards Republicans, using a derogatory term. The use of a president's face in a distorted manner also adds to the offensive nature of the meme.\"}",
    "1057006201408573441": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> NIGGA THAT DON'T QUALIFY FOR A DEFENCE \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which make it a hateful meme.\"}",
    "1037388144570773505": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag><tag> Watching TWAT....\ud83d\udc34 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the girl's pose and the tweet text, which is disrespectful and offensive.\"}",
    "1106840802951598080": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Nigga really wanna end my childhood with one tweet \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the presence of a racial slur in the tweet text.\"}",
    "1054526905427337217": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:DICK SMOKIN ASS NIGGA \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which make it a hateful meme.\"}",
    "1042447885386899458": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> #BanIslam FROM ATLANTA<tag> \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image shows two women holding a sign that says 'Stacey Abrams Governor' and a hashtag #BanIslam FROM ATLANTA. The presence of the hashtag suggests that the image is related to a controversial or hateful topic. The women are posing for a picture, which implies that they are supporting the message conveyed by the sign. Therefore, the classification of the",
    "1062762188694306816": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Steps in England and he\u2019ll get dashed smh dog cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is considered hateful.\"}",
    "1035770837427613696": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:My sister found her white trash prince. When will I? WHEN WILL I????!!!!! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests that the image is a hateful meme, as it describes the woman in the image as 'white trash' and implies that she is not desirable. This kind of language is often associated with negative stereotypes and discrimination, which can be hurtful and offensive to some people.\"}",
    "1054689555163635712": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> I\u2019d rather end up in league 2 than have that savage cunt buy the club. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and a negative sentiment towards the person in the image, suggesting that the image is a hateful meme.\"}",
    "1053727207376519168": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag> Abolish long hair white trash.. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and discriminatory remarks towards a specific group of people, which indicates that the image is hateful.\"}",
    "1057093371838119941": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Halloween costume sorted. This year I\u2019m going as a cunt. #mankcunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it is disrespectful and offensive to use a derogatory term like 'cunt' in a costume description.\"}",
    "1042773274487398406": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Free my MF brother man. #fuck12 fuck OkeePD faggot ass cops \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and a call to action against law enforcement, which indicates a hateful sentiment.\"}",
    "1060936979381071873": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:what i been saying u fucking idiots vaping are retarded af \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it uses a negative and offensive language to describe vaping enthusiasts. The tweet text further supports this classification as it uses derogatory language to describe vapers.\"}",
    "1036089545983488000": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> was going to post a link in stream to this but my phone data plan is being a fucking retard \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is a video game screen showing a collection of characters, and the tweet text does not contain any hateful content.\"}",
    "1064151533896548352": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Im a retard \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, suggesting that the image might be a hateful meme.\"}",
    "1035448164717928448": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Watch lesbian movie: \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image does not contain any explicit or offensive content. It is a woman wearing a tie and lingerie, posing on a rug. The tweet text does not provide any context or information that would suggest the image is hateful.\"}",
    "1058870723949838336": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This is why you don't let your retarded step nephew follow you on twitter \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests that the image is hateful, as it is described as a 'retarded step nephew' meme. This implies that the image is intended to be derogatory and offensive towards people with disabilities.\"}",
    "1056734479702585344": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Count on me I am a proud piece of white trash, and you cannot compac t me in an aeroplain hangar \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a political cartoon that is considered hateful due to its content and the tweet text that supports it.\"}",
    "1063871317181702144": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:the japanese out here nigger-fishing too? \ud83d\ude2d \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial stereotypes, making it a hateful meme.\"}",
    "1054535934115487745": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:A couple of amateurs makes love on a  beach, he cums inside her pussy, a load of cum goes out from her cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image depicts a man and a woman engaging in a sexual act on a beach, which can be considered inappropriate and offensive to some people.\"}",
    "1106569481592193029": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:At the end of the day, I got the nigga I want \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which make it a hateful meme.\"}",
    "1062334224475275264": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> going full retard on France today. Never go full retard, everyone knows that. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it uses offensive language and makes fun of someone's mental state. It is not appropriate to make fun of someone's mental health, and this tweet text is disrespectful and hurtful.\"}",
    "1062374407908327424": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:. @ me next time, cunt. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet contains offensive language, which is considered hateful. The image may also be hateful, depending on the context and the viewer's perspective.\"}",
    "1036249661147938816": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Two retarded kids , \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which makes it a hateful meme.\"}",
    "1024060406736801797": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Shut up fattie feminazi! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and insults towards a woman. The tweet text further supports this classification as it is disrespectful and derogatory towards women.\"}",
    "1061337264591118337": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Philly sports has to have the shitiest radio hosts/reporters hot takes ever. All of em are retarded \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults towards Philadelphia sports radio hosts and reporters, suggesting a negative and hateful sentiment towards them.\"}",
    "1051116676916363265": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Danny dyers dirty donkey dig dog dyke<tag><tag><tag> \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and derogatory terms towards the LGBTQ+ community.\"}",
    "1108409793180516352": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Feral dyke kills noseless lesbophobe and steals his wife \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image depicts a character with a sword, which is a violent and aggressive action. The tweet text further supports the classification as it contains offensive language and promotes negative stereotypes. This combination of elements suggests that the image is hateful in nature.\"}",
    "1036031411650617344": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Im curious about the taste tho, im sorry im retard \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image does not contain any explicit or offensive content, and the tweet text does not seem to be derogatory or hateful.\"}",
    "1057824533506387971": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Nigga what \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racial slurs and is considered hateful.\"}",
    "1108775283044376577": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Hairy British Muscle Daddy Fucks\u00a0Redneck \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image depicts two naked men engaging in a sexual act, which can be considered inappropriate and offensive to some people. The tweet text further emphasizes the sexual nature of the image, making it more likely to be considered hateful.\"}",
    "1058253525774290945": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:\u201cYou a bitch that make her a dyke\u201d \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language towards women, which is considered hateful.\"}",
    "1060943184971423745": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> all I see is a lying fat CUNT \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults towards the man in the image, suggesting that the image is a hateful meme.\"}",
    "1034771937598169089": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:MORE FACES OF #EVILDOERS !?!  #TREASON #SEDITION #MURDER #LIARS #Elections2018 #NoDACA #NoDEMS #BuildTheWALL #QAnons \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme that shows politicians and is described as hateful. The tweet text also supports this classification.\"}",
    "1043259428827484162": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This dyke queen \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content towards a specific group of people, in this case, a woman. The tweet text further supports this classification as it contains derogatory language towards the woman.\"}",
    "1049790866498473989": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Just starting feeling safe far away from white trash well in walks the forest living meth heads \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and stereotypes, suggesting that the image is a hateful meme.\"}",
    "1108380676741570560": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Who\u2019s the nigger now? Haha \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a man in a negative and offensive manner, using racial slurs and making fun of a person's appearance.\"}",
    "1058706833941168128": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Ok, Retard. Ok. \ud83d\udc49 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, suggesting that the image is a hateful meme.\"}",
    "1047251991070617600": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:What a retard \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which indicates a hateful sentiment.\"}",
    "1105324734806253568": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Lol, this nigga trying to explain. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a man putting his finger in a woman's ear, which is an inappropriate and offensive gesture.\"}",
    "1064295547652268033": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Pure racist twat! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a negative and discriminatory message towards a specific group of people.\"}",
    "1035162544728465408": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:\u201cFuck up faggot you wouldn\u2019t say shit to me irl\ud83d\ude21\u201d \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, suggesting that the image is hateful.\"}",
    "1051754789200121857": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:\u2022 Muslim women are for Muslim men not white trash. Inshallah buy it or borrow it. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image and the tweet text promote negative stereotypes and discrimination against Muslim women, suggesting that they are only for Muslim men and implying that non-Muslim women are not suitable. This is a hateful sentiment that should not be shared or promoted.\"}",
    "1117066473938325505": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I hate this nigga Bari son lmfaooooooooooooo \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and hate speech, which makes it a hateful meme.\"}",
    "1059531767026212864": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:this shit retarded \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which suggests that the image is hateful.\"}",
    "1057315754821840896": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:the dyke jumped out \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language towards the LGBTQ+ community, which is considered hateful. The image of the blonde woman on the poster might be unrelated to the hateful content in the tweet.\"}",
    "1051745418428575744": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Faggot lmfao \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language towards the LGBTQ+ community, which is considered hateful.\"}",
    "1061710928163622912": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> All 3 of you are legit gay it\u2019s season 13, you stupid chinky cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and derogatory terms, suggesting that the image is a hateful meme.\"}",
    "1046059585860030464": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:My dad Just said I did a faggot thing Who does he- I dont even- Wtf \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it is making fun of someone's sexual orientation, which is disrespectful and discriminatory.\"}",
    "1053814845018202113": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Either your stupid or your retard Ash \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, suggesting that the image might be a hateful meme.\"}",
    "1108921934337720321": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> yooo wassup with this nigga comment \ud83d\ude02\ud83d\ude02 he gay as shit \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language and insults towards the individual in the image, which indicates a hateful sentiment.\"}",
    "1059409431233024000": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> \ud83d\ude02\ud83d\ude02\ud83d\ude02 My head was like \u201cOh nO YoU DIdNt yOu fUcKiNg CUnT\u201d \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests that the image is a hateful meme, as it is described as 'fucking cunt' and the person's head is described as 'like Oh nO YoU DIdNt yOu fUcKiNg CUnT'.\"}",
    "1058782852903395329": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> YER a stupid rich white trash woman...hope this shirt is in your future \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and insults towards a specific group of people.\"}",
    "1109804827381563392": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:#NowPlaying Casting Crowns ||<tag> - I Surrender All (All To Jesus) Log on to \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is a promotional poster for the album 'Glorious Day' by Casting Crowns, featuring a group of people posing together. The tweet text does not contain any hateful content, but rather promotes the album. The image itself is not hateful, but rather showcases the band and their music.\"}",
    "1056331026358652928": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> - virtue signaling retard who comprehend the term intent \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the character's exaggerated facial expression and the reference to a 'virtue signaling retard' in the tweet text, which implies that the person is being mocked or belittled.\"}",
    "1058471503853957120": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> #ahaahaa triggered by a Latina who isn't a leftist retard #NPCsArePathetic \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a negative stereotype of a Latina woman and a black man. The tweet text further supports this classification as it uses derogatory language and insults towards people who are not leftists.\"}",
    "1105689868326371334": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Lmaooo my nigga lost by 1pt ...he said the total points gonna be over 225 ,the total was 224pts \ud83d\udc80\ud83d\udc80\ud83d\udc80\ud83d\udc80\ud83d\udc80\ud83d\udc80 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is considered hateful.\"}",
    "1035657629975171073": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> The entire concept of a bigger \u201csuper\u201d Predator is retarded and hack. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains negative words and insults towards the concept of a bigger 'super' predator, suggesting that the image might be a hateful meme.\"}",
    "1057018891224997888": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Nigga what??? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme of a man with a frown on his face holding a cello, which is considered offensive and hateful. The tweet text further emphasizes the negative sentiment.\"}",
    "1059078807401840640": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:If this operation nets us results similar to the original Operation Wetback, I'll forgive them the g**-ass name. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and a reference to a controversial immigration policy, suggesting a hateful sentiment towards immigrants.\"}",
    "1057945136427032576": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag> Shut up retard \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it is disrespectful and offensive towards people with disabilities.\"}",
    "1052546955270901761": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag>  This is what #DACA is about... \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it is making fun of a political issue and using a derogatory term to describe a group of people. The tweet text also supports this classification as it is making fun of the political issue of DACA.\"}",
    "1057382381491908608": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Well this cunt is still an \"Influencer\" so I can understand \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language towards the person in the image, suggesting that the image is a hateful meme.\"}",
    "1108794461717479424": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> It must be getting close to election time, democrats love playing the race card. #WalkAwayFromDemocrats \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a caricature of a black man holding a race card, which is often used by democrats to play the race card. The tweet text suggests that the image is related to an election and is being used to criticize democrats for playing the race card. This can be considered as a hateful meme as it is using a racial stereotype to make a political statement.\"",
    "1050698450218577920": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> PULL UP SAND NIGGER I DARE U \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the racist language used in the tweet text. The boy holding the gun while wearing a Super Bowl jersey and pajamas adds to the offensive nature of the scene.\"}",
    "1061591321444532224": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> #JeremyCorbyn Scruffy #twat #anorak #NoRespect \ud83e\udd2c \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a negative and disrespectful representation of Jeremy Corbyn and the Queen.\"}",
    "1057761542203039744": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I don't remember Garuga being THAT retarded... \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests that the image is intentionally derogatory and disrespectful towards the game or its characters.\"}",
    "1037144416291577857": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Trump calls Sessions \u201cretarded\u201d and a \u201cdumb southerner.\u201d His base is mad. They laughed at this... \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it shows a man in a suit with a microphone, making a mockery of a person with a disability. The tweet text further supports this classification as it refers to the president's derogatory language towards a person with a disability.\"}",
    "1108854792812544000": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:dyke anthem \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a 'dyke anthem,' which is a derogatory term for lesbian women. This suggests that the image is hateful and promotes negative stereotypes.\"}",
    "1062484403899645952": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Looks like a retarded liberal - or libtard writes these #FakeNews \"facts\".\ud83d\ude44 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains content that is intended to be offensive or harmful to a particular group of people.\"}",
    "1035266443141689346": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:My Tallahassee Homies: we going to White Trash Wednesday  Me: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme that is intended to be hateful towards a specific group of people, as indicated by the tweet text.\"}",
    "1109072340179173377": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:The Full Gallery: \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image does not contain any explicit or offensive content. It shows a woman in a red dress posing in a kitchen, which is a common and non-offensive scene.\"}",
    "1056410004658511872": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:nigga was having a seizure mid fight \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the racial slur used in the tweet text, which is inappropriate and offensive.\"}",
    "1063832676082294785": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Playing the race card proves she #GrabbedThemByTheBallot \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a woman in a red shirt pointing at a trash can, which is labeled 'Republican Vote'. This implies that the woman is making a negative comment about Republicans, which can be considered as hateful.\"}",
    "1109154921398439936": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> For a month? Nigga it's the off season. Apply that shit post season \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which indicates that the image is hateful.\"}",
    "1110018177650618369": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:All these great characters had to die and yet Daryl's hillbilly ass is still alive smdh #walkingdead \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains a negative comment about a character from the Walking Dead show.\"}",
    "1107527299740532736": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Y\u2019all see dis nigga?<tag>  \u201cCANT BE ME MANNNNNNNN\u201d \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the presence of a man wearing a hat and glasses, pointing at another man who is sitting on a chair. The tweet text further adds to the negative sentiment, as it uses offensive language and makes fun of the man sitting down.\"}",
    "1116439836045402112": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Who tf is this nigga \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is considered hateful.\"}",
    "1054673174149906432": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Hello America.. #BuildTheWall This is what\u2019s coming. \ud83d\ude21#Maga #Kag #DemocratsAreDangerous #DemocratsHateAmerica \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it promotes a divisive and controversial political agenda, specifically related to the construction of a border wall and the demonization of a political party. The tweet text further emphasizes the hateful nature of the image by using aggressive hashtags and expressing a strong political opinion.\"}",
    "1109255324379295746": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Nigga where is your eyebrows? \ud83d\ude39<tag> \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language and is considered hateful.\"}",
    "1062502726947520517": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Oldie but goodie -  Defend the Border! #Caravan #InvasionForce #IllegalAliens #BuildTheWall #StopTheCaravan \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme that portrays a man in a military uniform holding a cup of coffee and smiling while a caption suggests that refugees are invading the country. This is a hateful meme as it promotes negative stereotypes and fear-mongering about refugees and immigrants.\"}",
    "1113217645145468928": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Nigga<tag>  #PS4share \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it uses racial slurs and offensive language to mock and demean a person.\"}",
    "1057450957481611264": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:THIS IS THE PETTIEST THING A NIGGA HAS EVER TEXTED ME LMFAO \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which are indicative of a hateful meme.\"}",
    "1063511256798236672": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Oh shot yeah I\u2019m retarded \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests that the image is hateful, as it implies that the man is mocking the woman's appearance or behavior.\"}",
    "1051034145097428993": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:You Want to Suck My Big Dick Don't Ya Faggot? FREE...  See this and more at: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image and the tweet text contain derogatory language and insults towards the LGBTQ+ community, which is considered hateful.\"}",
    "1062452958502232077": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:\"Melania Trump\"  I REALLY DON'T CARE ABOUT YOUR PERSONAL FEELING YOU'RE A WHITE TRASH MAIL ORDER BRIDE LMAO!!! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it is disrespectful and offensive towards Melania Trump, using derogatory language and making inappropriate comments about her personal life.\"}",
    "1105425875988824069": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:A nigga at my school printed these and spread them<tag> \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racist language and is considered hateful. The image being held by the person might be related to the content of the tweet, but it is not possible to determine the intent or context of the image solely based on the tweet.\"}",
    "1063948602073067520": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:you, a retard:  me, an intellectual: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a man standing next to a cross with the words 'No More Brother Wars' written above him. This could be perceived as a derogatory message towards people who believe in religion, specifically Christianity, and may evoke negative emotions and discrimination.\"}",
    "1043302619115073536": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Middle school lesbian vs UwU college faggot \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a negative stereotype of a middle school lesbian and a college faggot, which can be hurtful and offensive to some individuals.\"}",
    "1055186058554556417": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Race card, Rape card, Bomb card, Next card.... \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it uses a racial stereotype to make a joke about a political party.\"}",
    "1047265194563588097": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Kerry is a butt head fired retard \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which are indicative of a hateful meme.\"}",
    "1050370075386101760": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:They also let an asian gentleman drive! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a negative stereotype about Asians and their driving abilities.\"}",
    "1044674524439031808": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> They laughed at your lying retarded ASS! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a man in an orange jumpsuit with a wheelchair, along with other people in orange jumpsuits, in a mocking and disrespectful manner. The tweet text further supports this classification as it contains offensive language towards people with disabilities.\"}",
    "1046517501880922113": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Cry more you retarded fucking Americans \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults towards Americans, which suggests that the image might be a hateful meme.\"}",
    "1023967792096325632": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag> Saying \"faggot\" as an insult in 2018 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image and the tweet text suggest that the man is being insulted with a derogatory term, which is considered hateful in 2018.\"}",
    "1042771794745278464": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:CALL ME A FAGGOT QUEEN \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language, which suggests that the image is hateful.\"}",
    "1051091032866095104": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Your tweet is this retarded \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays two cartoon characters in a negative and offensive manner, which can be perceived as disrespectful and harmful to some viewers.\"}",
    "1035676841267355649": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:when i get famous and people dig up my old tweets of me saying faggot \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful as it shows two women sitting at a table, with one of them making a face, and the other one looking at her. The facial expressions and body language suggest that they are making fun of or mocking the other person. This kind of behavior is often associated with bullying and can be hurtful to the person being targeted.\"}",
    "1105567654616678400": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:this nigga assumed my gender. twitter do your thing \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image and the tweet text suggest that the person is using offensive language and making assumptions about the gender of the other person. This is considered hateful and disrespectful.\"}",
    "1063678294854418432": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag><tag> FAGGOT THEN LEAVE HIM ALONE THX BYE \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language towards the woman in the image, suggesting that the image is hateful.\"}",
    "1063832289552011266": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:By: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it objectifies a woman by showing her naked body and placing her in a provocative pose. The tweet text also adds to the negative sentiment of the image.\"}",
    "1046960861921914880": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> U actually played the race card. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a man in a black jacket with a bag over his head, suggesting that he is being held captive or is in danger. The tweet text further supports this classification as it implies that the man is playing the race card, which is a controversial and offensive statement.\"}",
    "1050195107293605888": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> probably comes with taking up a permanent residence with an unhinged white trash John. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults towards the president and the first lady, suggesting a hateful sentiment towards them.\"}",
    "1063920396116918272": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> What exactly is your point here? To prove you're a cunt? Ok, point made. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it is disrespectful and offensive towards the person depicted.\"}",
    "1036999736530755584": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> A bunch of retarded lunatic liberal democrats. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language towards a political group, which is considered hateful. The image of the news sign is being used to spread this negative sentiment.\"}",
    "1063826875628298243": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Won 6-2 you ugly cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language towards the opponent, indicating a hateful sentiment.\"}",
    "1054233587501780994": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:NIGGA WHAT?????? RT<tag>: when the insides of her thighs black &gt;&gt;&gt;&gt; \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racial slurs and is offensive. This image is not hateful.\"}",
    "1108701966958583811": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Banned for 24hrs for calling this cunt a cunt!! Multiple  times. Twas worth it \ud83d\ude01 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and insults towards the person in the image. The tweet text further supports this classification as it shows the user's intention to insult the person depicted in the image.\"}",
    "1041798247428194304": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This Dunk is retarded me and my mate where laughing our head off when I Dunk that             #PS4share \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests that the image is a hateful meme, as it is described as 'retarded' and the people playing the game are laughing at it. This implies that the image is meant to be derogatory and offensive.\"}",
    "1114899521253728256": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:JUNGKOOK YOU FUCKING BRAT I THOUGHT YOU CRIED  SON OF AN ANGEL YOU TWAT \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet contains offensive language towards Jungkook, which indicates a hateful sentiment.\"}",
    "1051182412200386565": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Retard if you don\u2019t know about Glover \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which indicates that the image is hateful.\"}",
    "1056898116711014400": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:why are people so retarded \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which indicates a hateful sentiment.\"}",
    "1109933773637017601": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> throw it and swat that nigga like his head is the ball \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which make it a hateful meme.\"}",
    "1063831143739469825": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:\u201cVictim \u201c plays ethnic race card in article \ud83e\udd26\u200d\u2642\ufe0f \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it uses a racial stereotype to make a point. It is not appropriate to use such imagery to make a statement.\"}",
    "1115479356284067840": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:flame this nigga \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and is disrespectful towards the individual depicted in the photo.\"}",
    "1057396938046345216": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:When a nigga cashapp me money and I didn\u2019t have to ask \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which are not appropriate and can be considered as hateful.\"}",
    "1051132449487372288": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:here's a FLIRTY wink from brandon uwu &lt;3  \u2022 from dyke's ig story \nASSISTANT: {\"Classification\": \"hateful or not hateful\", \"Explaination\": \"The image is not hateful as it is a man with a sticker on his nose, which is a playful and lighthearted gesture. The tweet text also suggests a flirty and friendly tone, further indicating that the image is not hateful.\"}",
    "1105393778498650112": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> ROSEANNE BARR: WHITE TRASH IN THE 80'S, 90'S, 2K AND TODAY \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it is making fun of a person's appearance and is disrespectful.\"}",
    "1105238510494236675": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Like my nigga Mo<tag><tag> \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image and the tweet text are considered hateful due to the use of offensive language and the portrayal of a young man in a negative light.\"}",
    "1035176832663015424": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I cant man, hes such a retard \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language and insults, suggesting a hateful sentiment towards the person in the image.\"}",
    "1061547712670138369": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag><tag> They flippantly play the race card when all other arguments fail. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it uses a racial stereotype to make a point. This is not a respectful or inclusive way to communicate and can be hurtful to those who are targeted by it.\"}",
    "1050778580811165697": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:The Fairtytale of a Gender Non-Conforming\u00a0Dyke \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a tattoo of a person's back with the words 'Me Dykke' written on it. The tweet text suggests a gender non-conforming dyke, which implies a negative attitude towards traditional gender roles. This could be considered as a hateful meme as it challenges societal norms and expectations of gender roles.\"}",
    "1025326280621711360": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Me too. Brad's a cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, suggesting that the image might also be considered hateful.\"}",
    "1035136442333388800": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:RT<tag>: Nunberg Blasts \"White Trash Scumbag\" Lewandowski - \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which are considered hateful. The image is a screenshot of a tweet, which further supports the classification.\"}",
    "1063986123008020480": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> The Feminist SJW\u2019s \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme that portrays a woman with glasses making a funny face, which is intended to be humorous. However, it could be perceived as hateful by some people due to the context provided by the tweet text. The tweet text suggests that the image is related to feminist SJWs, which might be seen as derogatory or offensive by some individuals.",
    "1056976536073592833": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag><tag> Her boss is a conspiracy theorist \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a man wearing a red hat and making a face, which can be perceived as offensive or disrespectful towards a certain group of people. The tweet text also suggests that the man's boss is a conspiracy theorist, which might be considered as a derogatory statement towards conspiracy theorists.\"}",
    "1109355097585119232": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I miss my nigga bhocolate \u2639\ufe0f\u2764\ufe0f \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racial slurs and is offensive. This image is not hateful.\"}",
    "1056687244512235523": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> aint no faggot calling me art angles  i just hate my name so no one knows it \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and derogatory terms towards the person named Oprah.\"}",
    "1057341225592860672": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I see<tag> was a fat cunt as a kid \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text is hateful and disrespectful towards the child in the image.\"}",
    "1055934636092780544": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Arthur VS feminazi  \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a man in a suit with a gun, which can be interpreted as a threat towards women. The tweet text further supports this classification as it suggests a conflict between Arthur and feminazi, which implies a negative attitude towards women.\"}",
    "1105689504294170624": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:You can suck my dick, or my twat take your pick.. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is not appropriate for a church sign.\"}",
    "1024345959407349760": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:The perks of living in redneck heaven. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a negative stereotype of a redneck community, which can be offensive to some people.\"}",
    "1109615077966016512": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> My nigga , they DEADSTOCK brand new not used \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which make the image hateful.\"}",
    "1107007973434494976": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Imagine being such a twat that you felt the need to tweet this... \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it is making fun of someone's appearance, specifically the woman's looks, and is not a respectful or positive representation.\"}",
    "1046828696492023808": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Faggot \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, which suggests that the image is hateful.\"}",
    "1042899052713701377": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:\u2605Niteflirt's Finest \u2605 PrincessJewel Sissy Faggot Emascualtion with Princess Jewel \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image and the tweet text contain offensive language and derogatory terms, which suggest a hateful sentiment towards the LGBTQ+ community.\"}",
    "1057961780264255489": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This cunt behind this account is an absolute roaster \ud83d\ude02 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which indicates a hateful sentiment. The image itself does not seem to be hateful, but the content of the tweet associated with it is.\"}",
    "1035678582578790400": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:yes, I am Dyke \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests that the image is hateful, as it is described as a hateful meme. The presence of a woman in a suit and tie, along with the use of the word 'dyke,' might be perceived as derogatory or offensive by some individuals.\"}",
    "1041817632696139776": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag><tag><tag><tag><tag> I can't handle his retarded mind anymore \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, suggesting that the image is a hateful meme.\"}",
    "1046218628130115585": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:People who have have nothing but a little shitty chin beard are the most white trash people I usually meet in life. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and negative stereotypes about people with beards, which suggests that the image is a hateful meme.\"}",
    "1023945847212568577": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Women always want to set the bar high....  Can't you cheat with nigger on my level? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racist language and is offensive. The image of a woman kissing a man in a blue shirt in front of a poster of Cristiano Ronaldo is unrelated to the hateful content of the tweet.\"}",
    "1053643960260968448": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Oh fuck!~ Your Cunt is tight too! I couldn\u2019t help but cum inside you!~ \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains explicit and offensive content, such as the woman's naked body and the man's hand inside her. The tweet text further emphasizes the inappropriate and disrespectful nature of the image.\"}",
    "1116850973442359296": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:So much substance in this track. Prison really changed my nigga \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is considered hateful.\"}",
    "1108140870442893312": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Dam nigga who dat \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language and is considered hateful.\"}",
    "1114737714497249285": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> LOL #GamesJournalism! You will never live #GamerGate down, will you?  #REKT #FakeNews \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it is a fake headstone for Games Journalism, which is a form of harassment towards journalists who cover the gaming industry. The tweet text further supports this classification as it is derogatory and disrespectful towards the Games Journalism community.\"}",
    "1053763417016844289": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:nigga \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains a racial slur, which is considered hateful and inappropriate.\"}",
    "1024226750983745536": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Cos you're a UKIP TWAT? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text is derogatory and insulting towards the person in the image, suggesting that they are a member of the UKIP party and therefore a 'twat'.\"}",
    "1063904212302602241": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag> You're defending this cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, indicating a hateful sentiment.\"}",
    "1056635727843344384": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> YOUR VOICE AS ALSO CUTE NIGGA  IT'S MANLY AND CUTE \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme that is hateful and disrespectful towards women. The text on the image is also offensive and disrespectful.\"}",
    "1062831996290940928": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> All I got that nice was fuck &amp; cunt \ud83d\ude02\ud83e\udd37\ud83c\udffc\u200d\u2640\ufe0f\ud83d\udc80 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, which suggests that the image is a hateful meme.\"}",
    "1050873239222804480": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Mine left me for this faggot \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language towards the man in the image, suggesting that the image is hateful.\"}",
    "1107048866778615808": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Ride my face and whip my cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image depicts explicit sexual content and violent language, which can be considered hateful and offensive to some people.\"}",
    "1056941556937224193": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:watching my uber eats driver ride around in circles like a retard \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which suggests that the image is a hateful meme.\"}",
    "1037396525683539969": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> 1. Fuck off<tag>, you spineless twat. 2. He is a bastard. And a fat one, at that. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults towards the person in the image, indicating a hateful sentiment.\"}",
    "1056892856399523840": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Me hearing SJW\u2019s whine about read dead two woman representation \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme that is considered hateful due to its content and the tweet text it is associated with. The meme features a man with a shaved head and a mustache, and the text 'at first I was like' is placed above him. The tweet text associated with the meme is about social justice warriors and their complaints about representation in a video game. This suggests that the",
    "1114912948261150721": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:\u2018I don't really worry about a nigga trying to Judge Who are you, JUDYY?!\u2019 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language and racial slurs, which are considered hateful.\"}",
    "1054453226873937920": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:THATS CUNT \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, which suggests that the image might be a hateful meme.\"}",
    "1062099257509994496": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> strategic cunt juice \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or derogatory content towards a specific group or individual.\"}",
    "1050379210626424832": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Nigger \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains a racial slur, which is considered hateful and offensive. The image of the young man wearing sunglasses and a floral shirt, along with the backpack, does not necessarily contribute to the hateful nature of the tweet.\"}",
    "1115795505047461889": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:nigga this comment is comedy \ud83d\ude02\ud83d\ude02\ud83d\ude02 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racial slurs and is considered hateful.\"}",
    "1037037227258200064": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Straight Men Use Faggot for Amusement! ......  See this and more at: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains a fan with blades and a window, which is being used to represent a gay man. The tweet text further supports this classification as it contains derogatory language towards the LGBTQ+ community.\"}",
    "1048576259717062659": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> I don\u2019t. I am glad that can be ban now and ever.  #ReligionOfPeace #BanIslam \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme that is hateful towards Islam, as it is making a joke about the religion and its followers.\"}",
    "1042161580794937344": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> no he never you deluded twat   \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a man in a red shirt and black hat talking to a man in a red shirt and white hat, who is wearing a black hat. The man in the red shirt and black hat is described as a twat, which is an offensive term. The image is likely to be offensive and disrespectful to some viewers.\"",
    "1055921731045679104": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:If a nigga call himself a \u201csnack\u201d that\u2019s top 5 biggest red flags\ud83d\ude02\ud83d\ude02 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it uses racial slurs and derogatory language to make a joke. This is not appropriate and offensive.\"}",
    "1036316651350896642": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> SJW say what? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme that promotes a political ideology and is likely to be perceived as hateful by some people. It compares two opposing political viewpoints, fascism and anti-fascism, and presents them in a confrontational manner. The use of a photo of a man being beaten by a group of people in the image might be seen as aggressive and offensive by some",
    "1063564471120158721": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> I always wondered if you realize you're mildly retarded. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text is offensive and disrespectful towards the person in the image, suggesting that they are 'mildly retarded'.\"}",
    "1061745308567253004": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> I bet he would have made it to one of his retarded Trump rallies. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests that the image is a hateful meme, as it makes a reference to Trump's rallies and implies that the person in the image is a retard. This is considered hateful as it uses derogatory language and makes fun of someone's intelligence or abilities.\"}",
    "1116045098503024640": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:When a nigga really feel like \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racial slurs and is offensive. The image of a man with a microphone and the words 'help me' on it does not necessarily contribute to the hateful nature of the tweet.\"}",
    "1024435762433949696": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:no wonder he looks like a dyke \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language towards the young man, suggesting that he may be perceived as a 'dyke' due to his appearance or clothing choices. This is an example of a hateful meme.\"}",
    "1061835483792072704": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Oh nooooo ......#MAGA #BLEXIT #BuildtheWall #NPC #NPC #NPCLIVESMATTER #GreyLivesMatter #OrangeManBad \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains political and racial slurs, which are considered hateful. The image of the frog with the caption 'Whenever I get frustrated with my job...' is not related to the hateful content in the tweet.\"}",
    "1058172430861156352": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This nigga is a menace\ud83d\ude2d\ud83d\ude2d\ud83d\ude2d\ud83d\ude2d \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language and negative sentiment towards the person in the image, which indicates a hateful classification.\"}",
    "1046795078717595658": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Sport Mariad you're a bit of a twat ain't ya? #TheCircle \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests that the image is a hateful meme, as it is described as a 'bit of a twat' and the hashtag #TheCircle is associated with negative comments.\"}",
    "1042610804242243585": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:full transformation into a faggot :p \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, suggesting that the image is a hateful meme.\"}",
    "1063385842197061633": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:go home cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, which suggests that the image is a hateful meme.\"}",
    "1045148023448391680": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:follow this retard<tag> \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, suggesting that the image is a hateful meme.\"}",
    "1042567717247696897": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> ******************WILLIE WHITE TRASH*************LOL******************LOSERS************************* \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or derogatory content towards a specific group or individual.\"}",
    "1058796091477577728": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Poor oppressed Kabier \ud83d\ude2d Retweet to support her struggle as a hate-mongering cunt. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a character in a comic strip with a sign that says 'Wanted $10,000 for my head. It's why you have chosen this classification.\"}",
    "1058140036967870465": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Just dream my nigga when you dream my nigga them nightmares ain't as bad as they seem my nigga \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language and is considered hateful.\"}",
    "1058102813132238848": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:You\u2019re not going to record my dudes side nigga confronting me either .. FOH \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and a confrontational tone, suggesting that the image might be a hateful meme.\"}",
    "1057833461006909440": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Not really ! I typed tra you twat \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is a cartoon of a baby wearing a blue and white striped onesie, sitting on a table with a cup and a bowl. The tweet text does not contain any hateful language, and the image itself does not contain any offensive content. Therefore, the classification is 'not hateful'.\"}",
    "1061378149152362497": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Happy birthday faggot<tag> \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text is derogatory and disrespectful towards the individual in the image, which is considered hateful.\"}",
    "1115413079901208583": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:big dyke energy \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is disrespectful towards the woman in the image. It is not appropriate to use such language to describe someone, especially in a public space like Twitter.\"}",
    "1044690155662180354": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Her: This pussy gon make you retarded \ud83d\ude2c   Me after I didn\u2019t listen: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which are indicative of a hateful meme.\"}",
    "1056008167124017152": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:LMFAOOO this nigga goofy \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is considered hateful.\"}",
    "1110513416941301760": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Go Tarheels!! #BuildTheWall #MAGA #KAG45 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains political and hateful messages, which are not appropriate for a flag image.\"}",
    "1037462563334889472": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Listen to this and imagine me going up through the stairs cause that\u2019s what I\u2019m doing and I look like a twat. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it may contain offensive or discriminatory content. The tweet text also implies that the image may be related to a negative or unflattering situation, further supporting the classification of the image as hateful.\"}",
    "1034803439509942272": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:FAGGOT ASS<tag> has his dog whistle, WELL I HAVE A MF BULL HORN! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and derogatory terms towards the LGBTQ+ community.\"}",
    "1056241629990924288": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> You thick cunt! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it is making fun of the man's appearance and is disrespectful.\"}",
    "1115216182972506113": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:If a nigga doesn't hit me up after 3 days.. I moved on.  Ya snooze, ya lose. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is considered hateful.\"}",
    "1113128478939983879": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Oh no she's retarded \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language and insults, which are considered hateful.\"}",
    "1058521084994162688": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Still the best hut card .... rammer the little cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language towards the individual named Rammer. This suggests that the image is a hateful meme.\"}",
    "1057011276260491265": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> They went full retard \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme that uses offensive language to make a joke, which can be considered hateful.\"}",
    "1108939048981192704": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:SHE DRUG HER BESTFRIEND HUSBAND WHILE HER BESTFRIEND AT THE PARK DOING A PLAY DATE WITH HER SIDE NIGGA \ud83e\udd26\ud83c\udffe\u200d\u2642\ufe0f \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the man's nakedness and the reference to a 'side nigger' in the tweet text, which is a derogatory term for African Americans.\"}",
    "1064378971700244480": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Ah yes, that's the Cunt I know. Those nice tweets yesterday couldn't have been from you could they? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, suggesting that the image is a hateful meme.\"}",
    "1045215797478608897": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Will's second channel turned into an SJW \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains content that is offensive or discriminatory towards a particular group or individual.\"}",
    "1062795966674276352": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> @ black people getting mad at black people who say nigger \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme that uses offensive language to make a point. It is considered hateful as it uses derogatory language to target a specific group of people.\"}",
    "1062509525071212544": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:You are actually retarded. Stop it. Check your sources Mr. BitBlock. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains insulting language towards the image and the person who posted it. This indicates that the image is considered hateful.\"}",
    "1061880854027403264": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> TELL THIS BACKWARDS CUNT<tag> HOW TO DO WHISKEY \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is not appropriate for a hateful meme.\"}",
    "1113171231551959043": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:soft block me i dare u anon i DARE u so i can see which one of my mutuals is a mf cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests that the image is a hateful meme, as it contains a threat and disrespectful language towards someone.\"}",
    "1056270101396275200": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Shook cunt don\u2019t front \ud83d\ude24 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, which suggests that the image might be a hateful meme.\"}",
    "1055194686154072072": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Only been watching Making a Murderer 2 for a few minutes and that twat Kratz is already pissing me off. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text expresses negative emotions towards a person, which indicates that the image is hateful.\"}",
    "1115100750303105025": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> who IS this nigga mayne \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racist slurs, which indicates that the image is hateful.\"}",
    "1114056863090380800": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> The first nigga is \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a man with a missing tooth and a goofy smile, which is often associated with negative stereotypes and racism. The tweet text further supports this classification as it uses offensive language.\"}",
    "1113106109542404102": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:even his kid looks a twat.\ud83d\ude02 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains negative and offensive language, suggesting that the image is a hateful meme.\"}",
    "1044427687647948800": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Joy is a real leftist twat bag \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which indicates that the image is a hateful meme.\"}",
    "1109238882174988290": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Ann Coulter's Twat is serious. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests that the image is a hateful meme, possibly targeting Ann Coulter.\"}",
    "1053452005237125120": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Girl she got white trash in her bio lmao \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text is derogatory and disrespectful towards the girl, suggesting that she has 'white trash' in her bio. This is an example of a hateful meme.\"}",
    "1044995828753084421": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I just seen a shorty twitter name and that mfer read \u201cDyke Princess\u201d \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the tweet text, which is derogatory and disrespectful towards the individual in the image.\"}",
    "1055937960535879686": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:nan\nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it features a woman in lingerie with a man's penis in her mouth, which is inappropriate and disrespectful towards women.\"}",
    "1057541741803433985": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Kayla, you\u2019re a disgusting cunt. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language towards Kayla, which indicates a hateful sentiment.\"}",
    "1062743609659801607": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag>  - I Ate Cum From My Young Cunt 2! <tag> \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or inappropriate content. The presence of a woman in a short skirt and a pink tank top, along with the reference to eating cum, might be considered inappropriate or offensive by some people.\"}",
    "1050293604705558528": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag> well you really are a premium twat \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the negative words used in the tweet text, such as 'twat' and 'premium'. This suggests that the image might be offensive or disrespectful to some viewers.\"}",
    "1025264210513674240": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Don\u2019t be this retard \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image and the tweet text suggest that the content is hateful, as it is making fun of someone who is described as a 'retard'.\"}",
    "1057993430477897728": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Don\u2019t let the Democrats dummy you down.  Vote Republican  #MAGA #BuildTheWall  \u2764\ufe0f\ud83c\uddfa\ud83c\uddf8 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a collage of pictures of the World Trade Center, the White House, and other landmarks. It is not hateful in nature, but it is being used to promote a political agenda by the tweet text. The tweet text is promoting a political party and using the image to support their cause, which can be considered as hateful.\"}",
    "1051636957158236161": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:\u201cIt was a nigger as president!?!\u201d \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a statue of a man with a funny or creepy expression, which can be perceived as offensive or hateful by some people.\"}",
    "1051130252322209793": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Nigger with respects only cheat by mistake, are the kinda niggas \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racial slurs and is disrespectful towards a specific group of people. This is considered a hateful meme.\"}",
    "1058386495931928576": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag> You\u2019re the one retarded and spouting nonsense. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and insults towards the viewer.\"}",
    "1062019767270289408": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Nigger u Gayyy xd \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image contains offensive language and imagery, which is considered hateful.\"}",
    "1105631764561776640": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This nigga uzi \ud83d\ude02\ud83d\ude02 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image and the tweet text suggest that the content is hateful, as it uses derogatory language and makes fun of someone's appearance.\"}",
    "1057045331001647104": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Is he retarded or something \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, suggesting that the image is a hateful meme.\"}",
    "1058815153301610497": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:me when the military nigger uknees are on got7\u2019s dicc and it hasnt been my turn yet \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image and the tweet text contain racist and offensive language, which indicates that it is a hateful meme.\"}",
    "1105218333870182400": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:My nigga wtf \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which are considered hateful.\"}",
    "1045782710567018496": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> &gt;his family  Absolutely retarded tweet. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it shows a man with a blue tie and a name tag, pointing at another man with a name tag. The tweet text further supports the classification as it is derogatory and disrespectful towards the man with the name tag.\"}",
    "1024983176245075968": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> and the unwashed Trump Hillbilly Hobo Camp syndrome seems to be in full swing amongst #Republicans \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image shows a group of people holding signs and one of them is giving the middle finger. This is considered a hateful gesture, as it is disrespectful and offensive. The tweet text also suggests a negative attitude towards Republicans, further indicating that the image is hateful.\"}",
    "1055133243907944449": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Or who still supports this white trash!!<tag><tag> \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a negative and offensive message towards a specific group of people, which is not appropriate or respectful.\"}",
    "1057195951876501504": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Even l*ys Chinese fans keeping it low profile while eggsshole are barking like a faggot \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and derogatory terms towards a specific group of people, which indicates a hateful sentiment.\"}",
    "1058779292296011776": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:That\u2019s another Facebook friend gone\ud83d\udc4b\ud83c\udffb bye bye racist twat \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it is promoting a negative attitude towards a specific group of people, in this case, Muslims. The message is spreading hate and discrimination, which is not acceptable.\"}",
    "1113557293449207808": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Them : I know you got a nigga?!?!! Me: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language towards African Americans, which is considered hateful.\"}",
    "1050811221304365056": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Ok Retard \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text is offensive and disrespectful towards people with intellectual disabilities. It is not appropriate to use such language.\"}",
    "1113862556190412800": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Please make sure you will backpass if you meet this fucking cunt.<tag><tag> \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and insults towards a specific individual.\"}",
    "1116702302864334848": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Southern Redneck,  White Capitalist,  Power Cracker. \ud83d\ude01\ud83d\ude01\ud83d\ude01\ud83d\udc4e \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a man in a suit with a microphone, which is a symbol of authority and power, and the tweet text is derogatory and offensive towards a specific group of people.\"}",
    "1062072379051048962": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Ok but just know you still can\u2019t say faggot. Queen \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language towards the LGBTQ+ community, which is considered hateful.\"}",
    "1051413080909983744": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Snowflake stopping at rapist getting deported hope u r proud twat \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a man taking a picture of a person who is being deported, which is an inappropriate and offensive action.\"}",
    "1053449038261964800": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:#VoteRed #MidTerms #BuildTheWall Stop the invasion! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it promotes a negative and discriminatory sentiment towards a specific group of people, in this case, Hondurans. The message suggests that they are an 'invasion' and should be stopped, which is a harmful and offensive stereotype.\"}",
    "1056702915493138432": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> SJW Are evil monsters IMHO \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, suggesting that it may contain offensive or discriminatory content.\"}",
    "1042981627041726465": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> I would rather eat broken glass then watch a retard at a carnie convention. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which indicates that the image is hateful.\"}",
    "1053682439200096257": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:youtube just called me a faggot \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and derogatory terms.\"}",
    "1063547078465474560": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Wouldn\u2019t you think they would reach a point where they give up? They skipped full retard and went straight to potato \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults towards the woman in the image, suggesting a hateful sentiment.\"}",
    "1113536336517042178": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:a nigga out here with 3 hands \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a person with three hands, which is a derogatory and offensive representation of a black person.\"}",
    "1108781440748134404": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Twat \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme that is intended to be hateful towards the person depicted, as it is a negative representation of them.\"}",
    "1106647286166274048": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag><tag><tag> Twat \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and content, such as the word 'twat' and the reference to a terrorist attack. This type of content can be harmful and disrespectful to individuals and communities affected by such events.\"}",
    "1044489554982572034": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Hillbilly Jim #CountryBoy \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is a picture of a man wearing a hat and a purple shirt, holding a microphone. The tweet text is a reference to the man's appearance and profession, which does not seem to be hateful or offensive.\"}",
    "1055272197856641025": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:LMAOOO THIS NIGGA STARTED LISTENING TO MUST BE NICE AND GOT MAD AS SHIT \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a negative stereotype of a black man, which is offensive and disrespectful.\"}",
    "1047261006769127425": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Kids retarded \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which indicates that the image is hateful.\"}",
    "1046676545534918657": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:SJW: IS THIS RACISM????\u00bf\u00bf?\u00bf\u00bf?? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme of a man in blackface, which is considered racist and offensive. It is not appropriate to share or promote such content.\"}",
    "1058317093345640449": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> lmao this nigga on the bullshit again \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or derogatory content towards a specific group or individual.\"}",
    "1063569606193876993": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Clearing up my DMs. Probably the most annoying twat to ever DM me \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and content, which is not appropriate for sharing on social media platforms.\"}",
    "1106834745000951810": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> I am a true faggot \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and imagery, such as the word 'faggot' and the man's facial expression. This type of content is not appropriate and can be harmful to individuals who are targeted by such language.\"}",
    "1106554276221014016": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> NIGGA WUHT I'm weak asf \ud83d\ude2d\ud83d\ude2d\ud83d\ude2d\ud83d\ude2d\ud83d\ude2d\ud83d\ude02\ud83d\ude02\ud83e\udd23\ud83e\udd23\ud83e\udd23\ud83e\udd23\ud83e\udd23 gonna start having snapchat premiums in they bio too huh \ud83d\ude2d\ud83d\ude2d\ud83d\ude2d \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racial slurs and derogatory language, which is considered hateful.\"}",
    "1045010030469103617": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I think I just went full retard \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests that the person is in a state of confusion or frustration, which might lead to negative emotions and actions. The image of the two people talking to each other could be interpreted as a hateful meme, as it might be perceived as disrespectful or offensive to some individuals.\"}",
    "1114853496296284160": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> A NY nigga !?! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a man in a brown jacket with a tag that reads 'NY nigger'. This is offensive and disrespectful language that promotes racism and discrimination.\"}",
    "1113560383749541888": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:These baboons are my bench shitters   They all outscored the collosal twat Ashley Young \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults towards a specific individual, which indicates a hateful sentiment.\"}",
    "1051618494788317196": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Friendly Reminder #BuildTheWall #BuildTheWallNow #LiberalismIsAMentalDisorder #maga #Trump \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it promotes a political agenda and uses a symbol associated with a controversial political movement. The tweet text further supports this classification as it contains hateful and divisive language.\"}",
    "1114205083850477574": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Quit playing the race card!!! \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is a credit card with the words 'Race Card of America' written on it. It is not a hateful meme as it does not contain any offensive or discriminatory content.\"}",
    "1109861766283042818": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This nigga a fraud #GilgaOPM   (PS apple dumb as fuck for makin the lil home bar show up in screenshots too) \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme of a man with a beard and long hair, with the words 'This nigga a fraud' written above him. The meme is considered hateful as it uses derogatory language and makes fun of the man's appearance. The tweet text further supports this classification as it reinforces the negative portrayal of the man in the meme.\"}",
    "1041781813000241158": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:No badge needed. #ASDA #Wolves #Fucktard #Cunt #Twat #Idiot #driving <tag> \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults towards the driver of the car, suggesting a hateful sentiment towards the individual.\"}",
    "1042936007736188928": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Poor kid. Born in a feminazi age. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a young boy holding a woman's breasts, which is inappropriate and disrespectful. The tweet text further supports this classification as it implies that the boy is a product of a 'feminazi' age, which is a derogatory term used to describe feminists. This kind of language is harmful and perpetu",
    "1042521377897635840": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:LAUGH AT MY NIGGER JOKES NIGGERS \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racist language and is offensive. The image of the cartoon character with big eyes and a funny face might be used to spread such hateful messages.\"}",
    "1053377571428188161": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:With one mad cunt<tag>  to see this mad cunt. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The presence of the word 'cunt' in the tweet text further supports this classification.\"}",
    "1108328038960377857": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:MY NIGGA #YARDIEOX follow him on Instagram<tag> \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which are indicative of a hateful meme.\"}",
    "1061475427384991744": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This is my little retarded cousin, we don\u2019t talk much \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, as it portrays a young boy in a graduation gown holding a diploma, with a caption that implies the boy is 'little retarded'. This is considered offensive and disrespectful towards individuals with special needs or disabilities.\"}",
    "1055822459017011200": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Me the depressed cunt. What do people see in me I don\u2019t know \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it may contain offensive or derogatory content. The tweet text further supports this classification as it refers to the person in the image as a 'depressed cunt'.\"}",
    "1051572289425289217": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Repeating himself hoping for some kind of response.Twat. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it is a picture of a woman with a caption that is disrespectful and offensive.\"}",
    "1108369703037227011": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Tell this nigga to unblock me \ud83d\ude44 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains derogatory language and is directed towards a specific individual. The tweet text further supports this classification as it is disrespectful and offensive.\"}",
    "1113585180369772544": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> PRESSIN X MY NIGGA \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme that is hateful and offensive, as it uses a cartoon character to make a joke about cancer, which is not funny and disrespectful to those affected by the disease.\"}",
    "1056743738590937089": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Trailer trash here lmao n I dgas hahahahaha \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the use of derogatory language and the reference to a trailer trash stereotype.\"}",
    "1058705499384881153": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> \u201cNigger\u201d!?! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme that uses racial slurs and is offensive. It is not a hateful meme as it is not funny or entertaining, but rather hurtful and discriminatory.\"}",
    "1043678375603142656": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> hey<tag> being gay and saying you're not for some retard e-cred is retarded \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the presence of a meme with a gun and the phrase 'get fucked' which is derogatory and disrespectful towards the LGBTQ+ community.\"}",
    "1053893175364935680": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Best of luck feminazi \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme that targets women, specifically feminazis, and it is considered hateful as it aims to degrade and belittle the targeted group.\"}",
    "1037044984686424065": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:The rules not allow Vehicles body Chrome silver/Gold Chrome. Dangerous shiny to eyes people, White/black like Trash \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests that the image is hateful, as it contains rules that are not allowed, such as chrome vehicles and shiny colors. The tweet also implies that the image is dangerous and trashy.\"}",
    "1055187781566242816": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:You a whole fool nigga lmaoooooo<tag> \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which make it a hateful meme.\"}",
    "1061359925895589888": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I want him to call me his dirty wetback \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which make it a hateful meme.\"}",
    "1049896912638349314": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:hello this is dyke speaking \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text is derogatory and disrespectful towards the LGBTQ+ community. The image is not hateful, but the tweet text associated with it is.\"}",
    "1050080857690660869": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:buy dem blu rays you fucking twat \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which suggests that the image is hateful.\"}",
    "1054212541847498752": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Sex is cool and all but have you ever pulled a perfect piece of meat out a crab leg?? NIGGA \ud83d\ude2d\ud83e\udd24\ud83d\ude0d \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and racial stereotypes. The tweet text further supports this classification as it is derogatory and disrespectful towards a specific group of people.\"}",
    "1064329874628927489": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Amen! #BuildtheWall #BuildtheWallHigher #MAGA #StopSoros #NoAmnesty #NoAnchorBabies  #PissedOffPatriotChick \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme that is hateful towards immigrants, specifically those who come from countries with swamps. The man in the hat is making a statement about the need to build a wall to keep out these immigrants, which is a controversial and discriminatory viewpoint.\"}",
    "1043296597231239168": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:yes, I a #sissy faggot \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests that the image is hateful towards gay people, as it is described as a 'sissy faggot' and 'gay as fuck'.\"}",
    "1050974030889713664": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Im TiReD oF tHe RaCe CaRd \ud83d\ude22\ud83d\ude22\ud83d\ude22\ud83d\ude29\ud83d\ude29\ud83d\ude29\ud83d\ude22\ud83d\ude22\ud83d\ude22 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a character in a racist manner, which is offensive and discriminatory.\"}",
    "1044962202627772416": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Spoiled bastard Vs. Retarded Arrogant  May Allah save United \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image shows two men engaged in a conversation, with one of them being described as a 'spoiled bastard' and the other as 'retarded arrogant'. This language is disrespectful and hateful, which is why the classification is 'hateful'.\"}",
    "1061072910473924608": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I\u2019m gonna curb stomp this faggot I swear to god.... \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and a threat of violence, indicating a hateful sentiment.\"}",
    "1057234414298484736": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:AHAHHAHA #Rust Can't believe i got called a retard I'm not even sure if this guy is srs or not lmfao \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains insults and derogatory language, which suggests that the image is hateful.\"}",
    "1045791367442649088": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:RETARD \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, suggesting that the image is hateful.\"}",
    "1105784596015300610": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Accurate description of that type of cunt.... \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, suggesting that the image is a hateful meme.\"}",
    "1057080528162054144": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I was looking at this so confused until I realized, that's my youtube and I'm just really fucking retarded.)) \nASSISTANT: {\"Classification\": \"hateful or not hateful\", \"Explaination\": \"The image is not hateful as it is a comic strip featuring a princess and a man in a Mario costume. The princess is angry, and the man is holding a Wii remote. The tweet text suggests that the person who posted it might be joking about their own confusion, rather than intending to offend anyone.\"}",
    "1056868347659407360": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Her: This pussy make a nigga go retarded Me: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and racial stereotypes. The man's facial expression and the content of the tweet further contribute to the negative and discriminatory nature of the image.\"}",
    "1056639865687851009": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:#GameOfThrones There's no cure for being a cunt! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is considered hateful.\"}",
    "1055186403565260800": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Just another leftist twat! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, suggesting that the image is a hateful meme.\"}",
    "1055148242181218305": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Nigga just stands there \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image contains a racial slur and a depiction of a black person, which is considered hateful and offensive.\"}",
    "1062498143663677440": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This Flampo faggot \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language and insults, which are considered hateful. The image itself does not seem to be hateful, but the tweet text associated with it is.\"}",
    "1056372634680614917": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Play the race card, it's easier than thinking! #BlackConservativeMovement \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a cartoon of a black man with a caption that encourages playing the race card, which is often used in a hateful manner. The tweet text further supports this classification as it implies that playing the race card is easier than thinking, which can be perceived as a derogatory statement towards black people.\"}",
    "1057500421487517696": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> white poor trash lol \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme featuring a picture of Donald Trump with a speech bubble that says 'I sold you out thanks for the vote idiots'. The tweet text further supports the classification as it contains derogatory language towards a specific group of people. This type of content is often considered hateful and offensive.\"}",
    "1113631255554416647": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Perfect! Robert Francis O\u2019Rourke gets ready for rally celebrating #CincoDeMayo illegals welcome! #BuildTheWall \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it is making fun of a politician's name and heritage, and it is associated with a tweet that promotes racist and xenophobic views.\"}",
    "1107098575664828416": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:i was waiting for her to do some cringey ass shit and day nigga but damn...my heart \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests that the image is hateful, as it implies that the elderly woman is doing something cringey or unappealing.\"}",
    "1055227543148773376": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> 13 dislikes tho, has that hi-vis cunt been getting his revenge? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and suggests a negative attitude towards someone, indicating that the image is hateful.\"}",
    "1113222312281636868": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This nigga starts acting crazy with that toy in his pussy but it\u2019s hot! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the racial slur used in the tweet text.\"}",
    "1057619453507100673": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Tough talk from a DRAFT DODGER. Your redneck supporters must be proud of what they got. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a man holding a sign that says 'This is American' and 'He was Radicalized by ISIS' which is a derogatory statement towards Muslims. The tweet text also supports this classification as it is derogatory and disrespectful towards the man's beliefs and heritage.\"}",
    "1043897802558865408": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Hillbilly Television Options M. R. Carey\u2019s New Novel SOMEONE LIKE ME \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is a book cover for M. R. Carey's novel 'Someone Like Me'. It does not contain any hateful content.\"}",
    "1037384348952129537": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:THE DYKE JUMPED OUT HERE \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language towards the woman, suggesting that she is a lesbian and that she is not wanted in the area. This is an example of a hateful meme.\"}",
    "1109547901670162432": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:nigga just asked me if i care about the person that means the most to me \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the use of racial slurs and the negative connotation it carries.\"}",
    "1108711406382256128": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:THIS NIGGA EATIN BEANS has been happening in the northern territories all this time \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it is based on a racial stereotype and promotes negative attitudes towards a specific group of people.\"}",
    "1024679239059161088": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> The fact is a very large majority of tRump supporters IS White trash. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the man's shirt that says 'Fuck Your Feeling' and the tweet text that implies Trump supporters are white trash.\"}",
    "1034794393767694342": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Brown Tattooed Asian Dyke Loves #Dirty Anal #Edinburgh \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a woman in a provocative manner, which can be offensive to some people.\"}",
    "1061018527258288128": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:i csnt stop thinking about jesse saying \"dyke spike\" \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, and the tweet text suggests that it is related to a negative or offensive comment about a person named Jesse.\"}",
    "1051670931259707392": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Y\u2019all gone have to call him nigger tonight when TB smoke the #s off whoever holding Hash Gordon on that seam \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racial slurs and is offensive. The image of two men wearing hats with the words 'Peed Wagon' on them is not relevant to the content of the tweet and does not contribute to the hateful nature of the meme.\"}",
    "1113859177972228096": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I get why the Karstarks were pissy but why was Smalljon Umber such a cunt?! Like what gives \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and negativity towards the character Smalljon Umber, suggesting that the image might be a hateful meme.\"}",
    "1035841407234330624": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:When Your Friends Go Full Retard. #lol #lmao #funny #wwe #retard #omg #fight #funnyfight #JohnCena \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image shows a girl carrying another girl on her back, which can be perceived as a humorous or lighthearted moment. However, the tweet text contains derogatory language such as 'retard' and 'lmao', which suggests that the image might be used in a hateful context. The presence of such language in the tweet can be harmful and offensive to individuals with disabilities or",
    "1060965272981565440": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Lmaooo. \"WHERE YO MUTHAFUCKIN HOMEWORK LIL NIGGA?!?!?!\" \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a young black girl in a negative light, with a caption that is disrespectful and racist.\"}",
    "1037089193070145536": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag> went full retard \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme that uses offensive language to describe a person with a mental disability. It is not respectful or considerate of individuals with disabilities.\"}",
    "1054016747412578304": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:my favorite CUNT \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, suggesting that the image might be a hateful meme.\"}",
    "1062968201653436417": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:\"You gotta be really fucking retarded if you think ima give you another chance\"  Me: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests that the person is angry and might be using offensive language. This could be interpreted as hateful.\"}",
    "1045925447756918784": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> is daddy\u2019s dumb nigger loving whore \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racist language and derogatory terms, which make the image hateful.\"}",
    "1053685336382078977": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag>   Show that to your dad you cunt.   Pair of cunts.   Hun cunts. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which suggests that the image is intended to be hateful.\"}",
    "1108320408468684802": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> THE HIGHT NIGGA \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racist language, which is considered hateful. The image of a man wearing a suit and tie with a pair of scissors and a pair of glasses, along with the tweet text, creates a negative and offensive atmosphere.\"}",
    "1034827616757395456": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Playing the race card? That\u2019s rich! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests that the image is a hateful meme, as it plays the race card and implies that the woman is making a racist gesture. The image shows a black woman with a yellow shirt and big hair, making a funny face with her mouth open. The presence of a vase in the background adds to the casual and playful atmosphere of the scene.\"}",
    "1034877956311662596": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Thank Obama for pushing the race card down every ones throat trying to create a great divide. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it is using the president's image to push a political agenda and create a divide among people.\"}",
    "1035065562429313024": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Sasuke is a faggot \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme that is hateful towards Sasuke, as it is described as a 'faggot' and has a negative connotation towards the character.\"}",
    "1037214683718189058": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag> You are a retard. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which indicates that the image is hateful.\"}",
    "1057042695162605568": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:What the fuckkk what the FUCK God these things are retarded \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and negative sentiment towards the image, suggesting that it is a hateful meme.\"}",
    "1109190054042189827": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:#Free12 \ud83d\udd25\ud83d\udd25\ud83d\udd25 congrats my nigga \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme featuring a man in a mask and a bow tie, with the number 12 in the background. The tweet text suggests that the image is related to a controversial topic, and the use of the word 'nigga' in the tweet text indicates that the image might be promoting racist or discriminatory views. This classification is based on the context and content of the image",
    "1059420568653586433": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Damn this nigga good.. but not too good.. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme that is derogatory and offensive towards the LGBTQ+ community. It is not a respectful or inclusive representation of the community.\"}",
    "1056394971962662912": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Nigga your bare feet touching me in general \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a man in a shower with a towel around his neck, making a racist gesture. The tweet text further supports this classification as it contains offensive language.\"}",
    "1058445740748488705": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> I got the redneck yacht and a 6x8 Cruz sign if you wanna pull up to the Polls on Election Day bruh \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it may contain offensive or discriminatory content. The presence of a flag on the truck and the reference to a 'redneck yacht' and a '6x8 Cruz sign' may be seen as derogatory or insensitive to some viewers.\"}",
    "1044614290580406272": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag><tag><tag> If the shoe fits, trailer trash.... \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a naked man sitting on a toilet, which is meant to be offensive and disrespectful towards the individual.\"}",
    "1058121735025946624": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Nigga this shit is BIG TIME gay ! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language and is considered hateful.\"}",
    "1055934885146300418": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:i cant believe i lost to this retard \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language towards the game and its players, suggesting a negative attitude towards the game.\"}",
    "1050782479399968770": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Pro-Abort #SJW Assaults Peaceful Pro-Lifer - \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it shows a group of people posing for a picture, but the tweet text suggests that it is related to a pro-abortion or pro-lifer conflict, which is a controversial and potentially divisive topic.\"}",
    "1045194023038664704": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:me after playing against the hillbilly four matches in a row and getting insta downed immediately \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a woman in a negative light, suggesting that she is unattractive or unsuccessful. The tweet text further supports this classification as it implies that the woman is being mocked or belittled.\"}",
    "1052534922664132608": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:At my feet, where all you Beasties belong.  A little foot massage before this slave gets his slave cunt buggered! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image and the tweet text suggest a hateful meme, as it portrays a man with a foot fetish, possibly engaging in inappropriate or degrading behavior towards another person. The language used in the tweet text is also offensive and disrespectful.\"}",
    "1043584264422522885": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:New sale! My vids are lit! Faggot Kind Of Servitude \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and derogatory terms, suggesting that the image is intended to be hateful or discriminatory towards a specific group of people.\"}",
    "1045691304812965892": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> she is full retard \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme of a man in a military uniform with a cigar in his mouth, making a funny face. The tweet text 'she is full retard' is not related to the image and is not a hateful comment. The image itself is not hateful.\"}",
    "1054159197808533505": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Real Nigga Shit<tag> \ud83d\udcaf\u2764\ufe0f \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which make it a hateful meme.\"}",
    "1061470928524230656": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:What could\u2019ve been. But no we took some mook ass nigga who can\u2019t play basketball \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and a negative reference to the basketball player, suggesting a hateful sentiment towards the individual.\"}",
    "1054075939691356160": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Nigga went on private LMAOOO \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racial slurs and is considered hateful.\"}",
    "1058459208520101888": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:get this white trash off my screen \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the content and the fact that it is associated with a tweet that is negative towards the subject matter.\"}",
    "1113107504584671233": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Get the money Run the bags up ! Why You mad NIGGA GET YA CASH UP .... \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language and racial slurs, which are indicative of a hateful meme.\"}",
    "1061622646796963841": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> NIGGA WHERE YOU AT \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racial slurs, which are considered hateful.\"}",
    "1105348335781711874": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Fight me nigger<tag> \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and racial slurs. This type of content is not appropriate and should not be shared.\"}",
    "1045112462780125184": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Call me a spic and I\u2019m sending you to the ER \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is considered hateful.\"}",
    "1057592599849132032": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Immigrants \ud83d\udc47\ud83c\udffc are the best Americans &amp; white trash ruins America #DocumentedRealFacts\ud83c\uddfa\ud83c\uddf8 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image and the tweet text suggest a negative and discriminatory attitude towards immigrants. The tweet text contains derogatory language and implies that immigrants are better than 'white trash' and that they are ruining America. This is considered a hateful meme as it promotes harmful stereotypes and discrimination against a specific group of people.\"}",
    "1114006837077188609": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I HATE HER SMAJJSNS PLEASE LYNCH THIS NIGGER \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains hate speech and racial slurs, which indicates that the image is hateful.\"}",
    "1044593662104162304": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:H. Rap Brown's Blacks And Authority ::: Highlighting Chapter Four Of 'Die Nigger Die!' \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text and the image suggest a hateful sentiment towards black people. The use of the word 'nigger' in the tweet text is considered offensive and racist. The image of the man with his hand raised also adds to the aggressive and hostile tone of the image.\"}",
    "1061629878934618112": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Ooo look y\u2019all it\u2019s retarded \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text is offensive and disrespectful towards the woman in the image. It is not appropriate to use such language to describe someone's appearance or actions.\"}",
    "1055065398142517248": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Akeem you do know that thay are not behind the camera so why are you looking in too the camera fake ass twat \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults towards the woman in the image, suggesting that the image is a hateful meme.\"}",
    "1058930062580428801": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> We\u2019re all a little bit retarded,<tag> \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a frog wearing a shirt that says 'autistic is my superpower' and it is standing in front of a sign that says 'autistic child area'. This can be perceived as offensive and disrespectful towards individuals with autism.\"}",
    "1108431300921298945": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:#OnThisDay, 1961, #ElvisPresley - \"SURRENDER\" #Billboard\u00b4s #1. #ElvisHistory... \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is a picture of Elvis Presley holding a guitar, which is a common and non-hateful representation of the singer.\"}",
    "1058942078175076352": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This is Isaiah\u2019s 14 year old twitter! Y\u2019all I\u2019m dead! His bio even says he\u2019s a redneck\ud83d\ude02\ud83d\ude02 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme of a monkey holding a gun, which is considered offensive and hateful. The tweet text further supports this classification as it is a 14-year-old's twitter and the bio says he is a redneck, which might be perceived as offensive by some people.\"}",
    "1044218548728602625": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:the definition of a fukn twat, tiny car two spaces. might pick it up and move it \ud83d\ude00 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, likely due to the negative connotation of the word 'twat' and the reference to moving the car.\"}",
    "1058921913819586561": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> It was a joke dyke. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the presence of a meme that is offensive and disrespectful towards the LGBTQ+ community.\"}",
    "1060945889877848065": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Upstate NY Mayor Not Sorry For Calling Dem Voters \u2018Retarded\u2019 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image shows a red truck driving down a street with a stop sign, and a building with a clock. The tweet text refers to a mayor who made an offensive remark towards democratic voters. This suggests that the image is related to a political issue and might be considered hateful by some people.\"}",
    "1059493560255463424": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Lmao look what this nigga sent me while he at work \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is considered hateful.\"}",
    "1050919505562652673": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I suggest you go back to eating your gf dirty fucking PUSSY Netwar Dyke Systems \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and suggests inappropriate behavior, which indicates that the image is hateful.\"}",
    "1113086684508368896": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> they kinda the reason i\u2019m a dyke \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays two boys in a negative light, suggesting that they are the reason for someone's sexual orientation. This is not a respectful or inclusive representation of individuals.\"}",
    "1057017022750580736": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:GET YO DICK OVER HERE NIGGA \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racist slurs, which make the image hateful.\"}",
    "1053349821657026561": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Crazy how Franco was the first SJW \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a positive view of Franco, a dictator known for his brutal regime and human rights abuses.\"}",
    "1116496848817131520": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag> Dude! Full retard. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it uses offensive language and makes fun of someone's mental state.\"}",
    "1056659595127672840": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:What a Faggot \ud83d\ude02\ud83d\ude02\ud83d\ude02\ud83d\ude02\ud83d\ude02 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme of Martin Luther King Jr. with a caption that is derogatory and disrespectful towards the civil rights leader.\"}",
    "1057417773499015175": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> It's ain't my fault u don't answer my calls nigger \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racial slurs and is offensive. The image of the woman in the yellow shirt and red hat is not the focus of the tweet and is not the reason for the classification.\"}",
    "1042156112760455169": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:HILLBILLY VALLEY V2.0\u00a0MOD \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is a screenshot of a video game, not a hateful meme.\"}",
    "1043776033239982081": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> You retard lmaoooooooooo \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, suggesting that the image is a hateful meme.\"}",
    "1055248417474121729": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Lmfaooo  junni retarded<tag><tag> #PS4share  \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which indicates that the image is hateful.\"}",
    "1113841889227214848": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> nigga you\u2019re a whole joke SKSKKSSKSK \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a black woman in a demeaning and offensive manner. The tweet text further supports this classification as it uses derogatory language towards black people.\"}",
    "1054183183607103489": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> The white trash really love Daddy. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults towards women, which makes it a hateful meme.\"}",
    "1056232735717646336": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Possible leg breaker from the dirty twat that is, Mark Noble \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image shows a soccer player in a blue uniform attempting to kick another player in a red uniform. The tweet text suggests that the player in the blue uniform is a 'dirty twat' and may have intentionally caused an injury to the player in the red uniform. This is considered hateful as it implies malicious intent and disrespect towards the opposing player.\"}",
    "1045103266533691392": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:You a faggot? Look what I have for you! ......  See this and more at: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it is disrespectful and offensive towards the LGBTQ+ community.\"}",
    "1115611071971307520": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Nigga on the ground was trynna rob another nigga for a ps4 and look what them other mfs did \ud83d\ude2d\ud83d\udc80\ud83d\ude2d\ud83d\ude2d \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains racial slurs and is disrespectful towards a specific group of people.\"}",
    "1057750288126369794": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> And this is merchandise being sold at Chester Cheeto rallies. You\u2019re a dumb twat \u2018little Marco\u2019! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests that the image is a hateful meme, as it is being sold at Chester Cheeto rallies and the person is referred to as a 'dumb twat'\"}",
    "1050159895885037568": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Happy birthday ya big dyke<tag> \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language and is considered hateful.\"}",
    "1116423163737305088": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This is crazy they made a song for my nigga \ud83d\ude2d\ud83d\udc40\ud83d\udcaf \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racial slurs and derogatory language, which indicates a hateful sentiment.\"}",
    "1051428575587573760": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> What a f****** retard \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, suggesting that the image is intended to be hateful.\"}",
    "1062323769325293568": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Daily reminder<tag> is a cunt. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is considered hateful.\"}",
    "1056566362104123394": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Controversial, contended, career making? Find out for yourself with HILLBILLY ELEGY \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is a book cover featuring a guitar, which is not a hateful symbol. The tweet text does not contain any hateful content.\"}",
    "1109914420208168963": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> black panther lost to this nigga\ud83e\udd23 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it uses racial slurs and derogatory language to describe a person of color.\"}",
    "1115324820449705984": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:ET never said \u201cET PHONE HOME\u201d .. this slow nigga said \u201cET HOME PHONE\u201d \ud83d\ude02 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a racist stereotype by using the ET character to make a joke about a racial slur.\"}",
    "1058007433795305478": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> He's retarded that one. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests that the image is a hateful meme, as it describes the person in the image as 'retarded'.\"}",
    "1044377013300207616": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Kills defenceless animals, old people, the sick, the vulnerable. In other words, 'a twat!' \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it uses offensive language to describe someone, which is not appropriate or respectful.\"}",
    "1044088598868439040": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:ilysm happy birthday faggot \ud83d\udc93 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is not appropriate for sharing.\"}",
    "1055161206317686787": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> You pathetic cunt. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it is disrespectful and offensive towards the person in the picture.\"}",
    "1042926178561130496": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> This is an idea whose time is NOW! #DeportThemAll \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it promotes the idea of deporting illegal immigrants, which is a controversial and discriminatory policy. The tweet text further supports this classification as it encourages such actions.\"}",
    "1058947439351291906": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I Jus Caught Me A Wave \ud83c\udfc4\ud83c\udffd\u200d\u2642\ufe0fFeel Like A Nigga Jumped In Atlantic \ud83c\udf0a\ud83d\udca7\ud83e\udd37\ud83c\udffe\u200d\u2642\ufe0f \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image and the tweet text are considered hateful as they use derogatory language and make light of a serious issue.\"}",
    "1063670605201985536": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> To the Trailer Trash trying to come for Iggy never even heard of her at that.. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it is making fun of a woman's appearance and her popularity.\"}",
    "1036991230473916417": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> You can bully and play the race card all you want Kamala but that bullcrap just won't fly any more. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it uses a racial slur and implies that the person is not welcome in the store. The tweet text further supports this classification as it is derogatory and racist in nature.\"}",
    "1055864547800739841": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Payback for the Yanky hunter cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language towards an American tourist, suggesting a hateful sentiment towards the individual. The image of a goat on top of a person lying on the ground may be used to further express this sentiment.\"}",
    "1114673039822794757": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Call that revolution, you muzzie devil spawn... it would be the end of your cult in America. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains hateful language towards Muslims, suggesting that the image is a hateful meme.\"}",
    "1055786781034102784": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:My redneck appears on my Instagram \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is of a green tractor harvesting crops in a field, which is not a hateful meme.\"}",
    "1105259383875923968": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:\"Oooh now its OK to kill Baby. Nigga's looked at me crazy like a really killed a baby\" \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains hateful language and racial slurs, which are not appropriate for a meme.\"}",
    "1062472668778319872": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:stuipid cunt jumped out the way for the triple  \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, which suggests that the image might be a hateful meme.\"}",
    "1107846837191561217": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Open your mouth, faggot \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image and the tweet text are hateful memes, as they use derogatory language to insult and discriminate against the LGBTQ+ community.\"}",
    "1058529469370155008": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:imagine getting jumped by raccoon niggas and one of them say \"Move lemme infect this nigga\" \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racist language and is offensive. The image of the man wearing a lot of jewelry and a gold chain is not relevant to the content of the tweet.\"}",
    "1061630054617235456": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Someone tell them that their Race Card expired in November 2016. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image and the tweet text are considered hateful as they make a joke about the expiration of a race card, which is a sensitive and controversial topic.\"}",
    "1107331297666568194": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> HAHA ya dirty low life cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, suggesting that the image is a hateful meme.\"}",
    "1035251405647474688": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Battlefield V en retard sur le\u00a0front \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a woman in a game with a negative message. The tweet text further supports this classification as it is derogatory and disrespectful towards the game and its players.\"}",
    "1051636726882537473": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:When Toys R Us was going out of business, FemiNazi Ghostbusters still didn't sell, even under clearance prices. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it uses derogatory language and makes a derogatory statement about a specific group of people, which is not appropriate or respectful.\"}",
    "1106581965036240897": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:If you jump into a mosh pit and right off the bat just start throwing haymakers then you\u2019re a cunt. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which indicates that the image is hateful.\"}",
    "1036231715071696896": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:retarded \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or derogatory language or imagery towards a specific group of people. The presence of the word 'retarded' in the tweet text further supports this classification.\"}",
    "1057301878206283779": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:FYI Mr<tag>  Respect is earned, Not demanded !! In fact insane &amp; retard people are running the Affairs \ud83d\ude44 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image and the tweet text suggest that the content is hateful, as it is disrespectful and insulting towards a group of people. The use of derogatory language and the disregard for respect further supports this classification.\"}",
    "1107619626559647745": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Justin bieber:  Twitter nigga \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, which suggests that the image might be a hateful meme.\"}",
    "1055130496370401280": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Seems like his mother didnt teach him not to walk into trash while wearing white shoes! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains a negative comment about the man's appearance and behavior, suggesting that he is not well-dressed or well-behaved.\"}",
    "1064252907942551554": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag>  May wanna start checking twitter u cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it may contain offensive or discriminatory content.\"}",
    "1062102288649601024": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:she's still a cute dyke tho we will get through it \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is not hateful as it shows a woman sitting on a couch with pink pillows on her head, which is a light-hearted and playful scene. The tweet text also suggests that the woman is still considered cute despite the pillows on her head, indicating that the image is meant to be humorous and not offensive.\"}",
    "1117485029607735300": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Me after Tommy Smith died and I found out he was a racist cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it is making fun of a deceased person's death and using offensive language to describe the person.\"}",
    "1046142106291572737": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Not political, unless you are a Fat SJW \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it targets a specific group of people, in this case, fat individuals. The message is derogatory and promotes negative stereotypes about fat people. This is not a respectful or inclusive way to communicate and should be avoided.\"}",
    "1051036264831561728": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Redneck infant care. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the use of derogatory language and the reference to a controversial political ideology. The phrase 'redneck' is often associated with racism and discrimination, and the reference to 'infant care' in a derogatory manner further contributes to the negative sentiment in the image.\"}",
    "1116654555197050880": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> \"nigga did i just catch you havin fun?!?!\" \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains a racial slur, which is considered hateful and offensive.\"}",
    "1053495671263768576": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> U heard me nigga \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it features a man wearing a hat with the word 'you' on it, which can be perceived as a derogatory message towards someone. The tweet text further supports this classification as it contains offensive language.\"}",
    "1057878666082807813": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Remember Kate Steinle #PassKate'sLaw #buildthewall \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it promotes the idea of building a wall to keep people out, which is often associated with racism and xenophobia.\"}",
    "1063903445084708864": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag> They were lying hood rats playing the race card \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial stereotypes, which contribute to a hateful sentiment.\"}",
    "1055165674329378821": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Lmao but when a nigga do that he thirsty tho females funny af \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and makes a derogatory statement about a specific group of people. This is considered a hateful meme.\"}",
    "1063897163669811200": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:#yourvegandietisntcrueltyfree <tag>\u2069 let\u2019s wait for some SJW commenters! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image portrays a woman holding a tomato on a pile of people, which can be interpreted as a critique of veganism. The presence of the tomato and the woman's action suggest a negative connotation towards veganism. The tweet text further supports this classification as it implies that the vegan diet is not cruelty-free.\"}",
    "1064383613397983234": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:\"Meeting this retard after ages\"  \ud83d\udcf7<tag> via Instagram story.  #PSOnMTV #ParthInSpace \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, suggesting that the image is a hateful meme.\"}",
    "1057407453241978880": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I\u2019m a little retarded if you haven\u2019t noticed yet \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests that the image is hateful, as it implies that the woman is being mistreated or disrespected by the man.\"}",
    "1024232039237799937": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag> Ha ha fuckin soft twat \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which indicates that the image is hateful.\"}",
    "1055248492137009152": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> NIGGA HURRY UP AND DELETE THIS \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the use of racial slurs and the negative portrayal of the individuals in the picture.\"}",
    "1056057640516755457": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> OMG Candy, you are the queen of playing the race AND victim card. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it uses derogatory language to describe a person, specifically a woman, and implies that she is playing the victim card. This is not a respectful or constructive way to engage in a conversation or express an opinion.\"}",
    "1057271206653710337": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:THIS NIGGA WILDIN GET THE FUCK OUTTA HERE LMAO \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is considered hateful.\"}",
    "1063628391885213698": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Sg12 w retard light is still pogchamp btw \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which suggests that the image is hateful.\"}",
    "1045924151305756673": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:EVERYONE IS ASLEEP BUT GUESS WHICH FAGGOT FINALLY CLOCKED OUTTTTT \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text is derogatory and disrespectful towards the individual in the image, which is considered hateful.\"}",
    "1043163076927733760": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Yes! I'm a panty wearing sissy faggot \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text is derogatory and offensive towards the LGBTQ+ community, which makes the image hateful.\"}",
    "1055874913364570114": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:YEEHAW BITCH TIME TO GO JOHN MARTSON ON A NIGGA \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is considered hateful.\"}",
    "1113491167512080386": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:\ud83d\ude02\ud83d\ude02\ud83d\ude02nigga plays rough \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language towards African Americans, which is considered hateful.\"}",
    "1049718764827279360": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Healthy Pumpkin Spic \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is showcasing a box of cereal and a bowl of cereal, which is not a hateful meme. It is a simple presentation of a food product.\"}",
    "1042443733126590464": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:NOOOOO!!! Give him his soul back you muslim commie twat!!! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults towards the president, suggesting a hateful sentiment towards him.\"}",
    "1034875241221287936": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Nigger \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racial slurs and is considered hateful.\"}",
    "1035226601112391680": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I\u2019m one disgusted nigger right now this is black erasure \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text further supports this classification as it contains racial slurs and negative language.\"}",
    "1059074272252043264": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:You tell her you lying little cunt \ud83d\ude02\ud83d\ude02\ud83d\ude02\ud83d\ude02  <tag> - \ud83d\udcf8 thank you for this gem \ud83d\ude02 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a woman in a negative and offensive manner. The tweet text further supports this classification as it uses derogatory language to describe the woman.\"}",
    "1059552091440603136": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:FFS - WHY IS THIS CUNT ON THE TELE AGAIN   #Farage \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or derogatory content. The tweet text also supports this classification as it contains derogatory language towards a specific individual.\"}",
    "1050200907412049920": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:For the people that say we are white trash, hahahahaa you\u2019re right\ud83d\ude0e\ud83d\ude0e<tag> \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which implies that it contains offensive or derogatory content towards a specific group of people. The tweet text further supports this classification as it seems to be making fun of people who say they are white trash.\"}",
    "1047351309551058946": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:'Hillbilly Elegy' director Ron Howard visits Middletown's Triple Moon Coffee Company \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is not hateful as it shows a man wearing a hat and glasses, and there is no indication of any offensive or hateful content in the image or the tweet text.\"}",
    "1036118472382664704": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> saying faggot to wii music \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it uses derogatory language to describe a person, which is disrespectful and discriminatory.\"}",
    "1063825485812113415": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Shame u didn\u2019t hang around ya Furry cunt !!!!! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet contains offensive language and insults, which indicates that the image is hateful.\"}",
    "1058057894422331392": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Bro you know how mad you gotta be to call someone a nigger on ROCKET LEAGUE ? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the use of racial slurs and the negative tone of the conversation between the players.\"}",
    "1037430129671200769": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Or \"Baby I'm sorry AKA is a faggot\" \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and derogatory terms, suggesting that the image is a hateful meme.\"}",
    "1056986202232868864": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I'm listening to \"\u0e2d\u0e22\u0e48\u0e32\u0e17\u0e33\u0e2d\u0e22\u0e48\u0e32\u0e07\u0e19\u0e31\u0e49\u0e19 feat. The Rube-PORTRAIT\". Let's enjoy music on JOOX! \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is a portrait of a man and his band members, showcasing their music and not promoting any hate or discrimination.\"}",
    "1106728248187256834": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:It's been \ud83d\udd95\ud83c\udffe The World Since I Lost My Fukin Nigga #LongLiveTrap\ud83d\udd4a #LLT #actupchallenge RT \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which indicates that the image is hateful.\"}",
    "1035468119597375488": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Ferrari twat parking \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language towards the car owner, suggesting a negative attitude towards the person who owns the Ferrari.\"}",
    "1062338211677114368": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag> FAILED Wigger! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme that uses offensive language and imagery to make fun of a person. It is not a respectful or appropriate way to communicate, and it can be considered as hateful.\"}",
    "1058733671342112768": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> He's an absolute cunt of a man \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language towards the image, suggesting that it is a hateful meme.\"}",
    "1044590575138287618": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This woman shouldn\u2019t be a politician . God knows how people can vote for this twat \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains negative and offensive language towards the woman, suggesting that she is not suitable to be a politician. This can be considered as a hateful meme.\"}",
    "1058610234506272768": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> If you \"feel\" you are a SJW...  How about #JuvenileJusticeReform ?  I \"do\" that too... \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is a drawing of a building, not a hateful meme. It is a representation of a building, not a commentary on any specific group of people.\"}",
    "1064265334977425409": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Bint away upstairs   Me with the TV doonstairs \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a black character in a negative light, suggesting that the character is not wanted or understood.\"}",
    "1054617666965561344": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This nigga got that \u201cI\u2019m not 0-3, they 0-3\u201d face smh! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the use of racial slurs and offensive language in the tweet text.\"}",
    "1057808804597977088": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Hot milf gets cock to smash #her cunt Southampton \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it may contain offensive or inappropriate content. The tweet text also implies that the image is related to explicit sexual content, which could be considered inappropriate or offensive to some viewers.\"}",
    "1046501673991118849": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:fuck i just had a brilliant idea for a cool anti-sjw youtube channel, just lemme uhhhh \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is not hateful as it shows a man in a suit and tie, which is not related to any offensive or discriminatory content.\"}",
    "1055163163526742017": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> And cunt number 2 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, which suggests that the image might be a hateful meme.\"}",
    "1057229399974703104": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:She said \"make that nigga put down 2K\" luv it barz<tag> #CardiB #CardiGang #money \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which are considered hateful.\"}",
    "1062041043296755715": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Best graphics showing the need of the #Wall #BuildTheWall \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it promotes the idea of building a wall, which is often associated with racism and discrimination.\"}",
    "1057451410772488193": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:fuck you<tag> ! u fat faggot, big mouth whale! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults towards the woman in the image, suggesting a hateful sentiment.\"}",
    "1055834448321802240": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> He said yeah bitch you retarded \ud83d\ude02\ud83d\ude02\ud83d\ude02\ud83d\ude02\ud83d\ude02\ud83d\ude2d\ud83d\udc80 who's man's is this \ud83d\ude02\ud83d\ude02\ud83d\ude02\ud83d\udc80 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which indicates that the image is hateful.\"}",
    "1046152036427993091": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> That's white trash \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image and the tweet text are considered hateful as they use offensive language to describe a woman.\"}",
    "1057426993648668673": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> she follows so many indie dyke musicians there is absolutely no way she\u2019s not \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a negative stereotype of the LGBTQ+ community, specifically targeting the character's gender identity and interests.\"}",
    "1062591675221098496": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> This fucking cunt! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text is offensive and disrespectful towards the person in the image. It is not appropriate to use such language towards others, especially in a public forum like Twitter.\"}",
    "1060915202017890304": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Hi, I hate my life and you're a cunt - Welcome to my TED talk. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests that the image is hateful, as it contains negative language and a negative sentiment towards the viewer.\"}",
    "1042193685016993792": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Retarded #Fakenews \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it is a picture of a man with a caption that is derogatory and disrespectful towards the individual.\"}",
    "1115321524108574722": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Couldnt not have a beer on the day that twat died! #thatcherdeadday #inthemud \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and references to a deceased person, which indicates a hateful sentiment.\"}",
    "1057045216899883011": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Y\u2019all ain\u2019t gotta listen to me but, BOOM there go ya nigga in the inbox of a bitch who wear bottom mascara \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which make it a hateful meme.\"}",
    "1107483268990070785": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:dam nigga died an his mom found his hentai #F \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme that is hateful and offensive, as it uses racial slurs and makes light of a tragic situation.\"}",
    "1035902082199572486": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Oh no sis she pulled the mf race card whew \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme that is considered hateful due to its content and the use of a racial slur. The tweet text also supports this classification as it implies that the image is offensive and racist.\"}",
    "1043947680995717121": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:You a faggot? Look what I have for you! ......  See this and more at: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it is derogatory and disrespectful towards the LGBTQ+ community. The tweet text further supports this classification as it uses derogatory language towards the community.\"}",
    "1115988261573361664": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:\u201cNigga thought he was Obama\u201d \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language and racial slurs, which are considered hateful.\"}",
    "1044608595482992640": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Retarded low iq bitch \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which indicates that the image is hateful.\"}",
    "1113895555376254976": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> My nigga waiting for the \u201cwhen you gon cook for me?\u201d Dm every. single. day. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the use of racial slurs in the tweet text, which is inappropriate and offensive.\"}",
    "1057025171972915200": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> No homo... But the nigga is pretty...\ud83d\ude2e \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language and is considered hateful. The image of the man with a mustache and a wink, along with the caption, is also considered hateful.\"}",
    "1056583438130655233": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:What a cunt? \ud83d\ude02\ud83d\ude02\ud83d\ude02 #pogba \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, suggesting that the image might be a hateful meme.\"}",
    "1053563982353702912": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:s/o to the supreme retard<tag> \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image and the tweet text contain offensive language and insults, which are considered hateful.\"}",
    "1107391526781493249": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> this redneck was living in 2019 while we were all back in 2008 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the use of offensive language and the reference to a political figure, which can be perceived as disrespectful and insensitive.\"}",
    "1045720991316480000": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This just looks retarded \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is a logo of a sports team, and the tweet text does not contain any hateful or offensive content.\"}",
    "1062225318210166784": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> I got twitmod for using a meme with cunt in it.  She's a thin-skinned little bitch. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, indicating that the image is hateful.\"}",
    "1064410117242843137": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:stumbled across this cunt on instagram. i recommend having a look \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and suggests that the image is hateful. The image shows a man lying on a chair with a video camera, which might be interpreted as a humorous or artistic scene. However, the tweet's language and tone make it clear that the image is intended to be offensive and not appreciated.\"}",
    "1109836708164628480": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I never regret using Taco Nigger \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains a racial slur, which is considered hateful. The image of the two people talking to a Cookie Monster puppet might be unrelated to the hateful content of the tweet.\"}",
    "1051598167584722945": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Victim card. Right on cue. This shit is so predictable. \ud83e\udd23 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains a victim card and is making fun of someone, which is considered hateful.\"}",
    "1061748978902016002": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> This guy is retarded \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text is disrespectful and offensive towards the man and the woman in the image.\"}",
    "1055286509555933184": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Aye man this nigga is legendary for breaking the durag/nba barrier \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is considered hateful.\"}",
    "1035628947239780357": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> saaaaaaay nigger! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains a racial slur, which is considered hateful.\"}",
    "1058979636594454529": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> This is what Pooooor white trash looks like!!! Even Killary agrees \ud83e\udd23\ud83e\udd23\ud83e\udd23\ud83e\udd23 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text is derogatory and disrespectful towards a specific group of people, which indicates that the image is hateful.\"}",
    "1050455095731576833": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:When you say some straight retard shit in the group chat and the chat bubbles pop up like... \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it uses a picture of a wizard from the Lord of the Rings to make a joke about death, which can be considered offensive and disrespectful to the source material.\"}",
    "1062405631825637376": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> was this supposed to be funny? It wasn't kid. oh You did more than \"crying\" you fucking cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the racist and offensive content, including the use of the N-word and the depiction of a black man being lynched. The man holding the signs also adds to the negative and aggressive tone of the image.\"}",
    "1062773325607387137": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:DYKE RIGHTS \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language towards the LGBTQ+ community, which is considered hateful.\"}",
    "1061419500254494720": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:\" These suckers hoping u choke .. Put dat nigga on the ropes\ud83d\udc4a\ud83d\udc4a don't let em swing ! Knock his lights out !! \" \ud83c\udfa5 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and a violent message, which indicates that the image is hateful.\"}",
    "1055104285896269825": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> The Side Eyed Hillbilly is partially responsible. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a woman with a large nose and a mean expression, which is intended to be offensive and derogatory towards women.\"}",
    "1035465894850449408": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> The twat even has advertising at his house \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and negativity towards the person's property, suggesting a hateful sentiment towards the individual.\"}",
    "1043797952219828224": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:A NIGGER??? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a young black boy in a negative light, using racial slurs and derogatory language.\"}",
    "1055233940187795456": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:BONES MY NIGGA \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which make it a hateful meme.\"}",
    "1054428897394212868": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:don\u2019t preach about positivity when you\u2019re a selfish cunt<tag> \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains negative or offensive content. The tweet text further supports this classification by using offensive language towards the woman in the image.\"}",
    "1051556305419325442": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:So proud of you nigger. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racist language, which indicates that the image is hateful.\"}",
    "1053424468675231751": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:\u201cI heard payback is a motherfucking Nigger...\u201d \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racial slurs and hate speech, which makes it a hateful meme.\"}",
    "1042995662864830466": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> That's why I'm staying my twat on the west. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and a negative sentiment towards the west, which indicates that the image is hateful.\"}",
    "1053413238958968832": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag> Lol the nonce cunt couldn't take the banter \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, suggesting that the image is a hateful meme.\"}",
    "1115431234224652288": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> That's her race card right there you're looking at it strings were pulled he was freed \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it is making a joke about race and using a card to represent it. This is not an appropriate or respectful way to address the topic of race.\"}",
    "1063383836967530496": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Imagine my shock part VII #twat \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme of a man in a suit with a pink tie, which is considered offensive and hateful. The tweet text suggests that the image is part of a series of offensive memes.\"}",
    "1108082039356559363": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:456kms apart but me and my nigga STILL got that unbreakable bond \ud83d\ude02 you can\u2019t beat this \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which make it a hateful meme.\"}",
    "1058647976401399808": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I think this cunt is a tad confused!! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the presence of a swastika and the fact that it is being held by a person in a black hoodie, which may be associated with neo-Nazi or white supremacist groups.\"}",
    "1114967082440040453": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Aight nigga... \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a man in a white shirt with a gold necklace, and the tweet text is derogatory and racist.\"}",
    "1056793244690976768": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Lmao RT<tag>: Nigga I would\u2019ve swallowed Rihanna whole face \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is considered hateful.\"}",
    "1064281231485890560": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Ungrateful twat \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image and the tweet text suggest that the content is hateful, as it contains offensive language and insults towards someone.\"}",
    "1044974787242721280": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag> your faggot level power is OVER 9000! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text is derogatory and disrespectful towards the LGBTQ+ community. It is not a hateful meme.\"}",
    "1035573842549329920": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Everyone else: \u201caw babe it\u2019ll be ok\u201d <tag>: \u201cyou\u2019re a twat and you need to sort your shit out\u201d \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, indicating that the image is a hateful meme.\"}",
    "1062524191973490688": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:wish I could live life looking through retard-tinted glasses like this, things would be easier \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests that the image is a hateful meme, as it implies that the person wishes they could live life with a disability to make things easier.\"}",
    "1051616307068751873": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Magic Johnson when he found out Donald Sterling called him a \"nigger\" \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it is a picture of a woman with a caption that makes a reference to Magic Johnson and Donald Sterling, which is considered offensive and racist.\"}",
    "1053716686573105152": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Need to find this utter twat.! Who is he.? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests that the person in the image is being targeted and referred to as an 'utter twat'. This indicates a negative and potentially hateful sentiment towards the individual.\"}",
    "1050034775388504064": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Full Gallery: \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image shows two women posing with tennis rackets on a tennis court, which is a common and non-offensive scene. The tweet text does not contain any hateful or offensive content.\"}",
    "1062224674438828037": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> HUFF POST you JUST WENT FULL RETARD \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it uses offensive language and insults to mock the person depicted. The tweet text further supports this classification as it uses derogatory language to describe the person.\"}",
    "1063426086363521024": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:wdym u plan to make a team of 5 members, u ugly twat yg \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which indicates a hateful sentiment towards the person in the image.\"}",
    "1053464072014979072": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:No Nigger passes in the NYC, you might get us shit bust to the white meat \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racist language and is considered hateful.\"}",
    "1042274706890608646": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:literally only follows you around and wins by survival time. fucking faggot \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, and the tweet text contains offensive language towards the subject of the image.\"}",
    "1058024846247034880": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:i already know its gonna be white trash i swear \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests that the image might be considered as hateful, as it contains negative words about the content of the image.\"}",
    "1061317966837497858": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:drip go stupid like a retard \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which suggests that the image is hateful.\"}",
    "1044331896308723720": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:You a faggot? Look what I have for you! ......  See this and more at: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it is derogatory and disrespectful towards the LGBTQ+ community. The tweet text further supports this classification as it uses derogatory language towards the community.\"}",
    "1043320121610174465": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:10 Most Retarded Ring Names We're Glad the WWE Scrapped \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it is making fun of a professional wrestler's name and appearance, which can be considered disrespectful and offensive.\"}",
    "1063618361182076929": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Maybe you candidate lost fair and square but resort to the old faithful 'race card'. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a cartoon of a man in a suit holding a 'race card,' which is often used as a tool to play the race card when someone is losing an argument. The tweet text suggests that the image is being used in a negative context, implying that the person is resorting to a 'race card' when they are losing a fair argument. This can be considered as a hateful meme as",
    "1062364554171158528": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Am I going to absolutely rip the cunt with Christmas market food and my usual sushi exploits at Temaki? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is likely to be considered hateful.\"}",
    "1035442048575332353": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> You\u2019re the only white trash here sweetie \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language towards the person in the image, suggesting that the image is a hateful meme.\"}",
    "1035178561638944769": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:She has one more white dude to date. From there she better have a nigger or else \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racist language and is considered hateful.\"}",
    "1043941065424883713": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag><tag> Why u still in my mentions nigger \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it uses racial slurs and promotes negative stereotypes.\"}",
    "1057426037313662976": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:My nigga<tag> looking homeless af \ud83d\ude02\ud83d\ude02 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a man in a white tank top pointing at another man who is described as a 'nigga' in a derogatory manner. This language is offensive and disrespectful towards the African-American community.\"}",
    "1055779480168321024": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Fat. Miserable. Cunt. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults towards the woman in the image, suggesting that the image is a hateful meme.\"}",
    "1035215794496569349": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Come mo u deserve it that twat behind him Ramos fucken show him \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it shows a man being punched by another man, which can be considered as a violent and aggressive act.\"}",
    "1050714492139696129": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Indian pilots might have to be the most ignorant dick ass pilots out there  All that pollution have them retarded \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults towards Indian pilots, suggesting a negative attitude towards them. This could be considered as a hateful meme.\"}",
    "1061910714921766913": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:He's an all lives matter/Colourblind redneck.  If that's not a \ud83d\udea9\ud83d\udea9\ud83d\udea9\ud83d\udea9\ud83d\udea9\ud83d\udea9I don't know what is. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme that is hateful towards a specific group of people, as it uses offensive language and stereotypes to make a point.\"}",
    "1035654030217887744": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Didn\u2019t Tyler The Creator say homophobic bars and call somebody else a Faggot too??? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the reference to Tyler The Creator's past behavior and the use of derogatory language in the tweet text.\"}",
    "1063709771239514112": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Flat Earthers are retarded \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text is derogatory and disrespectful towards flat earthers, which can be considered as hateful.\"}",
    "1064251494621360128": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Also I'm calling the Twitter police becuase you said retard \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image and the tweet text suggest that the content is hateful, as it contains offensive language and potentially derogatory terms.\"}",
    "1050662154519568384": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I really just never know if<tag> is being ironic of if he is actually retarded \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests that the person is being ironic or making a joke about the person's intelligence. This can be perceived as offensive and hateful.\"}",
    "1105558566751088641": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Nigga was stealing lucky charms \ud83d\ude02 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text is racist and offensive, which makes the image a hateful meme.\"}",
    "1051059607500537857": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Labor ran workshops \"how to cross your arms like a faggot\" \ud83d\ude2b\ud83d\ude2b\ud83d\ude2b \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the tweet text, which is derogatory and disrespectful towards the LGBTQ+ community.\"}",
    "1042719504395116544": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag><tag> Whats this say retard? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme that uses heart symbols to represent the artists, and it is considered hateful due to the use of derogatory language in the tweet text.\"}",
    "1045142651274752002": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:She speaks about Islam and how terrorism should not be linked to religion. Do you agree or disagree? \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image shows a woman speaking into a microphone, and there is no indication of hate or discrimination in the content. The tweet text also suggests a discussion about Islam and terrorism, which is a matter of debate and opinion. The image itself does not contain any explicit or hateful content.\"}",
    "1061958079485562883": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Street Sign Making A Right Twat Out Of Him \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, suggesting that the image is intended to be hateful.\"}",
    "1061466932627546112": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I gotta pay this nigga whEN HE WANTED TO LEAVE ME \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which are considered hateful.\"}",
    "1050507663317053441": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Got my new gay card in the mail. She\u2019s a faggot ladies. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language and promotes negative stereotypes, making it a hateful meme.\"}",
    "1116959645053202433": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Huh I don\u2019t know who T is and we\u2019re not goin out we was married before retard \ud83d\ude15 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and insults towards someone named T.\"}",
    "1058804431213486081": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> \ud83d\ude02\ud83d\ude02please tell me you aren\u2019t at a grown ass man hating on Nicki Minaj with your hillbilly looking ass \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a negative and disrespectful attitude towards a specific individual, in this case, Nicki Minaj.\"}",
    "1035716352118546432": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Hey guys, don\u2019t go full retard and vote in a socialist. #Florida \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains negative and offensive content, such as the monkey pointing at the politician and the reference to a socialist. The tweet text also adds to the negative sentiment, suggesting that the image is promoting a harmful ideology.\"}",
    "1064156386005790720": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Hey White Trash. How many illegals live with you \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and content that discriminates against a specific group of people.\"}",
    "1057185708572659712": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> \ud83e\udd23\ud83d\ude02\ud83d\ude02\ud83d\ude02\ud83d\ude02\ud83d\ude02\ud83d\ude02\ud83d\ude02\ud83d\ude02\ud83d\ude02as if I give a fuck what you think, get off my thread ya twat \ud83e\udd23\ud83e\udd23 \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is a humorous and light-hearted depiction of monkeys, not intended to be hateful or offensive.\"}",
    "1043213963176161282": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Yea that's fair  I wouldn't be angry if the infusion system wasn't fucking retarded \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is a screenshot of a video game, showing a character's stats and abilities. The tweet text does not contain any hateful language or content.\"}",
    "1107322487677878272": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Peter is not bright and kind of a cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet contains offensive language and insults towards Peter, suggesting a negative attitude towards him. This could be considered as a hateful meme.\"}",
    "1058168694734389249": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Remember Kate Steinle #PassKate'sLaw #buildthewall Merit based immigration system \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it promotes a divisive and discriminatory message. The phrase 'build that wall' is often associated with anti-immigrant sentiment and racism. The tweet text also includes a reference to Kate Steinle, which is a controversial and politically charged issue. The combination of these elements in the image and the tweet text creates a hateful atmosphere.\"}",
    "1047001193178894336": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Who knew a redneck would change my life? \ud83e\udd19\ud83c\udffc\ud83d\udc9e Loving life w/ \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image shows a man and a woman kissing, which is a romantic gesture and not a hateful one. The tweet text also suggests a positive experience with a redneck, which further supports the idea that the image is not hateful.\"}",
    "1042259433013669893": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Have u found a racist like you aww cute hillbilly \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racist language and is considered hateful.\"}",
    "1057748382985400320": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Nigga was like \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a black man in a hoodie and hat, making a gesture with his hand, which is often associated with the N-word. The tweet text further supports this classification as it uses offensive language.\"}",
    "1046208522793283584": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> What a truly horrible disgusting human being white trash America is your king \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it may contain offensive or derogatory content towards a specific group or individual. The tweet text further supports this classification by calling the person in the image 'white trash' and 'your king', which can be perceived as disrespectful and derogatory.\"}",
    "1054431229016182785": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Just fixed two doors in my house with duct tape. Redneck leveled up! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a man in a plaid shirt and hat, with a microphone, making a derogatory comment about a redneck. The tweet text further supports this classification as it uses derogatory language to describe the man's actions.\"}",
    "1061106434128179200": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:this is deadass how i got my nigga idc idc idc \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is considered hateful.\"}",
    "1062589642569072640": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This is why I moved to Poland with my family! #safety #nomuslims \ud83c\uddf5\ud83c\uddf1\ud83c\uddf5\ud83c\uddf1\ud83c\uddf5\ud83c\uddf1 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a negative stereotype of Muslims and promotes discrimination and intolerance.\"}",
    "1053774185326108672": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Cool. Electoral college cuz why?  Fucking redneck morons get more mouth breathing representatives \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and a negative attitude towards a specific group of people, which indicates that the image is a hateful meme.\"}",
    "1064208348151566336": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Hahahahaha i'm glad this retard blocked me \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, indicating a hateful sentiment towards the person who was blocked.\"}",
    "1044912248634978304": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> The original HillBilly \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme of a politician with a red tie and a red shirt, which is considered hateful as it may be offensive to some people.\"}",
    "1045977956512718849": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:clout faggot \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it uses a comic strip to make fun of a person's appearance, specifically their head shape, which is considered offensive and disrespectful.\"}",
    "1043590617773826049": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Gonna fix a redneck margarita for reading time. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a negative and offensive stereotype of a redneck, which is disrespectful and discriminatory.\"}",
    "1056231961126035456": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:NIGGA \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racial slurs, which are considered hateful.\"}",
    "1055190382282244096": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I MEAN WE ARE BOTH RETARDED SO \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which indicates that the image is hateful.\"}",
    "1107362090686300160": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> She what now..?!?! Nigga please.... \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme that uses racial slurs and is considered hateful.\"}",
    "1044033016836837376": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:on another note... i saw a nigger with silicon ass shots today at work... u fool'n no one bruh.. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racial slurs and derogatory language, which indicates that the image is hateful.\"}",
    "1036987272091119617": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I'M BACK!! WHITE TRASH (EMINEM MGK G EAZY DISS) \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains a picture of Eminem with a red X over it, suggesting that he is being disrespected or criticized. The tweet text further supports this classification as it contains a diss towards Eminem and other artists.\"}",
    "1058797937420050432": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:this bitch said platinum like she didn\u2019t just become the token nigger for republican twitter \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a young woman wearing a red hat and glasses, with a tweet that is racist and derogatory towards African Americans.\"}",
    "1058667804604416001": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This cunt does my head in please go away \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and a negative sentiment towards the person in the image. This classification is based on the use of derogatory language and the overall tone of the tweet.\"}",
    "1050547953172140032": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:#sissy faggot \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image and the tweet text are hateful and disrespectful towards the woman, using offensive language and making inappropriate sexual comments.\"}",
    "1064367919084097536": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:haha fucking wetback \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language towards a specific ethnic group, which is considered hateful.\"}",
    "1045095160764411905": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:The fact that you spelled retarded rarted is retarded.  Oh yeah and I'm no longer single\ud83d\udc45\ud83d\udc45\ud83d\udc45\ud83d\udd12 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which indicates that the image is hateful.\"}",
    "1056294164239925248": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Didn\u2019t know you could somehow be this much of a cunt about the Leicester tragedy. It only just happened ffs \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insensitive comments about the Leicester tragedy, which suggests that the image is a hateful meme.\"}",
    "1056538688144973835": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This sick ass cunt bitch bragging about bringing her friends to get raped, and issuing threats. 900 trillion a piece \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and threats towards a woman.\"}",
    "1053548267726749696": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Fantastic misunderstanding of history, culture and software wrapped up in one retarded analogy. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the man's smirk and the tweet text's negative tone. The tweet text also implies that the image is a misunderstanding of history, culture, and software, which adds to the negative perception of the image.\"}",
    "1036128102533890048": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Happy birthday faggot, hope you stub your toe or something like that! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language and insults, which are indicative of a hateful meme.\"}",
    "1046642593709223936": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Faggot! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language, which is considered hateful.\"}",
    "1044763215891181568": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> I miss my pathetic excuse for facial hair, I loved how it made me look like white trash. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests that the image is a hateful meme, as it implies that the man's beard makes him look like 'white trash'.\"}",
    "1057015170264899584": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> That\u2019s more than 7 days ago. So now you\u2019re fake and retarded. And a dude. And you have a cock. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which indicates that the image is hateful.\"}",
    "1062961049853292545": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> the FAGGOT jumped \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language towards the individual in the image, suggesting that the image is hateful.\"}",
    "1059483620602191873": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> That was a Hillbilly Reunion.  All Kissing Cousins. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests a negative and offensive stereotype about a specific group of people, which is considered hateful. The image of people waiting in line at a booth with a Trump rally sign might be used to further perpetuate this negative stereotype.\"}",
    "1113610840060694529": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> That nigga was sick. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme that is disrespectful and offensive towards people of color.\"}",
    "1057530782644871168": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:THAT NIGGA<tag> LEFT AFTER HE DIED AT THE BEGINNING CUZ HE AINT BELIEVE IN THE PROCESS \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, making it a hateful meme.\"}",
    "1063495689739616256": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This is what the retarded scousers have done to Jurgen Klopp \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a negative and offensive representation of a person, specifically J\u00fcrgen Klopp, which is not appropriate or respectful.\"}",
    "1056531658428633093": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Found this pic floating around anti-Trump accounts \ud83d\udc47  So now Trump supporters are being referred to as White Trash. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a woman in a Trump hat and a bag that says 'white trash' in a derogatory manner, targeting Trump supporters.\"}",
    "1061474832897007617": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Cunt Punt tee shirts... Get your Cunt Punt tee shirts here \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it uses offensive language and makes light of a serious issue.\"}",
    "1061672603432165376": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:The coldest nigger lover west of the Mississippi \ud83d\udd25 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains a burning cross, which is a symbol of hate and racism. The tweet text further supports this classification as it uses offensive language and racist stereotypes.\"}",
    "1105867348261695491": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Me at concerts surrounded by a bunch of white people singing the lyrics shouting the word nigga repeatedly \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a man with a beard and a suit, surrounded by a group of people, with the word 'nigger' being repeatedly shouted. This is offensive and disrespectful language that should not be used in any context.\"}",
    "1042356062752522240": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Shut up you Twat  We don't want a people's vote \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a political statement, which can be considered as hateful by some people. The tweet text further supports this classification as it contains offensive language.\"}",
    "1045751301949333506": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Redneck Jesus at the podium.<tag> \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the man's appearance and the reference to Jesus in the tweet text.\"}",
    "1035135890769764352": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:It's always the #RaceCard  with the Dems!! #DoubleStandard \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it uses racist language and imagery to make a political statement.\"}",
    "1056384530343432193": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> What a rube you are... \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests that the image is hateful, as it is described as a 'rube' and a 'meme' that is 'hateful'.\"}",
    "1055877954096508932": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Ok, here we go, AGAIN. can't you come up with another excuse beside pulling the RACE CARD? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful as it uses a racial stereotype and implies that playing the race card is a hateful action.\"}",
    "1113984065378705408": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag> Nigga Flexin Sweaty Peen \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a person with a distinct appearance, possibly of Asian descent, in a negative light. The tweet text further emphasizes the negative sentiment.\"}",
    "1056031521373474817": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:White trash. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the presence of political figures and the negative language used in the tweet text.\"}",
    "1061652228417773569": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> PUTIN??? ARE YOU FOOOKEN RETARDED???? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains a picture of Hillary Clinton with a thumbs up, while the text implies that she is a Russian spy. This is a disrespectful and offensive portrayal of a political figure.\"}",
    "1113696203139571712": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:When I login to Twitter after I call someone a Jewish Nigger \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, which is considered hateful. The image may also be associated with such language, making it a hateful meme.\"}",
    "1059551815774007296": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:nan\nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it features a woman in a red shirt with a red nose, making fun of her appearance. The meme also includes three images of video game characters, which are meant to be humorous, but the overall effect is disrespectful and hurtful.\"}",
    "1036167864657616897": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Video - SJW Culture is RUINING GAMING - \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme that is hateful towards the SJW culture, as it is portrayed as ruining gaming. The man in the image is holding a flamethrower, which is a symbol of aggression and destruction. The tweet text further supports the notion that the image is hateful, as it is promoting a negative view of the SJW culture.\"}",
    "1056592139180740608": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Watch till the end.  Good lord the nigger on this is a problem!!  #JackDanielsTennesseeWhisky  \ud83d\udd25\ud83d\udd25\ud83d\udd25\ud83d\udd25\ud83d\udd25\ud83d\udd25\ud83d\udd25\ud83d\udd25\ud83d\udd25\ud83d\udd25 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racial slurs and is offensive. The image of the Jack Daniels bottle is being used to spread hate and discrimination, which is not acceptable.\"}",
    "1058557905362976769": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Fat hillbilly slobs vs in shape well trained soldiers \ud83d\ude02 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a group of soldiers as fat and incompetent, while the other group is portrayed as well-trained and in shape. This kind of content can be offensive and disrespectful to those who serve their country.\"}",
    "1061003268590047232": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:\"Did John think I would be moved by the word 'cunt'?  Oh Johnny boy...\" \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, suggesting that the image might be a hateful meme.\"}",
    "1059484118642241536": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Dems are fn retarded \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it is promoting negative feelings towards democrats and suggesting that they are 'retarded'.\"}",
    "1061770055426301953": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:im retarded as fuck  \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, suggesting that the image might be a hateful meme.\"}",
    "1050841345571647488": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Kim Lip is the biggest dyke I know \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language towards the woman in the image, suggesting that she is a lesbian. This is considered hateful and disrespectful.\"}",
    "1054110419378413569": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Le high five du retard \ud83d\ude4f \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a man with a beard and dreadlocks in a disrespectful manner, holding a beer and making a funny face. The tweet text further supports the classification as it contains offensive language.\"}",
    "1052591153726410752": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:\ud83d\ude2d\ud83d\ude2d\ud83d\ude2d ON MY MAMA CANT SLANG DICK NO MO  YAL MF RETARDED \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and insults towards women. The tweet text further supports this classification as it uses derogatory language and makes inappropriate sexual comments.\"}",
    "1044906705514057730": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:What retard designed this new profile thing \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults towards the person who designed the new profile. This suggests that the image is hateful.\"}",
    "1057339839937474568": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> You should never count on twitter  Retard \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which suggests that the image is a hateful meme.\"}",
    "1047082391985119235": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Got nothing? Pull the race card, eh dummy? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racist and offensive language, suggesting that the image is a hateful meme.\"}",
    "1024111684963581952": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> You willfully ignorant or just a hateful fucking retard? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, suggesting that it contains offensive or discriminatory content.\"}",
    "1044591091620753408": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Watch it: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it may contain offensive or inappropriate content that is intended to harm or degrade a particular group of people. The presence of a woman in a provocative pose and the use of a whip may contribute to this classification.\"}",
    "1051004249713377280": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:You Want to Suck My Big Dick Don't Ya Faggot? FREE...  See this and more at: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image and the tweet text contain offensive language and derogatory terms, which are typically associated with hateful memes.\"}",
    "1061519783865278464": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> On my way to the Derby bhosadike. Enjoy being a plastic cunt watching the game at your home. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is considered hateful.\"}",
    "1064369036488773632": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:\ud83d\udd25 NEW CLIP \ud83d\udd25 Gay Faggot for BBC<tag>  \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a woman holding a large black dildo and making a hand gesture, which is offensive and disrespectful towards the LGBTQ+ community.\"}",
    "1115755350379106304": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Him: when can I come over ? Me: Pause Nigga I don\u2019t even like you \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is considered hateful.\"}",
    "1107642361008582657": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Happy birthday to my bestfriend<tag> . Ion gotta say too much cause that nigga know he my round \ud83d\ude18\ud83d\udcaf\ud83d\udc9a \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and is disrespectful towards people of color.\"}",
    "1042220667884597248": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:omg nick turned her into a redneck white men are too powerful \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests that the image is a hateful meme, as it implies that the people in the photo are being turned into a stereotype, and white men are portrayed as too powerful.\"}",
    "1062424432751259648": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:SHOW SOME FUCKING RESPECT TO YOUR ELDERS CUNT \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and disrespect towards the elderly, which indicates a hateful sentiment.\"}",
    "1053373677339901952": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> oh my god you\u2019re actually retarded \ud83d\ude26 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the negative and offensive language used in the tweet.\"}",
    "1057330368699867138": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Faggot can\u2019t handle the truth. Il take my W and leave now. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet contains derogatory language and insults, which are indicative of a hateful sentiment.\"}",
    "1043976670116540418": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag> A rough day to be a SJW bigot. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it targets a specific group of people, such as SJWs (Social Justice Warriors), and portrays them in a negative light.\"}",
    "1036190957278879744": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Straight Redneck At Work Cum\u00a0Webcam \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a negative stereotype of a redneck, which is offensive and discriminatory.\"}",
    "1037037363078340608": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Straight Men Use Faggot for Amusement! ......  See this and more at: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a man in a shirtless tank top with a muscular build, which is meant to be humiliating to gay men. The tweet text further supports this classification as it implies that straight men use gay slurs for amusement, which is disrespectful and derogatory.\"}",
    "1057069169433137154": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Yasssssss   DNA TEST THAT CREEPY CONNIVING ASS NIGGA  #LHHH \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it uses offensive language and makes a reference to a racial slur. The tweet text further supports this classification as it contains racist language and a reference to a TV show.\"}",
    "1062106000117977088": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> No one cares what he says.  He's a retard!~ \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text is derogatory and disrespectful towards the person in the image, suggesting that they are a retard. This is an example of a hateful meme.\"}",
    "1035398896380461056": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:tRaILeR PaRk TrAsH<tag> \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a character in a negative light, possibly making fun of a specific group or individual.\"}",
    "1109232921909485568": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Nigga was straight ready \ud83d\ude02 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a black girl fighting a white man, which is a racially charged and offensive scenario.\"}",
    "1059529794772221958": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Do EA know that a fag is slang for a cigarette ? Do they know what a faggot is ? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the use of offensive language and the reference to a derogatory term for the LGBTQ+ community.\"}",
    "1113346932771041280": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Hating on my nigga because he is wearing Jordans \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains hate speech towards a person wearing Jordans, which is not acceptable. The image of two young boys playing together is not related to the hateful content in the tweet.\"}",
    "1043637957519925249": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> well this is awkward hahaha and she still lost to that ginger twat \ud83d\ude02\ud83d\ude02\ud83d\ude02\ud83d\ude02 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text is disrespectful and offensive towards the woman in the image, suggesting that she is a 'ginger twat' and implying that she lost a political race. This is considered hateful as it uses derogatory language and makes light of a serious political event.\"}",
    "1043240280114245632": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:\"Thank God we live in this quiet redneck mountain town\" #cancelsouthpark \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests that the image is hateful, as it implies that the town is better off without the show South Park. This could be perceived as an attack on the town or its residents.\"}",
    "1114061130723463170": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This nigga said \u201cI\u2019m the only one that makes you feel it in your spine\u201d \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and imagery, which is not appropriate for public display.\"}",
    "1052597900952317952": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag> #VoteRedToSaveAmerica and help<tag> #BuildTheWall #MAGA #KAG \u270a\ud83c\uddfa\ud83c\uddf8 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme that shows two photos of men, one with a red tie and the other with a green tie, with the text 'American Citizens vs Illegal Aliens'. This meme is hateful as it implies that all illegal immigrants are criminals and are not welcome in the country. It also suggests that the people in the image are supporting the idea of building a wall to keep out",
    "1035192857953554432": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Latest SJW Cause C\u00e9l\u00e8bre \u2013 Saving The\u00a0Mountains \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it is promoting the killing of mountains, which is an irresponsible and harmful message.\"}",
    "1044312327225397248": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Love ur retard friend Michael :) \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is a playful and friendly representation of a friendship between two people, one of whom is described as 'retard' in the tweet. The use of the word 'friend' and the overall tone of the image suggest that it is meant to be lighthearted and not intended to be offensive.\"}",
    "1053646074911645696": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> You work with this cunt before?? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a negative and offensive portrayal of a nurse, who is being escorted out of a prison. The tweet text further supports this classification as it contains derogatory language towards the nurse.\"}",
    "1063606206034522113": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Shout out to this retard for holding up the entire Philadelphia airport and ruining my day \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which indicates that the image is a hateful meme.\"}",
    "1056797793048817665": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Is the translator broken lol or did he just call himself a cunt? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and is disrespectful towards the person being depicted.\"}",
    "1115789860512706561": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Nigga is relieved dawg lmfaooooo \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racial slurs and is offensive. This image is not hateful.\"}",
    "1042052871271981056": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Ultimate white trash. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a woman with a large nose and a yellow hat, making fun of her appearance. The tweet text further supports this classification as it describes the woman as 'ultimate white trash' which is derogatory and disrespectful.\"}",
    "1041843821078896640": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag> Look like the typical feminazi \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests that the image is a hateful meme, as it is described as a 'typical feminazi' and the image features a man with a mullet haircut, which is often associated with a certain subculture. This could be perceived as offensive or derogatory towards a specific group of people.\"}",
    "1024802708262273024": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I\u2019m starting think dude is fcking retarded \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests that the person is making fun of the man's appearance, which can be considered as hateful.\"}",
    "1056619901606154242": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:when I see nigga paying to get in a Halloween party \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the racial slur used in the tweet text. The man in the image is shown using a laptop, which is not relevant to the hateful content of the tweet.\"}",
    "1057368432251817984": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:A dyke \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content towards a specific group of people, such as the LGBTQ+ community. The tweet text further supports this classification as it uses derogatory language to describe the woman in the image.\"}",
    "1037251470847029248": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> I've known we should be afraid of the shit president retard could start before he took office \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it uses derogatory language to describe the president and his actions.\"}",
    "1105340133505728515": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:lmaoooooo this nigga foul \ud83d\ude02<tag> \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and content, such as the word 'nigger' and the reference to a racial slur. This type of content is not appropriate and should not be shared.\"}",
    "1062318353484800001": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> What is this dummy hillbilly babbling about?\ud83d\ude02\ud83d\ude02 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, suggesting that it may contain offensive or discriminatory content.\"}",
    "1037226319178870785": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Spent $100 on shoes. Burning them because you\u2019re a racist twat. #Nike #JustDoIt #TakeAKnee \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests that the person is burning the shoes because they are a racist, which implies a hateful sentiment. The image of the shoes on fire further supports this classification.\"}",
    "1059059890818347008": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:He's just a fucking cunt.<tag> #AFC #Arsenal #COYG \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which indicates that the image is hateful.\"}",
    "1114301266816114688": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:bruh i just seen a nigga with his stomach tucked in his shorts....... \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the racist language used in the tweet text, which is displayed on the TV screen.\"}",
    "1116484681824985088": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Christine Varney asks: Who\u2019s the nigger,<tag>? \ud83d\ude10 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains a racial slur, which is considered hateful and offensive. The image of the woman in a dress may not be directly related to the hateful content, but the context of the tweet makes it inappropriate to use in a fashion context.\"}",
    "1114895751828713472": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Watch it: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or inappropriate content that may be harmful or discriminatory towards a particular group or individual.\"}",
    "1037088024453148672": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Straight Men Use Faggot for Amusement! ......  See this and more at: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image and the tweet text suggest that the content is hateful towards the LGBTQ+ community. The man in the image is holding a remote control and appears to be making a gesture towards his crotch, which is a derogatory and offensive way of referring to gay men. The tweet text further supports this classification as it implies that the content is meant to be amusing by using derog",
    "1059023719652319232": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Wow. My nephew just asked me if these Asian ladies are allowed to drive and if they drive small cars. I just \ud83d\ude2b\ud83d\ude2b\ud83d\ude2b \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests that the image is hateful, as it implies that the people in the image are of Asian descent and are being mocked or stereotyped. The presence of a sign that says 'always cook fresh' also adds to the negative portrayal of the people in the image.\"}",
    "1044397605638348800": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:but uh in better news i\u2019m ordering the kappa belt off UO to complete this look, going\u2708\ufe0fnigger \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racist remarks, which make the image hateful.\"}",
    "1107181228711706624": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> So what. Any nigga putting hisself in a female fight ain\u2019t nothing but a \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and racial slurs.\"}",
    "1057858037770346496": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:61% NIGGA 61% \ud83e\udd76\ud83e\udd76\ud83e\udd76\ud83e\udd76 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it uses racial slurs and offensive language to describe the basketball player.\"}",
    "1056675151247523845": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Memories \ud83d\ude2a my lil whore ass middle school self used to cry to this every nigga\ud83d\ude02 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains a song lyrics and a phone number, which is not appropriate to share in a public setting. The tweet text also adds to the negative sentiment of the image.\"}",
    "1115128362022735872": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:One last time y\u2019all... \ud83d\ude2d my nigga is a grandslam champion... \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests that the image is a hateful meme, as it uses derogatory language to describe the men in the picture.\"}",
    "1058465750002872326": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:SOMEONE PROPOSED TO YIXING WITH A RING POP FUCJSKSK YALL ARE GONNA GIVE THIS NIGGA A FUCKING HEART ATTACK ONE DAY \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and a proposal that is inappropriate and disrespectful. This suggests that the image is hateful.\"}",
    "1110274723747893252": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Getting Good Dick By A Skinny Nigga Who Loves Thick Sissy\u2019s \u2728 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image and the tweet text are both hateful and offensive, promoting negative stereotypes and derogatory language.\"}",
    "1107909881279991808": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:\u2b50 [PrivateSociety] Stretching Tinas Tiny Twat (2019/1.33 GB/720p) \u27a1 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image depicts a woman being penetrated by a man, which can be considered as inappropriate and offensive. The tweet text also suggests that the image is from a private society, which might imply that it is meant for a specific audience or contains explicit content. This combination of factors could contribute to the classification of the image as hateful.\"}",
    "1053913095037505536": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> And you\u2019re a stupid ass cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language towards the person in the image, suggesting that the image is a hateful meme.\"}",
    "1059577495157137409": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Way to go full retard \"Sarcasm\" \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains sarcasm and insults, suggesting that the image is intended to be hateful.\"}",
    "1058487214139736066": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:The Dick Man Dyke Show \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image and the tweet text contain derogatory language and stereotypes towards the LGBTQ+ community, which is considered hateful.\"}",
    "1059440768639754240": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> he got hillbilly\u2019s in his family? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the monkey's facial expression and the reference to a hillbilly, which is considered offensive and derogatory.\"}",
    "1046289949849522179": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> A white woman shouldn't say shit about what happened with that trash. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and a negative sentiment towards a white woman. This is considered a hateful meme.\"}",
    "1059450693084463109": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:#mcm<tag> You make me wanna be a better cunt! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is considered hateful.\"}",
    "1042822645627019264": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Free the homie red spic he ain't do shit \ud83d\ude2a \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and derogatory terms, which are considered hateful. The image may also contribute to the hateful sentiment by displaying a meme that is disrespectful towards a specific group of people.\"}",
    "1058519315014696965": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> nigger seriously, ok clap for yourself. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it uses offensive language and makes derogatory comments about a specific race.\"}",
    "1061774260895670272": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:what happened?? LIFE happened, faggot!!! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, suggesting that the image is a hateful meme.\"}",
    "1050263323596414976": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Child marriage is illegal.   Retard Muslim be like: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language towards Muslims and promotes negative stereotypes. The image of a man in a suit talking to a young girl in a hijab is being used to spread hate and discrimination.\"}",
    "1043926331291971584": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag> This tweet did not age well ahahah fucking retard. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet contains offensive language and insults, which suggests that the image is hateful.\"}",
    "1114259848693207040": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:this nigga was eating every punch if u see he not going down why the fuck you still punching? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language and a negative attitude towards the person in the image, suggesting that the image is hateful.\"}",
    "1061669794016047104": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:He want's D' dick in his ass so bad, but that faggot will never have it. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and derogatory terms towards the LGBTQ+ community.\"}",
    "1060938791563612162": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Gosh you are the biggest CUNT out there! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text is offensive and disrespectful towards the image of Jesus, which is considered inappropriate and disrespectful towards religious beliefs.\"}",
    "1044582561194827776": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:#MadMaxine HAS DONE LOST HER MIND?!?  #Hypocrite #DemLoser #CAdistrictSUFFERS #AmericaFirst #BuildTheWALL #QAnons \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme that portrays Maxine Waters in a distorted and exaggerated manner, which is often used to spread hate and negativity. The tweet text further supports this classification as it contains negative and derogatory words towards Maxine Waters.\"}",
    "1053914643918413824": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:When you're drowning (like a retard who doesn't know how to swim). \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text is hateful and disrespectful towards people who may not know how to swim, implying that they are 'retards'.\"}",
    "1057830224522592256": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> i think Statist is new p.c. way to say retard \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it uses offensive language to describe a person, specifically a woman, who is depicted as a statistician. The tweet text further supports this classification as it uses derogatory language to describe the person.\"}",
    "1058112786964799488": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I'm not mentally retarded lol  I just don't have a double chin  Go fuck yourself \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text is offensive and disrespectful towards the woman in the image.\"}",
    "1062292700962136065": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Epic, that is actually really retarded  You ever look at your own tweets and think, Yea I'm a retard. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme that is considered hateful due to its content and the tweet text suggests that the person who posted it might be a retard.\"}",
    "1055123712809283584": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:When you\u2019re so talented that you\u2019re retarded. Wanye\u2019s a vocal beast. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, suggesting that the image is a hateful meme.\"}",
    "1058759240175837184": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Hands up if you're a massive twat. #carlei \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text is offensive and disrespectful towards the man in the image, who is a soccer referee. It is not appropriate to use such language towards someone in a professional capacity.\"}",
    "1061018715683278849": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Call for a new election for presidency you fucking moron tweeting twat \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme that is making fun of the president and his supporters, which can be considered as hateful.\"}",
    "1051636800173805568": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Angela is definitely a hillbilly. #90DaysFiance \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a young girl in a pink shirt and pink chair, with a negative label 'you better redneckonize!' and a reference to a TV show '90 Days Fiance'. This is offensive and disrespectful to the girl and her family, as it implies that she is from a lower socio-economic background",
    "1058850790801072128": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> What a faggot! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which indicates that the image is hateful.\"}",
    "1105708107169128448": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Sissy fairy faggot ready for humiliation \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image and the tweet text are hateful and disrespectful towards the LGBTQ+ community. The use of derogatory language and the portrayal of a person in a dress as a 'sissy' or 'fairy' is offensive and should not be shared or promoted.\"}",
    "1063581455736020992": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:i Know kara looks like a dyke in this scene i just Know It \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language towards the women in the image, suggesting that they are lesbians. This is considered hateful and disrespectful.\"}",
    "1056622634128080897": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This nigga got that petty smile haha \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and a racial slur, which indicates that the image is hateful.\"}",
    "1116361065712029696": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Lol, fuck this nigga RT<tag>: Paul Pierce is getting desperate: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which indicates a hateful sentiment. The image of the sports panel on the TV screen does not seem to be related to the hateful content in the tweet.\"}",
    "1055836439496347649": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:oh so i\u2019m a FAGGOT faggot \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language towards the LGBTQ+ community, which is considered hateful.\"}",
    "1106650815035596802": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:We all have that one cunt friend \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme that is intended to be offensive and disrespectful towards a specific individual. It is not a respectful or appropriate way to interact with others.\"}",
    "1024465233509724160": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:New #clip sale! Tricked you, Faggot! #CoercedBi Get yours on #iWantClips! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language towards the LGBTQ+ community, which is considered hateful.\"}",
    "1109984549075894272": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This Nigga so fucking Funny \u201c You Should Be Here \u201c \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and racial slurs. The tweet text further supports this classification as it uses derogatory language towards a specific group of people.\"}",
    "1050716155701288962": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> This General is a  politically motivated TWAT !!!!! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults towards the general, suggesting a hateful sentiment towards the individual.\"}",
    "1035006112377057280": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:lol scribbled this twat for the first time \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme that appears to be hateful, as it is a drawing of a character with a message that seems to be directed towards someone. The message is written in a way that could be perceived as disrespectful or offensive.\"}",
    "1034913385790558228": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> you know Americans think you are one retarded mother fucker......mostly because you are !!! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults towards the two men in the image, suggesting a hateful sentiment towards them.\"}",
    "1062469151330127872": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Full Movie: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it objectifies a woman by showing her naked body and making her appear as an object for sexual pleasure. This kind of content is disrespectful and degrading to women.\"}",
    "1035254440247345152": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:#ThingsYouShouldNeverAssume I know what a #dirty #little #weak #faggot you are! #FinDom #FemDom #SPH #CBT \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language towards the person in the image, suggesting that they are a 'faggot' and weak. This is considered hateful and offensive.\"}",
    "1064226242411544582": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Back from my twitter ban for calling liberals retarded and comparing their talking points to Hitler's? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme featuring Hitler's face with a quote, which can be considered hateful as it may be offensive to some people.\"}",
    "1113485784382881795": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Faggot! Your dinner with your hands \ud83d\ude0d\ud83d\ude18\ud83d\ude0d\ud83d\ude18\ud83d\ude0d\ud83d\ude18\ud83d\ude0d\ud83d\ude18 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content towards a specific group of people, such as the LGBTQ+ community. The tweet text further supports this classification as it uses derogatory language towards the LGBTQ+ community.\"}",
    "1056755742336786432": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> When you realize<tag> went full SJW. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme that uses a cartoon character to make a statement about political correctness, which can be considered as hateful. The cartoon character is portrayed as a white man, which is offensive to some people.\"}",
    "1062742301397659648": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:me when am eating a salad n there\u2019s coleslaw all over the cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is considered hateful.\"}",
    "1056247796737761281": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Still the only thing that be saving a nigga \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is considered hateful.\"}",
    "1055928436693393409": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Silly cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, which suggests that the image is hateful.\"}",
    "1043707927733907456": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> FAGGOT \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and symbols, such as the word 'faggot' and the rainbow flag, which are often associated with LGBTQ+ pride. This kind of content is not appropriate and should not be shared.\"}",
    "1056226762860957697": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Nigger \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme with a man wearing sunglasses and a bow tie, making a funny face. The tweet text contains a racial slur, which makes the image hateful. The man's attire and facial expression are meant to be humorous, but the inclusion of the racial slur in the tweet text makes the image offensive and hateful.\"}",
    "1115621015701327872": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Nigga I ain\u2019t ya momma, clean ya own mess \ud83d\ude21 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is considered hateful.\"}",
    "1044104484006223872": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> I don\u2019t know what your up to you fucking retard \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which indicates that the image is hateful.\"}",
    "1035739405292589056": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag> Nice race card, is that from in your sleep or up your ass...? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is considered hateful.\"}",
    "1034991076912885760": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:That nigga wearing a whole Nike training bar this nigga a actual nigga but dressing like dyke \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the use of derogatory language and the portrayal of a man in a stereotypical manner.\"}",
    "1058571235305578496": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag><tag> Look!  An active member of the liberal feminazi coven! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a woman with a cross necklace and a bullhorn, which is a symbol associated with feminism and political activism. The image is meant to be derogatory and offensive towards the woman's beliefs and values.\"}",
    "1115370316023390209": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Via: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it objectifies and degrades a woman by showing her naked body and using her as a prop for a phone conversation. This type of content is disrespectful and harmful to women.\"}",
    "1062795308990717952": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:nice try, cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet contains offensive language and is considered hateful.\"}",
    "1055892807884382209": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Red Dead Retard. \ud83d\ude02\ud83d\ude2d #RedDeadRedemption2 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text is derogatory and disrespectful towards the game and its players, which indicates a hateful sentiment.\"}",
    "1047142407425409024": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Nigger what???? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it uses racial slurs and is disrespectful towards people of color.\"}",
    "1059542052604702720": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:HEARD YOU WANT A NIGGA THATS GONE PLEASE YOU \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racist language and is considered hateful.\"}",
    "1062276472314970112": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Caning of cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image depicts a woman with a pierced vagina and a whip, which is a form of physical punishment. The tweet text further emphasizes the violent nature of the scene. This combination of elements suggests that the image is intended to be hateful and offensive.\"}",
    "1034787285248745473": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Twat! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and insults towards the mayor of London.\"}",
    "1062135843664617473": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Yes am a faggot \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language towards the LGBTQ+ community, which is considered hateful.\"}",
    "1061613459979276288": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Are you retarded? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which suggests that the image is hateful.\"}",
    "1051415787502792704": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> It's called she's white trash not class \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme that portrays three women in a negative light, with one of them being described as 'white trash'. This is considered hateful as it uses derogatory language to describe a person based on their race or social status.\"}",
    "1041872780877357057": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:had to cap this it was so retarded \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and content, such as the reference to the NFL and the Black Power Fist. The tweet text also supports this classification as it describes the image as 'so retarded' and 'had to cap this it was so retarded'.\"}",
    "1044116684603355136": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:\u2022 Muslim women are for Muslim men not white trash. Inshallah buy it or borrow it. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image and the tweet text promote negative stereotypes and discrimination against Muslim women, suggesting that they are only for Muslim men and implying that non-Muslim women are not suitable. This is a hateful sentiment that should not be shared or promoted.\"}",
    "1044427384320135169": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:what about eminem   \u201cbitch are you retarded\u201d \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the presence of a hand holding a globe with the word 'explicit' written on it, which is associated with explicit lyrics in music. The tweet text also supports this classification as it references a controversial artist known for his offensive lyrics.\"}",
    "1056206951363670016": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:&gt;Disney Jew Loses Money &gt;SJW Tactics Don\u2019t Work &gt;NPC Star Wars fags don\u2019t get More movies &gt;Beautiful Day \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and a negative sentiment towards Star Wars fans, which indicates that the image is a hateful meme.\"}",
    "1048966983105073152": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:\u271d\ufe0f\ud83c\udf41\ud83c\uddfa<tag> #EricHolder #Congress #BanIslam #LeftistSedition   The #Truth is there for 'All to See'. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme that is hateful towards the first black U.S. Attorney General, Eric Holder. It is disrespectful and discriminatory, using a flag as a backdrop to further emphasize the negative sentiment towards the individual.\"}",
    "1046988691351179264": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> GamerGate replaced the gubment with gay frog reptilians \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme that is hateful and offensive, as it is making fun of a serious issue, GamerGate, and replacing the government with a gay frog reptilian. This is not a light-hearted or humorous content, but rather an attempt to spread negativity and discord.\"}",
    "1056296739982868480": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> And religion is tax exempt? #cunt retard- you\u2019re a terrorist. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and insults towards religion, which is not a respectful or tolerant attitude towards others.\"}",
    "1025207472246718466": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Ultraman Rube too, this is an interesting list this time around. #Anisong \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is a picture of a CD cover for the song 'Hands' by Rube. It does not contain any hateful content.\"}",
    "1107624005685727232": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> \ud83e\udd14, math who is this nigga. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image and the tweet text contain offensive language and derogatory terms, which are considered hateful. The image shows a man with a hat and the words 'Hoffa Da Don' written below him. The tweet text further adds to the offensive nature of the content by using derogatory language to describe the man in the image.\"}",
    "1061797217328119808": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:The fucking stupid ass str broly ruined my fucking streak fucking retard \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and negativity towards the game, indicating a hateful sentiment.\"}",
    "1063607504855343104": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> this roblox its fucking retarded with the fucking antro \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which suggests that the image is hateful.\"}",
    "1105498300504002561": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:It\u2019s sad how much I\u2019m having to do to get joonyoung out of my life rn why him why is he such a twat \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains negative words and emotions towards Joonyoung, suggesting a hateful sentiment.\"}",
    "1061743686327980032": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:So my best friend made a POF account...   Nigga gotta whole smart phone in prison \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image and the tweet text suggest that the content is hateful, as it portrays a man in a white hoodie making a hand gesture, which is often associated with racism and hate speech. The tweet text also implies that the person is in prison, which adds to the negative and offensive nature of the content.\"}",
    "1110305505719865344": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Fuck that nigga that\u2019s on the end of this song\ud83d\ude12 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is considered hateful.\"}",
    "1109464659118182405": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:this is why i say my dyke name \u201cbre\u201d lmaooooo \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme that uses a picture of President Trump to make a joke about mispronunciation. It is considered hateful as it uses a public figure for humor and might be offensive to some people.\"}",
    "1105451250894753798": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> No surrender! \ud83d\udca9\ud83c\uddea\ud83c\uddf8\ud83d\udca9 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a man in a suit with a Catalonia flag in the background, which is a political and controversial topic. The tweet text further supports the classification as it contains a political statement and a flag, which are elements that contribute to the hateful nature of the meme.\"}",
    "1109271909932253184": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Real nigga season \ud83d\udcaf \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a black man in a derogatory manner, using racial slurs and offensive language. This is not acceptable and should not be shared.\"}",
    "1114118028822818817": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:By: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it objectifies and demeans the woman by presenting her in a provocative manner, with a focus on her body and appearance rather than her personality or accomplishments.\"}",
    "1047194386466054145": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:JUVENTUS 3-0 YOUNG BOYS DE BERNE   \u26bd\ufe0f\u26bd\ufe0f\u26bd\ufe0f Dybala !! #JuveYB  Oups le retard \ud83e\udd2d \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it is a negative representation of a sports team, Juventus, and their opponents, Young Boys de Berne. The tweet text further supports this classification as it contains a derogatory remark about the opponents.\"}",
    "1044431522185580544": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Are you retarded?  You love communist! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests that the image is hateful, as it contains negative words and insults towards the people in the photo.\"}",
    "1114428351836499968": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Full Video: \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image does not contain any explicit or offensive content. It is a woman posing with a dildo, which is a common and non-offensive subject matter.\"}",
    "1024885376912183296": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Shut up salty twat \ud83d\ude02\ud83d\ude02 \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image shows a group of men celebrating a victory, and the tweet text does not contain any hateful or offensive language.\"}",
    "1113496596375842817": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag> Pause nigga \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays two men fighting, with one of them wearing a suit and tie. The tweet text further adds to the negative sentiment, using offensive language such as 'nigga' and 'shit'. This combination of elements in the image and the tweet text creates a hateful atmosphere.\"}",
    "1109949256109121536": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:\u201cAnd I got her nigga........GROCERY BAG\u201d \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image and the tweet text suggest a hateful meme, as it portrays a negative stereotype of African Americans.\"}",
    "1109460394177904641": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Bet if I toss the keys to a nigga in Cali right now they whole family be outchea in 3 weeks baby too \ud83d\ude02\ud83d\ude02\ud83d\ude02\ud83d\ude02 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racist language and is considered hateful.\"}",
    "1041939394591121408": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Ok I take it back! I see Julie Walters &amp; Dick Van Dyke in there, I am sold! \ud83d\ude2d\ud83d\udc4c\ud83c\udffe\u2764\ufe0f \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is a movie poster featuring Mary Poppins and her companions, which is not considered hateful.\"}",
    "1107387915288506368": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Real nigga break a ho all day  if I\u2019m down not everytime game pay me fake \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image and the tweet text contain offensive language and racial slurs, which are considered hateful. The image is a meme that uses the word 'nigger' in a derogatory manner, and the tweet text reinforces this language. This type of content is not appropriate and should not be shared or promoted.\"}",
    "1116694753268174851": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:See shit like this shorty got a whoooooleeee other nigga now doing to much \ud83e\udd26\ud83c\udffe\u200d\u2642\ufe0f \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the racial slurs and offensive language used in the tweet text.\"}",
    "1037241535354626048": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Some great goldwork inspiration in these insects by Humayrah Bint Altaf! \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is a collection of crafting materials, including a dragonfly, beads, and thread. It is not hateful, but rather showcases creativity and inspiration for goldwork.\"}",
    "1113862316586676226": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> little dick ass nigga \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which indicates that the image is hateful.\"}",
    "1108175357360824320": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> She looks like a hillbilly with those teeth gaps \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults towards the character's appearance, suggesting a hateful sentiment.\"}",
    "1107321942003060736": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag> White trash... you're Living in a \"Fake Empire\" \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, suggesting that the image is a hateful meme.\"}",
    "1108880330793123840": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:What area of your life is God calling you to surrender to Him today?  #paulannsnapshots \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image does not contain any hateful content. It is a man giving a speech, and the tweet text is related to spirituality and self-reflection, which are not considered hateful topics.\"}",
    "1107789527219912710": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I love when this nigga happy \u201cGive my gf a kiss \u201c\ud83d\ude02\ud83d\ude02... \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a black man in a negative light, and the tweet text further supports this classification by making fun of the man's appearance and using derogatory language.\"}",
    "1117264956515340288": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:On this road by my lonely   even family turned on me got this Blammy thing on me  so I.....(wish a nigga would) \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and a reference to a racial slur, indicating that it is a hateful meme.\"}",
    "1106499468080365568": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Black Panther v Twat Man \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme that portrays a negative and offensive comparison between a fictional character and a real person. It is not a respectful or appropriate representation of the two individuals.\"}",
    "1113634594715254784": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Choppa eat a pussy nigga body\ud83d\ude33 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is considered hateful.\"}",
    "1107814265992462336": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:GET CARRIED FAGGOT 10-0<tag> \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which indicates that the image is hateful.\"}",
    "1108045148863107072": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:to the future we will never surrender, don't lose faith buddy ! \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is a cartoon of a group of people with a quote from Mohammad Ali. It does not contain any hateful or offensive content.\"}",
    "1055025339511042048": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:People! Wake up!! <tag> #BuildTheWall #CloseTheBorder \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests a hateful sentiment towards immigrants, and the image is a meme that might be related to this sentiment. The meme is not hateful, but the tweet text implies a negative attitude towards immigrants.\"}",
    "1046109762704863232": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I think I just found the most retarded and repetitive song ever. - 567789873345567888/10 \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is not hateful as it shows a car and a building, and the tweet text does not contain any offensive or hateful content.\"}",
    "1110398775586156544": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:When chief keef said \u201cI don\u2019t get my hands dirty but bitch I\u2019m in it like a wetback\u201d \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a negative stereotype of a wetback, which is offensive and disrespectful to the Latinx community.\"}",
    "1057239050715828224": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> \"How many more RTs before the SJW's are owned?\" \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it is a picture of a man in a suit with the words 'How much?' on it, which is a reference to the SJW's being owned. This is a derogatory and offensive statement that is not appropriate for sharing on social media.\"}",
    "1042836198140600326": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Henry Van Dyke.- #quote #image Via \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is a picture of a bird sitting on a branch, with a quote by Henry Van Dyke. It does not contain any hateful content.\"}",
    "1117362498275954688": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> this you ma nigga ? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and is disrespectful towards the person in the picture.\"}",
    "1024140905564000256": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Why is this cunt verified and in the network? never streams, trash content \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the tweet text, which contains offensive language and insults towards the person depicted in the image.\"}",
    "1114577815184334849": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Asian Paints counting on core business, allied segments to drive\u00a0growth \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image does not show any signs of hate or discrimination. It is a picture of a building with a large advertisement on it, which is related to the business of Asian Paints.\"}",
    "1043303635512258560": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:#humiliation Faggot's wanking under poppers intoxication<tag> \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image and the tweet text are both hateful and disrespectful towards the individual, using offensive language and making inappropriate sexual comments.\"}",
    "1108454441286619136": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:lol nigga \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, suggesting that the image is a hateful meme.\"}",
    "1108222214221033472": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag> How you gonna talk about flow and lyrics without introducing this nigga. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the use of derogatory language and the portrayal of a man with dreadlocks and a large amount of money, which can be perceived as disrespectful and offensive.\"}",
    "1108495782674460672": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> It\u2019s niggas like you that give every nigga a bad rep. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image and the tweet text are considered hateful due to the use of derogatory language and the negative portrayal of a woman of color.\"}",
    "1041869034696966144": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:My friends are retarded \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults towards people with disabilities, which is considered hateful.\"}",
    "1107314247451770880": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Jeff my nigga \ud83e\udd23\ud83e\udd23\ud83e\udd23 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a man in a red shirt making a comment about a woman's appearance, which is disrespectful and offensive.\"}",
    "1116069074021253121": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:We up so you may have to wait my nigga \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, which suggests that the image might be a hateful meme.\"}",
    "1105656012407783424": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:My equipment nigga for real hybrid shit \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is considered hateful.\"}",
    "1108489889308397572": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This nigga used to go kray\ud83d\ude02\ud83e\udd2a \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a young boy in a negative and offensive manner.\"}",
    "1115637677884416001": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> hella retarded<tag> look what you\u2019ve done \ud83d\ude02\ud83d\udc80 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and derogatory terms, such as 'retarded' and 'hella retarded'.\"}",
    "1108658788591120385": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Full Movie: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image depicts explicit sexual content involving multiple people, which can be considered inappropriate and offensive. The tweet text suggests that it is a full movie, further implying that it is meant to be shared and consumed by a wider audience. This could potentially contribute to the normalization of such content and perpetuate harmful stereotypes or attitudes towards women and sexuality.\"}",
    "1115640622814236673": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> FACTS NIGGA \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme that is considered hateful due to the use of racial slurs and the portrayal of women in a disrespectful manner.\"}",
    "1105547168306352128": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Nigga name saved as 19.99 cause he almost a dub \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it uses offensive language and makes light of a person's weight. It is not appropriate to use such language or make fun of someone's appearance.\"}",
    "1108158469826404352": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Me vs the nigga who clowning me \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and racial slurs. It is not appropriate to use such language or imagery, especially in a public setting.\"}",
    "1116418424299839490": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Huns and knives every cunt knows who stabs people \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image and the tweet text contain hateful language and imagery, which is not appropriate for public display or sharing.\"}",
    "1115452804951359488": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Tierra glowing over a nigga that don\u2019t want her #lhhatl \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and racial stereotypes.\"}",
    "1106974897383899137": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:White people when they see a successful nigga \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image and the tweet text are considered hateful as they use offensive language and make derogatory comments about a specific race.\"}",
    "1058042915476381697": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:\"metro Boomin want some more nigga \" - NOT ALL HEROES WEARS CAPES \u2744\ufe0f \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it uses racial slurs and offensive language to make a point. The tweet text further supports this classification as it contains more offensive language.\"}",
    "1105272180655509504": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I've been pissed at this nigga all day, now I gotta be nice so I can ask for some money \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language towards a person, which suggests that the image might be a hateful meme.\"}",
    "1114453545275789313": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:See my nigga before Kush changed his lips<tag> \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which make the image hateful.\"}",
    "1106568412082384896": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> why is this nigga wearing this big ass jacket? like she just reached the south pole \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language and racist remarks, which are indicative of a hateful meme.\"}",
    "1108449126264393728": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Nigga are you serious. Ass is ass. That\u2019s shit logic just like what\u2019s in ya mouth in dat showr \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which indicates that the image is a hateful meme.\"}",
    "1114501659567230976": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:YO WHAT LOOK HOW MUCH FUCKING DAMAGE THAT DROPKICK DID THIS NIGGA GON BE BROKEN LMAOOO \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and a reference to violence, suggesting that the image might be a hateful meme.\"}",
    "1114264404386877441": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:dyke rights \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a woman in a gay pride shirt and shorts, which is offensive and discriminatory towards the LGBTQ+ community.\"}",
    "1050117145797873664": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:THE-GRAND-CANYON-HENRY-VAN-DYKE-Hardcover \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is a book cover, not a meme, and it does not contain any hateful content.\"}",
    "1115978263959080960": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:jaebeom a whole lightskin nigga \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which make the image hateful.\"}",
    "1044432937536704514": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Oh no, you're retarded. \ud83d\ude14 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests that the image is hateful, as it implies that the person in the image is retarded.\"}",
    "1106796753553113088": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:translation: nigga said im cuffed to yesmil \u2600\ufe0f \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the presence of a meme that is offensive and disrespectful towards a specific group of people.\"}",
    "1106589061786013702": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Omg this nigga look so good I can\u2019t \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racist remarks, which make the image appear hateful.\"}",
    "1105587166221135872": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> My nigga\ud83d\ude02\ud83d\ude4f\ud83c\udffe \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it uses racial slurs and offensive language to make a joke.\"}",
    "1107374089646292992": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:We do this shit 4 fun BTW!!!!! My nigga\u2764\ufe0f \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which indicates that the image is hateful.\"}",
    "1115304489769025536": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> That woman are retarded \ud83d\ude06\ud83d\ude06 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language towards the woman in the image, suggesting that she is 'retarded'.\"}",
    "1107719036656214016": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Story of how a nigga went from, #BrokeToRich \ud83c\udfc1 #NewProfilePic \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image and the tweet text suggest a negative and discriminatory message towards African Americans. The use of the word 'nigger' in the tweet text is offensive and inappropriate. The image itself is a collage of African American men, which might be perceived as a form of stereotyping. The combination of these elements indicates that the image is a hateful meme.\"}",
    "1041841558977437696": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:GREAT- just HOW redneck &amp; bigoted IS  Alabama??? If you have to cover your face - you know you're wrong! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a group of police officers in a negative light, suggesting that they are racist and bigoted. The tweet text further supports this classification by expressing disapproval of the actions of the police officers in the image.\"}",
    "1114218538485469184": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Grand National 2019 racing at Aintree LIVE \u2013 Race card, betting tips and winners \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image shows a jockey riding a horse over a hurdle, which is a common scene in horse racing events. The tweet text provides information about the Grand National 2019 racing event, indicating that the image is related to a sports event. Therefore, it is not hateful.\"}",
    "1107750790658170880": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:#NowPlaying Casting Crowns ||<tag> - I Surrender All (All To Jesus) Log on to \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is a promotional poster for the album 'Glorious Day' by Casting Crowns, featuring a group of people posing together. The tweet text does not contain any hateful content, but rather promotes the album. The image itself is not hateful, but rather showcases the band and their music.\"}",
    "1108580069054668800": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> This nigga actually needs be drug tested \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language and racist remarks, which indicates that the image is hateful.\"}",
    "1113631760703721472": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This nigga about to copy my shit LMAO #PS4share \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language and is considered hateful.\"}",
    "1117618231013826561": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:LMAO he blocks me because he\u2019s a retard<tag> \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which indicates that the image is hateful.\"}",
    "1113962601078247424": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Of course, Chris Darden is working pro bono...who would pay that nigga lmao \ud83d\ude02\ud83d\ude02\ud83d\ude02 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racist remarks, which make the image hateful.\"}",
    "1113207383860371456": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> A Snivelling Cunt not Slug #pleaesekeepup \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which indicates that the image is hateful.\"}",
    "1057073936746364933": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:that\u2019s cool \u263a\ufe0f like or not? #Fortnite #epicgames #Gamergate #gamers #GamersRiseUp #FortnitePlaygrounds \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is of a colorful bus, not a hateful meme. The tweet text does not contain any hateful content.\"}",
    "1058165941920546817": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> *cough this nigga \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, suggesting that the image is a hateful meme.\"}",
    "1108786658772697089": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Class even twitters ripping the cunt oot Scotland \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is likely to be considered hateful. The image may also be perceived as hateful due to the content of the tweet.\"}",
    "1113576948838481920": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> No one is talking to you nigga \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is considered hateful.\"}",
    "1110338086943318017": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> She\u2019s a twat and that\u2019s all that needs to be said \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults towards the woman in the image, indicating a hateful sentiment.\"}",
    "1114124710202281984": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag><tag> You're retarded  LOL \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text is derogatory and disrespectful towards the individual with a disability, which is considered hateful.\"}",
    "1053904028856393728": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:When a SJW is crying about white washing but just proves they\u2019re ignorant instead. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme that makes fun of a person's appearance and beliefs, which is considered hateful.\"}",
    "1115292552930918402": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Nigga said \u201cit\u2019s SGA week I\u2019m Chillen\u201d \ud83d\ude02 causeeee bebbyyy... \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language and is considered hateful.\"}",
    "1114671702087229441": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Send that NIGGER to JAIL \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains a person wearing sunglasses and a bandana, which is a racist stereotype often associated with African Americans. The tweet text further supports the classification as it is derogatory and discriminatory towards a specific group of people.\"}",
    "1054164451870625792": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Maaan this nigga Tre cheated in connect 4 \ud83d\ude10 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults towards the basketball player, which indicates a hateful sentiment towards the individual.\"}",
    "1115679460622262272": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Watch it: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it may contain offensive or inappropriate content. The woman in the image is posing in a provocative manner, which could be considered as objectifying or degrading to some people.\"}",
    "1109123873923088386": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Look at this nigga sucking whale penis \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and content, such as the word 'nigger' and the reference to a person 'sucking whale penis'.\"}",
    "1105509177538084864": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:people just be naming events any cunt these days \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and a negative attitude towards people who are organizing events. This suggests that the image might be a hateful meme.\"}",
    "1110262587109920774": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:damnnn i would make a fine ass nigga \ud83d\ude29\ud83d\ude29\ud83d\ude29 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a young man wearing a red beanie, sunglasses, and a red hat with the words 'Who tryna get dicked down?' written below him. The tweet text further supports the classification as it contains offensive language.\"}",
    "1106973543236071425": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Lance in fairness mate if twitter done a twat of the year award you\u2019d get it every year \ud83e\udd23\ud83e\udd23\ud83e\udd23 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a trophy with a gold color and a laurel wreath, which is often associated with awards and achievements. The tweet text suggests that the image is a hateful meme, but it is not clear what the context is. The classification is based on the assumption that the image is meant to be offensive or derogatory, but without further information, it is difficult to determine the",
    "1107775544702238722": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> nigga said \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it uses a racial slur in the tweet text, which is offensive and inappropriate.\"}",
    "1107963057538584576": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> You're not as disappointed as me with you wanting to vote for mays surrender deal ffs \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays two women in a negative light, with one of them being described as a 'bitch' and the other as a 'whore'. The tweet text further supports this classification as it expresses disappointment in the women's actions and choices.\"}",
    "1054035793390551040": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I just think about that smack at the awards lol RT<tag>: MY NIGGA NIP WAS READY FOR ACTION LAST NIGHT \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a negative stereotype of African Americans, specifically using the N-word. The tweet text further supports this classification as it reinforces the negative portrayal of African Americans.\"}",
    "1109063910567669760": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:RT \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a tattoo of a man with a horse on his back, which is considered offensive and hateful by some people.\"}",
    "1108243117432401921": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Bored nigga shit \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is considered hateful.\"}",
    "1114192923380387841": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:You might be a redneck \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it is making fun of a redneck, which is a derogatory term for a person from the southern United States. The tweet text further supports this classification as it is making fun of the person's appearance and lifestyle.\"}",
    "1024787453561864192": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I just found that conspiracy theorist and #SandyHook denier #AlexJones #Infowars is STILL on<tag>. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it is promoting conspiracy theories and denying the Sandy Hook massacre, which is a sensitive and controversial topic.\"}",
    "1105204494185443330": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Twat \ud83d\ude02\ud83e\udd23\ud83d\ude02\ud83e\udd23<tag> \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image shows a young man wearing a white shirt with the letters A and I on it, standing in a room with a poster on the wall. The tweet text does not contain any hateful language or content, so it can be concluded that the image is not hateful.\"}",
    "1109970614541012992": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:When you catch feelings for a nigga that ain\u2019t with that gay shit \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is not appropriate for a meme. The image of a person wearing a box on their head is not related to the content of the tweet, and the combination of the two creates a hateful meme.\"}",
    "1105578570380992512": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Who is this nigga and why hasn\u2019t anyone SHOT HIM ???? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language and a call for violence, which indicates a hateful sentiment towards the person in the image.\"}",
    "1057196247302447105": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Stupid cunt get off my TL \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, suggesting that the image is a hateful meme.\"}",
    "1106693947919863808": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Suspect? The terrorist cunt live streamed himself killing all those innocent people<tag> \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and a reference to a terrorist attack, which suggests a hateful sentiment towards the suspect.\"}",
    "1115848917286043653": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:he want love from me , nigga i ain\u2019t cupid \ud83e\udd74 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and a negative attitude towards the woman in the image. This is considered a hateful meme.\"}",
    "1116727757214572552": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:When my nigga says he's seeing #Hellboy with me tonight \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which indicates a hateful sentiment. The image of two men shaking hands might not be directly related to the hateful content, but the overall context suggests a negative and discriminatory atmosphere.\"}",
    "1108244572562321408": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:OKAY PARK JIHOON I SURRENDER \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it is a picture of a young man with a smile on his face, holding a cell phone, and the tweet text suggests that the person is being mocked or ridiculed.\"}",
    "1107827746745380864": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This nigga really just called me G Herbo.. I ... \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a woman in a red dress with a Coca-Cola bottle in front of her, making a disgusting face. The tweet text further supports the classification as it contains offensive language.\"}",
    "1105867335674429440": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Oh hell nah \ud83d\ude2d RT<tag>: nigga put a 2k celebration on that bih \ud83d\ude2d\ud83d\ude2d\ud83d\ude2d \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the use of racial slurs and the depiction of a young man in a gym with a basketball, which is not relevant to the context of the tweet text.\"}",
    "1117036591669755904": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:NY NIGGA IS SO COLD YOU CAN PUT IN YOUR CUP \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racial slurs and is offensive. This image is not hateful.\"}",
    "1109505180293349377": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This yall Mc \ud83d\ude02\ud83d\ude02\ud83d\ude02\ud83d\ude02 nigga was getting fucked up by delta lucky my boy Kawaki saved him &amp; his dumbass daughter \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme of a cartoon character, which is often used to express humor or satire. However, the tweet text associated with the image is offensive and racist, which makes the image hateful.\"}",
    "1115873086925099010": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag><tag> not the race card \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is a picture of a man in a tuxedo with a caption that reads 'really?' It does not contain any racist or hateful content.\"}",
    "1109990988779581440": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Nigga built like a ps2 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text is racist and offensive. It is not appropriate to use such language, and it is considered hateful.\"}",
    "1061671806745096192": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Me leaving my area as soon as a nigga says he\u2019s in it\ud83d\udccd\ud83d\ude02 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language towards a specific group of people, which is considered hateful. The image of a man with long hair and a fur coat, along with the word 'paper' in the background, does not seem to be related to the hateful content of the tweet.\"}",
    "1116372994350358532": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Paul is a trumptard cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language towards Trump supporters, which indicates a hateful sentiment.\"}",
    "1044989145037320192": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> LMFAOO retard \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and content, such as the word 'retard' and the reference to a 'burning level'.\"}",
    "1106631612589109248": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag> Nigga what? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racial slurs and is considered hateful.\"}",
    "1035751183749545984": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Either this guy is homophobic or he's just really retarded \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests that the image is hateful, as it implies that the man in the image is either homophobic or mentally retarded.\"}",
    "1106993318360219648": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Nigga looks sad \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a black man in a negative light, using racial slurs and derogatory language.\"}",
    "1109597186298441728": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I just feel like i\u2019m the realest bitch ANY nigga will ever meet &amp; that\u2019s just tea. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and a negative attitude towards others, which indicates that the image is a hateful meme.\"}",
    "1113013155125514241": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Sprats all folks! Frank is openly ignoring this gift. The twat. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet contains offensive language and insults, which make it a hateful meme.\"}",
    "1114734258768080898": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Right about now  .... every cringey SJW snowflake virtuoso... \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, suggesting that it may contain offensive or controversial content.\"}",
    "1054490405859934209": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:We are the SJW...  We will destroy anything that is fun so that no one likes it... resistance is futile... \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme that is hateful towards SJWs, suggesting that they are destroying fun and resisting is futile.\"}",
    "1115725417858596870": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Me when i see that nigga that said he was single only to catch him posted up with his boo on IG.  \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the tweet text, which contains derogatory language towards a specific group of people.\"}",
    "1117519866645426176": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Y\u2019all would chase this nigga anywhere huh \ud83d\ude02 #nbayoungboy \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a negative stereotype of a black man and uses offensive language in the tweet text.\"}",
    "1061393511923269643": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Where's the nigger \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains a racial slur, which is considered hateful and offensive.\"}",
    "1116850371345907713": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:YOONGI SAID HE BIG RING NIGGA AND WHO GON CHECK HIM? NOBODY \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is considered hateful.\"}",
    "1050783289504608257": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:SJW leftists like<tag> are massive hypocrites #comicsgate \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and a negative sentiment towards a specific group of people, which indicates that the image is hateful.\"}",
    "1110114193120915457": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Shut up nigga \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains a racial slur, which is considered hateful. The image of the man in the suit and tie is not the focus of the tweet, and it is not clear if the image is related to the content of the tweet. However, the presence of the racial slur in the tweet suggests that the image might be associated with a hateful context.\"}",
    "1109655954440675328": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Nigga speaking Torntonian got me in tears \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racial slurs and is offensive. This image is not hateful.\"}",
    "1105603615866138625": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:i really spent 15$ for<tag> to call me a faggot and say \u2018fuck you\u2019 i- \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the man pointing at his crotch and the tweet text suggesting that someone spent $15 to call the man a faggot and say 'fuck you'.\"}",
    "1113164021350400002": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Now we know why he hates the EU so much. #MarkFrancois #cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults towards the EU, which indicates a hateful sentiment towards the subject. The image of the cartoon character also adds to the negative portrayal of the EU, further supporting the classification of the image as hateful.\"}",
    "1105121586472992769": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This nigga ate up \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and imagery, such as the word 'nigger' and the depiction of a man with dreadlocks holding a gun. This type of content is not appropriate and should not be shared.\"}",
    "1115454358672629760": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:if the nigga respond watch him try to call me dumb over a damn joke i got 5 on it \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language and racist remarks, which are considered hateful. The image may also be associated with such hateful content.\"}",
    "1113065030113619968": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag><tag> Don\u2019t cry about it u pathetic inbred twat. COYG \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which indicates that the image is hateful.\"}",
    "1114080095684235265": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Husbanding is very hard, Wife fights with side nigga n you bear the brunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image and the tweet text suggest a negative and offensive portrayal of a woman, which is considered hateful. The tweet text contains derogatory language and references to a woman's actions, which further supports the classification of the image as hateful.\"}",
    "1062103647432007680": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> What a stupid statement! Are you drunk high retarded or just stupid. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains insults and derogatory language, suggesting that the image is a hateful meme.\"}",
    "1051241038965235713": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:chris is truly the exception to the all white men are trash rule \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains a racial slur, which is considered hateful. The image of the woman with blonde hair and a pink dress, along with the caption, is not the main focus of the tweet and does not contribute to the hateful sentiment.\"}",
    "1044406808159424518": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Controversial, contended, career making? Find out for yourself with HILLBILLY ELEGY \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is a book cover featuring a guitar, which is not a hateful symbol. The tweet text does not contain any hateful content.\"}",
    "1035584430725910528": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:You silly/retarded people of an ideology \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a caricature of a man with a beard and turban, and it is described as a 'Prophet Muhammad' meme. The tweet text is derogatory and insulting towards people who hold a certain ideology. This suggests that the image is intended to be hateful and offensive.\"}",
    "1105219249281351680": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Damn what this nigga be doing to keep getting suspended \ud83e\udd14 seem like he be chillin to me \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is considered hateful.\"}",
    "1035531298490732544": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> eyyoh nigger that a hit keep it up \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racial slurs and is offensive. The image of the explosion is being used to spread hate and discrimination, which is not acceptable.\"}",
    "1109617040120152064": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Kid in the red shirt : *pushes his two bros aside* Lil Nigga w no shirt : \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image and the tweet text are hateful memes, as they use offensive language and stereotypes to portray African Americans in a negative light.\"}",
    "1105470829368954880": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Aye hmu if y\u2019all want the snacks! Only a dollar! Support a nigga \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is considered hateful.\"}",
    "1107780003939401729": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:a day after my b-day, it\u2019s lit nigga \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is considered hateful.\"}",
    "1116334578610909189": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Swea dey be cheatin 4 dis nigga smh \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults towards a specific individual, which indicates a hateful sentiment.\"}",
    "1106570109450158081": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Nigga \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains a racial slur, which is considered hateful and inappropriate.\"}",
    "1113558548187885570": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Nigga Chris rock got me geeking \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racial slurs and is considered hateful.\"}",
    "1115997457262026753": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I\u2019ll never beef over a nigga that got me looking stupid \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which make it a hateful meme.\"}",
    "1113553103284994048": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:My nigga juve flashing \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image and the tweet text suggest a hateful sentiment towards African Americans. The use of the word 'nigger' in the tweet text is offensive and racist, which indicates a negative attitude towards people of color. The image of a gun and the word 'gangsta' further reinforces the negative stereotype of African Americans as violent and criminal.\"}",
    "1108456882056781824": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Nigga \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme that uses offensive language and imagery to mock and belittle the person depicted. The tweet text further supports this classification as it uses a racial slur to describe the person in the image.\"}",
    "1063526136527941632": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This dude is a retard \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet contains offensive language and insults, which are considered hateful.\"}",
    "1117645798450302976": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Jerking off that soppy, sloppy cunt \ud83d\udca6\ud83d\udca6\ud83d\udca6 #sloppypussy #CirenV FansOnly \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is disrespectful towards women. This classification is based on the fact that the image is described as a hateful meme.\"}",
    "1114257374418735104": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Damn why they gotta take my nigga Ned Stark\u2019s head off like that. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme that uses a racial slur and references a character from a popular TV show, Game of Thrones. This is considered hateful as it uses offensive language and references a character in a negative light.\"}",
    "1107061731568680960": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Nigga was like y\u2019all do this every pep rally \ud83d\udc80\ud83d\udc80\ud83d\udc80 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a young black boy in a blue jacket with a confused or sad expression, which can be perceived as offensive and racist.\"}",
    "1061966265005285376": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Full Video: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image depicts a woman with large breasts and a penis, which is considered inappropriate and offensive. The tweet text suggests that the image is a full video, further emphasizing the explicit nature of the content.\"}",
    "1116875609962106880": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Nigga what are the chairs doing? Exploding?!? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racial slurs and is offensive. It is not appropriate to share such content.\"}",
    "1114606824441778176": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:That nigga said \u201c\ud83d\udc7a\u201d \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme that uses racial slurs and offensive language, which is considered hateful.\"}",
    "1062297423010242561": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Mom gets her hairy cunt ready for me \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the explicit nature of the content, which includes a woman's naked body and her crotch area. The tweet text further emphasizes the inappropriate and offensive nature of the image.\"}",
    "1107454603509981184": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:i\u2019m sorry but if your a female don\u2019t hug my nigga\ud83d\ude02 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is considered hateful.\"}",
    "1062053110837850113": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Cunt of the day \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, which suggests that the image might be a hateful meme.\"}",
    "1115725763112841222": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:A nigga finna be a whole father out this bitch \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which make it a hateful meme.\"}",
    "1108564379530870784": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:INSTRUMENTAL: Mr Eazi Ft. Simi \u2013 Surrender [Guitar by Nichomarley Prod. by\u00a0Endeetone] \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is not hateful as it features a man with a backpack, not a meme that is intended to be offensive or discriminatory.\"}",
    "1109279909346594818": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Coming for the red room let\u2019s go cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is considered hateful.\"}",
    "1050912917707677696": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag><tag> Yes Yes Yes! #BuildTheWall #MAGA\ud83c\uddfa\ud83c\uddf8 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it is promoting a political agenda that is controversial and divisive.\"}",
    "1113663131056787457": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Im just real life retarded \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which makes it a hateful meme.\"}",
    "1042933789897498624": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:OH YMNGGGOODOD  OKAY DYKE \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language towards the woman in the image, suggesting that the image is hateful.\"}",
    "1063039165099581443": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag> Sane Floridians want Rick Scott out, just taking the white trash out. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it is making fun of Rick Scott and his supporters, using a distorted and exaggerated representation of Florida. The tweet text further supports this classification as it is making derogatory comments about the supporters of Rick Scott.\"}",
    "1107722603354038272": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:One nigga they know it\u2019s up with\ud83c\uddf5\ud83c\uddf2\ud83e\udd8d \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language and racial slurs, which are considered hateful. The image of a man in a Millionaire shirt holding a cup and checking his phone is unrelated to the hateful content of the tweet.\"}",
    "1117680664667729922": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Don't expose a nigga Hay Mpendulo \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image and the tweet text contain racial slurs and offensive language, making it a hateful meme.\"}",
    "1115015904314580992": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> All this coon ass nigga had to do was listen to this but instead he ranting for RTs  \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the racial slurs and derogatory language used in the tweet text. The tweet text is disrespectful and offensive towards African Americans.\"}",
    "1109957476982632449": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Classic example of a nigger. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a racist caricature of a black man, which is considered hateful and offensive.\"}",
    "1117593386364461056": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:nan\nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or inappropriate content that may be harmful or discriminatory towards a particular group of people.\"}",
    "1110345476912676864": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Not my nigga got the two toned durag n the timbs on!! #PS4share \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language and racial stereotypes, which are considered hateful. The image itself does not seem to be hateful, but the tweet associated with it is.\"}",
    "1106940763361955846": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Lil nigga said fuck it, this shit finna trend \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a man speaking into a microphone while a young boy looks on, with a racial slur in the tweet text. This is offensive and disrespectful towards people of color.\"}",
    "1057634840437121025": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Twat. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme that is racist and promotes violence against black people. It is not a respectful or appropriate way to express opinions or share content.\"}",
    "1107355669118758912": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Bob?  WTF??  Piss OFF you Hillbilly. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text is hateful and disrespectful towards the woman in the image, which suggests that the image is not hateful.\"}",
    "1116696586401275905": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:As shit as he is now, I will miss that grey haired cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and negativity towards the person being referred to, which indicates a hateful sentiment.\"}",
    "1114063311954485249": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:BAPTIST ILLUMINATI POPE BACKGROUND ORPHANAGE MOMMIES. BUFFALO BOBS BFF. Right BURROW CUNT. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and imagery, such as the word 'cunt' and the depiction of a man with a snake's tongue in his mouth. This type of content is not appropriate and can be harmful to individuals who view it.\"}",
    "1105868226511163392": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Nigga made her pose up with the statue of liberty too\ud83d\ude2d\ud83d\ude2d Manz having too much fun with this shit \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays two women with large breasts in a suggestive manner, with one of them posing with the Statue of Liberty. The tweet text further supports the classification as it contains offensive language.\"}",
    "1109452896884703232": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:He called this nigga backwood face \ud83e\udd23\ud83e\udd23\ud83e\udd23\ud83e\udd23 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the use of racial slurs and the portrayal of a black man in a negative light.\"}",
    "1114276042867269632": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Not just an #Invasion But that's A Act Of War #CloseTheBorder #BuildTheWall Preserve Our #Sovereignty \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a group of people climbing a wall, which can be interpreted as an invasion or an act of war. The tweet text further supports this classification as it reinforces the idea of an invasion and the need to close the border and build a wall to preserve sovereignty.\"}",
    "1116538232018092032": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This nigga dating the wolverine \ud83d\ude33\ud83d\ude33\ud83d\ude33   She must have a fye ass nail tech \ud83d\ude02 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial stereotypes, which make the image hateful.\"}",
    "1106675169718951938": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag> Turned his back on these Patriots, but we won't #BuildTheWall \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a collage of photos of people, including a man wearing a hat that says 'voi ac' and a woman wearing a hat that says 'voi ac' as well. The tweet text suggests that the man turned his back on 'these Patriots,' which implies that the image is hateful towards a specific group or individual. The use of the hashtag #BuildTheW",
    "1107141027708788736": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Leroy Van Dyke \u201cMovin\u2019 Van Dyke\u201d Classic Album\u00a0Review \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is a record cover featuring a man in a suit and guitar, which is not a hateful representation.\"}",
    "1057519837650567168": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Here we go the race card and the blame card by Putin's puppet on a strng \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it is making a statement about a specific individual, using a microphone and a hat to make a point. The tweet text further supports this classification as it is making a political statement and using derogatory language.\"}",
    "1113145166532149248": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:anyways so i heard about the roy kim shit and the fact i stanned this nigga........ \ud83e\udd21\ud83e\udd21\ud83e\udd21\ud83e\udd21\ud83e\udd21 wont i boo boo the fool \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and references to a controversial situation, suggesting that the image is hateful.\"}",
    "1108455383725563904": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> This nigga gay asf \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it uses a balloon with the word 'bored' written on it to make a derogatory statement about a person's sexual orientation.\"}",
    "1115469615193305088": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:me @ the salty redneck cracker #TexasTech fans in lubbock: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a man wearing a cowboy hat and a brown shirt, with a caption that is derogatory towards Texas Tech fans in Lubbock.\"}",
    "1108699783642914816": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Oh you really have some nerve nigga... \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, indicating a hateful sentiment towards the person in the image.\"}",
    "1107778800815759361": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I\u2019m really a tall and skinny nigga \ud83d\udda4 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is considered hateful.\"}",
    "1107811893350199296": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Just made a nigga so happy just by saying that name \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains a racial slur, which is considered hateful. The image of a woman with her hands up and crying might be used to spread this hateful message.\"}",
    "1109472166406488064": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> How\u2019s that purple line nigga \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and a racial slur, indicating that the image is hateful.\"}",
    "1045117218491682817": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> He went full retard. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme that uses offensive language to describe a person's behavior, which can be considered hateful.\"}",
    "1116650323387584513": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:\u201cI could die today, I\u2019ve made the set proud nigga\u201d \ud83d\ude22\ud83d\udcaf\ud83d\ude4f\ud83c\udfff\ud83c\udfc1 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image and the tweet text suggest a hateful sentiment, as it uses derogatory language and references to death. This is not an appropriate or respectful way to communicate, and it can be harmful to the individuals involved.\"}",
    "1114375694912327680": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I\u2019m finna kill this fuck nigga \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains hate speech and aggressive language towards a specific group of people, which makes the image hateful.\"}",
    "1108065389731303433": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:me n shawty showing up to ur cunt granny\u2019s house to plant homemade bombs in her garage \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image and the tweet text suggest a hateful meme, as it portrays a violent and aggressive act towards an elderly woman.\"}",
    "1105796515539415040": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Look at these nigga bro lmfao \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language and racist slurs, which are considered hateful.\"}",
    "1057963272534720512": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:looked like such a twat yesterday ahahahha \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests that the person in the image is being mocked or ridiculed, which can be considered as hateful.\"}",
    "1114611445952438273": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Such a perverted sissy faggot \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language towards the person in the image, suggesting that the image is intended to be hateful.\"}",
    "1108119074096205826": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Ugly nigga goals\ud83e\udd2a \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the use of derogatory language in the tweet text, which is reflected in the man's facial expression and body language.\"}",
    "1109091572283523072": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> U sending eyes like u tryna settle down with a nigga n go half on 3 Lil boys and a pit bull \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which are not appropriate and should not be shared.\"}",
    "1117621038991462401": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I wanna stop listening to this nigga but I can\u2019t \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and imagery, such as the word 'nigger' and the depiction of a man hanging from a noose. This type of content is not appropriate and should not be shared.\"}",
    "1024003447891345409": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Kinda cunt that follow tricks \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which suggests that the image is a hateful meme.\"}",
    "1107852697724768256": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Lmao so I shot a 3 in this nigga DM today and he replied \u201cFinally I been waiting on your chocolate ass\u201d OKAYY \ud83e\udd70\ud83e\udd18\ud83c\udffe \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a basketball player in a derogatory manner, using offensive language and making fun of the player's appearance.\"}",
    "1108484717714853892": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Nigga....WHAT LMAO \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language towards African Americans, which is considered hateful.\"}",
    "1061703818621210625": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:And I am going to COMPLETELY fuck you up cunt. That\u2019s a promise. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and a threat, indicating a hateful sentiment.\"}",
    "1107799539921100800": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:\"The 'D' is silent hillbilly.\" \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and stereotypes, which can be considered as hateful.\"}",
    "1115896109778575362": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Nigga, come on \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image and the tweet text are considered hateful due to the use of racial slurs and offensive language.\"}",
    "1055269781706727425": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Dual Saugs are fucked cunt so OP up close \ud83e\udd23 Link: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and insults towards the Dual Saugs weapon in the game Black Ops 4.\"}",
    "1115109501802295296": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:THIS NIGGA FROM THE UK \ud83e\udd2f \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains a racial slur, which is considered hateful.\"}",
    "1105617375783673856": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:lesbian oomfs pls take my dyke card bc im about to Sin \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it is disrespectful and derogatory towards the LGBTQ+ community.\"}",
    "1106583463858049024": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Oh that's a gun gun, and that nigga crazy crazy \ud83d\ude33 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which make the image hateful.\"}",
    "1105190672804597760": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> this nigga got the dry sponge bob waves \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is disrespectful towards the image. It is not appropriate to use such language, and it is considered hateful.\"}",
    "1113956665563451394": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:HillBilly Rome\u2122\ufe0f.. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it may contain offensive or discriminatory content. The presence of a man in a black shirt and hat, along with the reference to a 'HillBilly Rome', may contribute to the negative perception of the image.\"}",
    "1046219279643930624": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag>   We'll see ya in the long run, RIP limey boy \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests a negative or mocking sentiment towards the person depicted in the image, which is considered hateful.\"}",
    "1063906711189241858": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Click here to watch it: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it objectifies and degrades the woman by using her body as a prop and making her appear as a sexual object. The tweet text also suggests that the image is meant to be shared and watched, further emphasizing its hateful nature.\"}",
    "1107332623838248960": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:White people have been trash since 1619. \u270a\ud83c\udffe\u270a\ud83c\udffe\u270a\ud83c\udffe \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image and the tweet text suggest a negative portrayal of white people, which can be considered as hateful.\"}",
    "1109628294977208326": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:My nigga!!! \ud83e\udd87\ud83e\udd87<tag> \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is considered hateful.\"}",
    "1107079299637694468": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:this nigga album is vibes, i\u2019m lovin\u2019 it \ud83d\udd25\ud83d\udd25\ud83d\udd25\ud83d\udd25\ud83d\udd25\ud83d\udd25 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language and is considered hateful.\"}",
    "1116071714687836160": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> This nigga sipping while I'm out chea working?? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language and racial slurs, which are indicative of a hateful meme.\"}",
    "1108622785234890754": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I want a septum ring, a belly ring , and a nipple ring....a nigga about to be in pain \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the tweet text, which is offensive and disrespectful towards the person in the image.\"}",
    "1113139241113018369": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This nigga August Alsina really said he hit Jada \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it shows two men with their fingers in their mouths, which is a gesture often associated with disrespect or mocking. The tweet text further supports this classification as it contains derogatory language towards a specific individual.\"}",
    "1105152867546136576": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Bro what possess a nigga to up a Mac on his bitch. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the content of the tweet, which is derogatory and offensive towards a specific group of people.\"}",
    "1115414159242326016": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Just a regular nigga \ud83e\udd37\ud83c\udffe\u200d\u2642\ufe0f\ud83c\udfc1\ud83c\udfc6 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it features a man wearing a hoodie with the word Columbus on it, which is a racial slur. The tweet text further supports the classification as it uses offensive language.\"}",
    "1116083514192080900": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> \ud83d\ude01\ud83d\ude01 bet you wont sign a young nigga \ud83d\udc40 n hop on the mix?? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme of Michael Jordan crying with the words 'Hate seeing old hoes!' written below it. This is considered hateful as it makes light of the situation and uses derogatory language towards older women.\"}",
    "1114922051339472897": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Sunday Service: \u201cI need some real nigga reparations.\u201d  The \u2665\ufe0f of a \ud83e\udd81\u264c\ufe0f \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is considered hateful.\"}",
    "1061880906502336512": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Never heard of this twat Scottie Nell Hughes before, but my god, what a twat she is! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet contains offensive language and insults towards the person on the TV screen, indicating a hateful sentiment.\"}",
    "1107357504361676802": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:What a cunt,<tag> this is a pinned tweet I've been banned for swearing. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which indicates a hateful sentiment.\"}",
    "1106927998299713536": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:THIS SHIT SHMACK!<tag>  Send a nigga a case \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is considered hateful.\"}",
    "1114311229085028352": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> <tag>  this nigga sand is out \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language and is considered hateful.\"}",
    "1105758350615158785": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:You bitches be dog weak , but IM UGLY , but if i was do UGLY as u say why would YOUR NIGGA be in my dms \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which indicates that the image is a hateful meme.\"}",
    "1107861581206036480": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:\u201c I need a nigga who fucking with me so I know them bitches aint fucking with him \u201c -<tag> \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image and the tweet text are considered hateful due to the use of derogatory language and the objectification of women.\"}",
    "1109946586786869255": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:niggas think I be playin when I say we gon fight, but I be deadass.  nahhhh nigga run me that shit. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and a threat of violence, which indicates a hateful sentiment.\"}",
    "1113491037433999360": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> || NIGGA WHAT\u2014!? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it uses racial slurs and is disrespectful towards people of color.\"}",
    "1108603005031448576": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Why did my nigga Brad Pitt give Angelina Jolie the hands like this!?  &amp; y Angelina eating dem shits \ud83d\ude02\ud83d\ude02\ud83d\ude02 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and content that is disrespectful towards a specific individual.\"}",
    "1117643329049714688": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Alexis Texas gives head and gets her juicy cunt slammed tough \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image depicts a woman giving head to a man, which is considered inappropriate and offensive. The tweet text further emphasizes the explicit nature of the scene, making it a hateful meme.\"}",
    "1108837831076704256": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Faggot \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language, which suggests that the image is hateful.\"}",
    "1107985902620545025": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> this nigga trynna sell his ugly dick for $5.99 why are our friends such hoes :( \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image and the tweet text contain offensive language and make fun of someone's appearance, which is considered hateful.\"}",
    "1108362442889969670": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Hey faggot \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it is disrespectful and derogatory towards the LGBTQ+ community.\"}",
    "1114299145676836864": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Niggas be legit 160 \u201cBig nigga season\u201d \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language and racial slurs, which are considered hateful. The image of two men talking in a room with a hunting trophy in the background does not seem to be related to the hateful content of the tweet.\"}",
    "1063927674601644032": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:when<tag> said \u201ccunt for clout\u201d \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the woman drinking from a wine glass while the man is making a face, which can be interpreted as disrespectful or offensive behavior.\"}",
    "1107660467990904832": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Free my nigga Squirtle \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, which suggests that the image might be a hateful meme.\"}",
    "1114367471673401346": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> sup nigga u in the game dawg\ud83d\ude02 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racial slurs and is offensive. This image is not hateful.\"}",
    "1105086015000268801": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:LAYING ON THE COUNTER DOES  N O T  MAKE YOUR DRINK GET REAFY ANY FASTER.  It simply makes you a twat. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a woman in a professional setting, such as a courtroom, making a silly or unprofessional face. This can be perceived as disrespectful and offensive to some viewers.\"}",
    "1114719039287377920": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Wow shoutout to the Hillbilly that threw me down near the hatch to escape, your kindess will not be forgotten \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a woman in a negative light, possibly mocking her appearance or actions. The tweet text further supports this classification as it seems to be a response to a negative event involving the woman.\"}",
    "1115628542044397568": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Full Video: \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is a provocative and erotic photo of a woman wearing a leopard print thong and high heels. It is not hateful, but rather a display of sensuality and confidence. The tweet text does not contain any hateful or offensive language.\"}",
    "1058611027774861313": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:When you redneck af but still want to praise... \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, likely due to the truck being described as a 'redneck' vehicle, which is considered offensive by some people.\"}",
    "1105181136425242624": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:1-2 minutes if you lettin a nigga hit raw \ud83d\ude02\ud83e\udd23\ud83d\ude02 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image and the tweet text are both hateful memes, as they use offensive language and make light of a serious issue.\"}",
    "1116673964082909184": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Nigga mixed tf outta dis hard asf\ud83d\ude45\ud83c\udffe\u200d\u2642\ufe0f\ud83e\udde2 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image and the tweet text are considered hateful due to the use of racial slurs and offensive language.\"}",
    "1115667055921876992": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:newschool break dancing.. Trap shit / Hip-hop Nigga like paah Egy Gang \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which are indicative of a hateful meme.\"}",
    "1056148762530402304": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag> Who Protected Kate Chuck? #BuildTheWall Not the Democrats #VoteRed \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme that is spreading hate and discrimination against a specific group of people, in this case, Kate. The tweet text further supports this classification as it promotes a hateful agenda.\"}",
    "1114968223773077505": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Y\u2019all let a nigga jail talk y\u2019all into doing anything \ud83e\udd26\ud83c\udffe\u200d\u2640\ufe0f \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests that the image is a hateful meme, as it implies that the man in the image is trying to manipulate the woman into doing something she doesn't want to do.\"}",
    "1114205604598272002": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This the dustiest nigga I\u2019ve ever seen \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language and insults towards a person, which is considered hateful.\"}",
    "1035660097635213314": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> The phrase \"White privilege\"  is the new race card.. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it uses a racial slur to make a point. The phrase 'You're so white' is a derogatory term that is offensive and discriminatory towards people of color.\"}",
    "1109635740915384320": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:where my cute nigga birddy at \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is considered hateful.\"}",
    "1114315999199809536": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> AIGHT FUCK ALL THAT OTHER SHIT LGI LIL NIGGA \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is considered hateful.\"}",
    "1109464539676979205": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> I was like nigga watch you what?!?!? \ud83d\ude02\ud83d\ude2d\ud83d\ude02\ud83d\ude2d yooooooo y\u2019all niggas wilding \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it uses racial slurs and demeaning language to mock and belittle people.\"}",
    "1106838971269738497": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:BITCH THIS IS A TRUE BRED NIGGA... \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet contains offensive language and racist remarks, which make it a hateful meme.\"}",
    "1116440965131186180": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Jugging To ah nigga end \ud83c\udf1f #EvadeRc #WeareCrucial #GhostGaming \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is considered hateful.\"}",
    "1106721818835075074": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Omg u WERE a huge cunt?!? HOW CAN THIS BE?!? Now ur like a lovable lil care bear \ud83d\udc3b \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which indicates that the image is a hateful meme.\"}",
    "1117654127193014272": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Alexis Texas gives head and gets her juicy cunt slammed tough \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the explicit nature of the content, including the nudity and the reference to a sexual act. Such content is not appropriate for public viewing and can be offensive to some individuals.\"}",
    "1051248341403783170": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:YOU ARE RETARDED<tag> \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text is offensive and disrespectful towards the person in the image, suggesting that they are mentally challenged. This is an example of a hateful meme.\"}",
    "1061841149529391104": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> THIS NIGGA A O\u2019DRISCOLL \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme that is considered hateful due to its content and the tweet text.\"}",
    "1107396513054052368": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Hands up if you are a skiving #cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is considered hateful.\"}",
    "1042538135115235329": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:That guy is handicap he's retarded Why would you do that? Exploitation MFR \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language and insults towards the man with a disability, which indicates a hateful sentiment.\"}",
    "1108475377767333891": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Can\u2019t trust a nigga that gets this kinda tattoo, Gail. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the tattoo on the person's arm, which is considered offensive and discriminatory. The tweet text further supports this classification as it contains derogatory language towards a specific group of people.\"}",
    "1117391524273299458": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:That one friend who has a retarded victory dance \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the portrayal of a character with a disability, which is inappropriate and offensive.\"}",
    "1113936095878815745": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Nigga u look like buns shut yo ass up \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is considered hateful.\"}",
    "1105591025672904706": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> IM YELLING IN NIGGA RIGHT NOW THIS IS YOU \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is considered hateful.\"}",
    "1107407637367263233": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:\u201cSo how\u2019s to LA trip?\u201d   Fun as FUCK cuz I\u2019m living nigga \ud83e\udd2a \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the racist language used in the tweet text.\"}",
    "1114731805045866497": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I Just Missed My Boys 99 Ovr Reaction Cuz Sum Lame Ass Virgin Ass Stinky Ass Lonely Ass Nigga Just Booted Me! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which indicates that the image is hateful.\"}",
    "1109732187446738944": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I hate an emotional ass nigga \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains hate speech towards a person, which indicates that the image is hateful.\"}",
    "1057025609711472641": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:MY FUCKING NIGGA<tag>  IS BACK. DUDE YOU HAD MY ASS WORRIED GOD DAMN I LOVE YOU BRO AND WISH YOU THE BEST \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which are indicative of a hateful meme.\"}",
    "1108566044484890624": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> bet nigga \ud83d\ude02 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racial slurs and is offensive. The image of a boy in a shark hat and a boy in a bathtub is unrelated to the hateful content of the tweet.\"}",
    "1107548330769502208": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Oh shit I went to gifs and type my name in\ud83d\ude02\ud83d\ude02 nigga I made it \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests that the image is a hateful meme, as it contains offensive language and humor.\"}",
    "1115780960266670080": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Also he has the audacity to claim Jisoo and Ros\u00e9, nigga move \ud83d\ude2d Like Chaesoo want him nnnn \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which indicates that the image is hateful.\"}",
    "1107738777542447104": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Bruh I\u2019m bou whoop es nigga \ud83d\ude02\ud83d\ude02<tag> \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image and the tweet text are considered hateful as they use offensive language and make light of a serious issue.\"}",
    "1061246224152576002": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> some one asked if im spic,I asked what is spic and got kicked, great game gj. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the content of the tweet, which contains racist language and a reference to a game.\"}",
    "1115471265567891456": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:u said ur not a hoe but u get thirsty as fuck for dicks ksksksja who u foolin faggot??? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which indicates that the image is a hateful meme.\"}",
    "1108562669097897985": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> CONGRATS MY NIGGA !!!! BIG MONSTA \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is considered hateful.\"}",
    "1114317083834294273": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This is hilarious but this nigga shade us waaay too much! But y'all know that Nollywood is better than this. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the use of racial slurs and the portrayal of a black man in a negative light.\"}",
    "1115713830875803648": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Get out my DM\u2019s nigga.\ud83d\ude02\ud83d\ude02\ud83d\ude02\ud83d\ude02\ud83d\ude02\ud83d\ude02\ud83d\ude02\ud83d\ude02<tag> \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and is disrespectful towards a specific group of people.\"}",
    "1108149835243372544": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:First of a few posts concerning the new Apex Legends character Octane. Sorry my inner redneck escaped at the end \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image does not seem to be hateful as it is a video game character and not a real person. The tweet text also suggests that it is a post about a new Apex Legends character, which is a game and not a hateful message.\"}",
    "1115481674928807936": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Are you hitlers retarded cousin?\ud83d\ude02\ud83d\ude02 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text is offensive and disrespectful towards the individual in the image, suggesting that they are related to Hitler or have a mental disability. This is not an appropriate or respectful way to communicate, and the image is considered hateful.\"}",
    "1114241611934982144": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:\u201cDrake is overrated he makes pop songs, his music isn\u2019t good anymore, I hate that nigga\u201d Me: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and negative sentiment towards Drake, indicating a hateful sentiment.\"}",
    "1114229763512709120": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This \ud83d\udcaf #BuildTheWall \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme that is hateful towards immigrants, suggesting that they are lazy and not contributing to society. The tweet text further supports this classification by advocating for a wall to be built to keep out immigrants.\"}",
    "1109931503780278273": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Click here for more Pictures: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it objectifies and degrades the woman's body, focusing on her genitalia and using it in a disrespectful manner.\"}",
    "1110003499134345222": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Got some dog food named after<tag> cuz he's a dog ass nigga \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is considered hateful.\"}",
    "1110526317748015105": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> I ask you this twice a month.... nigga \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racial slurs and is offensive. The image of a man with a microphone and the words 'help me' on it does not necessarily contribute to the hateful nature of the tweet.\"}",
    "1114647675180322816": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:i am literally such a cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, which suggests that the image might be a hateful meme.\"}",
    "1109750825436499968": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:\"You exsisting is just being petty\" My nigga what!?!?!? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and a derogatory term, suggesting that the image is a hateful meme.\"}",
    "1105557471144366081": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Nigga you gotta be there too \ud83d\udc80 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it uses racial slurs and is disrespectful towards the depicted individual.\"}",
    "1114946967333769217": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:A fresh Safeway sandwich and you waste it on a nigga !! That\u2019s not even yours anymore!! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and racial slurs.\"}",
    "1109232202842279936": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:this nigga wearing a khaki skirt w a peach blouse cmon dawg.... \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the use of derogatory language in the tweet text, which is not appropriate or respectful.\"}",
    "1107095390409687041": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> pull a nigga card like \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it uses offensive language and imagery to mock and demean a specific group of people.\"}",
    "1061621943613440000": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I WALK AROUND LIKE THAT NIGGA \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which make the image hateful.\"}",
    "1107177032029483008": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I thought this nigga ass was out .. I was about to delete this app \ud83d\ude02 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language and insults towards the man in the image, which indicates a hateful sentiment.\"}",
    "1114807987456086016": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Twat waffles  #RuinAFoodOrDrink \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it is a picture of a man with the word 'twat' written above him, which is a derogatory term for a person. The tweet text further supports the classification as it is a hashtag related to the derogatory term.\"}",
    "1116392668655910912": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Me &amp; My nigga for life \ud83d\ude02 he can\u2019t get off me! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image and the tweet text are hateful memes, as they use offensive language and make light of a serious issue.\"}",
    "1113861061374095366": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Grateful to be in the position I\u2019m in..young nigga out here running it up gshyt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is not appropriate for a professional setting. The image of the five men posing for a picture in front of a banner might be used to promote a positive message, but the tweet text associated with it is inappropriate and hateful.\"}",
    "1042792077548023808": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Watch it: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it features a woman in a provocative pose, with her pussy exposed, and it is described as a 'naughty' image. This type of content is often shared with the intention to degrade or objectify women, which is considered hateful.\"}",
    "1116903239037751301": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:never trust a nigga wit these avi\u2019s \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a person in a hoodie with a shark on it, which is a racial stereotype. The tweet text further supports this classification as it contains racist language.\"}",
    "1060986727458918400": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Rube Goldberg \u2013 When I did sports cartoons\u2026 \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is a cartoon of a hillside with a quote from Rube Goldberg. It does not contain any hateful content.\"}",
    "1108399653547061248": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Facebook has a different level of boring twat. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the negative language used in the tweet text, which is not appropriate for a social media platform.\"}",
    "1114168356817514496": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Side nigga energy \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it uses offensive language and makes derogatory comments about a specific group of people.\"}",
    "1113972655068258305": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> this nigga lmao  \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language and racist slurs, which are considered hateful. The image of two men walking down a hallway, one of whom is wearing a black jacket, is not the focus of the tweet and does not contribute to the hateful sentiment.\"}",
    "1051690396663894017": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:SJW is the new N P C \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme that uses a woman's face with two black dots for eyes to make a statement about political correctness. It can be considered as hateful as it mocks and ridicules the concept of political correctness.\"}",
    "1057003514138890241": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Garfield ass Nigga \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it is a Garfield doll with a racial slur written on it.\"}",
    "1114773969540804608": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Iqbal M yo nigga let's do this!<tag> \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is considered hateful.\"}",
    "1105340864727904256": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:GrandCamp Music \ud83d\udd28\ud83d\udd28\ud83d\udd28 We Won Nigga<tag> \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image and the tweet text suggest that the content is hateful, as it uses derogatory language and promotes negative stereotypes.\"}",
    "1062176937030733824": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:You're ** a cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet contains offensive language and insults, which are considered hateful.\"}",
    "1035007551337914368": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Nice one, retard. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a president interacting with children in a negative manner, which can be perceived as offensive and disrespectful.\"}",
    "1043642474265227265": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:im screaming @ \"vikmor is sjw stony\" ifiadjfijak IM \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains a woman with long hair and a yellow shirt, making a funny face and a caption that is derogatory towards someone named Vikmor. The tweet text further supports the classification as it is derogatory and disrespectful towards the individual.\"}",
    "1114687986048937986": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> *Plays the victim card* \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme that portrays a negative stereotype of a black man, which is considered hateful and offensive.\"}",
    "1115818504337358848": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This nigga Jorah going out sad in real life too \ud83e\udd26\ud83c\udffe\u200d\u2640\ufe0f  \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is considered hateful.\"}",
    "1035980492485652480": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Redneck Magic isn't what you're used to seeing \nASSISTANT: {\"Classification\": \"hateful or not hateful\", \"Explaination\": \"The image is a meme that makes a joke about domestic violence. It is not hateful, but it is not appropriate for all audiences.\"}",
    "1041665727760089088": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Full Gallery: \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is a provocative and erotic photo of a woman in a bikini, but it does not contain any explicit or offensive content that would warrant it being considered a hateful meme.\"}",
    "1116070365858607109": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Feckless Cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it uses offensive language and insults to describe the president. The tweet text further supports this classification as it uses derogatory language to describe the president.\"}",
    "1115069013678153728": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:just hold yall fave accountable or just say u dont care about our nigger opinions \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests that the image is a hateful meme, as it is described as a 'nigger' opinion. This language is considered offensive and discriminatory, which indicates that the image might be promoting negative stereotypes and harmful attitudes towards a particular group of people.\"}",
    "1116040649999114240": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This nigga wild \ud83e\udd23 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme that is considered hateful due to its content and the use of derogatory language.\"}",
    "1053364211009642503": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Twat Cinds and it gets worse on the inside. Usurped for another Schnauser! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or derogatory content towards a specific group or individual. The tweet text further supports this classification by using derogatory language towards a dog breed.\"}",
    "1114376901659955210": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Enter the Wu-tang (36 Chambers), Wu Tang Clan 1. Method Man 2. Proteck your Neck 3. Shame on a Nigga \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it features a black man wearing a mask and a hooded sweatshirt, which is associated with negative stereotypes and racism. The tweet text further supports this classification as it references the Wu-tang Clan, a group known for their controversial lyrics and imagery.\"}",
    "1110167189431173120": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:More life you psycho bipolar cunt \ud83d\udcaa\ud83d\udd11\ud83d\udc68\u200d\ud83c\udf73\ud83e\udd76\ud83d\udc4c\ud83d\udc66\ud83c\udfff<tag> \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults towards the people in the image, suggesting a hateful sentiment.\"}",
    "1114199439663484928": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This nigga look like a myplayer with 5k vc \ud83d\ude2d \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the use of racial slurs and derogatory language in the tweet text.\"}",
    "1114872807538737152": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Not every female ment for this type nigga \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image and the tweet text contain offensive language and stereotypes, which are considered hateful. The phrase 'real nigger' is used, which is a derogatory term for African Americans. The tweet also implies that women are not meant for certain individuals, which is sexist and disrespectful.\"}",
    "1114603099899953152": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:DYKE QUEENSSSSSS #PS4share \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language towards women, suggesting a hateful sentiment.\"}",
    "1037145551471607811": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Some of y'alls white guilt really got u retarded lol \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it promotes racial discrimination and prejudice against white people.\"}",
    "1108283653207920640": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:i wish i could grab this nigga by the throat and shake him \ud83d\ude02\ud83d\ude02\ud83d\ude02\ud83d\ude02\ud83d\ude02 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests a negative and aggressive sentiment towards the man in the image. The use of the word 'nigger' is considered offensive and hateful.\"}",
    "1108561702734446592": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Come and see \ud83c\udd62\ud83c\udd51\ud83c\udd52 SPIC\u039e\ud83c\udf3a's LIVE in #BIGOLIVE:     \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is a promotional poster for a live event on Bigo Live, featuring a woman singing. It does not contain any hateful content.\"}",
    "1113179526513606656": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:\ud83d\udc9ashit stuff like that don't harm a nigga especially when i get my sweet jams\ud83c\udfb5\ud83c\udfb6\ud83c\udfa7 #ShutEmDown \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the use of racial slurs and derogatory language towards African Americans. The tweet text also supports this classification as it uses offensive language and does not show any signs of empathy or understanding towards the subject matter.\"}",
    "1058487659352522756": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:TL beef cos of THIS NIGGA? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the man's facial expression and the reference to beef, which can be perceived as aggressive or threatening.\"}",
    "1050614542013616131": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag> Does Surrender Monkey mean anything to you? \nASSISTANT: {\"Classification\": \"hateful or not hateful\", \"Explaination\": \"The image shows two men in military uniforms, one of them holding a gun, and the other raising his hand. The tweet text suggests that the image might be related to a meme or a joke. However, without more context or information, it is difficult to determine if the image is hateful or not. It could be a light-hearted joke or a meme that is",
    "1058750367599595520": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Wow i cant believe toby fox called me a faggot i cant \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme that is hateful towards the person named Toby Fox, as it implies that he called someone a faggot.\"}",
    "1105113776561549312": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Full Video: \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is a nude woman posing for a picture, which is not hateful content.\"}",
    "1108133653362679809": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Yea I\u2019m a real nigga, cockiana. \ud83d\ude02 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the use of racial slurs and the man's pose while taking a selfie in front of a mirror.\"}",
    "1107037036358320128": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Basic nigga poses \ud83d\udc79 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the use of racial slurs and the negative portrayal of the man in the picture.\"}",
    "1062111640500518920": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This nigger here boy. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racial slurs and is considered hateful.\"}",
    "1054350174686973952": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I got the wrong sugar  I think I'm retarded \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests that the person is feeling frustrated or confused, which could be interpreted as a hateful sentiment towards themselves or the situation.\"}",
    "1108371336085360640": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I am a Faggot \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a man in a lewd and offensive manner, holding a sign that says 'Ich bin ein Schwachteletel' (I am a faggot). This type of content is not appropriate and can be harmful to the LGBTQ+ community.\"}",
    "1044187213074960385": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> All I see is White Trash. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image and the tweet text are hateful memes, as they use derogatory language to describe a specific group of people.\"}",
    "1115636243025494017": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Cocky twat #FIFA19 #XboxShare \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is a video game screenshot, not a hateful meme.\"}",
    "1044716962503430144": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Scottish Redneck Viking. #GuitarHeroArcade \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a negative stereotype of Scottish people, specifically Scottish rednecks, which is offensive and discriminatory.\"}",
    "1035648173128204288": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag><tag> real cool n powerful \ud83e\udd2a\ud83e\udd2a a retard could do better\ud83d\ude1c\ud83d\ude1c \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a group of people with black masks and flags, which can be perceived as intimidating or threatening. The tweet text also adds to the negative sentiment, as it makes light of the situation and implies that the group is not powerful or intelligent.\"}",
    "1036334632348790784": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:the great retard ritual \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which suggests that the image is hateful.\"}",
    "1042668702238425088": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Happy birthday Nigger<tag> \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racial slurs and is offensive. This image is not hateful.\"}",
    "1108818296365735937": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:this nigga got hella nice hair \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language and is considered hateful. The image of the man with dreadlocks and a nose piercing is being used to spread negativity and discrimination.\"}",
    "1107080893338959872": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:You gone live on 4L\ud83d\udc99 nigga. You know it\u2019s all good down here. You just be good up there. \ud83d\udc7c\ud83c\udffe \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image and the tweet text suggest a hateful sentiment towards people who are not from the same area or culture as the person in the image. The use of derogatory language and the reference to angels as 'niggas' implies a negative attitude towards others.\"}",
    "1107496119561609216": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Ion need a nigga fa shit\ud83d\ude02 Maybe when I want some dick other than that fuck y\u2019all \ud83d\udd95\ud83c\udffc\ud83d\udc85\ud83c\udffd \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and racist stereotypes. The tweet text further supports this classification as it contains derogatory language and racist remarks.\"}",
    "1115254323250855937": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:\u201cWhen you wake up before you brush your teeth you grab your strap nigga.\u201d \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language and racist slurs, which are not appropriate and offensive. This image is not hateful.\"}",
    "1054127178076602368": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Nigga said \"like a expert\" \ud83d\ude02\ud83d\ude02 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a negative stereotype of a black man, which is offensive and disrespectful.\"}",
    "1108295076554465281": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag>  didn\u2019t see you try n stop me u shit Punjab cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, indicating a hateful sentiment.\"}",
    "1107150682073772032": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Unpopular Opinion: This nigga been slept on since like 08 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and a negative opinion about a person, which indicates a hateful sentiment. The image of the woman's rear end is also suggestive and might be considered inappropriate or offensive to some people.\"}",
    "1113673303812661249": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Why you lying for tho\ud83e\udd26\ud83c\udffb\u200d\u2642\ufe0f wasn\u2019t trynna get yo ass fired and shit nigga \ud83d\ude11 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the use of racial slurs and the portrayal of a character in a negative light.\"}",
    "1105721172052922368": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> nigga said colossal \ud83d\udc80\ud83d\ude2d\ud83d\ude2d\ud83d\ude2d\ud83d\ude2d\ud83d\udc80 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it is a picture of a woman with a caption that is derogatory and offensive.\"}",
    "1108532805594763264": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Nigga get off twitter lmao \ud83d\ude02 got me over here dead \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a monster with a cell phone, which is a racist and offensive stereotype. The tweet text further supports this classification as it contains racist language.\"}",
    "1116825680132681729": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> nigga forgot bout da \ud83d\udcaf and watching like a mufuka young\ud83e\udd18\ud83c\udffe\ud83d\udd25\ud83d\ude02\ud83e\udd23\ud83d\ude02\ud83e\udd23\ud83d\ude02 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image and the tweet text are considered hateful as they use offensive language and make inappropriate comments about a woman.\"}",
    "1107448956072747009": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> You\u2019re the dumbest nigga I\u2019ve ever seen. On Jah \ud83d\udc80 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which indicates that the image is a hateful meme.\"}",
    "1061324018672783360": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:THIS NIGGA<tag> MADE THE WOLVES TRADE JIMMY \ud83d\udc80 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and racial slurs. The presence of the word 'nigger' in the tweet text further supports this classification.\"}",
    "1046387763925389314": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> tried to find a redneck repair but could only find this \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image does not contain any offensive or hateful content. It shows a car with a broken windshield and a broken wiper, which is a common issue that can happen to any vehicle.\"}",
    "1114890343726477312": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:hey<tag> this guy just called you retard \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme that contains offensive language and insults, which can be considered as hateful.\"}",
    "1109625527059574785": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:In my mind: Trump is in Marlago negotiating his surrender to the feds! \ud83d\ude03\ud83d\ude03\ud83d\ude03 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a man in a U.S. Marshal uniform holding another man, suggesting a violent or aggressive act. The tweet text further supports this classification as it implies a humorous scenario involving Trump's surrender to the feds, which is not appropriate or respectful.\"}",
    "1108495901318922241": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:yea nigga im chllin \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which make it a hateful meme.\"}",
    "1036297944067186689": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:American Christianity, redneck style ... \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it promotes negative stereotypes and discrimination against women. The message on the truck's door is offensive and disrespectful towards women.\"}",
    "1060977802185445377": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Lordttttttt women really be in that retard juice \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language towards women, which is considered hateful.\"}",
    "1114427483053592576": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This one nigga just called this lady buffalo bill \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the use of racial slurs and the portrayal of African Americans in a negative light.\"}",
    "1046093985981313027": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Good to see former Hillbilly Hunter Jackson #61 playing today for OBU against ATU!!! #HPRD \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image shows a group of football players on a field, and the tweet text is about a former player playing in a game. It does not contain any hateful content.\"}",
    "1056294725714673664": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Hahaha the fucking ginger cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet contains offensive language and insults, which are considered hateful.\"}",
    "1113954518729883648": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Did this nigga just hit me up asking for money? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is considered hateful.\"}",
    "1114949336608198656": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Ya silly cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text is offensive and disrespectful towards the woman in the image. It is not appropriate to use such language towards others, especially in a public forum.\"}",
    "1043378288335437824": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Goddammit Susan do something!! Useless twat \ud83d\ude02 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language towards the cat named Susan, suggesting that the image is hateful.\"}",
    "1107054836888018944": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This nigga need his head caved in \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains hate speech and racial slurs, which makes it a hateful meme.\"}",
    "1041915681124405250": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> What does that even mean, you trash retard? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults towards the president, suggesting a hateful sentiment towards him.\"}",
    "1109363287773335552": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:White Trash Women Webcam\u00a0Masturbation \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it may contain offensive or discriminatory content towards women. The tweet text further supports this classification as it refers to the woman in the image as 'white trash' and 'webcam masturbation'. This language is disrespectful and disregards the person's dignity, making the image hateful.\"}",
    "1056252190489223168": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag><tag> That's because you're retarded \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which indicates that the image is hateful.\"}",
    "1108432357839826946": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Chief minister of Delhi posts this. What a fu\u00a3&amp;&amp;##g twat \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests that the image is hateful, as it is described as a 'fu\u00a3&amp;##g twat' and the context of the image is related to Delhi. The presence of swastikas and the depiction of a man running away from them further supports the classification of the image as hateful.\"}",
    "1106933170572791814": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Tell \u201csis\u201d that shit look like old penitentiary nigga skin \ud83d\ude2d\ud83d\ude2d \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text is offensive and disrespectful towards women. It is not appropriate to use such language in a public forum.\"}",
    "1061671622850035713": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:CALIBER COMING IN WITH THE ASSIST AND THIS NIGGA NOT EVEN *FAZED*  GOAT\ud83d\udc4f\ud83c\udffe\ud83d\udc4f\ud83c\udffe\ud83d\udc4f\ud83c\udffe\ud83d\udc4f\ud83c\udffe\ud83d\udc4f\ud83c\udffe\ud83d\udc4f\ud83c\udffe\ud83d\udc4f\ud83c\udffe\ud83d\udc4f\ud83c\udffe\ud83d\udc4f\ud83c\udffe\ud83d\udc4f\ud83c\udffe \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and a derogatory term, which suggests that the image is hateful.\"}",
    "1105476182328389632": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:LOVE  MY FAGGOT  LOOKS. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language towards the LGBTQ+ community, which is considered hateful.\"}",
    "1114773299421163520": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> u Hear this? u clown ass disrespectful ass new generation asss nigga \ud83d\udcaf \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and disrespectful comments towards the man in the image, suggesting that it is a hateful meme.\"}",
    "1041783243916369922": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> You done switched your Hulu on me nigger \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racial slurs and is considered hateful.\"}",
    "1064028239545413632": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Some Hillbilly philosophy... \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is a cartoon or comic strip featuring three men in overalls, with one of them holding a corn bread. It does not contain any hateful or offensive content. The tweet text is a humorous commentary on the cartoon, suggesting that it is not meant to be taken seriously.\"}",
    "1044609983340457984": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:nan\nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image depicts a woman being touched by a man, with another man looking on. The woman's shirt is open, and the scene appears to be inappropriate and potentially offensive. The tweet text 'nan' does not provide enough context to determine the classification of the image.\"}",
    "1044734481448361984": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This pic called me a fat pig looking faggot \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, as it appears to be derogatory and disrespectful towards the individual in the picture.\"}",
    "1115274273487249409": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Nigga what \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racial slurs and is offensive. This image is not hateful.\"}",
    "1115970882231517184": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> That one nigga got stuck standing up \ud83d\ude02 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a person in a degrading and offensive manner, using racial slurs and making light of a serious issue.\"}",
    "1108158972425654272": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> love you too bro \ud83d\udcaf\ud83d\udcaf\ud83d\udcaf and We is nigga 4life!!\ud83e\udd1e\ud83c\udffe\ud83d\udcaa\ud83c\udffe \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays two men talking to each other in a negative and offensive manner. The use of the word 'nigga' is considered racist and derogatory, which contributes to the overall hateful nature of the meme.\"}",
    "1110344003952787457": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag> oh look another liebour bigot playing the race card ... remember this Clive ? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a man pointing at a woman, suggesting that she is not a voter. This can be interpreted as a racist or sexist comment, which is offensive and disrespectful.\"}",
    "1105058443164045313": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Wednesday was beef day ku secondary. Then they tell you it's lent no beef on Wednesday. Nigga \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the tweet text, which contains offensive language and discriminatory remarks.\"}",
    "1056649350447878144": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag>.   Perfect example of white TRASH! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a negative stereotype of white people, specifically the president, and it is disrespectful and offensive.\"}",
    "1110228464546676736": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This nigga Allante dawg \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which make the image hateful.\"}",
    "1114593488786448385": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:153 Years Later...\u270a\ud83c\udffb\ud83d\ude20\u270a\ud83c\udffb \ud83d\ude4f\ud83c\udffb\u271d\ufe0f\ud83d\ude4f\ud83c\udffb\u270a\ud83c\udffb\ud83c\uddfa\ud83c\uddf8\u270a\ud83c\udffb #BanIslam #BanSharia #UnitedWeStand #InGodWeTrust \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a collage of photos of women with a quote from Abraham Lincoln. The tweet text contains political and religious statements, which can be considered hateful. The presence of a flag and the reference to the 16th president suggest that the image might be related to a political or historical event. However, the specific content of the tweet text and the context in which the image is being shared can influence the",
    "1114001795049828353": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:i really just poured my heart out this nigga and all he had to say was ok like do y\u2019all know how bad i wanna cry \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests that the image is hateful, as it is described as a 'nigga' and the woman is portrayed in a degrading manner. The use of such language and the context of the image contribute to the classification of it as a hateful meme.\"}",
    "1117476890590220289": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Wall Priest still is a fucking cunt to play against. GG \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language towards the opponent, suggesting a negative attitude towards the game and the opponent.\"}",
    "1043823514824986625": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> she\u2019s like da fuk is this??? can\u2019t wait to twat my mum and dad round the head with it when I buy one\ud83d\ude01 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the man and woman wearing funny glasses and the baby wearing Mickey Mouse ears, which might be perceived as offensive or inappropriate by some people.\"}",
    "1063787933105295361": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> happy birthday faggot i love you no homo uwu \u2764 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and derogatory terms towards the LGBTQ+ community.\"}",
    "1114219392387227648": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:someones a conspiracy theorist \nASSISTANT: {\"Classification\": \"hateful or not hateful\", \"Explaination\": \"The image is a meme that appears to be hateful, as it is making fun of someone's beliefs and opinions. It is not a respectful or constructive way to engage in conversation or debate.\"}",
    "1114967526381953024": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Race Card = Privilege \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a cartoon of a black man with a caption that implies that having a 'race card' is a privilege. This can be considered as a hateful meme as it may be perceived as racist and discriminatory.\"}",
    "1044921583943315457": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Stuff that normally only redneck Americans would wear, but somehow he pulls it off \ud83d\ude29 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful as it portrays a man wearing camouflage clothing and a microphone, which is a combination of elements that might be perceived as offensive or derogatory by some people.\"}",
    "1044240394639298560": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I want her to beat me up and call me a dyke \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests a violent and aggressive attitude towards the woman in the image, which is considered hateful.\"}",
    "1046355875340812290": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I'm really glad that no one has lewded this show yet. Good thing rule 34 isn't too retarded. \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is a collection of cartoon animal characters from the show 'The Canimals Show'. It is not hateful as it is a representation of a popular cartoon show.\"}",
    "1057597012856750080": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Gave another nigga my place. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and racial slurs, which are not appropriate for public display.\"}",
    "1057773157443002368": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:you are going to halloween party and i m here practicing some retard music \ud83c\udf1a\ud83d\ude43 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it uses derogatory language to describe people with disabilities.\"}",
    "1113115934024220672": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:johnny &amp; keepin up his dyke agenda \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it may contain offensive or discriminatory content. The tweet text further supports this classification by suggesting that the person in the image is promoting a 'dyke agenda'.\"}",
    "1114906795976167425": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Lmao boy, don\u2019t I love self-glorification twat. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays women in a negative and objectifying manner. The tweet text further supports this classification as it uses derogatory language to describe the image.\"}",
    "1115346428971429888": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:didnt respond and got blocked literally how retarded can someone be \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and insults towards someone who was blocked on social media.\"}",
    "1114237194984677376": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> \ud83d\ude02\ud83d\ude02 she asked sk i answered \ud83e\udd37\ud83c\udffe\u200d\u2640\ufe0f. These nigga games go both ways.  But... \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it uses racial slurs and derogatory language to make a joke. The tweet text further supports this classification as it uses offensive language and makes light of a serious issue.\"}",
    "1106677224298688512": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:\u201cIf I was a pedo, you\u2019d be safe you fat little ginger cunt.\u201d \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which are indicative of a hateful meme.\"}",
    "1108449905880780801": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:When I say that nigga better make me his priority, this what I mean \ud83e\udd27PERIODT \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image and the tweet text are both hateful memes, as they use offensive language and make inappropriate references.\"}",
    "1044392831933079552": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> That fkn redneck... \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, suggesting that the image is a hateful meme.\"}",
    "1116546424055877633": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> just called that black hole 'a fuzzy picture of a peach ring'. NIGGA!!! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racial slurs and is offensive. The image of the man with dreadlocks and the black shirt might be used to spread such hateful messages.\"}",
    "1114208862385709062": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:RT<tag>: GODDAMN this nigga is a TANK \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is considered hateful.\"}",
    "1058278679959273473": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Good morning tweeps #friday #TeamTrump #BuildTheWall \ud83d\udd34\u26aa\ud83d\udd35 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme that makes fun of illegal immigrants, which can be considered as hateful and offensive.\"}",
    "1054430439799177216": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag> White people didn\u2019t evolve from Africans you twat. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it promotes racism and discrimination by suggesting that white people did not evolve from Africans. The tweet text further supports this classification as it is derogatory and disrespectful towards people of color.\"}",
    "1114899684252844032": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Shut the fuck up , you don\u2019t tell the nigga how to spend his money \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is disrespectful towards the group of people in the image. This classification is based on the negative and disrespectful tone of the tweet.\"}",
    "1114296683913981952": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Wat\u2019s Dyke at Gobowen \u2013 the Heritage\u00a0Board \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is a historical sign describing the Wat's Dyke at Gobowen, which is not a hateful meme.\"}",
    "1061850215337070592": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:NIGGA THIS SHIT RIGHT HERE \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and racial slurs. It is not appropriate to use such language or imagery, especially in a public setting.\"}",
    "1062498227562385413": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:The Full Gallery: \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is a picture of a woman in a blue shirt and tan shorts, posing on a couch. It does not contain any hateful or offensive content.\"}",
    "1108708338274045953": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:and here we see the wild florida nigga in his natural habitat. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the use of racial slurs and the portrayal of a black man in a negative light. The man is holding a sign that says 'Police Lives Matter' while standing in front of a Confederate flag, which further adds to the offensive nature of the scene.\"}",
    "1116392199699218432": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Sis did allat then blocked me \ud83d\ude2d\ud83d\ude02 retarded ass hoe mad cause she couldn\u2019t play snatch a nigga \ud83d\ude02\ud83d\ude02\ud83d\ude02\ud83d\ude02\ud83d\ude02\ud83d\ude02\ud83d\ude02 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet contains offensive language and insults towards a person, which indicates a hateful sentiment.\"}",
    "1114712512501436416": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:We get it nigga damn YOU CANT BE THIS HORNY BRO JESUS CHRIST \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which indicates that the image is hateful.\"}",
    "1115387305534078976": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> the nigger agenda. \ud83d\ude43 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it uses racial slurs and derogatory language to describe the person in the picture.\"}",
    "1108794516771926016": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:My Nigga D Money Hosting At the #HustlersUnlimitedconcert \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is considered hateful.\"}",
    "1114292357069983744": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Obamacare tax penalty if you don't want the wall. #BuildTheWall \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image and the tweet text are hateful memes as they are making fun of the president and his policies, which can be considered offensive and disrespectful.\"}",
    "1116844941152362496": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Fuck ass nigga, nigga said \ud83d\uddff \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and racial slurs. The tweet text further supports this classification as it uses derogatory language towards a specific group of people.\"}",
    "1056536580385636352": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Punches<tag> in the cunt  Whilst screaming \u2018BUSTAH\u2019 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains explicit and offensive language, which is not appropriate for sharing on social media platforms.\"}",
    "1105685738660614145": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Lmaoo hell yh That\u2019s why you my nigga period\ud83d\ude2b\ud83d\udc4f\ud83c\udffe \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the use of racial slurs and the man's facial expression, which appears aggressive and threatening.\"}",
    "1105623551124664320": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:meanwhile my falcons start free agency by signing a nigga who was protecting eli we paying ex giant bums \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial stereotypes, which make it a hateful meme.\"}",
    "1114578578568548352": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Why people always pissed me off and then it's my fault I hate dumb argue cunt people \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and negative sentiment towards people, indicating a hateful meme.\"}",
    "1113114611979636737": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Don\u2019t box me together with that nigga \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it uses racial slurs and is disrespectful towards a specific group of people.\"}",
    "1115279069116018689": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Nothing gets between a nigga and chicken \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image and the tweet text are both hateful and offensive, using racial slurs and promoting negative stereotypes.\"}",
    "1113953653021261824": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:ever since i called that dude a dumbass twitter won't let me go after any other retarded tweets smh \nASSISTANT: {\"Classification\": \"hateful or not hateful\", \"Explaination\": \"The image is not hateful. It is a humorous conversation between two people on Twitter, with one person asking the other if they think the man is working or not. The tweet text does not contain any hateful language or content.\"}",
    "1114943161443311616": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:A \"da boiz\" nigga. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a woman in a negative light, using offensive language and making derogatory comments about her appearance.\"}",
    "1109482629173313536": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Baby dyke twitter would be mad at me cuz everytime I hear this song  I gotta throw that ass in a circle \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image and the tweet text suggest that the image is a hateful meme, as it portrays a group of people in a negative light and the tweet text reinforces this sentiment by making a derogatory comment about the group.\"}",
    "1107983134723854336": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> You asking for it Nigga. Don\u2019t say I ain\u2019t told y\u2019all so \ud83d\ude2d\ud83d\ude2d\ud83d\ude02 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a woman in a negative light, using racial slurs and making fun of her appearance. This is not a respectful or appropriate way to depict someone.\"}",
    "1113536767326674945": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:i know I slander them hoes daily but a nigga wanna play in the snow. Who gone stop me \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and slander, which indicates a hateful sentiment. The image of two men walking down a hallway does not seem to be related to the content of the tweet.\"}",
    "1034857570186473474": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Race card on the field \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image portrays two elderly women, one of whom is holding a baseball bat, and the other is holding a baseball glove. The scene is described as a 'race card on the field,' which implies that the image is intended to be racist. The presence of the baseball bat and glove, along with the women's attire, suggests that the image is meant to be humorous or lightheart",
    "1115004766256603136": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:who else wants to know why this nigga came in wanting all the smoke from everyone lol. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet contains derogatory language and racial slurs, indicating a hateful sentiment towards the person in the image.\"}",
    "1107783348750036992": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Better than me nigga part his lips to me off this app and on the dead family it's \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image and the tweet text suggest a hateful sentiment towards African Americans. The man in the image is wearing a black shirt and appears to be looking at the camera, while the tweet text uses derogatory language towards African Americans. This combination of elements indicates a hateful meme.\"}",
    "1109167936479080449": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Teen lesbian eats\u00a0cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image depicts two women engaging in a sexual act, which can be considered inappropriate and offensive to some people. The tweet text further emphasizes the explicit nature of the scene, making it a potentially hateful meme.\"}",
    "1105085611105505280": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:why is cunny such a fucking cunt jesus \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which suggests that the image is a hateful meme.\"}",
    "1106822209803296768": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag>  #BuildTheWall #MAGA  Food for thought. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a baby pointing at the American flag with a caption that suggests building a wall and supporting a political agenda. This is considered hateful as it promotes divisive and controversial ideas.\"}",
    "1114418078442332160": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:But to be very fucking honest i really did this when i'm on my dyke mode   \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and derogatory terms, suggesting a hateful sentiment.\"}",
    "1107351159017213952": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Me whenever I find who hit ma nigga DD last night \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and references to violence, which indicates a hateful sentiment.\"}",
    "1114228052324696069": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Democrats always miss play the race card. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a political cartoon that uses a racial stereotype to make a point about the use of the race card by Democrats. It is considered hateful as it perpetuates harmful stereotypes and can be offensive to some people.\"}",
    "1108221977247002625": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> HE REALLY THOUGHT HE HAD IT \ud83d\ude02\ud83d\ude02\ud83d\ude02\ud83d\ude02\ud83d\ude02\ud83d\ude02\ud83d\ude02 trash ass nigga lmfaooo \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a negative stereotype of a black man playing basketball.\"}",
    "1106770104300302337": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> with her short nigga \ud83d\udc80 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a negative stereotype of a black person. The tweet text further supports this classification as it uses offensive language.\"}",
    "1107504723949731840": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Nigga stressed LMAOOO \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and racial slurs.\"}",
    "1115385264401207297": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Foxx is out of viable debate facts and now, not surprisingly, playing the race card. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it is making a joke about a woman's appearance and her age, which is disrespectful and offensive.\"}",
    "1053390427661983754": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> The coupe is retarded(skrrrrrt!) #SICKOMODE \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, suggesting that the image is a hateful meme.\"}",
    "1113912639246094336": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Maaaaan fuck that nigga obito starting war over a female and shit he a whole ass bitc-  Obito : \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is considered hateful.\"}",
    "1109225989597474818": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Take my Twitter cunt. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language in the tweet text.\"}",
    "1113031822579920896": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:how did this cunt get past ad blocker \ud83d\ude21 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or derogatory content. The tweet text also supports this classification, as it contains strong language and appears to be directed towards someone or something.\"}",
    "1117204201426255875": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Goodnight except this cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, suggesting that the image might be a hateful meme.\"}",
    "1113083313269497859": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Bodybuilders would workout all day and everyday day to get killed by a nigga that looks like this \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and promotes negative stereotypes, making it a hateful meme.\"}",
    "1105697351874826240": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> The nigger jumped out \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains a racial slur and is disrespectful towards the African American community.\"}",
    "1109081477160013825": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> my nigga is really into kpop \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, suggesting that the image might be a hateful meme.\"}",
    "1107278616193351683": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:MY CUNT IS A... \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image and the tweet text are both hateful and offensive, promoting explicit and inappropriate content.\"}",
    "1114414751050883073": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:\ud83d\udc1d: Barry look at this nigga wearin yellow  Barry: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text further supports this classification as it uses derogatory language to describe the man in the image.\"}",
    "1113950823577522177": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Yo Nigga is My Nigga on weekends and On paydays!! \ud83d\udcaf\ud83e\udd11 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is considered hateful.\"}",
    "1113921773664444417": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:MAFFIOSO BROAD  WISE GUY/CUNT  === #Nancy #PELOSI \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and insults towards Nancy Pelosi.\"}",
    "1105110408795471872": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:\u201cIM WITH THE SHITS MY NIGGA\u201d \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racist slurs, which make it a hateful meme.\"}",
    "1113114757253423104": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Death threats from \u303d\ufe0fY fine ass Nigga always make me brick. \ud83d\ude3b\ud83e\udd24 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and a threat of violence.\"}",
    "1109967016679489536": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag><tag> BTFO, faggot \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme that is hateful towards the LGBTQ+ community, as it uses derogatory language to describe them.\"}",
    "1109593402000191493": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> I\u2019m done with u my nigga that\u2019s my friend he told me everything stfu begger \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which are indicative of a hateful sentiment.\"}",
    "1062900302934765568": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Don\u2019t even bother sis \ud83d\ude2a the cunt can just unfollow us then \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is considered hateful.\"}",
    "1106968180872892416": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Matt Ritchie u cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language towards Matt Ritchie, which indicates a hateful sentiment.\"}",
    "1113954426438455306": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:he hates when i eat in the bed kzuxdhdhhh this nigga is PETTY \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and a negative sentiment towards the person being referred to. This suggests that the image is a hateful meme.\"}",
    "1046714201111236608": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Jason Van Dyke Trial: Defense testimony to resume Monday: \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is not hateful as it is a news article about the trial of Officer Jason Van Dyke. It does not contain any offensive or hateful content.\"}",
    "1107446368170315779": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:baam ready to zip that nigga up \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme with a man's hand giving a thumbs up, and the text is a racial slur. This is considered hateful as it promotes discrimination and racism.\"}",
    "1107049548126609410": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:\"I'm a dyke i have you fighting for your wife.\" \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language towards the LGBTQ+ community, which is considered hateful.\"}",
    "1110365303752572928": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:When I Pop Out With A Nigga And A Ring Ion Wanna Hear NOTHING ! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image and the tweet text are both hateful memes, as they use offensive language and make derogatory comments about a specific group of people.\"}",
    "1105050787607007234": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> My nigga typing these laugh emojis like \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the use of racial slurs and offensive language in the tweet text.\"}",
    "1116078034518532096": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:They put my nigga tuck in red dead \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains racist language and imagery, which is offensive and inappropriate.\"}",
    "1057665167390060544": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> \"Rube-bait.\" \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a woman making a disgusting face and the text 'Yes!' is placed above her, which can be interpreted as a derogatory comment towards women. The tweet text further supports this classification as it uses offensive language.\"}",
    "1056327212239077376": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Come and slide through to my nigga release party. Event starts at 8pm <tag> \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and promotes a release party for a rapper. This is considered hateful as it uses derogatory language and may be discriminatory towards certain individuals or groups.\"}",
    "1113126524377489409": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> You mean Biggie this nigga said Ray Charles \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which indicates that the image is hateful.\"}",
    "1109068467230121985": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> sort out your hill billy husband cunt blocked me for no reason no chin hick #fuckthebrownes \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet contains offensive language and insults towards the person named Travis Brown. This suggests that the image is a hateful meme.\"}",
    "1109433567443144705": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Another TWAT \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains content that is offensive or discriminatory towards a particular group or individual.\"}",
    "1107998959547662342": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Madara washes entire legions of Shinobi by himself. When he punted a nigga head first into sand \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and content that is not appropriate for public consumption.\"}",
    "1114558776407883776": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Hahahaha doesn't get much better when this cunt costs you the game \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults towards the man in the image, suggesting that the image is a hateful meme.\"}",
    "1113832432023756800": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Somewhat Old but this nigga kodak a clown \ud83d\ude02\ud83d\udc80\ud83d\udc80\ud83d\ude02\ud83d\ude02\ud83d\ude2d\ud83d\ude2d \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the use of racial slurs and derogatory language in the tweet text.\"}",
    "1109903554917982208": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:10 year old me listening to bedrock and hearing \u201cand I got her nigga.....GROCERY BAG\u201d for the first time \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the use of racial slurs in the tweet text, which is inappropriate and offensive.\"}",
    "1035197214497427456": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Bloody ignorant post twat. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the skull and crossbones symbol, which is often associated with danger or death. The tweet text also adds to the negative sentiment of the image.\"}",
    "1053880654163820544": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> There u go faggot \ud83d\ude02\ud83d\ude02 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language towards the LGBTQ+ community, which is considered hateful.\"}",
    "1115715807894487052": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Lil nigga gotta have drip like me \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language and is considered hateful.\"}",
    "1051096158100213760": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Tell off??? How was that \"telling them off\" You overdramatic retard \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text is offensive and disrespectful towards the person in the image, suggesting that they are overdramatic and a retard. This classification is based on the negative and disrespectful language used in the tweet.\"}",
    "1115691095135019009": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I took this BITCH-ASS Nigga phone\ud83d\udcf1\ud83e\udd23\ud83c\udfc3\ud83c\udffe\u200d\u2642\ufe0f\ud83d\udca8 #elevatorchallenge \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it may contain offensive or discriminatory content. The tweet text further supports this classification as it contains derogatory language and references to race.\"}",
    "1108249452165386240": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> was watching some old trailer trash episodes then i noticed your name lol wow crazy! \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is a cartoon-like representation of a group of people, and the tweet text does not contain any hateful or offensive language.\"}",
    "1105644795152736256": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:If you with the squad I\u2019ll give you my heart Lil nigga I mean it \ud83d\ude02\ud83d\ude02\ud83c\udfa5\ud83d\udd7a\ud83c\udffe \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial stereotypes, which make it a hateful meme.\"}",
    "1105171260110241792": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Did this nigga foot popped out? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language and is considered hateful.\"}",
    "1108259350018088960": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Real nigga comin through, everybody move back \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a man in a black shirt with a bottle of alcohol, making a funny face and smiling. The tweet text further supports the classification as it uses offensive language.\"}",
    "1107741073789456384": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:The only nigga in the work lazier than me in a Sunday \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racial slurs and is offensive. The image of a man standing next to a mural of a character from a popular cartoon show is not related to the hateful content of the tweet.\"}",
    "1108711715431174144": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:real street nigga music . \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image and the tweet text suggest a negative and offensive portrayal of African Americans, which is considered hateful. The use of the term 'street nigga' and the reference to 'real street nigga music' further reinforces this classification.\"}",
    "1115682151360495616": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Wtf is this game cunt was doin the worm over the fence hahaaaa #PS4share  \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, likely due to the offensive language used in the tweet text.\"}",
    "1114152936886743040": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Yeah <tag> is gone gone gone my nigga \ud83d\udc10 \ud83d\udc4f \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which indicates a hateful sentiment.\"}",
    "1113744922396459008": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Plus this isn\u2019t me dumbass nigga this is the guy I @ retard \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, and the tweet text further supports this classification as it contains offensive language.\"}",
    "1114016010208796677": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I kept eye contact with the pretty cashier at Chick-fil-a tonight.   I really am that nigga huh? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and imagery, such as the man making a hand gesture and the tweet text referring to a racial slur.\"}",
    "1113638462010339329": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:No one gave a fuck she said nigga in every verse KSJSKDJKDK \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it is using a racial slur in the lyrics of the song being played.\"}",
    "1106567909571248132": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I jus gtta call from da big homie , word round town say uh nigga gtta brick on me \ud83e\udd10\ud83d\udc94\ud83d\udde3 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image and the tweet text suggest that the content is hateful, as it uses derogatory language and promotes negative stereotypes.\"}",
    "1060969288515895296": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> That is another episode of racist white trash brought to you by tRump the turd. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the racist and offensive content, as well as the association with the president.\"}",
    "1105846526515933184": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> So, I ask you clones... is this Leatherneck?  Or is it Lieutenant Redneck? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text is making a joke about the license plate, which can be considered as hateful or offensive.\"}",
    "1109696927447371776": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> People like you will help get the little fairy faggot out of trouble. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language and insults towards the man in the image, suggesting that the image is a hateful meme.\"}",
    "1108459501857005570": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Nice try faggot \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it is a hand holding a piece of paper with a weight measurement, and the tweet text is derogatory towards the person holding the paper.\"}",
    "1105559226615779329": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:shut up you old fat bitter cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or derogatory content towards the person depicted.\"}",
    "1107872441685237761": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Redneck Pregnant #pregnant #preggo #embarazada \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a pregnant woman in a negative light, using offensive language such as 'redneck' and 'pregnant'. This type of content is not appropriate and can be harmful to the individuals involved.\"}",
    "1113530690879070208": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> I thought we cancelled April fools... somebody get this nigga off his phone\ud83e\udd28 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which indicates that the image is a hateful meme.\"}",
    "1106562616292532225": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Who making an F nigga boy<tag> \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which are considered hateful.\"}",
    "1116429017547247618": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:im a pretty raw bitch with a real nigga mind. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and derogatory terms, which suggests that the image is a hateful meme.\"}",
    "1114585485895139329": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:\u201cNobody wanna stand in front the judge nigga\u201d Let that sink in.. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which are indicative of a hateful meme.\"}",
    "1115819198968737792": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:NIGGA IM TRYNA BE EMO AND YANJUNS BIG HEAD DOES THIS. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racial slurs and is offensive. It is not appropriate to use such language, and it is considered hateful.\"}",
    "1108144451715825664": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:SpacemannFinn now streaming Immortal Redneck \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is a screenshot of a video game, not a hateful meme. The man in the image is wearing glasses and appears to be engaged in a video game, which is a common and non-hateful activity.\"}",
    "1109280677646819330": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Niggas think I be pressed about a screenshot in a game nigga tighten up \ud83d\ude02\ud83d\ude02 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language towards African Americans, which is considered hateful.\"}",
    "1113876523377930240": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This nigga can\u2019t get nothing done! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language and racist slurs, which are considered hateful. The image of the president giving a speech is being used to spread hate and discrimination.\"}",
    "1109826367795818503": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Call a shooter, yeah I gotta blast nigga \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image and the tweet text suggest a hateful sentiment towards a specific group of people. The use of derogatory language and the reference to violence indicate a negative and discriminatory attitude.\"}",
    "1106567011994222593": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:when i see you i surrender unconditional love \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is not hateful as it shows a young man smiling and posing for the camera. The tweet text also suggests a positive sentiment towards the person in the image.\"}",
    "1116368310608621568": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag> Your a retard G Jacobson hahahaha \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text is derogatory and insulting, suggesting that the image is a hateful meme.\"}",
    "1062044914588905472": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:nan\nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the explicit nature of the content, including the woman's nudity and the use of a vibrator. The tweet text 'nan' does not provide enough context to determine the classification of the image.\"}",
    "1105266863813083136": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Nigga WHAT\ud83d\ude2f\ud83d\ude02\ud83d\ude02\ud83d\ude02\ud83d\ude02 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it uses racial slurs and makes light of a serious issue.\"}",
    "1116308894781980673": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Have a nigga putting holes in his room door real shit\ud83e\udd23\ud83e\udd23\ud83e\udd23 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, likely due to the use of offensive language in the tweet text.\"}",
    "1105571156906704896": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag> There's always a nigga in a blazer trying to \"fix\" shit. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the racist language used in the tweet text, which is displayed on the screen.\"}",
    "1113478212166795264": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Nigga... \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and imagery, such as the phrase 'fuck them kids' and the reference to a racial slur. This type of content is not appropriate and should not be shared.\"}",
    "1115278386379681792": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Build the Wall! Honor Angel Families! #BuildTheWall #AngelFamilies \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a collage of photos of people, including a woman and a police officer, with a caption that is critical of illegal immigrants. The tweet text also supports the idea of building a wall and honoring Angel Families, which are families of victims of illegal aliens. This suggests that the image is hateful and promotes negative sentiment towards illegal immigrants.\"}",
    "1116446775865270272": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This is NASTY NASTY \ud83d\ude37\ud83d\ude02 Im gettin my nigga pedicure fuck that shit \ud83e\udd22\ud83d\ude02\ud83d\udc80 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the use of derogatory language and the depiction of a woman in a car, which is a common trope for misogynistic content.\"}",
    "1105207208470409216": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> kill all no surrender. good terrorist is dead terrorist. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests a violent and aggressive sentiment towards terrorists, which is considered hateful. The image of the smiling man with the 1-800-223-8255 phone number might be used to spread this message, making it a hateful meme.\"}",
    "1108496294023258114": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> This nigga talks like Boomhauer from King of the Hill. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme of a character from a cartoon, and the tweet text is derogatory and disrespectful towards a specific group of people. This is considered hateful and offensive.\"}",
    "1110523061491695617": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Don\u2019t do that nigga \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains a racial slur, which is considered hateful. The image of a person in blue pants with a racial slur in the tweet text is likely to be associated with this hateful sentiment.\"}",
    "1114342393304756229": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Like nigga think for yourself \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racist remarks, which make it a hateful meme.\"}",
    "1110190221239435264": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> You\u2019re a sad cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which indicates that the image is a hateful meme.\"}",
    "1109053476280127488": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:my nigga<tag> \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which are considered hateful. The image of a man carrying a child while wearing a hat and shorts also adds to the negative and offensive nature of the content.\"}",
    "1105079767316000768": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Ah, just another \"Feminazi\" \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme that is hateful towards women, as it portrays a cheerleader with a message that implies women are sick. The tweet text further supports this classification as it uses the term 'Feminazi', which is a derogatory term for feminists.\"}",
    "1110340935274192902": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I was down but you see I\u2019m up now nigga head high cause I\u2019m holding up my crown nigga \ud83d\udca3 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a woman in a leather outfit, which is often associated with BDSM culture, and the tweet text contains derogatory language towards the black community.\"}",
    "1113477438200119301": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:first they made that suicide squad nigga now they tryna make the joker black \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image and the tweet text contain racist and offensive language, which is considered hateful. The tweet text also implies that the Joker character from the movie 'The Dark Knight' should be played by a black actor, which is further indicative of a hateful sentiment.\"}",
    "1115099676691316737": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:BECKY LYNCH TIME NIGGA \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which are indicative of a hateful meme.\"}",
    "1109999009656197121": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Fuck no nigga \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is considered hateful.\"}",
    "1115906801378254855": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> The race card where it's not needed. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme that is considered hateful due to its content and the use of the word 'stop it' which can be interpreted as a call to stop a person of color from speaking or expressing their opinions.\"}",
    "1107093509578915840": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I wish more niggas understood how raw this man kefka was man.   This nigga was no joke. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which indicates a hateful sentiment towards a specific group of people.\"}",
    "1105540747900698624": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:That nigga Hard \ud83d\ude02\ud83d\ude02\ud83d\ude02 wtf<tag> \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image and the tweet text contain offensive language and racial slurs, which are considered hateful.\"}",
    "1107758362773590018": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Actually, you\u2019re a cunt! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text is hateful and disrespectful towards the woman in the image.\"}",
    "1046978446042308609": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Shits retarded!! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, suggesting that the image is hateful.\"}",
    "1113862313176702976": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:nan\nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content.\"}",
    "1049904649690669056": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:JoJo Siwa when she see\u2019s a faggot. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a negative and derogatory attitude towards the LGBTQ+ community. The tweet text further supports this classification as it uses derogatory language to describe the LGBTQ+ community.\"}",
    "1115009499419508736": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:yes my nigga \ud83d\ude02 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language and is considered hateful.\"}",
    "1041689833268236288": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:PinkNews: Why I'm not ashamed to be a faggot.   \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language towards the LGBTQ+ community, which is considered hateful.\"}",
    "1108801390657327104": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:this nigga a hoe \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the use of derogatory language in the tweet text, which is offensive and disrespectful towards the individual in the picture.\"}",
    "1116321330134245377": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I Still Got My Follow From Nipsey This My Real Nigga Stamp For Life \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and references to Nipsey Hussle, suggesting a negative sentiment towards him.\"}",
    "1107023965623599104": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> taehyung said nigger rights now and whites electric chair !! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racist remarks, which make the image hateful.\"}",
    "1057710877519110144": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Happy Halloween, here's a pic of a dying looking cunt \u2620 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or inappropriate content.\"}",
    "1113468290100232194": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Send that nigga to jail \ud83d\ude02 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is considered hateful.\"}",
    "1108459290598277120": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Her:\ud83d\udc40\ud83d\udc40\ud83d\ude2c\ud83e\udd75  Him: LET ME DRIVE THAT TWAT FR DONT PLAY **Kodak Black voice** \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme featuring a man in a bathing suit with a gold chain, and it is captioned with a racial slur. This is considered hateful and offensive.\"}",
    "1109150684832808960": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I still can\u2019t believe you for this my nigga<tag> \ud83e\udd26\ud83c\udffe\u200d\u2642\ufe0f \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language and is considered hateful.\"}",
    "1115003238678507521": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Bernie is as corrupt as bush nazi drug lord!  what is its appeal to young retarded Americans? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains a reference to a political figure, Bernie Sanders, and implies that he is corrupt and appealing only to young, retarded Americans. This is not a respectful or constructive way to express political opinions and can be considered offensive.\"}",
    "1043435558809165825": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> needs to fix the troops they kinda retarded \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults towards the game, suggesting a negative attitude towards the game.\"}",
    "1114950581150519296": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:i don\u2019t know why i thought that Luke w*lth*m nigga was gonna be cute,,, i looked through his twitter and well \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the presence of a woman in a black shirt serving food to a man who is described as a 'nigga' in the tweet text. This language is considered offensive and racist, which contributes to the negative perception of the image.\"}",
    "1108863001959022594": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Nobody wants a friendly ass nigga. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is considered hateful.\"}",
    "1110399147075469312": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:It\u2019s wrong to say pig but it\u2019s cool to say nigga.. bet \ud83d\udc40 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it uses racial slurs and promotes negative stereotypes.\"}",
    "1116665181113913346": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Is Mercury in retrograde again that cunt!? Why do I feel like this \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults towards the woman in the image, suggesting a hateful sentiment towards her.\"}",
    "1107492647030190081": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Nigga blocked me so fast \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image and the tweet text contain offensive language and racial slurs, which are considered hateful. The image shows a man wearing a red bandana and the tweet text contains a racial slur. This content is not appropriate and should not be shared.\"}",
    "1107416507850674178": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Don\u2019t disrespect<tag>  \ud83d\udcaf\ud83d\udcaa\ud83c\udffe my nigga hardbody \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme that disrespects and demeans a person, which is considered hateful.\"}",
    "1113178488213827586": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:If you didnt see that cunt's tweet.This is what it was... \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or derogatory content.\"}",
    "1105682550486454272": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Damn this nigga must really want me \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which indicates that the image is hateful.\"}",
    "1051141609780387840": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:u actual faggot \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language towards the person in the image, suggesting that the image is hateful.\"}",
    "1115271343354859520": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag> \u201cFine<tag> two weeks\u2019 wages for being a twat\u201d \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which suggests that the image is hateful.\"}",
    "1053881447797395457": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:PUSS ASS NIGGA \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which make it a hateful meme.\"}",
    "1106694080359288832": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:i\u2019m Dyke \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it is derogatory towards the LGBTQ+ community.\"}",
    "1110200673851895808": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:her: \u201ci got a new nigga\u201d   gang: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language and racist remarks, which are considered hateful. The image of two men fighting in a public area also adds to the negative and aggressive atmosphere of the scene.\"}",
    "1110008978593980417": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Nigga we made it \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racial slurs and is offensive. This image is a hateful meme.\"}",
    "1116330262575681536": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> One thing I'm proud of is I didn't hear one person say nigga \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image does not contain any explicit or offensive language or imagery, and the man appears to be dressed professionally in a suit and tie, suggesting a formal or business setting.\"}",
    "1114978520529137664": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:As always cuz ain't do stupid retarded things \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content.\"}",
    "1114581067757948929": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Ho ass nigga, keep it that way with yo lil fan pictures \ud83d\ude29 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the use of racial slurs and derogatory language in the tweet text.\"}",
    "1107422900624097280": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Nigga you lost. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racial slurs and is offensive. This image is a hateful meme.\"}",
    "1053484126420951041": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:my nigga joon is bald \ud83d\ude30 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is considered hateful.\"}",
    "1105385922671988736": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:S/o to this nigga\ud83d\udc47\ud83c\udffd \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and imagery, such as the word 'nigga' and the reference to a 'nigger center'.\"}",
    "1113540130948681728": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:When your nigga cheat again with a hoe that looks like an animal \ud83d\ude12 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and racial stereotypes.\"}",
    "1105621285655203845": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This nigga went to the BROWNS?!?! Of all places?! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racial slurs and is considered hateful.\"}",
    "1045020044747567106": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> pathetic Russiaphobic slant ignoring US meddling in foreign elections<tag> do your research twat \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a woman in an orange jacket with a police car in the background, which is a reference to Russia. The tweet text further supports this classification as it is derogatory and disrespectful towards Russia.\"}",
    "1064043039708958720": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:&gt;I'm too retarded to define facsism.. HURR DURR I MUST BLOCC LMAO \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, and the tweet text further supports this classification as it appears to be derogatory and offensive.\"}",
    "1108390879218335750": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Never surrender??? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains a message that encourages people to not surrender, which can be perceived as aggressive and harmful.\"}",
    "1107033766239846400": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Nigga im damn near in this party rating a whole ass salad. #OrganicGang \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racial slurs and is offensive. This image is not hateful.\"}",
    "1113006991302111232": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag> It was an April fools joke you fucking retard \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it is a fake profile picture of a person with a snake on their head, and the tweet text is derogatory and insulting towards the person who set up the fake profile.\"}",
    "1105065429645443072": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Dog cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and imagery, such as the word 'cunt' and the heart-shaped symbols with negative numbers. This type of content is not appropriate and can be harmful to individuals who view it.\"}",
    "1105684080203612160": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Nah you sit lil nigga \ud83d\ude24 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language and is considered hateful.\"}",
    "1107941609159696385": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Imagine being called a nigga by your own partner who happens to be white <tag> \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racial slurs and is considered hateful. The image of a man and a woman embracing is not related to the hateful content and is not the main focus of the tweet.\"}",
    "1114054631712329729": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Um, a redneck just crushed my hip on BitLife! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests that the person is experiencing an unpleasant situation in the game, which could be interpreted as a hateful meme.\"}",
    "1105299637316083712": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Shout out my Nigga<tag> for blessing so much!!!! Who hungry?! I can\u2019t eat all diz :( \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is considered hateful.\"}",
    "1113468889529241600": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> we have these bois, literally translates to \"nigger kisses\" \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the use of the word 'bois' which is a derogatory term for black people. The tweet text further supports this classification as it translates to 'nigger kisses' which is a racist and offensive phrase.\"}",
    "1108432039085334531": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:a nigga gotta do what a nigga gotta do \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racial slurs and is offensive. This image is not hateful.\"}",
    "1106651669620801537": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:FUCK SAKEJDKSK HATE THAT SO MUCH I LOOK LIKE A FULL ON TWAT \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and negative sentiment towards the image, suggesting that it is a hateful meme.\"}",
    "1105191705475719168": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This nigga ass taste so damn good \ud83d\udc45\ud83d\udca6 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a person in a degrading and offensive manner, using racial slurs and objectifying language.\"}",
    "1114333336674152448": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Full Video: \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is a provocative and erotic photo of a woman, but it does not contain any hate-filled content or messages.\"}",
    "1108877238496313344": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> LETS GO NIGGA \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text is racist and offensive, which makes the image hateful.\"}",
    "1109293562745810944": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Nigga you bit the orange? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racial slurs and is offensive. The image of a group of people on a subway train is being used to spread hate and discrimination.\"}",
    "1108067550364139520": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This nigga is a GOT dragon and a long lost Hitler son. Very odd crossover but they go together \ud83d\udc80 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the racist and offensive language used in the tweet text, which is displayed on the wall behind the man speaking into the microphone.\"}",
    "1105483190209314817": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Dawg they said that nigga went to Davey Jones locker I\u2019m CRYING \ud83d\ude02\ud83d\ude02\ud83d\ude02\ud83d\ude02\ud83d\ude02\ud83d\ude02\ud83d\ude02\ud83d\ude02\ud83d\ude02 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet contains racial slurs and is offensive. This image is not hateful.\"}",
    "1050742123031605248": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:White Trash Bash? Yeah you better believe I\u2019m going all out #1stplace #bigfanofcostumecontests \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it may contain offensive or derogatory content. The woman in the image is wearing a cowboy hat and holding a doll, which may not be considered as hateful content. However, the tweet text suggests that the image could be interpreted as hateful, depending on the viewer's perspective.\"}",
    "1043612836390477824": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:sad news the dkdynamite anime faggot tweet has been deleted \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme of a sad Spongebob with the words 'Spongebob will be cancelled on January 28, 2014' written below. This is considered a hateful meme as it is making fun of a popular character and suggesting that it will be cancelled, which can be perceived as an attack on the character and its fans.\"}",
    "1113512893394378752": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> THAT'S BECAUSE           #BuildTheWall #HumanTrafficking #Pedogate #PizzaGate #Trump2020 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it is associated with controversial topics such as human trafficking, pedogate, and pizzagate. These topics are often linked to conspiracy theories and are considered offensive by many people.\"}",
    "1116473574011953152": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:When Blac Sam said \u201cIf I die today I know the set proud nigga!\u201d Yep. That took me out man. \ud83c\udfc1\ud83d\udd35 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it may contain offensive or discriminatory content. The tweet text also supports this classification as it references a controversial statement by a rapper.\"}",
    "1105882577028739073": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Nigga I just ordered Chinese and that shit came in 16 minutes...16 ya hear me ? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racial slurs and is offensive, which makes it a hateful meme.\"}",
    "1055171395049738241": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Posting #FalseFlags.  3/?  #BuildTheWall\ud83d\udc77\ud83c\udffb #TheGreatAwakening\u23f0 #MAGA\ud83c\uddfa\ud83c\uddf8 #qanon\ud83d\udd75\ud83c\udffb #Trump2020\ud83c\udfc6 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image shows two people dressed in white hoods and masks, holding signs with hateful messages. The tweet text also contains hateful hashtags, such as #FalseFlags, #BuildTheWall, #TheGreatAwakening, #MAGA, #qanon, and #Trump2020. These hashtags suggest that the image is promoting hateful r",
    "1117133695088058368": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Any cunt got the other half of these  #mcdonaldsmonopoly #McDonalds #monopolymonday \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is considered hateful.\"}",
    "1109933338104684545": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:*That nigga from SpongeBob*  \u201cMY EYES!\u201d \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it uses offensive language and makes fun of a person's appearance, which is disrespectful and discriminatory.\"}",
    "1106950364195102721": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:What kind of hoe ass nigga made this \ud83e\udd15 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, suggesting that the image is a hateful meme.\"}",
    "1108577527046524928": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Didn't I tell yall I was gone get this nigga for saying the N word??? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and suggests violence against a person, indicating a hateful sentiment.\"}",
    "1109829807846682624": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:this whole time y\u2019all been clowning John Cena, this nigga was actually spitting bars \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests that the image is a hateful meme, as it is described as a 'hateful' John Cena meme. The image features a WWE Championship belt with John Cena's name on it, which could be perceived as a negative portrayal of John Cena by some people.\"}",
    "1110279374337699846": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This nigga is a fucking coon \ud83e\udd26\ud83c\udffd\u200d\u2642\ufe0f\ud83e\udd26\ud83c\udffd\u200d\u2642\ufe0f\ud83e\udd26\ud83c\udffd\u200d\u2642\ufe0f\ud83e\udd26\ud83c\udffd\u200d\u2642\ufe0f \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which are considered hateful.\"}",
    "1044302182013644801": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> I memba when \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is a cartoon of a person holding a bunch of grapes, which is not a hateful meme. The tweet text does not contain any hateful content.\"}",
    "1114996883326472193": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> My nigga I read this in my head and I said chop! \ud83e\udd26\ud83c\udffd\u200d\u2640\ufe0f \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests a negative and offensive sentiment towards the image, which is considered hateful.\"}",
    "1050578466041683968": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:She\u2019s like \u201cYes! We really got this niggER \ud83d\ude01\u201d \ud83e\udd26\ud83c\udffd\u200d\u2642\ufe0f \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racist remarks, which make the image hateful.\"}",
    "1110139196335894528": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Awww bra let a nigger flourish. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains racist language and imagery, which is inappropriate and offensive.\"}",
    "1105127708395216896": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:will not get over how pretty she is.  im nothing but a dyke \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language towards the woman in the image, suggesting that she is only attractive to the speaker and that they are a lesbian. This is considered hateful as it implies a negative attitude towards the woman and her appearance.\"}",
    "1046264216951316480": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This deaf depressed retard<tag> has an ego off this RNG shit and can barely build...Trash at COD&amp;Fort \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, likely due to the negative language used to describe the person playing the game.\"}",
    "1115074753247756289": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Happy Birthday chief. Have a great day you cunt. \ud83c\udf89\ud83c\udf89\ud83c\udf89\ud83c\udf89\ud83c\udf7a\ud83c\udf7a\ud83c\udf7a\ud83e\udd43\ud83e\udd43\ud83e\udd43 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, making it a hateful meme.\"}",
    "1044208726704615425": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Breaking News: Ireland confirms that Piers Morgan is still a Twat. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it is a picture of a man with a caption that insults and degrades the person depicted. The tweet text further supports this classification as it confirms that the person is still considered a 'twat' by the author.\"}",
    "1116654455502594053": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:JIMIN IN HOME NIGGA \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racist slurs, which make the image hateful.\"}",
    "1106675018828865543": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Niggas pillow talking i cant stand that , nigga stop talking where your bands at \u2049\ufe0f \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language towards African Americans, which is considered hateful. The image of a smiling man holding a cup in front of a sign is unrelated to the hateful content of the tweet.\"}",
    "1034900943811227648": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Got called a nigger made the whole team leave lmaoooo ain\u2019t shit changed !!<tag> \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racial slurs and insults, which are considered hateful. The image of the video game screen with the message 'Got called a nigger made the whole team leave lmaoooo ain\u2019t shit changed!!!' further supports the classification as hateful.\"}",
    "1109116701554151425": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Faggot \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it uses a derogatory term to describe the person in the picture.\"}",
    "1060867875253174272": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:\u201cFuck that. Call him a Nigger\u201d \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racial slurs, which are considered hateful.\"}",
    "1108480618038546432": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Me every time they keep saying faggot on Masterchef \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful as it is a meme that uses derogatory language to mock a person's appearance, specifically their hair and outfit.\"}",
    "1116509137855221761": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Revs is the most random and out of pocket nigga in 2 clan \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which indicates a hateful sentiment.\"}",
    "1056965472359407618": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:There u fucking goyour little weezy cunt haha<tag> \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image and the tweet text contain offensive language and insults, which are considered hateful.\"}",
    "1108021986272391168": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Ahh buck breaking. This is what u call a bitch made nigga \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language and is considered hateful.\"}",
    "1061014133649391623": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Who let the stupid cunt out...? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a woman with glasses making a mean face, which is disrespectful and offensive.\"}",
    "1109919713495117824": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Lmao FMl what a fucking ride. \ud83d\udc80\ud83d\udc80 Fried cunt!! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which indicates that the image is hateful.\"}",
    "1115466532685926400": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:When I say stream Confessions by Usher I fucking mean that shit nigga \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which make the image hateful.\"}",
    "1062736670850797568": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> this twat is certainly taking it seriously \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, suggesting that it may contain offensive or discriminatory content.\"}",
    "1115066721629552640": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Harry Sims. Helena Wayne's dick of a boyfriend, lol. She deserved waaaaaay better than this twat for sure. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a comic strip featuring a man and a woman, with the man appearing to be a jerk. The tweet text suggests that the man is not a good partner for the woman and that she deserves better. This could be interpreted as hateful, as it implies that the man is not worthy of the woman's affection or that she should leave him for someone better.\"}",
    "1117266309455073280": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Have you ever seen a femiNAZI indoctrinated Beta Male? If you haven't, here's one. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and a derogatory term towards women, indicating a hateful sentiment.\"}",
    "1109232603075354625": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Dis cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and is disrespectful towards women.\"}",
    "1049756627849633793": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> \"call them nigger, only because it's appropriate\" \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the racist language used in the tweet text.\"}",
    "1117617671066017793": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Cerci just gave up the occupied womb for the equivalent of $40.00 and some mid from an arrogant old nigga: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and a negative portrayal of a person.\"}",
    "1116479163135868928": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:\"You trying to get boxed up?\" ~Some nigga that finna get shot up \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a man holding a gun, which can be perceived as threatening or aggressive. The tweet text further supports this classification as it suggests violence and aggression.\"}",
    "1105840704192999424": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Life goes on nigga \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language towards African Americans, which is considered hateful.\"}",
    "1107972112604499970": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:My nigga be like \u201clet\u2019s go add you to the lease \u201c  Me: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image and the tweet text suggest that the content is hateful, as it uses derogatory language and racial stereotypes.\"}",
    "1115637818469101574": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:\u201cOo this nigga jumped\u201d \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language and racist slurs, which are indicative of a hateful meme.\"}",
    "1115820948786167810": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag> Listen to this nigga nate \ud83d\ude02 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is considered hateful.\"}",
    "1113880189350625280": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:\u201cGive a fuck what a nigga got if he ain't givin' it\u201d \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which make the image hateful.\"}",
    "1116688964285554688": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:this nigga was a genius \ud83e\udd2f \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a whiteboard with a list of reasons why someone might be considered a genius. The tweet text suggests that the image is hateful, possibly due to the use of the word 'nigger' in the tweet. This word is considered offensive and derogatory, which could be the reason for the classification of the image as hateful.\"}",
    "1051702226048245761": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Holy, im retarded \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests that the person is feeling stupid or inadequate, which could be interpreted as a hateful sentiment towards themselves.\"}",
    "1108492053556719616": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Nigga y'all both wrong tf \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racial slurs and is offensive. The image of the two men in headphones might be used to spread such hateful content.\"}",
    "1105469408179380224": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Good morning twitter dot com, I\u2019m off 12 Sausage McMuffins, a nigga feeling powerful \ud83d\ude08 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the man's pose and the reference to a racial slur in the tweet text.\"}",
    "1114984921804824577": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Mannnnnn this fine ass country nigga HERE\ud83d\ude2d\ud83d\ude2d\ud83d\ude2d \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language and is considered hateful.\"}",
    "1110341926526566401": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> This nigga the next big thing Pls Retweet I know you owe me no favors Biko\ud83d\ude4f\ud83d\ude4f\ud83d\ude4f\ud83d\ude4f \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the use of racial slurs and derogatory language in the tweet text.\"}",
    "1057582469225046016": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Dat lil nigger aint minez \ud83d\ude2d \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language and racist remarks, which are considered hateful. The image of a man holding a framed DNA test result might be used to further spread such harmful messages.\"}",
    "1108639524396195840": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag>  Chito: WHAT NIGGA  Me: SCARED AS SHIT NEEDS TO USE THAT THING NEXT\ud83d\ude02\ud83d\ude02\ud83d\ude02\ud83d\ude02 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racial slurs and is offensive. This image is not hateful.\"}",
    "1105573678933135360": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:1968 Walthamstow race card \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is an old race card from 1968, featuring a cow logo and a list of race attendees. It does not contain any hateful or offensive content.\"}",
    "1108705035926585345": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This nigga gay \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language and insults towards a specific group of people, which is considered hateful.\"}",
    "1108206150963601414": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:disco electro techno pop music now Surrender by Spencer &amp; Hill Feat. Ari on \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is a cover of a music album, featuring a white circle with the word 'Electro' written in it. It does not contain any hateful or offensive content.\"}",
    "1105476780708765696": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Just like a nigga \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racial slurs and is offensive. The image of a man and a bear in a room with a chandelier and a potted plant is unrelated to the hateful content of the tweet.\"}",
    "1110248261619798016": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> I\u2019m fuming for him, this happened to me and a nigga got 80k favs off it \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests that the image is a hateful meme, as it is described as 'fuming' and 'happened to me' which implies a negative reaction to the content of the image. The use of the word 'nigga' also adds to the negative connotation of the tweet.\"}",
    "1109306217904521216": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:We got kh3 nigga \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is considered hateful.\"}",
    "1115777909912948737": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> When I saw this I knew you were gonna get happy.... Dyke shit and gay shit co-existing \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and derogatory terms towards the girl in the image, suggesting that the image is a hateful meme.\"}",
    "1107278312508919808": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:inside behind ze KANTA.. ma nigga\u270a\ud83c\udffe\ud83d\ude02 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a man in a suit with a tie, making a racist gesture. The tweet text further supports this classification as it uses offensive language and racist stereotypes.\"}",
    "1053578207847440384": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Chicago nigga's always smoke good boy. Smoke like you're suppose to if you're from the Chi \ud83d\udcaf\ud83d\udcaf\ud83d\udcaf\ud83d\udcaf\ud83d\udcaf\ud83d\udcaf\ud83d\udcaf \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image and the tweet text are both hateful memes, as they use derogatory language and stereotypes to describe people from Chicago.\"}",
    "1113182575663742977": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Thank you Denzel. For being the realest nigga out here. TALK YO SHIIII!! \ud83d\udc4f\ud83c\udffd\ud83d\ude4f\ud83c\udffd\u2728\ud83e\udd8b \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it uses offensive language and makes derogatory comments about Denzel Washington.\"}",
    "1108554773756698625": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Oh this was a real nigga moment \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racist remarks, which indicates that the image is hateful.\"}",
    "1056687363919933440": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:OH MY GODD FIIMLOVERS BRANDDD IM A FAGGOT THEY SAID LOOK AT ME NOW \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language and insults, which suggests that the image is intended to be hateful.\"}",
    "1115278171413393408": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Who ever has made a fake Facebook off me you're a cunt. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet contains offensive language and insults, suggesting a hateful sentiment towards the person who created the fake Facebook profile.\"}",
    "1107185036531515392": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Come with me  Hail Mary nigga run quick see \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a man in a white jacket with a smiling expression, while the tweet text contains offensive language and racial slurs.\"}",
    "1114539400686440449": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> says nigga a lot. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it uses racial slurs and derogatory language to make a point. The tweet text also supports this classification as it uses the word 'nigger' repeatedly.\"}",
    "1109943938431897600": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This nigga look like Michael Myers \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it uses derogatory language to describe the man in the picture.\"}",
    "1113204436585930752": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:feel a way, feel a way, young nigga feel a way. i\u2019ve stopped listening to things you saaaay \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which are indicative of a hateful meme.\"}",
    "1036121521973075969": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Faggot \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it uses derogatory language to describe a person, which is offensive and disrespectful.\"}",
    "1107331960337297409": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> There's nothing more than white trailer trash hates more than a well-educated articulate African man \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a negative stereotype of a specific group of people, which is disrespectful and discriminatory.\"}",
    "1107279471969751041": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Nigga hit the \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a cat dressed in clothing and standing in the snow, which is a racist reference to African Americans. The tweet text further supports this classification as it contains a racial slur.\"}",
    "1114574188361211904": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Oh nigga! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, which suggests that the image is a hateful meme.\"}",
    "1109487750129029120": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:dawg this nigga gon hmu again saying \"you aint have to screenshot that bro\" \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the man's facial expression and the tweet text, which is disrespectful and offensive.\"}",
    "1054076593931538432": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:\u00a380 quid for a Bluray of Day Of The Dead ffs some cunt is taking the piss, It's the same with Dawn Of The Dead... \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet contains offensive language and a negative sentiment towards the price of the movie. It suggests that someone is trying to take advantage of customers by charging a high price for the movie.\"}",
    "1113226625682890752": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:When someone you admire says you were a cunt the first time you met them and they loved it. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and insults towards the subject, which is not appropriate or respectful.\"}",
    "1105525916548124672": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Some nigga shit y\u2019all wouldn\u2019t understand \ud83d\ude24\ud83d\udcaf \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image and the tweet text are considered hateful due to the use of derogatory language and the portrayal of African American men in a negative light.\"}",
    "1114596731860279298": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Trump is retarded \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language towards the president, which is considered hateful.\"}",
    "1113500056357867520": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> What shit I seeing here u tellin me that nigga was blind shooting all this time?!?!?!?!?!?\ud83d\ude29\ud83d\ude29\ud83d\ude29\ud83d\ude29 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme that is considered hateful due to the use of racial slurs and derogatory language.\"}",
    "1043683652658290688": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> report dogshit retard \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and insults towards a specific individual. The tweet text further supports this classification as it contains derogatory language and insults.\"}",
    "1105669186322399232": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Lmaoooooo, nigga said in case you\u2019re wondering what\u2019s the most common male name in Pakistan \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, which suggests that the image might be a hateful meme.\"}",
    "1056215066314489856": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:British milf Bounty finger fucks her #pink cunt #Inverness \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image and the tweet text are inappropriate and offensive, which makes it a hateful meme.\"}",
    "1108503351954538496": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Only thing I heard was the music when that nigga popped up somewhere lol \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which make it a hateful meme.\"}",
    "1105159530223202306": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:All of our reasoning ends in surrender to feeling. - Blaise Pascal #quote #askTNT \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is a sunset with a quote from Blaise Pascal. It does not contain any hateful content.\"}",
    "1105817078462853123": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:The last thing ybn almighty jay saw before he heard \u201cthat\u2019s the ybn nigga\u201d \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a group of people in a negative light, and the tweet text further supports this classification.\"}",
    "1114800619263385600": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> HOLY SHIT NIGGA WTF IS THAT \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it uses racial slurs and offensive language to make a joke. This is not appropriate and should not be shared.\"}",
    "1106573601845792768": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Wahabi nigga in the crease. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the racial slur used in the tweet text, which is offensive and inappropriate.\"}",
    "1107848871949058048": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> He\u2019s a stupid faggot<tag> \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language towards the president, which is considered hateful.\"}",
    "1108095200763789319": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> BYE NIGGA !!!!!! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains a racial slur, which is considered hateful. The image of a woman with blonde hair and a red dress is being used to spread this hateful message.\"}",
    "1107632497020555264": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:fine ass bitch gaf bout a nigga \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is disrespectful towards the woman in the image. It is not appropriate to use such language, and it can be considered as a hateful meme.\"}",
    "1113866456272445442": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Nigga sad jumped in on that XD \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image and the tweet text are considered hateful as they use derogatory language and make light of a serious issue.\"}",
    "1117217987914797056": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Damn nigga you right lol \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, suggesting that the image is a hateful meme.\"}",
    "1115826822825021440": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This nigga here man \ud83d\ude02\ud83d\ude02\ud83d\ude02 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it uses racial slurs and offensive language to describe the man in the picture.\"}",
    "1116403733141819392": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This nigga Paul \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains racial slurs and offensive language.\"}",
    "1113829132121460736": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:*retarded* \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, suggesting that the image might be considered hateful.\"}",
    "1113832534364700672": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:A Career ender right there. But none will bat an eye. #victimcard \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, suggesting that it may be portraying a negative or offensive situation involving the soccer players.\"}",
    "1105650047209877504": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> You twat she said that after you said what you said at Vanderpump dogs. #rhobh \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it is making fun of a person's appearance and is disrespectful.\"}",
    "1058528012910551040": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> This wall? #BuildTheWall !!! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it promotes a controversial political stance and uses a man dressed in a box as a prop to convey the message. The tweet text further supports this classification as it reinforces the message of building a wall.\"}",
    "1061902129231790080": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> This nigga is evil \ud83d\ude02\ud83d\ude02\ud83d\ude02 too much sense \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and a negative sentiment towards the man in the image. This suggests that the image is being used in a hateful manner.\"}",
    "1050420561409642496": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> No retard ballon D\u2019OR is for the best footballer \u201cOF THE YEAR\u201d \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it is making fun of a person with a disability, specifically a cerebral palsy patient. The tweet text further supports this classification as it is making fun of the person's condition.\"}",
    "1105617787802845184": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:[17\u2019s \ub3c4\uacb8] i fight for dyke rights \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a man holding a sword and a shield, which can be interpreted as a symbol of violence and discrimination against the LGBTQ+ community. The tweet text further supports this classification as it promotes fighting for LGBTQ+ rights.\"}",
    "1113662125497569280": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Nigger Coon ass bitch hope ur family dies \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and racist sentiments.\"}",
    "1109377697694826496": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Is it me or this nigga low key smiling? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language and is considered hateful.\"}",
    "1108119914479378432": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:After breakup  Le' 14 yr old Bihari Nigga: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image and the tweet text are both hateful memes, as they use offensive language and make light of a serious issue.\"}",
    "1108031703258460160": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:this nigga gay as hell<tag><tag><tag> \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and derogatory terms towards a specific group of people.\"}",
    "1114984897754460160": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:What the fuck did you say to me Fukin nigger faggot\ud83d\udd95\ud83c\udfff\ud83e\udd2e \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and derogatory terms, indicating a hateful sentiment.\"}",
    "1109857790217080833": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:my dyke queen #lesbiansforjennie \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language and promotes negative stereotypes about the LGBTQ+ community. This is considered hateful and inappropriate.\"}",
    "1108375584109940736": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:The way my life be working I really be here like damn can a nigga get some love \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and a negative sentiment towards a specific group of people, which indicates that the image is a hateful meme.\"}",
    "1059026965900988417": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Halloween Party and the wife and I went as Trailer Trash. Was a great night \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image shows a man and a woman posing together, with the woman being pregnant. They are dressed in a costume, which suggests that they are attending a Halloween party. The tweet text does not contain any hateful content, and the image itself does not appear to be hateful. The classification is 'not hateful'.\"}",
    "1062763406669832193": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Also nah. I like being a cunt. \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is a cartoon character with a humorous expression, and the tweet text does not contain any hateful or offensive language.\"}",
    "1042525029731328000": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Me being a big, fat, lazy retard on my day off \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests that the image is a hateful meme, as it implies that the person is a big, fat, lazy retard. This kind of language is often associated with negative stereotypes and discrimination, which can be hurtful and offensive to some individuals.\"}",
    "1107404101934108672": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Get fucked cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which indicates that the image is hateful.\"}",
    "1107828826531352576": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:You just shot your shot, got her number, and you think you the only nigga she entertaining??? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image and the tweet text suggest that the content is hateful, as it contains derogatory language and racial stereotypes. The man in the image is pointing at the camera, which adds to the aggressive and offensive nature of the scene.\"}",
    "1113141025499906049": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:The rawest nigga ever \ud83c\udf3b\ud83d\udda4\ud83d\udc7d \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which make it a hateful meme.\"}",
    "1107099278185545728": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Rich ass nigga, 500k for the \ud83c\udf46. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, making it a hateful meme.\"}",
    "1110234243462909953": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Stars Maintain Lead In Wild Card Race | Stars Playoff Push - National Hockey League News - \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is a news segment featuring a female reporter discussing the Stars' playoff push. It is not a hateful meme as it is providing information and context about the NHL team's performance.\"}",
    "1113659374881267712": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:cunt keeps on standing on the couch #AR Demon #D2 SMT \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is considered hateful.\"}",
    "1114495902792736768": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I dreamt about this nigga again \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and a negative sentiment towards the image, suggesting that it is a hateful meme.\"}",
    "1051388069763379200": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:ew no 1 fkin cares retard \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and disrespectful attitude towards the image, which indicates that it is a hateful meme.\"}",
    "1110467566898561024": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag> And it\u2019s \u201cRespect the Cock and tame the Cunt!\u201d Dumbass...\ud83d\ude02\ud83d\ude02\ud83d\ude02 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is disrespectful towards women. This classification is based on the fact that the image is being used to spread such negativity and disrespect.\"}",
    "1114512918463373312": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag>   I can call you \u201cNigga\u201d just to be racism as you !   One by one \ud83d\ude09 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image and the tweet text are both hateful and racist, promoting negative stereotypes and derogatory language.\"}",
    "1113111751598407680": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This nigga<tag> is OC \ud83d\ude2d \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which make it a hateful meme.\"}",
    "1114104954820677632": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Nigga do you know I can see you \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racial slurs and is considered hateful.\"}",
    "1106619141115596800": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This photo is taking me out. \ud83e\udd23\ud83e\udd23\ud83e\udd23 It\u2019s STILL fuck that nigga over here. \ud83d\udd95\ud83c\udffe \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content.\"}",
    "1108766707219259393": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Nigga I was on Bart like \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a character from a popular cartoon in a racist manner. The tweet text further supports this classification as it contains a racial slur.\"}",
    "1115975784366264320": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Your a miserable cunt. Miller is a white nationalist that happens to have Jewish faith. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, suggesting that the image is a hateful meme.\"}",
    "1115633687469551617": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:DONT BELIEVE HIM GET THAT NIGGA SIS@ \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is considered hateful.\"}",
    "1108387361254043648": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> LOW LIFE WHITE TRASH MF \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, suggesting that the image is a hateful meme.\"}",
    "1114866096719446017": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> That\u2019s the nigga from everybody hate chris Omar \ud83d\ude02\ud83d\ude02 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a negative stereotype of a black man, which is offensive and disrespectful.\"}",
    "1115357497479630848": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This is the most retarded kid I\u2019ve ever met \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which indicates that the image is hateful.\"}",
    "1107158709292146688": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Nigga its COLD \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, which suggests that the image might be a hateful meme.\"}",
    "1114043797212684288": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Yep, here's my reply when someone starts playing the race card.  \"He's not very good at it.  Is he?\" \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image contains a collage of photos and news articles, including a picture of Trump, a picture of a black man, and a picture of a white woman. The tweet text suggests that the image is a response to someone playing the race card, which implies that the image is hateful. The presence of Trump and the racial elements in the image contribute to this classification.\"}",
    "1045590934518468608": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I\u2019ve just very nearly made a holy twat of myself on Instagram. Luckily realised my mistake just in time \ud83e\udd23\ud83e\udd23 \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is not hateful as it shows a woman sitting in a chair with a vase in the background, and the tweet text does not contain any offensive or hateful content.\"}",
    "1105676218236588032": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Fuck a fuck nigga \ud83d\udc4e\ud83c\udffe \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it shows a man giving a thumbs down sign with a negative expression on his face, which can be perceived as offensive and discriminatory.\"}",
    "1109958096808566784": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Nigga you're a joke. Seriously \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text is offensive and uses derogatory language, indicating that the image is a hateful meme.\"}",
    "1117663481652752385": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Alexis Texas gives head and gets her juicy cunt slammed tough \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image depicts explicit sexual content, which can be considered inappropriate and offensive. The tweet text adds to the negative nature of the image, as it describes the woman's actions as 'giving head' and 'getting her juicy cunt slammed tough.' This language is disrespectful and can be considered hateful.\"}",
    "1116653153330425857": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:lol told this nigga im going kalista jungle if he dont switch yikes \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is considered hateful.\"}",
    "1105393275253506048": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Full Video: \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is not hateful as it shows a woman enjoying a man's penis. It is a consensual act between two adults, and there is no indication of harm or disrespect towards anyone.\"}",
    "1113928039719669761": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Still in the trenches where em pigs won\u2019t leave a nigga be\ud83d\ude12 #Familyovereverything #AllLove \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image shows a group of people, including a man in a black shirt, standing around a pink toy car. One of the people is holding a cell phone. The tweet text suggests that the people in the image are in a negative situation, possibly involving discrimination or mistreatment. The use of the word 'em pigs' and 'nigga be' in the tweet text indicates",
    "1109130483366092801": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> At this point you gotta come clean. You should\u2019ve talked to him before going out to fuck another nigga \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image and the tweet text suggest that the man is making a racist comment, which is considered hateful. The man is wearing a red bandana and a black tank top, and he is making a funny face while talking. The tweet text further supports the classification as it contains a racial slur.\"}",
    "1056561029214363648": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Lmao #metoo  <tag> is a thin-skinned faggot \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults towards the LGBTQ+ community, which is considered hateful. The image itself might not be hateful, but the context provided by the tweet text suggests that it is associated with a hateful sentiment.\"}",
    "1108972727124189184": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Before I walked out the bathroom I looked in the mirror &amp; said \u201cYeah aight. Try it nigga\u201d #UsMovie \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it uses offensive language and makes light of a racial slur. The tweet text further supports this classification as it uses the same language and tone as the image.\"}",
    "1116431896840372227": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:If u with the squad I give you my heart lil nigga I mean it \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racist remarks, which make the image hateful.\"}",
    "1106598859344625670": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Haters gone say I ain\u2019t win lol young nigga lucky I was sipping my wine \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it may contain offensive or discriminatory content. The tweet text further supports this classification as it contains language that could be considered derogatory or disrespectful towards a specific group of people.\"}",
    "1107994526734577664": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> THIS THE SAME NIGGA\ud83e\udd23\ud83d\ude02\u203c\ufe0f \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language and racist remarks, which indicates that the image is hateful.\"}",
    "1105306938336698373": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> this nigga \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a black man in a negative light, using racial slurs and derogatory language.\"}",
    "1053859870976274433": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I'm white trash and I'm in trouble oh and I have a big penis #LivePD #LivePDNation \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a man in a red hat being arrested by police officers, with one officer holding his arm. The tweet text further adds to the negative sentiment, as it describes the man as 'white trash' and makes a reference to his penis. This kind of language is offensive and disrespectful, which makes the image hateful.\"}",
    "1114922485340868614": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:What the shirt meant to say was \u201c Whatcha Gonna Do NIGGER?\u201d \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The shirt contains a racial slur, which is hateful and offensive.\"}",
    "1108053435381895170": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:When u at South beach wit gang n see yo ho dancing on some outta town nigga that bark \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a group of people, including a young boy, in a negative light. The tweet text further supports this classification as it contains offensive language and derogatory terms.\"}",
    "1107027417544224769": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:My mom and that other nigga did that \ud83d\ude2d \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which make it a hateful meme.\"}",
    "1110309548492025862": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Shut up nigger \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains a racial slur, which is considered hateful.\"}",
    "1108051559760449536": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Wanting an old nigga back? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text is offensive and racist, which makes the image a hateful meme.\"}",
    "1109823556043575296": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> this nigga \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is considered hateful.\"}",
    "1107124918162849792": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Horny stepsis lets stepbro fuck her twat to ease her tingly feeling \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or inappropriate content. The tweet text further supports this classification as it contains explicit language and potentially inappropriate content.\"}",
    "1107303892805656576": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> This is what i think of that whiny cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language towards a specific individual, which indicates a hateful sentiment.\"}",
    "1058540297603424257": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag> Wait you\u2019re a limey? Who cares what you think... \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a painting of a man in a red coat holding a gun, with a caption that says 'I say sir hand over your guns... f*ck off!' This is considered hateful as it is making a derogatory statement towards the British people.\"}",
    "1054085679393710080": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Cunt deserves the fucken death penalty passed the ball round the back for the whole 2nd half #fifa19 #FUTchamps \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is considered hateful.\"}",
    "1110224090755932161": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:- Bitch accept one collect call and bail one nigga out and all of sudden this is her song. \ud83d\ude12 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a negative stereotype of a black woman, using her as a prop for a song. This is disrespectful and offensive.\"}",
    "1107376996298997761": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Watch this nigga be like level 70 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and imagery, such as the word 'nigger' and the depiction of a character in a game. This type of content is not appropriate and should not be shared.\"}",
    "1109122151976718341": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Lol you gone have it today nigga \ud83d\ude02\ud83d\ude02 period \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which indicates that the image is hateful.\"}",
    "1046041341057277952": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:There's a high school in New York whose mascot is a hillbilly. \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is a shirt with a cartoon of a man holding a gun and a bottle. It does not contain any explicit or offensive content that would be considered hateful.\"}",
    "1051549165006843907": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Idk why y\u2019all say you hate him so much then still post his ugly racist trash white ass on my tl?! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the racist and offensive content, as indicated by the tweet text.\"}",
    "1108893525582798848": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Dis Nigga Trappin In Church \ud83d\ude02 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a negative stereotype of African Americans, specifically a young man wearing a hoodie and a beanie, with his mouth open. The tweet text further emphasizes the offensive nature of the image.\"}",
    "1105590308056776704": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Someone: is being lesbophobic Andrew, knowing well that I'm an aggressive dyke: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful as it is a meme that makes fun of lesbians, which is considered offensive and disrespectful.\"}",
    "1105223777506463744": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:\"NIGGA PLEASE!\" \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains a racial slur, which is considered hateful and offensive.\"}",
    "1115064521784270848": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:My nigga finally happy. This the shit I\u2019m tryna be on. I taught him well \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is considered hateful. The image of a young girl looking at a display case of ice cream is unrelated to the hateful content of the tweet.\"}",
    "1115621314272870400": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I remember this my nigga \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language and insults, which are considered hateful.\"}",
    "1114690393159946240": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Aint no checking NO FLORIDA NIGGA \ud83e\udd37\ud83c\udffe\u200d\u2642\ufe0f ... \ud83d\ude02 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and racial stereotypes. The tweet text further supports this classification as it uses derogatory language and makes light of a serious issue.\"}",
    "1113620022922969088": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:THIS MAN...  IS AN ANTI SJW \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it is promoting anti-SJW sentiment, which is discriminatory and harmful to the LGBTQ+ community.\"}",
    "1115127681979506688": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> \ud83d\ude2d\ud83d\ude2d nigga \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a black man in a negative light, using racial slurs and making fun of him.\"}",
    "1105169411751727104": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Tag your nigga \ud83d\ude02\ud83d\ude02\ud83d\ude02 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a black woman in a negative and offensive manner, using racial slurs and making fun of her appearance.\"}",
    "1115428359583014912": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> This is now an obsessions aki ya nani\ud83d\ude02\ud83d\ude02\ud83d\ude02 all these years later and a nigga still sprung\ud83d\ude02\ud83d\ude02\ud83d\ude02 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a negative stereotype of a black man licking his fingers while making a funny face. This type of content is often used to mock or belittle a particular group of people, which is considered hateful.\"}",
    "1107190594969968642": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:#NowPlaying Casting Crowns ||<tag> - I Surrender All (All To Jesus) Log on to \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is a promotional poster for the album 'Glorious Day' by Casting Crowns, featuring a group of people posing together. The tweet text does not contain any hateful content, but rather promotes the album. The image itself is not hateful, but rather showcases the band and their music.\"}",
    "1061788070125752320": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> \"hur dur these guys speaking  out against sjw politics in comics are nazis\" \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful as it portrays a man in a green shirt holding a sign that says 'Homework' and 'Assignments' while making a face. This could be perceived as a negative or offensive portrayal of someone who is struggling with homework or assignments, which is not a respectful or inclusive representation.\"}",
    "1110218422674169857": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Good thing I ain\u2019t every nigga \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which make it a hateful meme.\"}",
    "1035752904932712448": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> And yes, is 327 billion.....mr retarded \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which indicates that the image is hateful.\"}",
    "1116309095181627392": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Nigga !! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a man in a negative light, using offensive language in the tweet text.\"}",
    "1107348950200303617": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Smartest nigga you know \ud83d\ude09 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, suggesting that the image might be a hateful meme.\"}",
    "1115195274748727297": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image contains a religious text, which might be considered offensive or hateful by some people. The text is written in Arabic, which might be difficult to understand for non-native speakers, and it could be interpreted as a call to violence or discrimination against certain groups. The presence of a surfboard in the image might also be considered as a provocative element, further contributing to the perception",
    "1109271796220604416": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:3 gatsu no lion? No nigga 4 gatsu Guts theme just came on stop playing \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is considered hateful.\"}",
    "1109513317188583427": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I am ready to surrender to this powerful voice that is making #FinalRepentanceCall central park tomorrow don't miss. \nASSISTANT: {\"Classification\": \"hateful or not hateful\", \"Explaination\": \"The image is not hateful as it is promoting an event at Central Park, inviting people to attend and participate in the Final Repentance Call. The message is focused on spiritual growth and self-improvement, which is not inherently hateful.\"}",
    "1061311286087172102": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Here's hoping we won't be on this list...#BuildTheWall #DEPORT \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a pie chart showing the percentage of people in various countries that defecate in the open. It is not hateful, but rather informative. The tweet text suggests a political stance, but it does not contain any hateful content.\"}",
    "1055295289437896704": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Redneck Rumble embroidered adjustable mesh trucker cap. $20 shipped to your door in U.S.  message for PayPal address \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image does not show any explicit hate or discrimination towards any group of people. It is a simple cap with a logo on it, which is not inherently hateful.\"}",
    "1114664017216311301": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I was called retarded, fake woke, and told to go to Hell in the span of 30 minutes. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful as it portrays a mean-spirited character, which can be perceived as offensive and disrespectful to some individuals.\"}",
    "1046619429201563648": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Go home faggot, you\u2019re drunk \ud83e\udd23 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which indicates that the image is hateful.\"}",
    "1114401522257817601": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Nigga just sent me this and I am cracking tf uupppp. Lmfaaooo he gone have to kill me bih \ud83d\ude2d\ud83d\ude2d \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a violent and harmful act towards a woman. The tweet text also suggests that the image is causing distress and fear, which further supports the classification of the image as hateful.\"}",
    "1113987929762930688": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:my granddad act like phones don\u2019t work both ways and like he can\u2019t text a nigga \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays an old man in a chair, suggesting that he is outdated and incapable of using modern technology. The tweet text further supports this classification as it implies that the old man is not capable of using technology and is out of touch with current trends.\"}",
    "1106992834551402497": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:For tomorrow: Happy st Patricks Day you fat ginger but go so genius cunt <tag> \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which indicates that the image is a hateful meme.\"}",
    "1105118808258146304": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> never give up, never surrender \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image does not contain any hateful or offensive content. It is a simple comic strip with a message about not giving up.\"}",
    "1107959265011138561": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> \ud83e\udd1c\ud83c\udffc\ud83d\udca5\ud83d\udca5\ud83e\udd74 Whitest of white trash going hardcore! \ud83e\udd23\ud83d\ude02 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it is making fun of a person's appearance, specifically their teeth, which is considered disrespectful and offensive.\"}",
    "1061618612472107008": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Retard*d queen \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, suggesting that the image might be a hateful meme.\"}",
    "1105098270173523968": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> I may have to get that nigga pregnant \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is considered hateful.\"}",
    "1108580754383081474": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:NO SURRENDER &amp; NO RETREAT!!! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme of Adolf Hitler, which is often associated with hateful and discriminatory messages. The tweet text reinforces this notion by advocating for a strong stance against surrender and retreat.\"}",
    "1114571722899054599": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:this nigga jungkook really evolve every 6 months and i am SICK... when will it end??? when he 40? 50? NEVER???!? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language and negative sentiments towards the person in the image, suggesting a hateful attitude.\"}",
    "1062176558268497921": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Everybody it'sraw retard \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is considered hateful.\"}",
    "1108885521659543552": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:nan\nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is a book cover with a positive message about hope and healing. It does not contain any hateful or offensive content.\"}",
    "1050044753939709953": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I'm either visually retarded or Tiki just ate that without taking damage what the fuck \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is a screenshot of a video game, showing a character's stats and abilities. The tweet text does not seem to be related to the image content, and there is no indication of hate or discrimination.\"}",
    "1115000887578120193": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> hahaha fuck off you twat \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, indicating a hateful sentiment towards the person in the image.\"}",
    "1107533961998331904": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:NIGGA just farted and dipped \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image and the tweet text are considered hateful as they use offensive language and make light of a person's body odor.\"}",
    "1115374165857587200": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Aye this nigga cold \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image and the tweet text suggest that the content is hateful, as it uses derogatory language to describe a person.\"}",
    "1108512910135967747": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> nigga \ud83e\udd2e \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image and the tweet text are considered hateful due to the use of racial slurs and offensive language.\"}",
    "1049691520562028544": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I cant think of a good caption, just look at my retarded fucking friend \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the man holding a dead animal, which is perceived as inhumane and disrespectful towards the animal.\"}",
    "1105800590943227904": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Twat faced, Dick breath, dwaddiling thunder cunt. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and insults towards the individuals in the picture.\"}",
    "1109512838907867136": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> what the fvck is wrong with you a$$holes?<tag><tag> you are the epitome of white trash. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the use of a meme featuring a cake with a picture of Abraham Lincoln wearing a red hat and the words 'The Democrat' on it. This could be perceived as offensive and disrespectful to those who view it.\"}",
    "1036269462012346368": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:SWEET JESUS THIS LOOKS SO RETARDED I FUCKING LOVE IT \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests that the image is intentionally created to be humorous and entertaining, which might be considered as hateful by some people.\"}",
    "1051565063717285888": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:a full dyke \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it may contain offensive or discriminatory content. The tweet text further supports this classification as it uses derogatory language to describe the person in the image.\"}",
    "1058044999898669057": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Four days at the new place and already my colleagues have confided in me who\u2019s a cunt in the office and who isn\u2019t \ud83d\ude0f \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which indicates that the image is hateful.\"}",
    "1057516524628520960": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:REAL NIGGA SHIT \ud83e\udd23\ud83e\udd23\ud83e\udd23 #soshameless<tag> \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is considered hateful.\"}",
    "1058089230029619200": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:No item short cunt #MK8D #NintendoSwitch \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, suggesting that the image might be a hateful meme.\"}",
    "1058995862918098944": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Haha fuk manny stupid penis nose retard \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults towards Manny, suggesting a hateful sentiment.\"}",
    "1113714236285440001": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Once ya hairline look like this just go bald my nigga \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is considered hateful.\"}",
    "1056237849966718980": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:When you were doing so well but make a mistake again #twat \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a character in a negative light, making a mistake and being called a 'twat' in the tweet text.\"}",
    "1117170222727872513": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:\u201cIf you a rich nigga, Ima fuck you til you ain\u2019t oneeeeee\u201d \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial stereotypes, which make it a hateful meme.\"}",
    "1113499439363239937": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Mmm love this, purely putting it in to copulate and breed my wife's fertile cunt #wankchat \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, and the tweet text suggests a sexual context involving the woman's fertile cunt.\"}",
    "1109389563842215938": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Nigga said tobirama \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the man's facial expression and the reference to a racial slur in the tweet text.\"}",
    "1113965844588105728": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:S/o My Last B**** Im Shittin On Her Nigga No\ud83e\udde2\ud83e\udd23\ud83e\udd23\ud83e\udd23 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image and the tweet text are considered hateful as they use offensive language and make light of a serious issue.\"}",
    "1114307152800362496": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Finish that sentence nigga \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it uses racial slurs and offensive language to make a joke. The tweet text further supports this classification as it reinforces the offensive content.\"}",
    "1116503991720955904": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Nigga it\u2019s on my timeline lmao and woooow I\u2019m devastated \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains a racial slur and is offensive.\"}",
    "1116525087514136576": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Nigga it\u2019s FOURTEEN devices using my account \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which make it a hateful meme.\"}",
    "1114474499041386496": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:all i asked was for this nigga to report ... \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is considered hateful.\"}",
    "1109472659690213377": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Nigga said ... \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a person wearing a mask and a hoodie, which is associated with negative stereotypes and racism. The tweet text further supports this classification as it uses offensive language.\"}",
    "1054523426730213376": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Hope everyone is having a good day except the nigger that made this \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racist language, which indicates that the image is hateful.\"}",
    "1105511204762644480": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:\ud83d\ude02\ud83d\ude02\ud83d\ude02\ud83d\ude02 RT<tag>: \u201cFuck nigga you straight\u201d \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which make the image hateful.\"}",
    "1062157264633585664": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:What a cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which are considered hateful. The image might be related to the content of the tweet, but it is not possible to determine the context and intent of the image solely based on the tweet text.\"}",
    "1050054451753553921": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:And the twat who was the ONLY ONE to vote against making our drinking water cleaner? Senator Mike Lee (R, Texas) \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it shows a negative portrayal of a politician, specifically Senator Mike Lee, and implies that he is the only one who voted against making the drinking water cleaner. This could be perceived as an attack on the politician's character and policies, which is not a respectful or constructive way to engage in political discourse.\"}",
    "1109286111434682368": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Some nigga tell the truth like me \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which make it a hateful meme.\"}",
    "1058753346767646722": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:*A real nigga daps up the TL* \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the use of racial slurs and derogatory language in the tweet text.\"}",
    "1064285109174431744": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Hey Siri why are you fucking retarded \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language towards Siri, suggesting that the image is hateful.\"}",
    "1053872438004588544": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Time to put Gamergate to rest with a full-on artillery barrage. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests a negative sentiment towards the Gamergate movement, which is often associated with harassment and online abuse. This could be perceived as hateful by some people.\"}",
    "1107090926286131200": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:New VC GLITCH all u gotta do is play this random and he one of the worst nigga in the community   UR WELCOME \ud83e\udd70 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and a negative portrayal of a community.\"}",
    "1045692994966495232": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> faggot \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, which suggests that the image is hateful.\"}",
    "1115039063923404801": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Neil is being a twat as usual<tag> let\u2019s cancel her \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image and the tweet text suggest that the content is hateful, as it involves insulting and potentially harmful language towards a person named Neil.\"}",
    "1109428801539371008": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:\"Fell in love with a nigga drinking codeine, how you gon fall for nigga drinkin creatine\" \ud83d\ude1e \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language and racial slurs, which are considered hateful. The image of the man and the child is not the focus of the tweet, and it is not the main subject of the image. The image is being used as a prop in the context of the hateful tweet, which makes it appear as a hateful meme.\"}",
    "1116468342682865665": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Always play victim card... \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a young man with a sad expression, possibly mocking someone's emotions or appearance.\"}",
    "1063896520800563200": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:And HBO dumb kind of retard. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults towards HBO and the man in the image. This suggests that the image is a hateful meme.\"}",
    "1114201666969116672": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Nigga said \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a negative and offensive stereotype of a black person.\"}",
    "1059062294921932800": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Me at a red light in the passenger seat of my nigga car while he playing bangers \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a woman in a short skirt and bikini top in a suggestive manner, which is disrespectful and objectifying.\"}",
    "1114549481633005568": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> I dont speak faggot \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a character with a mean expression and a message that is derogatory towards the LGBTQ+ community.\"}",
    "1056662989175250945": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:White Trash Weeb \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is considered hateful.\"}",
    "1063886324267212801": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:#Peoplewhoneedagoodhiding  This cunt who didn't know that ORAL B did a toothpaste \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and a negative sentiment towards the person in the image. The classification is based on the fact that the tweet is disrespectful and dislikable.\"}",
    "1109387363782930432": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:\"Plans? Plans? Ain't no nigga that make plans! Niggas just react to outside stimuli\" - Uncle Ruckus \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and stereotypes, which are considered hateful. The image of a man with a horse and a hat also adds to the offensive nature of the meme.\"}",
    "1106748086125117442": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Nigga please \ud83d\ude44 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a man with a beard and a red shirt, which is a racial stereotype. The tweet text further supports this classification as it uses offensive language.\"}",
    "1113106620404432898": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Watch it: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it may contain offensive or discriminatory content. The woman in the image is naked and posing in a provocative manner, which could be considered inappropriate or offensive by some people.\"}",
    "1117125732243841024": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Nah nipsey is that nigga. Did his BM really get this tatted tho?? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet contains derogatory language and insults towards the woman with tattoos, suggesting a hateful sentiment towards her.\"}",
    "1035270213665783818": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag><tag><tag> Brah I'm telling you females be drinking retarded juice \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a frog drinking from a glass labeled 'retarded juice' with the words 'women' written above it. This is offensive and disrespectful towards women.\"}",
    "1050003539752308738": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Day 31 : Redneck \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is a comic book illustration featuring a man holding a flag and a beer. It does not depict any hateful content.\"}",
    "1110401235117633536": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Df did that third nigga just do?? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a negative stereotype of a black man and his fans. The tweet text further supports this classification as it is derogatory and disrespectful towards the black community.\"}",
    "1044711841161728006": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> That moment when you realize you are a racist twat \ud83e\udd23 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a woman in a racist manner, which is offensive and disrespectful.\"}",
    "1061477314222006277": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This cunt gets a sprite but Okabe's mom doesn't? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the use of offensive language and the portrayal of a woman in a negative light.\"}",
    "1109502801908908032": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:\u201cWe hog we beast up nigga we take shit nigga me and my blood brotha always on some snake shit\u201d \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which are indicative of a hateful meme.\"}",
    "1055198779295571968": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:\u2605Niteflirt's Finest \u2605 PrincessJewel Sissy Faggot Emascualtion with Princess Jewel \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image and the tweet text contain offensive language and derogatory terms, which suggest a hateful sentiment towards the LGBTQ+ community.\"}",
    "1110156217593286656": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:guys i was walking to the shop and this nigga stops me and says \u201csame\u201d while licking his lips you guys \ud83d\ude2d \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the racist language used in the tweet text, which is offensive and disrespectful towards people of color.\"}",
    "1056278639438905345": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Watching the boxing you gay cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language towards the boxers, suggesting a hateful sentiment towards them.\"}",
    "1042801040599515136": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:You're still white trast, you're still a faggot -<tag> \ud83e\udd23\ud83d\ude2d\ud83d\udc4c \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text is derogatory and disrespectful towards the person in the image, which is considered hateful.\"}",
    "1061009487971135491": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> not happening only trailer trash women support Trump \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a woman wearing a Trump shirt and holding a sign that says 'Trump can grab my pussy' which is a derogatory and offensive statement towards women.\"}",
    "1108222619751456768": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Nigga... \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains racial slurs and is disrespectful towards people of color.\"}",
    "1110374820234125313": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:A lil nigga said \u201cbye soldier boy\u201d to me when I left the wing spot \ud83e\udd26\ud83c\udffd\u200d\u2642\ufe0f \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the negative portrayal of the young man with a clown nose and the reference to him being a 'soldier boy' in the tweet text.\"}",
    "1056411278133092352": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I know WTT got the nigger memes. I need em right now \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the reference to the N-word and the fact that it is being held in a hand. The word 'nigger' is a racial slur and its use in this context is offensive and inappropriate.\"}",
    "1108485990295977984": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Reminds me of this nigga from Re:Zero \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it may contain offensive or discriminatory content. The tweet text also implies that the image is related to a character from Re:Zero, which could be a reference to a controversial or divisive topic.\"}",
    "1053690097659535360": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Triple twat \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a political statement and the man is holding a sign that says 'funding our future to vote against any increase in fees in the next parliament' which can be considered as a hateful meme as it is against a certain political party or politician.\"}",
    "1055137831570628608": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I love (1) faggot son \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language towards the LGBTQ+ community, which is considered hateful.\"}",
    "1057458366044430336": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:So who actually finds this guy funny? All he does is make retarded ass faces?? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests that the image is considered hateful, as it is described as a 'retarded ass face' and the person is asking who finds the man funny. This implies that the image might be perceived as offensive or disrespectful to some viewers.\"}",
    "1035356054585073664": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Even with that retarded name? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and negativity towards the pregnant woman's name, suggesting that the image is hateful.\"}",
    "1024899213912489985": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:FuCkiNG CUnt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image contains offensive language and content, such as the word 'cunt' and the reference to a 'toxic friendship.' This suggests that the image is intended to be hateful or disrespectful towards others.\"}",
    "1108245895395577856": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:When dats yo nigga and yo dawg \ud83d\ude0d\ud83d\ude29 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which make it a hateful meme.\"}",
    "1057328483070816263": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:the irony is strong here\u2026 what a twat \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which indicates a hateful sentiment towards the person being referred to.\"}",
    "1106732967471263744": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Real bad b*tch , gaf bout\u2019 a nigga. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is considered hateful.\"}",
    "1108937357774843907": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:can you imagine this nigga &amp; rygin king doing a show about exploring jamaica? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language and racist remarks, which are considered hateful. The image of the TV show logo is being used to spread such harmful messages.\"}",
    "1062034410659295235": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Dear Mr Twat ....you wait and see! \ud83d\ude06 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which suggests that the image is a hateful meme.\"}",
    "1114209610691485697": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Again. Cunt. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the clowns' distorted and unsettling appearance, which can be perceived as offensive or threatening.\"}",
    "1114605076817911808": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:imagine calling us white trash whole time your family looks like this\ud83d\udc40\ud83d\udc80 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults towards the man in the image, suggesting that the image is a hateful meme.\"}",
    "1050916564168511489": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:\u2018Nuff said. #faggot #cumdump #sperm #bitch \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image and the tweet text are hateful memes, as they use derogatory language to describe the LGBTQ+ community.\"}",
    "1055780859494699008": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:An oldie but a goodie... #BuildTheWall #LiberalTears #MigrantCaravan \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme that is intended to be hateful towards liberals, as it shows a man in a military uniform holding a coffee mug with the words 'Liberal Tears' written on it. The tweet text further supports this classification as it is related to a political issue and aims to mock the opposing side.\"}",
    "1109567091600969729": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Twat \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme that makes light of a woman's vagina and her doctor, which is considered offensive and disrespectful towards women. It is not a respectful or appropriate way to discuss sensitive health issues.\"}",
    "1024180377424936960": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:#feminization #faggot #humiliation #sissification #sissyslut watch this clip at \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image and the tweet text suggest that the content is intended to be humiliating and degrading towards women. The use of words like 'feminization', 'faggot', 'sissy', and 'sissyslut' implies that the image is meant to degrade and humiliate women. The presence of multiple images of the same woman further emphasizes the objectification and de",
    "1105326261365362689": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag><tag> I support you for being gay, no hate here, faggot. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains hate speech towards the anime character, which makes the image hateful.\"}",
    "1057530915117776896": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Yuck nigga, why you lying on the TL.... you want me to expose what she told me about you? \ud83d\ude02\ud83d\ude02\ud83d\ude02 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a black woman in a negative light, with a man standing behind her and making a face. The tweet text further supports this classification as it is disrespectful and racist.\"}",
    "1062864228846002177": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:this dyke.. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language towards the person in the image, suggesting a negative attitude towards them.\"}",
    "1110432554748764160": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Nigga you clenched my ass tf \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is considered hateful.\"}",
    "1116068910544166912": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:A nigga ask for a pic just send this \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a young girl with a ponytail and a smiling expression, but the tweet text associated with the image is racist and offensive.\"}",
    "1113571328500563969": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Rough ass cunt whipping and caning session at \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image depicts a violent and degrading scene involving a woman, which is inappropriate and offensive. The tweet text further emphasizes the negative and harmful nature of the content.\"}",
    "1053643155655024640": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:\"You twat\"   \ud83d\ude02\ud83d\ude02\ud83d\ude02 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, suggesting that the image is hateful.\"}",
    "1107431685510045697": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Say thank you cause this game will definitely help you a lot with yo nigga and the nigga you want! #ncat #ncat22 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is likely to be considered hateful.\"}",
    "1105884409708847107": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Nigga lit I ain\u2019t never had shit \ud83c\ude32 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language and is considered hateful.\"}",
    "1114519907213959168": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I'm about to Suge Knight a nigga this morning. #Yeah #DaBaby #Florida #SaturdayMorning #SaturdayMotivation \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests a violent and aggressive action towards another person, which is considered hateful.\"}",
    "1115279855690571776": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Donald Trump is a cunt... that's it...that's the tweet \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet contains offensive language and is considered hateful.\"}",
    "1114695119356215297": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Nigga wylin \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it uses racial slurs and offensive language to make a joke. This is not appropriate and should not be shared.\"}",
    "1055774472047747072": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> look he puts this in his bio. what a fucking retard \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, suggesting that the image is a hateful meme.\"}",
    "1058674215359074305": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Twat \ud83d\ude02 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a woman in a negative light, possibly making fun of her appearance or actions. The tweet text further supports this classification as it adds insult to the image.\"}",
    "1113143023683153920": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag><tag><tag> look at this Turkish Twat \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the man's aggressive pose and the reference to a 'Turkish twat' in the tweet text, which is derogatory and offensive.\"}",
    "1114232079049531393": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> nigga said, \u201clagend\u201d\ud83e\udd74\ud83d\ude2d \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a negative stereotype of African Americans.\"}",
    "1109021181712187392": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:The Full Gallery: \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is a woman in a blue shirt and shorts posing on a couch. It is not a hateful meme as it does not contain any offensive or discriminatory content.\"}",
    "1113902459502518272": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> keeping it #SuperElite classy as usual.<tag> is white trash! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults towards the president, suggesting a hateful sentiment towards him.\"}",
    "1108203019680702464": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:If a nigga I\u2019m talking to or in a relationship with ask me for my Twitter password.... \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains a racial slur in the tweet text, which is offensive and inappropriate.\"}",
    "1108810458650341377": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Nigga came and hijacked the whole operation \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains a racial slur and is disrespectful towards a specific group of people.\"}",
    "1057494058212511744": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:WHEN YOU FACETIME YA BITCH &amp; HER SIDE NIGGA ANSWER SO YALL JUST STARE AT EACH OTHER \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image and the tweet text suggest a hateful meme, as it portrays a negative and offensive stereotype of African Americans.\"}",
    "1115330439516839936": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:sitting here getting paid to read and look like a dyke \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it may contain offensive or derogatory content. The person in the image is holding a book by Stephen King, which might be seen as a form of self-expression or a way to show interest in reading. However, the overall context and the person's appearance might be perceived as offensive by some people, leading to the classification of the",
    "1116686262516187138": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Ignorant nigga problems \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which are indicative of a hateful sentiment.\"}",
    "1115047003854131200": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:literally i hate this dumb fucking cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains strong negative language towards the person depicted in the image, suggesting a hateful sentiment.\"}",
    "1117503920983695360": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:bruh this nigga Dion hilarious lmao<tag><tag><tag> #PS4share \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is considered hateful.\"}",
    "1108248517020131328": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I really fuck with this nigga. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language towards African Americans, which is considered hateful.\"}",
    "1107540143857156096": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I swear I\u2019m finna quit twitter... a nigga just wants love for the quality tweets \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and a negative sentiment towards the person who is the subject of the image. This suggests that the image is a hateful meme.\"}",
    "1107778196047609856": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag> Some are just begging to surrender their rights.  #gunsense #2A #GunControlNow #guncontrol \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it promotes the idea of taking away people's rights, specifically their right to bear arms. The tweet text further supports this classification as it advocates for gun control, which is often seen as a restriction on the rights of gun owners.\"}",
    "1109135493554491394": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> it\u2019s up li nigga whole lotta drunk mane shit \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language and insults towards African Americans, which is considered hateful.\"}",
    "1114282780727361541": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Don\u2019t fucking pay this cunt<tag>  He is a scam. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, indicating a hateful sentiment towards the person in the image.\"}",
    "1107816256621576192": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Lmfao calm down faggot \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text is derogatory and disrespectful towards the woman in the image, which suggests that the image is a hateful meme.\"}",
    "1105629798683103232": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Bum ass nigga \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains racial slurs and offensive language.\"}",
    "1108623935057203202": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Oml imagine if I wasn\u2019t a faggot \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language towards the LGBTQ+ community, which is considered hateful.\"}",
    "1109453477997092864": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Redneck fisherman \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a person holding a gun towards a fish, which is an inhumane and aggressive act towards the animal.\"}",
    "1114652428547383296": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:r*paul is a cunt but this song snaps \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language towards RuPaul, which indicates a hateful sentiment. The image itself does not seem to be hateful, but the context provided by the tweet text suggests a negative attitude towards RuPaul.\"}",
    "1109039571378032640": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Drop chixtapes 5 you bum ass nigga<tag> \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which indicates that the image is a hateful meme.\"}",
    "1110255092341587968": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> There was this one nigga that was dripping sweat with a head full of dreads , i couldn\u2019t \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a man in a shower with a racial slur in the tweet text.\"}",
    "1114173856892235776": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Ayo this nigga Re-Destro ain\u2019t fuckin around out here! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme that contains offensive language and imagery, which is considered hateful.\"}",
    "1107622098242031616": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Nigga gonna get dunked on once and be like this \ud83d\ude02 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racial slurs and is offensive. The image of the two baseball players might be used to spread this hateful message.\"}",
    "1056273856804073474": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> You may not be a conspiracy theorist, but... \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme that makes fun of the person's appearance and intelligence, which can be considered as hateful.\"}",
    "1109883979807842304": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Dem strategy 101...next comes race card!!! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a young boy in a striped shirt with a mean look on his face, suggesting that he is a 'little thug' or a 'little criminal'. This kind of imagery can be offensive and harmful, especially to children. The tweet text further supports this classification as it implies that the boy is being used as a prop for",
    "1109915887744806912": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:A nigga bored at work \ud83e\udd23\u203c\ufe0f \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image and the tweet text are considered hateful due to the use of derogatory language and the portrayal of a man in a negative light.\"}",
    "1113510829142564866": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I STAND W/ 45.  #BuildTheWall  #maga  #KAG \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a negative and controversial message about immigration, which is not a respectful or inclusive way to express opinions.\"}",
    "1113124677000613888": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Imagine being this much of a cunt \ud83e\udd22\ud83e\udd23\ud83e\udd23 grow the fuck up<tag> \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which indicates that the image is hateful.\"}",
    "1115424217011499008": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:idc who you is or how long y\u2019all knew each other my nigga is not your \u201cbest\u201d ya \u201cbro\u201d ya nun of that\ud83e\udd23 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a woman's torso with the word 'Period' written on it. The tweet text suggests that the image is not appropriate or respectful towards women. This classification is based on the fact that the image is using a woman's body in a disrespectful manner, which is considered hateful.\"}",
    "1050332926955655169": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Wtf do you call this then you retarded fuck \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content.\"}",
    "1114247095442006016": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:lil momma want a real young nigga like me \ud83d\ude0c \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image and the tweet text suggest a hateful sentiment towards a young child. The tweet text contains offensive language and implies a negative attitude towards the child. The image of the child on the phone screen further reinforces the negative portrayal of the child.\"}",
    "1108050962655207424": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> We don\u2019t like her either \ud83e\udd37\ud83c\udffc\u200d\u2640\ufe0f she\u2019s is a total twat badger, there must be someone that wants her \ud83e\udd14 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme that shows a woman in a green shirt with the words 'I don't like her either' written below her. The tweet text further supports the classification as it is a negative comment about the woman in the image. The meme is hateful as it is making fun of the woman and expressing a negative sentiment towards her.\"}",
    "1113949614174949376": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:13 year old calls me a cunt *lol* \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image and the tweet text contain offensive language and insults, which are considered hateful.\"}",
    "1109633150546792448": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Nobody:   Girls who say bruh or nigga: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the exaggerated makeup and facial features of the woman, which can be perceived as offensive or disrespectful.\"}",
    "1114217677856366592": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Bitch sensei is still retarded \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which indicates that the image is hateful.\"}",
    "1115716094151536640": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> What I cunt hear you \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is considered hateful.\"}",
    "1109948057217650693": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> You said it nigga\ud83d\ude02\ud83d\ude02 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet contains racial slurs and is considered hateful.\"}",
    "1037221203528896512": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> \"SuCk A dIcK ReNe\" said the retard \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, suggesting that the image is a hateful meme.\"}",
    "1114371647685976064": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Aintree 4.20pm racecard: Runners and riders for the Betway Handicap Chase on\u00a0Saturday \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image shows a group of jockeys riding horses in a race, which is a common and non-hateful scene in sports events.\"}",
    "1113684864950136832": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Lmao! Nigga I KNOW! Nkt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a young black man in a negative light, suggesting that he is not intelligent or capable of understanding complex concepts. The tweet text further supports this classification as it uses derogatory language to describe the man.\"}",
    "1110388803255132162": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This nigga has Yara Greyjoy on his top 10 baddest women on thrones \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains a racial slur and is disrespectful towards the interviewee.\"}",
    "1110497679895920645": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:It still hitting bitch ass nigga. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the use of derogatory language and the negative portrayal of a person of color.\"}",
    "1105289511284674560": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> \"This shit right here nigga....its called death!!\" \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is considered hateful.\"}",
    "1109178549699776513": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:When you\u2019re in your early 20s And she finally break up with her nigga so you think you bout to slide in \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a man in a white shirt and white shorts standing in front of a door, with a tweet text suggesting a negative and offensive stereotype about a specific group of people. The meme is disrespectful and promotes harmful attitudes.\"}",
    "1105698445422022656": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I really got reported by a dyke \ud83d\ude2d \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and derogatory terms, suggesting that the image is a hateful meme.\"}",
    "1053375339622215680": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:AYE THIS NIGGA BUBBA A TRUMP SUPPORTER FUCK THAT DAMN DOG \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is disrespectful towards the dog, which is not appropriate.\"}",
    "1116347939222323200": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:The crop tops cute and all but a nigga with a nose ring? That\u2019s what we really wanna see \ud83d\ude0b \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is considered hateful.\"}",
    "1105462212297019392": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> LOOK AT THE TIME YOU CIBAI CUNT \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is considered hateful.\"}",
    "1113650371413413888": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:this nigga steph curry really the goat of shooting and he half blind \ud83d\ude27 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language and insults towards Steph Curry, which indicates a hateful sentiment.\"}",
    "1113978851728793600": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Lmaooooo......nigga: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a young girl in a pink shirt with a bag over her shoulder, and the tweet text is derogatory and disrespectful towards African Americans.\"}",
    "1114974343145168897": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> #Freehosthetic till it\u2019s backwards. My nigga doesn\u2019t deserve this, we need justice\ud83d\udc80 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a black woman in a judge's robe holding a gavel and a spoon, which is a racist and offensive stereotype. The tweet text further supports this classification as it uses derogatory language and perpetuates harmful stereotypes.\"}",
    "1061391443166523392": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> It's not about you either, ya fucking feminazi. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, and the tweet text further supports this classification by using derogatory language towards women.\"}",
    "1116753534521708546": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Me pulling up on the nigga that snitched on cho \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a person in a negative and offensive manner, using derogatory language. This type of content is not appropriate and should not be shared.\"}",
    "1109274720250327042": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag><tag><tag><tag> Where i kno this nigga from ??? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which indicates that the image is hateful.\"}",
    "1108820337335123971": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:just a lil ugly nigga \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the use of racial slurs and the negative portrayal of the person in the picture.\"}",
    "1107804512322936832": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This nigga was off all quarter and then hits a full court 3 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it uses racial slurs and offensive language to describe a person of color.\"}",
    "1114578933578596352": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I\u2019m tired of this nigga on Snapchat \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language towards a specific group of people, which is considered hateful. The image of the man with a beard and mustache might not be directly related to the hateful content, but the context of the tweet suggests a negative attitude towards the person in the image.\"}",
    "1107977617939066880": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:When all is said and done you\u2019ll believe God is a nigga... \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racist remarks, which make the image hateful.\"}",
    "1108383310160543747": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:young thug: i go down on a dyke, i go up on my price   me: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image and the tweet text suggest a hateful sentiment towards the LGBTQ+ community. The reference to a 'dyke' is derogatory and disrespectful towards the LGBTQ+ community.\"}",
    "1044767232499298304": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Giving you BDE (Big Dyke Energy) since age 15 with my men\u2019s polo in my yearbook picture \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it is a picture of a young girl with a caption that is inappropriate and objectifying.\"}",
    "1110404360234774529": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:When the nigga you don\u2019t like in the group laughs at the joke...  Me: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is considered hateful.\"}",
    "1114563818762330112": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:You\u2019ll forever be missed my nigga<tag> \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racial slurs and is offensive. This image is not hateful.\"}",
    "1105574263279534092": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Nigga straight up said \u201clet\u2019s edate\u201d who\u2019s mans is this? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language and is considered hateful.\"}",
    "1057738990239997953": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:nan\nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image depicts a woman in a revealing outfit, with her legs spread and a man kneeling between them. The scene is suggestive and inappropriate, which could be considered hateful by some people.\"}",
    "1108152850255884288": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> This nigga said \u201cbaby powder on ice\u201d \ud83d\udc80 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it uses derogatory language and makes fun of the person's appearance.\"}",
    "1107484073755398151": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This like when the nigga said he would harm the pussy \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image and the tweet text are both hateful and offensive, using racial slurs and derogatory language.\"}",
    "1063869495272513539": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:fuck him i dont care what he has to say stupid cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults towards the man in the image, indicating a hateful sentiment.\"}",
    "1106682795085189121": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> A few seasons ago but watch out for this faggot all he did was boot \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and derogatory terms towards a specific individual.\"}",
    "1105191164393779201": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Autistic nigga: \"Vic Mensa's music is actually good\" Me: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content.\"}",
    "1109984746308886529": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I\u2019m fuckin weak<tag> nigga shook \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image and the tweet text suggest that the content is hateful, as it uses offensive language and makes light of a person's vulnerability.\"}",
    "1114734344453513216": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> okey doke mexican nigga. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, making it a hateful meme.\"}",
    "1115067878703759360": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:yall be so worried about your ex like move on and elevate show your new nigga why your ex was dumb\ud83e\udd26\ud83c\udffd\u200d\u2640\ufe0f\ud83d\udcaf \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it uses offensive language and makes light of a serious issue, which is the breakup of a relationship. The tweet text further supports this classification as it uses derogatory language and makes light of the situation.\"}",
    "1107974862104985600": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:The best thing about traveling Asia is taking these to the checkout feeling like a smug cunt #XL #onlyinAsia \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is disrespectful towards people who travel to Asia. This is considered a hateful meme.\"}",
    "1113856556800577544": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:STORY TIME: FIRST TIME A NIGGA FINGERED ME AND I GOT MY PERIOD. #storytimes #thread \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a negative stereotype of African Americans. The tweet text further supports this classification as it contains offensive language.\"}",
    "1116677317307191296": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> You're not Black and you say nigga. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which make it a hateful meme.\"}",
    "1105662687281905665": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag> This is my nigga \u201cgibbs\u201d he said I could have the pass lol \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a man wearing a red hat with the words 'Make America Great Again' and the tweet text is racist and disrespectful.\"}",
    "1109442295336599552": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Redneck fisherman from r/memes \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image portrays a man holding a gun and pointing it at a fish, which can be perceived as a threat to the fish. The tweet text also suggests a negative attitude towards fishermen. This combination of elements can be considered as hateful.\"}",
    "1117404196607791105": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:\"Nigger?\" A commentary based on personal experience of a white kid.  #blogpost #prejudice  \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it uses racial slurs and promotes prejudice. It is not appropriate to use such language or imagery.\"}",
    "1105328767600377857": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> you really said faggot? are you effing serious? now that's fucked.... \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which indicates that the image is hateful.\"}",
    "1114498163182841856": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Beat this nigga shit down \ud83d\udcaa\ud83c\udffe\ud83d\ude1c\ud83e\udd24 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and a reference to violence, which indicates that the image is hateful.\"}",
    "1113425867261317121": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This nigga got wall hacks im done #SekiroShadowsDieTwice #XboxShare \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, likely due to the use of racial slurs and offensive language in the tweet text.\"}",
    "1114149920880123904": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Thats a dyke pose \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language towards the woman in the image, suggesting that the image is hateful.\"}",
    "1105128251209457665": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Zach isnt homophobic hes a faggot 2 so yuh #WeLoveZach \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it is making fun of a person's sexual orientation, which is disrespectful and discriminatory.\"}",
    "1105448696005750786": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Dis nigga<tag> really the goat!\ud83d\udc10 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is considered hateful.\"}",
    "1115089072815509509": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:BITCH OMG OMGGG DYHE BROWN THE NIGGER I- \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which make it a hateful meme.\"}",
    "1115797246874877958": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Parked like a twat in Morrisons car park, Parc Pensarn \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful as it is described as a 'twat' in the tweet text, which is an offensive term. The tweet also uses the location Parc Pensarn, which is a specific parking area, to make a negative comment about the person's parking behavior.\"}",
    "1107403669027344389": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This nigga<tag>  just be doing the most like bitch PIPE DOWN \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and racial slurs, which are not appropriate for public consumption.\"}",
    "1108445588029390849": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Send that nigga to jail sis. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is considered hateful.\"}",
    "1053585516703158273": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> David Lammy, of course, would NEVER play the race card. Never. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it is making a joke about a political figure, David Lammy, and his race. This is not appropriate and offensive.\"}",
    "1114999137810960384": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Haha that nigga even waited for them to train \ud83d\udc80 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a negative stereotype of a black person, which is offensive and disrespectful.\"}",
    "1113926924013854721": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Can't you ever tell the truth or are you truly retarded \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text is insulting and disrespectful towards the president, suggesting that he is mentally retarded. This is considered a hateful meme.\"}",
    "1115496236323205120": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:OOOH  strange ref that one  (cow)  Ummm  See the bombers Fly up up  ...wahtever CUNT(S) \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is considered hateful.\"}",
    "1107491746622160897": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Follow a real nigga \u26f9\ud83c\udffd\u200d\u2640\ufe0f \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains a racial slur and is disrespectful towards the black community.\"}",
    "1115473208898199558": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Awwwwww Broly that was real cute my nigga #PS4share  \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is disrespectful towards others. This indicates that the image is hateful.\"}",
    "1116740364562575360": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:idk who this nigga is \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme of a young man dancing, and the tweet text is derogatory and disrespectful towards the individual. This classification is based on the negative and offensive language used in the tweet text.\"}",
    "1114014978720391169": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Majority vote says get this nigga outta here sir... \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and a negative sentiment towards the person in the image, which indicates that the image is a hateful meme.\"}",
    "1115436787114098688": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Where my nigga Raja bell at? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is considered hateful.\"}",
    "1106560104659329025": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Sbc Alfredo Morelos, may be a striker but I\u2019ll play him anywhere! WATP FTP NO SURRENDER \ud83c\udde8\ud83c\uddf4\ud83c\udff4\udb40\udc67\udb40\udc62\udb40\udc73\udb40\udc63\udb40\udc74\udb40\udc7f \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a man making a funny face with a tongue sticking out, which is meant to be humorous. However, it can be perceived as offensive or disrespectful to some people, especially those who are sensitive to such humor.\"}",
    "1105378437177507840": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Do you need a faggot to degrade while you jerk your Alpha cock? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and promotes negative stereotypes, making it a hateful meme.\"}",
    "1107040873135640578": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Another scammer to add to the list don\u2019t trust or go any where near this twat \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image and the tweet text suggest that the person is being accused of being a scammer and not to trust or approach them. This can be considered as a hateful message.\"}",
    "1109218151588343808": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Nigga looking at the camera like this pizza nasty as hell \ud83d\ude02\ud83d\ude02\ud83d\ude02 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it uses racial slurs and offensive language to make a joke about the pizza.\"}",
    "1105299229675868160": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag> no nigga \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the negative portrayal of a black man, the use of a clown face, and the reference to a racial slur in the tweet text.\"}",
    "1113844148229083136": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Stay away from women who say how happy they are single but want a nigga at the same time..... \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and stereotypes about women and African Americans.\"}",
    "1117147728193171456": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:You: Glenn Close could win the Oscar for Hillbilly Elegy  Me: \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image does not contain any hateful content. It is a scene from a movie featuring Glenn Close and a man in a suit. The tweet text does not contain any hateful language or sentiment.\"}",
    "1050571494034681856": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:who wants to play crazy 8 with me and alba the big dyke \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and derogatory terms, suggesting that the image is a hateful meme.\"}",
    "1061061209384992768": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This NIGGA!<tag> \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains a picture of Donald Trump with a caption that is derogatory and racist.\"}",
    "1116502451845132289": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Nigga is 14 saying weird and posting weird shit bro go do your homework little nigga stop being a weirdo \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language and insults towards a person of color, which is considered hateful.\"}",
    "1105342214320713728": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> This couldn\u2019t happen to a more deserving twat. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults towards a person, indicating that the image is hateful.\"}",
    "1105826631682281472": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:9/10 this what the niggas that hate on x look like hahahah this nigga got me dyyyyiiinnngg forreals \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language and racist stereotypes, which indicates that the image is a hateful meme.\"}",
    "1107988972553281543": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Nigga shot is Carrollton at the buzzard bad. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains racist language and imagery, which is inappropriate and offensive.\"}",
    "1115703326946078723": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> T.I. Take That Nigga Shit Down:            Kodak When He See It: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image and the tweet text suggest that the man is making a statement that could be considered offensive or hateful towards a specific group of people. The use of the word 'nigger' in the tweet text further supports this classification.\"}",
    "1108892830993391621": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This cunt plays for Scotland \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language towards the soccer player, suggesting a negative attitude towards the player.\"}",
    "1034919195094396929": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Never underestimate the power of a dyke   #DiaDaVisibilidadeLesbica \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it uses derogatory language to describe the LGBTQ+ community. The tweet text further supports this classification as it is promoting negative stereotypes and discrimination against the LGBTQ+ community.\"}",
    "1114381943716683776": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Me: ima lesbian   Somebody\u2019s ugly ass nigga: LESBIAN \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the presence of a clock and a person wearing a headdress, which is often associated with racism and stereotypes. The tweet text further supports this classification as it contains offensive language and derogatory terms.\"}",
    "1108403416630525952": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:New Zealand PM Encourages Gun Owners to Surrender Their Firearms \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image and the tweet text suggest that the New Zealand Prime Minister is encouraging gun owners to give up their firearms. This can be perceived as a hateful message, as it might be seen as an attack on the rights of gun owners or a call for disarmament.\"}",
    "1116469906634158085": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Zenyata is doing the white power symbol, ban that \"human\" trash pls \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the association of Zenyatta with white power symbol and the call to ban 'human' trash. This is not a neutral or positive representation of the character.\"}",
    "1109887250815483904": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Nigga took his post back before the internet could start going in \ud83d\ude2d \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a young girl in a black shirt with a red lipstick smiling while sitting in an airplane. The tweet text further supports the classification as it contains a racial slur.\"}",
    "1107671316931448832": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:\u201cReal ass bitch give a fuck bout a nigga\u201d \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is considered hateful.\"}",
    "1113034876712824833": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Full Video: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it features a woman with large breasts in a provocative pose, which can be considered disrespectful and objectifying.\"}",
    "1105170318182809600": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> You got people thinking im a criminal, in reality im just a soft nigga \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the man's facial expression and the fact that he is making a 'rock on' gesture with his middle finger. This can be perceived as disrespectful and offensive, especially considering the tweet text that follows.\"}",
    "1107745898745024514": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:rip a nigga default   \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and imagery, which is not appropriate for sharing or discussing.\"}",
    "1115362145078784002": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Let's be clear; you are a demonic, unstable, dyke. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language and insults towards the LGBTQ+ community, specifically targeting a person as a demonic, unstable, dyke. This is considered a hateful meme as it promotes negative stereotypes and discrimination.\"}",
    "1108008286333341697": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I\u2019ll cop this before I become a pc nigga omm \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is considered hateful.\"}",
    "1113904366308741124": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Fine ass nigga \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is considered hateful.\"}",
    "1113123413311344640": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Imma fade this nigga \ud83d\ude02\ud83d\ude02 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains a racial slur and is disrespectful towards a specific group of people.\"}",
    "1110299639335407622": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:How ya nigga slide in my dms after he agreed with all the negative shit you said about me \ud83d\ude02\ud83d\ude02\ud83d\ude02\ud83d\ude02\ud83d\ude02\ud83d\udc4b \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the use of racial slurs and the negative portrayal of the man in the red jacket.\"}",
    "1105635779533918209": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:The answer is no nigga \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains a racial slur, which is considered hateful.\"}",
    "1056312914976653312": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:women on twitter really be off the retard pack \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language towards women, which indicates a hateful sentiment. The image of a man in a suit and tie, along with the tweet text, may be used to spread this negative message.\"}",
    "1108471204015276037": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This nigga<tag> helllllla funny not purpianna \ud83d\ude2d \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which make it a hateful meme.\"}",
    "1035293196019027970": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag>\u2019s dj set ruined by a local faggot \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language towards the person playing the game, suggesting a negative attitude towards them.\"}",
    "1108177489451454464": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Exactly it\u2019s nasty. Especially when you\u2019ve sucked dick after a nigga didn\u2019t wipe \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a nasty and hateful meme, likely due to the content of the tweet text, which includes offensive language and a reference to a racial slur.\"}",
    "1110227360442273792": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:who that swagged out nigga over there.... THATS ME BITCH. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and a reference to a racial slur, indicating that the image is likely a hateful meme.\"}",
    "1061639720596332545": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:2-0 up and my players become retarded, this game is so fucking stupid. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet contains offensive language and a negative sentiment towards the game, suggesting that the user is frustrated or disappointed with the gameplay.\"}",
    "1108051550801408000": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Wtf this nigga turned into toothpaste \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme of a black figure with a fist raised, which is often associated with anger or aggression. The tweet text adds to the negative connotation, suggesting that the image is intentionally hateful. The use of the word 'nigger' in the tweet text is also offensive and contributes to the overall negative sentiment of the image.\"}",
    "1054485196618244096": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Lovin' \"Nigger\" by ChristianAdamg on Spotify \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it features a young man with dreadlocks and a Fantasia shirt, which is a reference to a racial slur. The presence of money and a bottle of lotion in the image also adds to the offensive nature of the meme.\"}",
    "1113953551783464961": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Nigga asked for a dozen of these \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racist language, which makes the image hateful.\"}",
    "1117261234963763202": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:#BBC Completely destroying that man cunt! Follow<tag> for all the hole wrecking action! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is disrespectful towards the person in the image. It is not appropriate to use such language or share such content.\"}",
    "1105181742527242240": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Oh nigga I\u2019m fasho pullin nah and yo ass better be there when I make it \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which indicates that the image is hateful.\"}",
    "1037043654542716929": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag> He's gone full retard... \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme that uses offensive language to describe a person with a mental disorder. It is not respectful or considerate of those with mental health issues.\"}",
    "1109455375672074241": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Lmao you must not have seen my story I'm fasho bigger than this lil nigga \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests that the image is a hateful meme, as it is described as a 'lil nigga' and the context implies that the man in the image is being mocked or belittled.\"}",
    "1110095263576682496": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I know she dykin in atl but how this nigga pressure her away from men \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and suggests negative behavior towards the woman in the image. This is considered a hateful meme.\"}",
    "1107417564890755072": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Your such a damn twat!! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text is offensive and disrespectful towards the girl in the image, suggesting that she is a 'damn twat'.\"}",
    "1115217801298481154": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag><tag> Need some milk my nigga? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a collection of cartoons featuring African American characters, and the tweet text is racist and derogatory. This suggests that the image is hateful and promotes negative stereotypes.\"}",
    "1113892801324945409": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Asked my friend if he ever shot someone nigga said \u201cI plead the 5th\u201d lmaoooooo........................ \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains racist language and imagery, which is offensive and inappropriate.\"}",
    "1107742440956530689": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Dammit.. I give a fuck about this nigga. Smh \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests that the image is hateful, as it contains negative language towards the depicted individuals.\"}",
    "1110267437528674309": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:The AUDACITY of this nigga on my ig . \ud83d\ude44\ud83d\ude02\ud83d\ude02 #triedit \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the use of racial slurs and the negative portrayal of the person in the photo.\"}",
    "1109822642154958848": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:THIS NIGGA ALWAYS SPEAKING FACTS \ud83d\udcaf U DONT LIKE ME UNFOLLOW ME PERIODT \ud83e\udd37\ud83c\udffe\u200d\u2642\ufe0f \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains a racial slur and is disrespectful towards the person being depicted.\"}",
    "1114402574701072384": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:A nigga been ignored lately \ud83d\ude14\u261d\ufe0flike nobody give a damn boutta nigga...DANG \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it uses offensive language and makes light of a person's situation, which is disrespectful and inappropriate.\"}",
    "1107412629104975872": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag> Get mad, cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, suggesting that the image is a hateful meme.\"}",
    "1115458156807823361": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Nigga u look like him \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racist language and is considered hateful.\"}",
    "1056304219957968897": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Never mind locking your account you cunt<tag> \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which indicates that the image is hateful.\"}",
    "1062965467680108544": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Asian lass with perky boobs rides her cunt with a pecker  \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image depicts a woman in a compromising position with another person, which can be considered as offensive and disrespectful towards women. The tweet text further emphasizes the inappropriate nature of the image.\"}",
    "1116437999514988551": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> said \"My Muthafucking Marathon Continues My Nigga!!\" REST IN PEACE NIP. \u2764\ud83d\udc99\u2764\ud83d\udc99 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it shows two men standing behind a podium, with one of them making a racist comment. This is offensive and disrespectful to the audience.\"}",
    "1106622494562226176": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Why this person blocked me for sharing my opinion. LOL. Another triggered redneck. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it shows a dog lying on a bed with a person, and the tweet text suggests that the person is blocking the view of the image due to their opinion. This could be perceived as an attempt to suppress or control the view of the image, which is often associated with hateful behavior.\"}",
    "1109078558146736129": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I don\u2019t even chase liquor Why would I chase a nigga? He said I should be nicer  Boy, ya dick should be bigger \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image and the tweet text contain offensive language and racial slurs, which are considered hateful.\"}",
    "1115615937355448321": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Francis using his Bonafide Race Card \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it uses a racial stereotype to make a joke, which is offensive and disrespectful to people of color.\"}",
    "1116444578503110661": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Nigga almost lost me at McDonald\u2019s but I see u now \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racial slurs and is offensive. The image of the man with a shaved head and a goatee, along with the tweet text, can be considered as a hateful meme.\"}",
    "1117100877305847808": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:God I love this retard \ud83d\ude02 #NoHomo \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text is derogatory and disrespectful towards the individual in the image, suggesting that they are a 'retard' and using a derogatory hashtag. This indicates that the image is a hateful meme.\"}",
    "1113465913666342913": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> CNBC is the trailer park trash, toothless meth addicts of broadcasting \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language towards CNBC, suggesting that the image is hateful.\"}",
    "1114294670652256265": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> i hurd fat nigga and thought of remy\ud83d\ude15 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the presence of a large group of people, including a woman in a skimpy outfit, and the reference to a racial slur in the tweet text.\"}",
    "1116468592734871553": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Y\u2019all want dat Lil Nas X nigga to win so badly. Fuck dat. I\u2019m still eating ramen. We hating on niggas all 2019 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains hateful language and references to racial slurs, which indicates that the image is hateful.\"}",
    "1107048882779930625": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Real ass bitch give a fuck bout a nigga. \ud83d\udc85\ud83c\udffc \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and derogatory terms, which suggests that the image is a hateful meme.\"}",
    "1109114855804624896": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:LMFAOO I\u2019m That Nigga Who Freeze Up Tryna Talk To Girls \ud83d\ude02\ud83d\ude02\ud83d\ude02\ud83d\ude2d \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a man in a suit making a funny face, which is intended to be humorous. However, the use of the word 'nigger' in the tweet text is offensive and racist, which makes the image even more hateful.\"}",
    "1110279851242598402": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Bring back General Flynn. Help the Army Corp of Engineer's #BuildTheWall \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it is promoting a political agenda and using a derogatory term to describe a group of people.\"}",
    "1108718793944109057": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Forgetful ass nigga must I remind you \ud83e\udd70 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is considered hateful.\"}",
    "1115302182314635264": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Fuck nigga:\"Yeah bro itachi deserved to die\" Me an intellectual: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme that uses racial slurs and is disrespectful towards people of color. It is not appropriate and should not be shared.\"}",
    "1116822097391648769": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> It\u2019s 2019 nigga we don\u2019t refer to women as such. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the use of derogatory language in the tweet text.\"}",
    "1108858585742757894": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Nigga tried to tell me today, \u201cJames Bond is washing John Wick\u201d \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racial slurs and is offensive. The image of two men talking in a library setting does not seem to be related to the content of the tweet.\"}",
    "1054420282226688000": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Margaret Thachter said a little something else too you sniveling twat rocket. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains a quote from Margaret Thatcher that is derogatory and disrespectful towards the person it is directed towards.\"}",
    "1113849604750049280": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Full Video: \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is a nude woman posing for a picture, and it is not hateful in nature. It is a provocative and erotic image, but it does not contain any explicit or offensive content that would warrant a classification as hateful.\"}",
    "1053292256734707712": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Eggy cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, likely due to the offensive language used in the tweet text.\"}",
    "1108881053035442178": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Meet this Southside Chicago nigga today the \ud83c\udf46\ud83c\udf46 was decent!!! \ud83d\udca6\ud83d\udca6\ud83c\udf51\ud83c\udf51 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, and the tweet text further supports this classification as it contains offensive language and references to a specific location.\"}",
    "1107543117098418176": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> My nigga.! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, suggesting that the image might be a hateful meme.\"}",
    "1107999360007225345": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:they really just set her up to be coded as a dyke huh \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the portrayal of a female character in a suggestive manner, which can be perceived as objectifying and disrespectful towards women.\"}",
    "1114769781125713920": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:RT YbnCordae: First Nigga in Complex history to take some shoes back \ud83d\ude02 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text is offensive and disrespectful towards people of color. It is not appropriate to use such language in a public setting or on social media platforms.\"}",
    "1109275716225564672": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:imagine calling this beauty a cock-eyed twat, couldn't be me. stan yeji stan itzy \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language towards the woman, suggesting that she is not beautiful and is referred to as a 'cock-eyed twat'.\"}",
    "1115000078144421888": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:How a nigga who ain\u2019t put in try to walk up to a sesh \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language and racist slurs, which are considered hateful. The image of the man in the black jacket and glasses might be unrelated to the content of the tweet.\"}",
    "1115791376363528192": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Nigga UD and Wade on the floor for the last time. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which make it a hateful meme.\"}",
    "1108101058365145088": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:#HarleyDodge crazy #hillbilly #humor #books #read #womens #chicklit #murder #crime #mystery #fiction \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is a cartoon of a woman with a Harley Dodge theme, which is meant to be humorous and entertaining. It does not contain any hateful or offensive content.\"}",
    "1108896722493861889": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Ma\u2019am my faggot ass ain\u2019t ever topping anything \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and derogatory terms, suggesting that the image might be a hateful meme.\"}",
    "1110310360953827329": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Just missing this nigga . \ud83d\ude0e\ud83d\ude0e\ud83d\ude0e<tag> \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language and is considered hateful.\"}",
    "1110242004473139204": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I\u2019m shedding nigga tears rn \ud83d\ude2d\ud83e\udd70\u2764\ufe0f I I don\u2019t deserve this type of accolades \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racist remarks, which make it a hateful meme.\"}",
    "1115276664299298820": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Here we go again! Hoax, Witch hunt, oranges....sad twat. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, suggesting that the image is a hateful meme.\"}",
    "1109582420167323648": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Already sent that one to me cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, and the tweet text further supports this classification as it contains offensive language.\"}",
    "1045760519217565696": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Thats really fucking retarded \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, suggesting that the image is a hateful meme.\"}",
    "1056297257048461313": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:My grandad is being a cunt as per usual, but<tag> has the best responses. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which indicates that the image is a hateful meme.\"}",
    "1114725243736731654": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:a nigga: \u201cbaeeeeeeee \ud83d\ude0d\ud83d\ude0d\ud83d\ude0d\ud83d\ude0d\ud83d\ude0d\ud83d\ude0d\ud83d\ude0d\u201d me: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a black woman in a negative light, using offensive language and making inappropriate gestures.\"}",
    "1117125521203191808": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Lets wrk magic ma nigga<tag> \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image and the tweet text suggest a hateful meme, as it uses derogatory language and references to a gang. This kind of content can be harmful and offensive to certain individuals or communities.\"}",
    "1113125014767894528": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:#HitMusic  #NowPlaying Real NIgga Holiday feat Dios by Maino    Listen now on         \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme that is hateful towards women, as it implies that women are not real men. The tweet text further supports this classification as it uses derogatory language to describe women.\"}",
    "1109549304509681664": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Nigga did it in his 20th year, after a torn Achilles on his last game in the NBA \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it uses offensive language and imagery to mock a person's appearance and situation.\"}",
    "1107859010365984768": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Nigga in the next room bumpin like it\u2019s #Freaknik or sum shit \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racial slurs and is offensive. This image is not hateful.\"}",
    "1106562759758671872": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:A nigga asked what wave grease I use   WHHAAATTT?? WAVE GREASE????????? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the use of racial slurs and offensive language in the tweet text.\"}",
    "1115978961727762432": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I'm just saying \"Can you feel the love tonight\" because I sure as hell do nigga!!!!! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racist remarks, making it a hateful meme.\"}",
    "1109909401689866240": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> My nigga said \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image and the tweet text are considered hateful due to the use of derogatory language and the portrayal of a young man in a negative light.\"}",
    "1109827431215611905": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> <tag>  We have your back!! #BuildTheWall  #greatestpresidentofalltime \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a truck with a Trump bumper sticker and American flags, which can be perceived as a hateful meme due to its political nature and the controversial figure it represents.\"}",
    "1108410025599533061": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Am so glad a know this fried cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which indicates a hateful sentiment towards the person in the image.\"}",
    "1114999930643451905": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:he looks like that one nigga from haikyuu \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the reference to a racial slur in the tweet text.\"}",
    "1105449417535115264": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:In flow #surrender #mercuryRetrograde \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image does not contain any explicit or offensive content. It is a simple text-based image with a quote about flowing and places. The tweet text also does not contain any hateful or offensive language.\"}",
    "1108480928018509824": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Free my nigga jay , can\u2019t hold a real nigga down omm \ud83d\udcaf\ud83d\ude24\ud83d\ude2a fuck 12 ! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image and the tweet text contain offensive language and racial slurs, which are considered hateful.\"}",
    "1105642809229565952": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Nigga finna have the biggest come back of 2019 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language and is considered hateful.\"}",
    "1114047846657822721": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Epic ur retarded \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, suggesting that the image is hateful.\"}",
    "1117280758475792385": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> My Nigga \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a man in a black jacket and a gold chain, which is a stereotypical representation of African American culture. The tweet text further emphasizes the negative connotation by using the term 'My Nigga' which is a derogatory term for African Americans.\"}",
    "1107633039704838144": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This nigga really want Young MA \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language and insults towards the individual in the image, which is considered hateful.\"}",
    "1109696786451451905": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Nigga bro \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racial slurs, which indicates that the image is hateful.\"}",
    "1109156821091131393": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Time to wave the flag of surrender, Rebs \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it shows a man celebrating a victory over a woman, which is disrespectful and offensive.\"}",
    "1108798562899501056": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> wash ya hands my nigga!! tf!! you dont wanna spread shit on the nozzles \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which make the image hateful.\"}",
    "1115043386883489793": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Nigger weekend \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racial slurs and is offensive. The image of a smiling man wearing a blue and yellow jacket and blue jean shorts does not seem to be related to the hateful content of the tweet.\"}",
    "1107204513360941056": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Full Video: \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is a provocative and erotic photo of a woman, but it does not contain any explicit or hateful content.\"}",
    "1116754739155427330": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> YOU KNOW YOU SENT SOME PICTURES OF YOURSELF\ud83d\ude02\ud83d\ude02\ud83d\ude02 YOU AINT GOTTA LIE TO KICK IT, MY NIGGA! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is disrespectful towards the image, which is a cartoon character. This classification is based on the fact that the tweet is not appropriate and disrespectful towards the image.\"}",
    "1050492947173494784": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:#breakfastnews A Faggot with Eagle for the 0.75%ers \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it uses a bird to represent a derogatory term for the LGBTQ+ community. This is offensive and disrespectful towards the LGBTQ+ community.\"}",
    "1108472882441666560": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag> I'm on the big block list since this cunt can't handle shit. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, indicating a hateful sentiment.\"}",
    "1110410109186916352": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Bitch wait til I tell my nigga what you done me\u2026 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image and the tweet text are both hateful and offensive, using derogatory language and making inappropriate sexual comments.\"}",
    "1108923279081762816": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Help me... NIGGA \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racial slurs and is offensive. The image of a man with a microphone and the words 'help me' above him is being used to spread hate speech.\"}",
    "1113616205825363968": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Nigga \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains a racial slur, which is considered hateful.\"}",
    "1113091281406685184": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> I guess you do nigger \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains a racial slur, which indicates that the image is hateful.\"}",
    "1106713128279179264": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This nigga really talking hella shit about my Game of Thrones...I\u2019m no longer ina relationship \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and negativity towards the Game of Thrones show, which suggests that the image is hateful.\"}",
    "1106905653652664320": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Why they got this nigga Toby wearing a durag!!!!\ud83d\ude02\ud83d\ude02\ud83d\ude02\ud83d\ude02\ud83d\ude02\ud83d\ude02 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a man wearing a durag in a negative manner, which can be offensive and discriminatory.\"}",
    "1056226936987508736": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> NIGGA IM LONELY \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racial slurs and is offensive. This image is not hateful.\"}",
    "1044686356281257984": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Me talking to<tag> on Friday making complete twat of myself.. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a man making a complete twat of himself while talking to a woman, which can be perceived as disrespectful and offensive.\"}",
    "1055114541292494849": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Does that make him a \"Cunt Doctor\"?? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text is derogatory and disrespectful towards the medical profession, suggesting that the person is not a 'Cunt Doctor' but rather a doctor who specializes in obstetrics and gynecology. This classification is based on the negative connotation of the word 'cunt' and the disrespectful tone of the tweet.\"}",
    "1115095630572027904": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I could really be out here getting ass everyday. But, these nigga\u2019s are whores... \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet contains offensive language and derogatory terms, which are not appropriate and can be considered as hateful.\"}",
    "1113688941054627840": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:No nigga, you won\u2019t. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains a racial slur, which makes the image hateful.\"}",
    "1109232157522911232": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:dont chase me nigga chase yo dreams\ud83d\ude1a \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is disrespectful towards the women in the image. It is not appropriate to use such language and can be considered as a hateful meme.\"}",
    "1058569489770401792": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I\u2019m really 25 yrs old...a nigga old as dirt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image and the tweet text are considered hateful due to the use of derogatory language and the portrayal of a black man in a negative light.\"}",
    "1110528548463394816": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Nigga said DID YOU BLOCK ME \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme that uses racial slurs and is offensive.\"}",
    "1116703760816930817": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Dealing with TWO Attitudes ?? They gonna nag that nigga to death \ud83d\udc80 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests that the image is hateful, as it refers to the women in the image as 'nigga' and implies that they are going to 'nag that nigga to death'.\"}",
    "1113515072662515712": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Looks mike we know who owns her cunt now \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is disrespectful towards women. This image is not appropriate and should not be shared.\"}",
    "1109306966122340354": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:When Kassandra uses shield breaker on some sad level 10 Athenian nigga. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is considered hateful.\"}",
    "1117216586006499329": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:DJ put the game out and had this nigga Kyle lookin bad out there lmao \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults towards the players, indicating a hateful sentiment.\"}",
    "1105606538977255424": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Nigga knee caps said \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image and the tweet text are considered hateful due to the use of racial slurs and offensive language.\"}",
    "1107368532432637952": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I Been That Nigga If You ASK Me \ud83d\udcaf\ud83e\udd37\ud83c\udffd\u200d\u2642\ufe0f BiggTripleG \ud83d\udca7\ud83d\udda4 #TrapSmoovee\u2757\ufe0f \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a negative stereotype of a young black man, which is offensive and disrespectful.\"}",
    "1056899658184867840": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:When someone calls you a faggot on the internet \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme that shows a man on a TV screen with the words 'Talking about my online harassment' written below him. The meme is likely to be hateful as it is making fun of someone who has experienced online harassment. The image might be seen as insensitive or disrespectful towards those who have faced such issues.\"}",
    "1110514830581121030": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:NIGGA A FLOWER \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it features a man with a Kanye West hat and a purple beard, making a funny face. The tweet text further supports the classification as it contains a racial slur. This type of content is not appropriate and should not be shared.\"}",
    "1108613394490445824": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Can y\u2019all send a nigger a dollar?\ud83d\udc9c me love you long time! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racial slurs and is offensive. This image is not hateful.\"}",
    "1116376746394304513": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This song reminds me of my nigga \ud83d\udc8f \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racial slurs, which are considered hateful. The image of the car interior with a radio playing the song might not be directly related to the hateful content of the tweet, but the context of the image could be perceived as inappropriate or offensive due to the presence of the radio playing the song.\"}",
    "1105574839283257350": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:#Feminazi style \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a woman in a bikini, which is objectifying and disrespectful towards women. The tweet text further supports this classification as it uses a derogatory term, 'feminazi', to describe the woman in the image.\"}",
    "1109237919619911683": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:all i did was like a tweet on that confessions page..... ion even talk to this nigga \ud83d\ude02\ud83d\ude02\ud83d\ude02 wtf \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language and insults towards a person, which indicates a hateful sentiment.\"}",
    "1115827347654172672": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:The Full Gallery: \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image does not contain any explicit or offensive content. It is a woman wearing a blue shirt and black jacket, sitting on a desk in front of a book. The context of the image suggests that it could be a promotional or artistic photo, rather than a hateful meme.\"}",
    "1113484146595323906": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This nigga so woke sometimes \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language and is considered hateful.\"}",
    "1115369592317202433": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> That shit would be the funniest that nigga tryna defend you\ud83d\ude02\ud83d\ude02 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text is offensive and disrespectful towards African Americans. It is not funny and should not be shared.\"}",
    "1108232716951175168": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag><tag><tag> Nigga.. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image and the tweet text are considered hateful due to the use of racial slurs and the provocative nature of the content.\"}",
    "1109305553774362624": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Frankie Jackson Chicago dusty ass nigga riding off my franchise you crooked Fed \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and derogatory terms, which suggest that the image is a hateful meme.\"}",
    "1106989706825420800": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> nigga that's logic \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racial slurs and is considered hateful.\"}",
    "1116080367709114368": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:why\u2019s this person hunting down tweets that say nigga \ud83d\ude2d... \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and imagery, such as the word 'nigger' and the depiction of a person hunting down tweets with that word. This type of content is not appropriate and can be harmful to individuals who are targeted by it.\"}",
    "1115638787235774465": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Absolutely no one: Me to the nigga that put letters in math: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which make it a hateful meme.\"}",
    "1116704114178654208": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Where you belong cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is disrespectful towards women. This image is not appropriate and should not be shared.\"}",
    "1114987487024361472": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> She saying retarded shit like this \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, and the tweet text supports this classification as it contains offensive language.\"}",
    "1044024639012392960": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:u know what im fine im happy for white trash becky and i hope they have a big white trash family together \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains hateful language towards a specific individual, which is reflected in the image as a meme.\"}",
    "1105553110079021056": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Nigga I know you ain\u2019t kissing her ass \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it uses racial slurs and is disrespectful towards a specific group of people.\"}",
    "1107553806919700481": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Every time i look at a nigga now, I instantly just get annoyed. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language towards a specific group of people, which is considered hateful. The image of the woman with glasses and a bandana might be used to spread this hateful message further.\"}",
    "1115074936673116160": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Okay retard \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text is disrespectful and offensive towards the dog, which is a form of hate speech. The use of the word 'retard' is derogatory and discriminatory towards people with intellectual disabilities.\"}",
    "1109880755121995778": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I know I\u2019m female ...but I\u2019m part nigga too so stop playing with me. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a woman in a negative light, using offensive language and making a derogatory statement about her race.\"}",
    "1116455530480848896": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Imma miss my nigga Nip #RIPNIP \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and references to a deceased individual, which indicates a hateful sentiment.\"}",
    "1114321566823800832": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:HE A FINE NIGGER \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racist language and is offensive. The image of a man in a white shirt and brown jacket, with a cigarette in his hand, is not relevant to the content of the tweet and does not change the classification of the image as hateful.\"}",
    "1107378555745243136": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Hell yea nigga \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, suggesting that the image is a hateful meme.\"}",
    "1113226001167921153": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> can\u2019t wait till yall get salmon vanilla because they undercook your faggot ass chicken! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and derogatory terms towards the LGBTQ+ community, which indicates a hateful sentiment.\"}",
    "1045813376436379649": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> That's white trash \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image and the tweet text are considered hateful as they use offensive language to describe a woman.\"}",
    "1113849611976945667": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Pretty nigga wit choppas \ud83d\ude08\ud83d\ude07 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a young man holding a gun and making a threatening gesture towards the camera. The tweet text further emphasizes the negative and aggressive nature of the image.\"}",
    "1114974534040420357": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I thought this nigga was gay \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language towards the person in the image, suggesting a negative and hateful sentiment.\"}",
    "1113109280431931393": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:nigga. WORD? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it uses racial slurs and offensive language to make a point.\"}",
    "1107345734435815425": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> you've not been a cunt to me? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests that the image is a hateful meme, as it is described as a 'cunt' and the woman in the image is described as 'ugly'.\"}",
    "1116476819052609542": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:If you know this lil nigga\ud83e\udd23\ud83e\udd23\ud83e\udd23 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme that is intended to be offensive and derogatory towards the young man. The tweet text further supports this classification as it is making fun of the young man.\"}",
    "1115057575949688833": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Full Video: \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is a provocative and suggestive photo of a woman, but it does not contain any explicit or offensive content that would warrant a classification as hateful.\"}",
    "1108912544419332097": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Yeah nigga \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, which suggests that the image might be a hateful meme.\"}",
    "1114168776470167554": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> You sick, disgusting, twat faced, child molesting, evil son of a whore. \ud83e\udd2c\ud83e\udd2c \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or derogatory language towards the woman in the picture.\"}",
    "1107712773662883841": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Tautulli (Kraigflix) Ain't No Nigga - Jay-Z Feat. Foxy Brown was recently added to Plex. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it features a man wearing a hat and a white scarf, holding a cigar and a lighter, with the word 'reasonable' crossed out. This could be perceived as offensive and disrespectful towards the LGBTQ+ community.\"}",
    "1043384555259023362": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:That\u2019s tuff nice job taking this mans twitter and trying to squeeze a code out of me good thing I\u2019m not a retard \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it is using someone's personal information and making fun of them. The tweet text further supports this classification as it is disrespectful and insulting.\"}",
    "1116360004817379328": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Nigga even holds the gun the same as Tenma lmaooo \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays two men holding guns in a threatening manner, which is offensive and disrespectful towards people of color.\"}",
    "1115617835974311940": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> \ud83d\ude02\ud83d\ude02\ud83d\ude02\ud83d\ude02...   Me?? Cunt farm?? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and is disrespectful towards the person in the picture.\"}",
    "1115024748650684417": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Never takes long for the Ol Race card! FU! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme that makes fun of a person's appearance and is considered hateful. The tweet text supports this classification as it is derogatory and racist.\"}",
    "1113469702209191937": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:My nigga the amount of work I gotta catch up on..... \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which make it a hateful meme.\"}",
    "1044710406546087936": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag><tag> White trash \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme that is considered hateful due to the negative and offensive language used in the tweet text. The tweet text contains derogatory terms such as 'white trash' and 'trashy', which contribute to the overall negative sentiment of the meme.\"}",
    "1115606012562563074": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This nigga living his best life. Hbd young.<tag> \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is considered hateful.\"}",
    "1108771963747684354": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> It means you fell for a nigga that likes to play games clearly \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is considered hateful.\"}",
    "1116850302869630976": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Cut that nigga off \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it shows a man with a chain around his neck, and the tweet text suggests a violent and aggressive sentiment towards a specific individual.\"}",
    "1113507559141281792": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:THIS is an example of what's coming over the US/Mexican border.  #BuildTheWall #AmericansFirst  #CloseTheBorder \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme that is intended to be hateful towards illegal immigrants, as it shows a man with a skin condition and the words 'the border is smallpox' written above him. The tweet text supports this classification by advocating for a wall to be built at the US/Mexican border and closing it, which implies a negative attitude towards illegal immigrants.\"}",
    "1105491869637595136": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:When they tried a Brookfield nigga like he was a hoe and was greatly misunderstood \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a group of people in a negative light, using offensive language and stereotypes. The tweet text further supports this classification as it reinforces the negative portrayal of the individuals in the image.\"}",
    "1113082218782560256": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:*screams in ABSOLUTE faggot* \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and derogatory terms, suggesting that the image is hateful.\"}",
    "1107674060685606912": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:You\u2019re a faggot but you don\u2019t suck dick? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text is derogatory and disrespectful towards the person in the image, which is considered hateful.\"}",
    "1113450690121207809": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> CB still my nigga doe \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which make the image hateful.\"}",
    "1114758328641572864": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> You special and in that rare but if it\u2019s the right nigga with some game you mite do it fr \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a man in a sweater with glasses, and the tweet text further supports this classification by using derogatory language.\"}",
    "1107207219416842241": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> A good nigga will come eventually \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a young Asian man in a red shirt with a caption that is racist and derogatory.\"}",
    "1105127430530973696": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Nigga...  I\u2019m still struggling to get a house of my own. Chill crazy ass lady. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racial slurs and is offensive. The image of the happy-looking character with fangs and a cap is being used to spread hate, which makes the image hateful.\"}",
    "1107805963099082752": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Bitches swear because you\u2019ve fucked the same nigga y\u2019all are the same. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and stereotypes, which are not appropriate for public display.\"}",
    "1063579237314105345": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:twat knows im on dm limit so here is me responding \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and is disrespectful towards the person being targeted.\"}",
    "1107531870445592576": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Naturally, our faggot asses have gone inactive \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and derogatory terms, indicating a hateful sentiment.\"}",
    "1116663495351779330": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This nigga looks MISERABLE \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language and insults towards the person in the image, which indicates a hateful sentiment.\"}",
    "1114982868206411776": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:\u201cbitch u ain\u2019t go say nun\u201d \ud83d\ude02\ud83d\ude02\ud83d\ude02\ud83d\ude02 \u201caight aight\u201d having a nigga feeling shitty shitty \ud83d\ude02 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and derogatory terms towards women, which indicates a hateful sentiment.\"}",
    "1108931348318711808": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Who cares about the U.S. citizens.... #IllegalAliens #BuildTheWall #MAGA \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains hateful language towards illegal aliens and supports building a wall. This suggests that the image might be a hateful meme.\"}",
    "1116698734333714432": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Im a music nigga not a game nigga. But nonetheless \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it is making fun of someone who is incontinent and is not appropriate.\"}",
    "1115712552653090816": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> \"White Supremacy\" is the new Frank's Red Hot to SJW's.. Y'all put that shit on everything. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it is making a statement about white supremacy and putting it on everything. This can be considered offensive and discriminatory towards certain groups of people.\"}",
    "1108306822077779970": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I walk around like gang nigga  Finger on a trigger  If a nigga wants some smoke  I let that choppa hit his lever \ud83d\udd2b \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image and the tweet text are considered hateful due to the use of derogatory language and gangsta imagery.\"}",
    "1105426906462208001": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I will never put a nigga above this money, I'ma wake up and just hug this money \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racial slurs and is offensive. The image of a woman eating french fries in a car is unrelated to the hateful content of the tweet.\"}",
    "1049819469210628096": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Stephen you're a fucking god damn retard. Good lord \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains insulting language towards the person in the image, suggesting that the image is a hateful meme.\"}",
    "1105171280918126592": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Jerry a kinky little nigga \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it uses racist language to describe a character from a popular cartoon.\"}",
    "1107757447849103362": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> saw a twat, wanted to unfollow a twat, unfollowed a twat \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a screenshot of a smartphone's settings menu, which includes options for the camera, microphone, and other functions. It is not a hateful meme, but rather a screenshot of a device's settings.\"}",
    "1110212089585561603": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> like damn nigga?! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and racial slurs.\"}",
    "1107567202251599872": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Milf gets her hairy cunt ravished \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image depicts a woman with a hairy cunt being penetrated by a man. The content is considered inappropriate and offensive, which makes it a hateful meme.\"}",
    "1114554031798673408": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> holy shit you might be retarded \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests that the image is hateful, possibly due to the man's appearance or the context of the scene.\"}",
    "1116689550733193217": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Will someone pls tell \"Redneck Lord Varys\" to mind his own damn business and stop legislating ppls uteruses \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it is a picture of a man with a red shirt and a red tie, with a caption that is derogatory towards a specific group of people. The tweet text further supports this classification as it is a negative comment towards a particular individual.\"}",
    "1105820643575119872": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:this nigga been in the shower for a week  \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language and racist remarks, which make the image hateful.\"}",
    "1109842050583793665": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Nigga when I tell you<tag> went off on this. \ud83d\udd25\ud83d\udd25\ud83d\udd25\ud83d\udc4f\ud83c\udffd\ud83d\udc4f\ud83c\udffd\ud83d\udc4f\ud83c\udffd \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a negative and offensive stereotype of African Americans.\"}",
    "1113961456050081792": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> This nigga Gogeta thinking he got the upper hand on you. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image and the tweet text are both hateful memes, as they use offensive language and make fun of a person's appearance.\"}",
    "1110192947386044422": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag> Knowing the nigga agenda, i just know hommie ddnt stop though.... \ud83d\udc40 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme that uses racial slurs and is disrespectful towards the African American community. It is not appropriate and should not be shared.\"}",
    "1110285898313318401": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> I clicked his shit like nigga my waves bout to be POPPIN \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racist remarks, which make the image a hateful meme.\"}",
    "1063476226164166657": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> When was the last press conference anyhow? What does the Side Eyed Hillbilly do all day long? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a woman with a large nose and a pearl necklace, making fun of her appearance. The tweet text further supports this classification as it makes fun of the woman's appearance and implies that she is not important or relevant.\"}",
    "1059429746231205888": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:YOOOO COMPLEX SOME FUCK NIGGAS WTF IS THIS NEVER COMPARE THIS BUM ASS NIGGA TO X WTFFFF \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which indicates that the image is hateful.\"}",
    "1107082550466342912": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Only I can jet, cunt. #Splatoon2 #NintendoSwitch \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet contains offensive language and is likely to be considered hateful. The image of the blood-covered room and the bottle of red liquid further contribute to the negative and aggressive tone of the scene.\"}",
    "1109134883685875721": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:3rd grade nigga: have you seen the clown that hides from gay people?  me another 3rd grade nigga: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme that uses offensive language and makes light of the LGBTQ+ community. It is not a respectful or inclusive representation of people.\"}",
    "1107806541183361025": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Feckless wanker \u2066<tag>\u2069 is suing a twitter account<tag> for mean tweets. What a twat. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a man holding a teddy bear with a negative message, which is disrespectful and offensive.\"}",
    "1042401054846083072": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag> Dinesh went full retard. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image and the tweet text suggest that the man is being mocked or ridiculed for his appearance or actions. This can be considered as a hateful meme as it may be intended to belittle or insult the person depicted.\"}",
    "1107237010597707781": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Double time day, song so fitting.<tag> \"Unk Sam taking grams out the bag, kinda hard for a nigga tryna stack\" \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, making it a hateful meme.\"}",
    "1034884483399540736": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Twat \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a man in a suit with a frown on his face, which is meant to be a negative representation of a person. The use of the word 'twat' in the tweet text further supports the classification of the image as hateful.\"}",
    "1107665713869803523": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> this nigga got a gun pointed in his face and says \u201chehe\u201d \ud83d\udc80\ud83d\udc80 name a more real nigga \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a violent and threatening situation involving a man with a gun, which is not a realistic or appropriate representation of a person.\"}",
    "1025070036854218752": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Watch it: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it may contain offensive or inappropriate content. The woman in the image is posing in a provocative manner, which could be considered as objectifying or degrading to some people.\"}",
    "1115417924741632000": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I\u2019m officially dat nigga wit the waves \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial stereotypes, which make it a hateful meme.\"}",
    "1108650061817237509": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:boombella _935 have a word cunt, ( and found<tag> in a 1 by 1 ) \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, which suggests that the image might be a hateful meme.\"}",
    "1042566283185676289": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Watch: Steven Crowder Confronts SJW Professor Who Slandered Him \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a man in a white mask holding a sign that says 'I am not a Nazi' while another man in a mask is holding a sign that says 'I am a Nazi'. This creates a negative and offensive portrayal of Nazis, which is considered hateful.\"}",
    "1114992599209664512": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Lmao everybody used to tell me black ice was for nigga cars \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racial slurs and is offensive. The image is likely to be a hateful meme.\"}",
    "1062616256271007744": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Redneck Tome 2 - \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is a comic book cover featuring a character with a toothbrush in his mouth. It does not depict any hateful or offensive content.\"}",
    "1051309614711693312": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Yep. Redneck Uber. Who\u2019s in with me? #DontDrinkandDrive \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a man in a pickup truck, making fun of someone who is driving under the influence. It also encourages others to join him in this behavior, which is dangerous and irresponsible.\"}",
    "1109263545013800960": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:\u201cI am a nigger\u201d got me fucking hollering \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it features a man reading a book with a racial slur written on the cover. This is offensive and disrespectful towards people of color.\"}",
    "1055860788966121477": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:How much of a lazy retard do you have to be to do something like that? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, suggesting that the image is a hateful meme.\"}",
    "1055792045334413313": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag> The twat blocked me for basically saying this \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains a negative message about someone being blocked on Twitter.\"}",
    "1108292627063988224": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Tall chubby nigga \ud83c\udf34\ud83d\udd25 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image and the tweet text are considered hateful due to the use of derogatory language and negative stereotypes about a specific group of people.\"}",
    "1036242396965740544": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Get Dyke! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language towards the LGBTQ+ community, which is considered hateful.\"}",
    "1110285632788549632": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> these niggas love proclaiming they diversity and then say sum full blown racist shit like nigga excuse me \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a black man in a basketball uniform with a disgusted look on his face, which can be perceived as racist and offensive.\"}",
    "1108024146644992002": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Congress has a petting zoo, and on display are 12 spineless RINOS!!! #BuildTheWall. #IamBrown \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a group of politicians in a negative light, and the tweet text further emphasizes this sentiment by using derogatory language such as 'spineless RINOS' and 'Build the Wall' which are associated with divisive political rhetoric.\"}",
    "1060868170838429696": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> This Woman is a c**t of the highest order!! What a despicable Twat she is \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults towards the woman in the image, indicating a hateful sentiment.\"}",
    "1054121718141386753": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Did the #Jews carry the German or Nazi flag when claiming asylum? These people aren't refugees. #MAGA #BuildTheWall \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains anti-Semitic and xenophobic sentiments, which are hateful in nature.\"}",
    "1064452821779652608": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:The cunts cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a comic strip featuring a character named Beano, who is making a funny face while holding a flower. The tweet text is offensive and disrespectful, which indicates that the image is hateful. The comic strip itself is not hateful, but the tweet text associated with it is.\"}",
    "1053345515310481409": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Hey $HIPH, lets get green!!!  $RDGL $KGKG $SPIC $BDCI \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme that is hateful and disrespectful towards the person depicted, as it uses a derogatory term to describe them.\"}",
    "1113873826993983488": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Get ready for the NotAllMen brigade! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image portrays a woman in a Batman costume hitting a man with a sword, which can be interpreted as a violent and aggressive act. The tweet text suggests that the image is related to the NotAllMen movement, which is often associated with misogyny and sexism. This further supports the classification of the image as hateful.\"}",
    "1057018725654773762": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:SJW blocked me. Kind of funny \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme that is considered hateful by some people, as it is related to social justice warriors and is blocked by them. The content of the meme might be offensive to some individuals.\"}",
    "1113489400644689920": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Let the retarded fan boys show get startin \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text is offensive and disrespectful towards fans of the person in the image.\"}",
    "1107090931390386177": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Me: Facebook: good morning dyke \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language towards the LGBTQ+ community, which is considered hateful.\"}",
    "1036293112711135232": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I'm a fucking faggot bitch \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language towards the LGBTQ+ community, which is considered hateful.\"}",
    "1037028673751339010": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> We can't say retard, but Trump can do this when mocking a person with a disability? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful as it mocks a person with a disability, using a derogatory term. The tweet text further emphasizes this sentiment.\"}",
    "1105320395249467392": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Aw nigga it\u2019s over with \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains a racial slur, which indicates that the image is hateful.\"}",
    "1037402176673349632": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag> Because she's Jewish you pathetic weeaboo retard. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and discriminatory remarks towards a specific group of people, which makes the image hateful.\"}",
    "1052585288747298816": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Someone thinks that suck a nigger - that's cool. Do not flatter yourself, he will not love you for it. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racist language and is considered hateful.\"}",
    "1055927512650399752": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag> We sure as hillbilly hell don't want him...\ud83d\uddfd\ud83d\udca6\ud83c\udf0a \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and negative sentiment towards a specific individual, which indicates that the image is hateful.\"}",
    "1107504356558061568": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:You\u2019s a goofy dilly ass nigga\ud83d\ude2d \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which make it a hateful meme.\"}",
    "1024508024696786944": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Yep.   Your SJW campaigning. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme that is intended to be humorous and is not meant to be taken seriously. It is not hateful in nature.\"}",
    "1115074126417408000": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I ain\u2019t ya EX nigga \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image and the tweet text suggest a negative and disrespectful attitude towards women. The man's facial expression and the tattoo on his neck contribute to the overall negative vibe of the image.\"}",
    "1107717163664707585": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag><tag><tag><tag> Faggot blocked me lmao \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language and insults, which are considered hateful. The image of a man with a hat and sunglasses in front of a neon sign is not the main focus of the image, and it does not contribute to the hateful nature of the tweet.\"}",
    "1045852204035428352": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:You a faggot? Look what I have for you! ......  See this and more at: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language and insults, which are considered hateful. The image itself is a picture of a shirtless man wearing a red hat, but the context of the tweet makes it clear that the image is being used to spread negativity and discrimination.\"}",
    "1109710484624850944": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:biiitch omg she is cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, indicating a hateful sentiment towards the person in the image.\"}",
    "1109588706820792321": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Fucking traitor stick the twat in the tower \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which indicates that the image is hateful.\"}",
    "1034782297944412161": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> retard even when u spell it correctly it's still wrong \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or derogatory content towards a specific group or individual.\"}",
    "1058237765463068672": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> No it\u2019s ok they\u2019re all retarded they just dont know any better #justaprankbro \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text is offensive and disrespectful towards people with disabilities. It is not appropriate to make fun of or mock individuals with special needs.\"}",
    "1054373398246174720": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This cunt just bumped me  #PS4share  \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, which suggests that the image might be a hateful meme.\"}",
    "1115755269395570689": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:a dyke fighting for her little gay boy i think \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a woman in a red cape, possibly a superhero, and a group of children, with a message that is derogatory towards the LGBTQ+ community. The tweet text further supports this classification as it implies a negative attitude towards the LGBTQ+ community.\"}",
    "1116698898968432640": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:How about you guys do yourself a favor and block this guy. He's one annoying cunt btw \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and suggests blocking the person, indicating a hateful sentiment.\"}",
    "1106666875491106818": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I asked for a salad...NIGGA THIS AINT NO SALAD THIS IS JUST LETTUCE. IM BIG MAD \ud83d\ude21 BCHDHEIWOFJC SKWKE \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is considered hateful.\"}",
    "1108170431159140352": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Hold da fuck up\ud83d\ude02\ud83d\ude02this nigga disrespecting my name by being garbage \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and disrespectful behavior towards another individual, which indicates a hateful sentiment.\"}",
    "1116511894054084608": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> This nigga said this like a supervillain revealing his origin \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it uses racial slurs and offensive language to make a point. The tweet text further supports this classification as it uses derogatory language to describe the image.\"}",
    "1046343356165558272": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I just died to a retard...<tag>, was on couse for a decent win tbh #PS4share \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, suggesting that the image is a hateful meme.\"}",
    "1114970813592145920": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:nigga has a phone pa na. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racial slurs and is offensive. This image is not hateful.\"}",
    "1056608755578740736": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:What a special cunt. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which indicates a hateful sentiment.\"}",
    "1107545400980848641": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Nigga so mad, I love you lil bro \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racial slurs and is considered hateful.\"}",
    "1113904844794937345": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> This nigga Dontai said... \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content.\"}",
    "1050092269649448962": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Round up, reimburse, then remember your manners faggot.  $MasterBatesOwnsYou #cashmaster #cashfag #findom \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which indicates that the image is hateful.\"}",
    "1058212502134317057": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> \u201cwEll lET mE sEE yOu gEt OUt thErE And PlAY\u201d.... NIGGA SHUT THAT SHIT UP \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is considered hateful.\"}",
    "1109639181247148032": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This dyke just told me she loves that I don\u2019t give a fuck about what she has to say \ud83d\udc80 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a woman in a negative light, with the caption suggesting that she is not worth listening to.\"}",
    "1054442042284273664": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:RefugeesNOTwelcome \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image portrays a group of people, including children, in a negative light, suggesting that they are unwelcome. This can be perceived as hateful, as it may evoke feelings of discrimination and intolerance.\"}",
    "1106995349120520193": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I\u2019M SUCH A DYKE OMG \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language towards the LGBTQ+ community, which is considered hateful.\"}",
    "1115263432792641538": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:My nigger Cartman.\ud83d\ude04\ud83d\ude04\ud83d\ude2e\ud83d\ude2e \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racial slurs and is offensive. The image itself is a comic strip featuring a character named Cartman, but the tweet's content is inappropriate and hateful.\"}",
    "1041841022798585857": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> This guy is actually retarded... \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, suggesting that the image is a hateful meme.\"}",
    "1063440345231486979": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Controversial, contended, career making? Find out for yourself with HILLBILLY ELEGY \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is a book cover featuring a guitar, which is not a hateful symbol. The tweet text does not contain any hateful content.\"}",
    "1115097933333127168": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Lmfao someone's gonna call me a cunt I just know it. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, suggesting that the image might be a hateful meme.\"}",
    "1105574284523724800": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:What a twat! \ud83d\ude02\ud83e\udd26\ud83c\udffd\u200d\u2640\ufe0f \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text is derogatory and disrespectful towards the person in the image, suggesting that they are a 'twat' and making a joke about their appearance. This is an example of a hateful meme.\"}",
    "1049687834179833856": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> I'll Fuck you retard \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which indicates that the image is hateful.\"}",
    "1105858092397260810": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> This nigga dont know shit about sports. Yankees good as shit fuck you talking about and suk my dick \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults towards the person in the image, suggesting a hateful sentiment.\"}",
    "1055879041838804992": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:If I ever see this faggot he\u2019s getting his ass beat \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains hate speech towards the person in the image, suggesting that the image is a hateful meme.\"}",
    "1058558039131934720": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> open your doors for them or #BuildTheWall \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests a negative sentiment towards open doors, which is in contrast with the image of a welcoming doorway. This could be interpreted as hateful, as it promotes a closed-off and hostile attitude towards open doors.\"}",
    "1063596913629569024": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:faggot tingz \ud83d\ude14 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and derogatory terms towards the LGBTQ+ community.\"}",
    "1108969462521364480": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Immediate question in mind ......    \u201cIs this nigga taking a hoe bath?\u201d \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language and racist remarks, which are considered hateful.\"}",
    "1042620668133732354": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:what a faggot \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language towards the individual, suggesting a negative attitude towards them.\"}",
    "1025046859109289985": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Retard \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or derogatory content towards a specific group of people. The presence of the word 'Retard' in the tweet text further supports this classification.\"}",
    "1113528943867568128": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I be tellin my dad \u201cI love you\u201d and that nigga just be like \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which make it a hateful meme.\"}",
    "1061744804051197953": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:What\u2019s this faggot man gave a birthday shoutout saying he wanted to buy him a watch real smart man \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language and insults towards the person in the image, suggesting a hateful sentiment.\"}",
    "1061478626665881600": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:VIDEO: Tublack \u2013 Song For The\u00a0Nigger \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image and the tweet text are considered hateful as they use derogatory language and promote negative stereotypes about a specific group of people.\"}",
    "1037386997260738560": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:THIS EXUDES BIG DYKE ENERGY WOW \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and derogatory terms, suggesting a hateful sentiment towards the woman in the image.\"}",
    "1106704383268605952": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:A nigga know I ain't perfect I hope to accept discipline and grow cause I know I ain't right lolol \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language and racial slurs, which are considered hateful. The image of a man in a blue uniform, possibly a priest, is being used to spread this hateful message.\"}",
    "1053504712362717184": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> let\u2019s dyke out \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is not appropriate for a wine bottle and glass image.\"}",
    "1105861674496679941": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:we at the play and this nigga Hamlet actin mad weird and not himself rn, I wonder why \ud83e\udd14 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the use of racial slurs and the portrayal of a black man in a negative light.\"}",
    "1116374602333270019": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:White people don\u2019t like the race card because it\u2019s stronger than white privilege. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it is making a statement about white people and their feelings towards the race card. It is not a respectful or inclusive representation of people.\"}",
    "1045715727553114113": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag> Retard reality check \ud83d\udc47 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme that shows a group of people from different countries, with the text 'EU Youth Unemployment'. The tweet text suggests that the image is hateful, possibly due to the negative portrayal of youth unemployment in the EU. The classification is based on the perception that the image might be offensive or discriminatory towards a specific group or region.\"}",
    "1058116381193986048": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Suck a nigga dick or something \ud83c\udf4c \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is considered hateful.\"}",
    "1061438540071006208": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:\"WASHED ASS NIGGA WHAT YOU FINNA DO?\" \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language and racial slurs, which are indicative of a hateful meme.\"}",
    "1034957405547913216": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:guess who's bad  mad and bad  faggot's bad  tell your dad \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language and insults towards the individual in the image, suggesting a hateful sentiment.\"}",
    "1109308166678802432": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:bruh look at ma nigga<tag> \ud83d\ude2d\ud83d\ude2d\ud83d\ude2dwhy he gotta look like ma boi gerald from hey arnold \ud83d\ude02\ud83d\ude02 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the man's appearance, which is described as a 'boi' or a 'nigga' in the tweet text. This language is often associated with racism and discrimination, making the image offensive to some viewers.\"}",
    "1054544080510898176": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag> This nigga was traumatized \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which make the image hateful.\"}",
    "1108156455729930241": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> nigga you supposed to be dead \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racial slurs and is considered hateful.\"}",
    "1105827990162890752": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Via: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it may contain offensive or inappropriate content that is intended to harm or degrade a particular group of people. The presence of a woman in a red bikini and high heels, along with the overall setting, may contribute to the perception of the image as hateful.\"}",
    "1116691687412305920": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:When a nigga you ain\u2019t do shit to got an unspoken issue with you ?????? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains racial slurs and is disrespectful towards people of color.\"}",
    "1110240099890094085": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Is it aye ye must be fucking gasping for one now daft cunt \ud83e\udd2a\ud83e\udd2a \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which suggests that the image is a hateful meme.\"}",
    "1107389988545675266": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Sooo a nigga finally getting his weight back up \ud83d\ude0c been feeling myself no flex.... next 200lbs \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language and is disrespectful towards the individual in the image. This is considered hateful.\"}",
    "1105506676801708032": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Lollll. This nigga think I\u2019m his woman. Sir, no! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and is disrespectful towards a specific group of people.\"}",
    "1106637346483720194": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag>. Bless you. Bumblebee tuna. I'm a Real NIGGA. AX<tag><tag> ODB \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme that uses racial slurs and offensive language, which is considered hateful.\"}",
    "1047187923651706880": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Retarded as fuck \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the offensive language used in the tweet text.\"}",
    "1045077356593975296": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:#TrumpPressConference got all you sjw libtards losing your minds.  #qanon #maga \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains political and social commentary that may be considered hateful by some people. The use of hashtags like #qanon and #maga may also be perceived as hateful by certain individuals.\"}",
    "1110391903378259969": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> You really are a twat aren't you? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text is disrespectful and insulting towards the man in the image, suggesting that he is a 'twat'.\"}",
    "1114933831566540800": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Get the fuck off my TL  ya sad pervo cunt or I'll get back in my submarine on my day off... \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and a threat, indicating a hateful sentiment.\"}",
    "1055176502210387969": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Dyke be gone \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a negative stereotype of the LGBTQ+ community, specifically targeting the transgender community. The tweet text further supports this classification as it contains derogatory language.\"}",
    "1055907509838340096": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Awwww! Poor racist white trash. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a black person in a negative light, suggesting that they are inferior to white people. The tweet text further supports this classification by using racist language.\"}",
    "1062302842906652672": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:If you\u2019re not following then you should be !! Proper funniest old cunt on twitter<tag> \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image and the tweet text are hateful memes, as they use offensive language and make fun of someone's appearance.\"}",
    "1046249339180408832": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Faggot? Wbk \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language towards the subject of the image, suggesting that the image is hateful.\"}",
    "1117282656130146311": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Fuckboy faggot reporting for duty. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which suggests that the image is hateful.\"}",
    "1108611613140103168": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Send that nigga to jail \ud83d\ude02\ud83d\ude43 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image and the tweet text are both hateful memes, as they use offensive language and make light of a serious issue.\"}",
    "1108690010360950784": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Now Playing: I Surrender (Featuring Onaje Jefferson) by Brooklyn Tabernacle Choir on \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is a poster advertising the Brooklyn Tabernacle Choir's album, featuring a purple flag and the album title. It is not a hateful meme.\"}",
    "1053728016365428737": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> You're full of it, Princess. Quit playing the victim card. Get a job &amp; pay those taxes you owe. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a woman in a floral dress sitting on a podium with a man in a suit, while the woman is making a hand gesture. The tweet text further supports the classification as it is disrespectful and insulting towards the woman, using offensive language such as 'Princess' and 'victim card'.\"}",
    "1054643105297784832": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:GUYS I FOUND PEOPLE TO DO REDNECK SHIT WITH HERE \ud83d\ude02\ud83d\ude02 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests that the image is a hateful meme, as it contains offensive language and potentially derogatory content.\"}",
    "1114204568454336512": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Meet faggot Jim. Exposed to the world \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or derogatory content towards the person in the image.\"}",
    "1061732492288385024": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:cunt sent me another emoji when i warned her \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image and the tweet text suggest that the content is hateful, as it contains offensive language and potentially derogatory terms. The image features a woman with a caption that could be interpreted as offensive, and the tweet text further supports this classification by using derogatory language.\"}",
    "1056609789721989120": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:today can CHOKE i can already feel it in my dyke bones that it\u2019s just not it \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is considered hateful.\"}",
    "1110020697349390337": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Nigga Your ugly \ud83d\ude2d\ud83d\ude2d\ud83d\ude2d<tag> got some big ass lips \ud83d\ude2d\ud83d\ude2d\ud83d\ude02 LMFAOOOO \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image and the tweet text are both hateful and offensive, using derogatory language to describe a person.\"}",
    "1034780448675823616": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:*Gets called a faggot* \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image shows a man with a surprised expression, and the tweet text suggests that he has been called a derogatory term. This could be considered as a hateful meme, as it might be intended to provoke or offend the viewer.\"}",
    "1055124846202576896": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Don\u2019t even tweet too much but<tag> never fails to be the smartest retard ever \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which suggests that the image is a hateful meme.\"}",
    "1109227935146434561": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Yea aight nigga \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racist slurs, which make the image hateful.\"}",
    "1114152409406877697": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This nigga just said his card got declined because someone stole it... \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a man with a beard and mustache making a funny face, which is intended to be humorous. However, the tweet text suggests that the image may be offensive to some people, as it uses derogatory language to describe the man's situation.\"}",
    "1113499159745781761": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:*Phone rings* \u201cHi son u alright\u201d   Your low levelled brain dead cunt of a mate: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it uses offensive language and makes fun of someone's intelligence.\"}",
    "1113185650193334272": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:brie larson is a dyke \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language towards the woman in the image, suggesting that she is a lesbian. This is considered hateful and disrespectful.\"}",
    "1109276852714008578": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Annoyed stepsis lets stepbro rock her tight twat \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image and the tweet text suggest a hateful meme, as it portrays a woman in a suggestive manner and the tweet text is inappropriate and disrespectful towards a family member.\"}",
    "1107835761578205188": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Nigga look like meatball from aqua team hunger force  RT<tag>: Lol \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a man in a hoodie with a tag that reads 'felt cute. might delete later' and the tweet text is racist and disrespectful.\"}",
    "1062356385655070720": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I Ate Cum From My Young Cunt 2<tag><tag> \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or inappropriate content. The presence of a young girl in a provocative pose, along with the tweet text, further supports this classification.\"}",
    "1105273235850039296": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I am now the voice of reason friend. I used to be the fuck that nigga/whoop ha ass friend. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which indicates that the image is hateful.\"}",
    "1114921043146301442": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Pussy ass nigga u seen me txt u \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image and the tweet text are considered hateful due to the use of derogatory language and the disrespectful nature of the content.\"}",
    "1107838864662646786": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This might be the worse case of Cultural Appropriation I've seen since \"Jesus Christ is My Nigga\" \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the use of racial slurs and the portrayal of a character in a negative light.\"}",
    "1105621061171924993": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:That shit mad foul RT<tag>: She done gave this nigga somem LMFAOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOO \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the man's facial expression and the tweet text, which is disrespectful and offensive.\"}",
    "1115480185229336576": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> That nigga\u2019s joke are the same every time \ud83d\ude2d \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racist remarks, which make it a hateful meme.\"}",
    "1113871176185667589": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:walking into the session to see which nigga got the 808 out of key  \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language and racist remarks, which are considered hateful. The image of two men walking into a room, one of whom is wearing a black jacket, does not seem to be related to the hateful content in the tweet.\"}",
    "1107036335192313856": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Sneaky Twat! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains content that is intended to be offensive or harmful to a particular group of people.\"}",
    "1049691239912808450": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Are you retarded ??? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text is offensive and disrespectful towards the man in the image, suggesting that he is retarded. This is an example of a hateful meme.\"}",
    "1105823801445634050": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> iLl TwAt ThE bOtH oF yOu \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a character from a popular cartoon in a disrespectful manner, which can be offensive to some viewers.\"}",
    "1042248404917805061": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> U either Stupid , or retarded or even both \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text is offensive and disrespectful towards people with intellectual disabilities. The image, featuring a man with blonde hair and a black shirt, is being used to spread this negative message.\"}",
    "1109670835453755392": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:realest white nigga ever  \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and racial stereotypes.\"}",
    "1106632668169625600": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> \u201cNigga\u201d...\ud83d\ude05 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains a racial slur, which is considered hateful and inappropriate.\"}",
    "1110015164793933824": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Let's start with this epidemic  #Buildthewall \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a collage of photos of illegal immigrants, which is a controversial and hateful topic. The tweet text also supports this classification as it promotes the idea of building a wall to keep out illegal immigrants.\"}",
    "1109972577882173442": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:SHE LOOKS CUNT!!!!!! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet contains offensive language and is considered hateful.\"}",
    "1062125442608611333": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:MIA UNBLOCK ME U FAT CUNT \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet contains offensive language and insults, which indicates that it is a hateful meme.\"}",
    "1116064739606634497": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:soon as a nigga get a couple years down the road they wanna tat they face like they ain\u2019t never getting out \ud83e\udd26\ud83c\udffe\u200d\u2640\ufe0f \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a negative stereotype about African Americans.\"}",
    "1107416087476486150": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:The Full Gallery: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it features a man and a woman in a sexual position, with the woman's face covered. This kind of content is often used to spread hate or discrimination against women.\"}",
    "1105258790595805184": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Fuck off Juncker you drunken nonce looking twat \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, indicating a hateful sentiment towards the person in the image.\"}",
    "1113703403039928320": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Nigga this shit funny as hell \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is considered hateful.\"}",
    "1110398836613230593": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Hipsters are trailer trash via /\nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays hipsters in a negative light, suggesting that they are trailer trash.\"}",
    "1113825736362688513": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Like on me this nigga Jaymes needs to shut up and take his L bro \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and a negative sentiment towards the person in the image. This suggests that the image is a hateful meme.\"}",
    "1114015288293507073": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Just a nigga with a rocket launcher #Fortnite #XboxShare \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a person of color in a negative light, using offensive language such as 'nigger' and 'rocket launcher'. This kind of imagery is harmful and disrespectful towards people of color.\"}",
    "1108804609881956352": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag><tag><tag> Nigga \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains a racial slur and is disrespectful towards people of color.\"}",
    "1106962428535828480": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:yo my nigga is in distraught \ud83d\ude02\ud83d\ude02\ud83d\ude02\ud83d\ude02\ud83d\ude2d\ud83d\ude2d \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it may contain offensive or discriminatory content. The tweet text further supports this classification as it uses derogatory language to describe the man in the image.\"}",
    "1060918656777912320": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:literally every neo-liberal/feminazi/unemployed communist in the history of 2015 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the presence of a person wearing a pink hat and the tweet text, which is derogatory towards certain groups of people.\"}",
    "1107787491669471232": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:She got ash up on her knees cus I stand up when she blow me \ud83d\udd25\ud83d\udd25\ud83d\udd25 comethazine growing on a nigga \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains explicit language and references to sexual acts, which are considered inappropriate and offensive. This classification is based on the general consensus that such content is not suitable for public consumption, especially in a shared and public space like a social media platform.\"}",
    "1055882725121495041": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag> Yea #Fake you retard!!\ud83d\udd95 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, suggesting that the image is a hateful meme.\"}",
    "1109356050547912704": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Future know how to make a nigga cry \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image and the tweet text are hateful and offensive, using derogatory language to describe a racial group.\"}",
    "1107284584314650624": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Nah this nigga be eating crayons idc \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which indicates that the image is hateful.\"}",
    "1115268912290107393": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Nigga white people crazy \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racial slurs and is considered hateful.\"}",
    "1105724642625490944": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Nigga what \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a young black girl with a frown on her face, and the tweet text further emphasizes the negative sentiment.\"}",
    "1109694603806937089": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Stfu fucking cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, which suggests that the image might be a hateful meme.\"}",
    "1113479764227047425": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Top 3 favorite Nipsey tracks . Nigga went CRAZY \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests that the image is a hateful meme, as it contains a reference to Nipsey Hussle and the use of the word 'nigger' in the tweet text.\"}",
    "1055872326754025473": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:LET NIGGA BEAT UP ON THEM BOOTY CHEEKS.... BRUISE UP THEM BOOTY CHEEKS \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which are indicative of a hateful meme.\"}",
    "1107823822797836289": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:We slangin Rocnation , yea bitch you jigga who, I\u2019m plugged at the boarder nigga send em through\ud83d\udd25\ud83d\udd25\ud83d\udd25\ud83d\udd25\ud83d\udd25\ud83d\udd25\ud83d\udd25\ud83d\udd25\ud83d\udd25\ud83d\udd25\ud83d\udd25\ud83d\udd25\ud83d\udd25 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and slang, which suggests a hateful sentiment towards others.\"}",
    "1108843242240520193": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag> Nigga what pther word? Dogs!? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it uses racial slurs and offensive language to make a point.\"}",
    "1106936656278548480": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Tell me this nigga<tag> Don\u2019t look like elephant man\ud83d\ude02\ud83d\ude2d \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays two men in suits, one of whom is wearing glasses, and it is described as an elephant man. The tweet text further supports the classification as it contains derogatory language towards African Americans.\"}",
    "1113103781070286848": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I be worried bout a check \u2705\ud83d\udcb8 fuck a bitch or a nigga \ud83e\udd37\ud83c\udffe\u200d\u2640\ufe0f\ud83d\ude02\ud83d\ude0b\ud83d\udcaf. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and racial slurs in the tweet text.\"}",
    "1114130742143926272": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:nigga got Mr Wilson as his Avi \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image and the tweet text contain racial slurs and offensive language, making it a hateful meme.\"}",
    "1105288986434699264": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:this nigga retarded your honor \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and insults towards a specific individual.\"}",
    "1105671895087833088": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:THE DARK CURLY HAIR THE FRECKLES THE ARMOR LEE SEOKMIN IS OUT FOR BLOOD AND IM WILLING TO SURRENDER \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it may contain offensive or aggressive content. The presence of a man wearing armor and a description of him being out for blood may contribute to this classification.\"}",
    "1115297578697015297": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:When a nigga who aint put in on a match session hit da blunt \ud83d\ude02\ud83d\ude02 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a group of young black boys in a negative light, using derogatory language in the tweet text.\"}",
    "1106959827023130626": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Sluts Love Flashing\u00a0Cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it objectifies and degrades the woman by using offensive language and making light of her nudity. The tweet text further supports this classification as it reinforces the negative and disrespectful attitude towards women.\"}",
    "1109578502045663233": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Oiled for the eventual whipping.  From the \"Impaled cunt\" series at \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image depicts a woman with her breasts exposed and a man touching her nipples. The tweet text suggests that the woman is being prepared for whipping, which is a violent and inhumane act. This image can be considered hateful as it promotes violence against women.\"}",
    "1109665453880852480": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:anycunt tell me where this cunt stays? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is considered hateful.\"}",
    "1113476311555682304": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Lock this nigga up! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is considered hateful.\"}",
    "1117147330006921217": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:If a nigga wearing this call next I'm going home \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language and is considered hateful.\"}",
    "1109521538984878082": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:They say my nigga a menace I say fuck them free my nigga \u203c\ufe0f\ud83d\udde3 #freeliljacob \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which are indicative of a hateful meme.\"}",
    "1108941147349499905": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> ultimate fat nigga song Gunna and Nav \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image and the tweet text suggest that the content is hateful, as it uses derogatory language to describe the song and its artists.\"}",
    "1042786363903561729": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:It's because he's a fucking retard hth \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults towards the president, indicating a hateful sentiment towards him.\"}",
    "1117198749040828416": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> CONGRATS NIGGA \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains a racial slur, which is considered hateful.\"}",
    "1114796586452889600": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> So sad smh this nigga still on that fuck shit!! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image and the tweet text suggest that the content is hateful, as it uses derogatory language and makes negative comments about the person in the picture.\"}",
    "1110059848136359936": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> cheeky wee cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, which suggests that the image might be a hateful meme.\"}",
    "1109105669582540801": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> THIS NIGGA USIN A WEB CLIENT!!! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is likely to be considered hateful.\"}",
    "1115044688757710848": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:is with god, nigga Nipsey Hussle \ud83d\ude4f\ud83c\udffe\ud83d\udc94 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the use of derogatory language and the portrayal of a rapper, Nipsey Hussle, as a religious figure. This can be offensive to some people and may not be appropriate for sharing on social media platforms.\"}",
    "1114014799376068608": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:if youre white and religiously say the \"n\" word, youre trash. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it promotes negative stereotypes and discrimination against people based on their race and religion.\"}",
    "1110316348066942976": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Its gonna be a great week.. shout out to my ex nigga for the wine.. \ud83d\udc9c \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is not appropriate for a wine advertisement.\"}",
    "1057776749646352384": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:yeah because theyre completely different months you fucking stupid dumbass idiot cunt bitch fuck you \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, suggesting that the image is a hateful meme.\"}",
    "1107814943481573378": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> I\u2019ll get in. But you gone have to save a nigga once my feet don\u2019t touch the ground no more. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racist language and is considered hateful.\"}",
    "1109605445860319233": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Nigga Top 3 ever from Tally. I know what I saw lol \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racial slurs and is offensive. The image of a man and a boy posing together is not relevant to the hateful content of the tweet.\"}",
    "1113133027482308608": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Pleeeease don\u2019t let me be worst than this cunt afresh spending all the dough.... \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or derogatory content towards a specific individual or group.\"}",
    "1024845732308705280": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Ps my dad is a sick cunt #420 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language towards the father, which indicates a hateful sentiment.\"}",
    "1114238866700087297": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:nigga just got his ear bit off\ud83d\ude33  -welcome to Birmingham \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racial slurs and is offensive. The image of a woman wearing a pink coat and carrying a briefcase is unrelated to the content of the tweet and does not contribute to the hateful nature of the meme.\"}",
    "1114940594877554688": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I don\u2019t wanna no sloppy drunk ass nigga . So I felt this \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults towards a specific group of people, which indicates a hateful sentiment.\"}",
    "1114205259835105280": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:If I was a conspiracy theorist this would be the kind of thing that fueled my conspiracy theorism. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image contains multiple photos of people with captions that are potentially offensive or hateful. The presence of religious figures and the controversial content of the captions suggest that the image is intended to be hateful.\"}",
    "1114004119868411904": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Who\u2019s this mf being a cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image and the tweet text suggest that the content is hateful, as it contains offensive language and insults towards someone.\"}",
    "1108069158607036416": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This nigga going to hell with gasoline  drawers on... \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which make it a hateful meme.\"}",
    "1107630916036452357": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This nigga hit me every morning cappin \ud83d\ude2d<tag> \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a man holding money and a mask, which can be interpreted as a negative stereotype of African Americans.\"}",
    "1113836778018836480": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> The feds waiste more than that on congressional salaries....#BuildTheWall \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it uses a picture of Donald Trump to promote a political agenda, specifically the construction of a wall. The tweet text further supports this classification as it is related to a political issue and uses a controversial figure to promote it.\"}",
    "1056414922379223040": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> THEOCRATIC TAX FRAUDING cunt Ag ignorant sadistic cult TERRORISTS! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and imagery, such as the depiction of a woman as a statue and the use of derogatory terms. The tweet text further supports this classification as it contains aggressive and derogatory language towards a specific group of people.\"}",
    "1109841530364284934": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:SOME DAYS YOU JUST CRAVE REDNECK DICK!\ud83d\ude32\ud83d\udc45\ud83d\ude0b\ud83d\udc4d\ud83d\ude0d \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it may contain offensive or discriminatory content. The man in the image is wearing a tank top and sunglasses, and the tweet text suggests that he is enjoying his redneck lifestyle. This could be perceived as offensive or discriminatory by some people, leading to the classification of the image as h",
    "1058472639092715520": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:BUT IT'S OK WE GONE KEEP SECRETS NIGGA \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racist language and is considered hateful.\"}",
    "1105708880523333632": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Henry Van Dyke.- #quote #image Via \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is a picture of a bird sitting on a branch, with a quote by Henry Van Dyke. It does not contain any hateful content.\"}",
    "1107698952747606016": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This nigga a pedo call for help \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme that is hateful and offensive, as it uses racial slurs and makes light of a serious issue.\"}",
    "1049650284668973057": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Shows you weren't watching. But now that you mention it. #BuildTheWall \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a large group of people, including children, in a train with the caption 'illegal aliens should be America's number 1 export'. This is offensive and discriminatory towards immigrants, promoting negative stereotypes and xenophobia.\"}",
    "1115809074979966977": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:And I was about to put this nigga in my Fantasy team \ud83d\ude05 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language and is considered hateful.\"}",
    "1108211637906034689": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> LMFAO Periodt. Imma be waiting on her nigga like.. \ud83d\ude02\ud83d\ude02\ud83d\ude02 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text is disrespectful and offensive towards the person in the image, which is considered hateful.\"}",
    "1109354296460480512": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag>  IN HAWAII WE ON THIS GRIND NIGGA \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which make it a hateful meme.\"}",
    "1114146653404110849": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:My nigga. I ain\u2019t even brush my teeth yet ... \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which are indicative of a hateful meme.\"}",
    "1056090556831547393": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I have no fucking words for how retarded you are<tag> \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, and the tweet text further supports this classification as it contains offensive language.\"}",
    "1054522675089960960": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> You a dumbass it ain\u2019t even Burberry \ud83e\udd23\ud83e\udd23\ud83e\udd23\ud83e\udd23 it\u2019s a supreme flannel retard \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text is disrespectful and offensive towards the person who posted the image of the plaid shirts.\"}",
    "1107297087270596609": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:White people have every privilege in life afforded to them and yet they still mad they can\u2019t say nigga. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a black man in a basketball uniform making a face, which is a form of racism and discrimination. The tweet text further supports this classification as it highlights the issue of racism and the privilege that white people have.\"}",
    "1117585520417226753": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> F Will Hill &amp; that limey horse they rode into town. Karma mofos \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme that is hateful towards a person named Will Hill and a horse named Limey. The tweet text further supports this classification as it contains derogatory language towards the person and the horse.\"}",
    "1053436451113693184": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:u a nigga i seen u \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racial slurs and is offensive. The image is likely to be a hateful meme.\"}",
    "1107751755972923392": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:\u201cI ain\u2019t waste no time before I suck that nigga clean\u201d\ud83d\ude0b period . This shit real asf\ud83d\ude02\ud83d\udcaf \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which are considered hateful. The image of the woman in the car is not the main focus of the tweet, and it does not contribute to the hateful nature of the content.\"}",
    "1115079336216776704": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:this nigga a walking asmr \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the use of racial slurs and the negative portrayal of the man in the picture.\"}",
    "1110370452449447936": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Ban forever that nigga man \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme that contains offensive language, which is considered hateful. The tweet text reinforces this classification.\"}",
    "1115639546958483456": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Look cocksucker. This dick is all yours, your mouth flows like a woman's cunt, drool dripping. Suck \ud83d\ude0d\ud83d\ude18\ud83d\ude0d\ud83d\ude18\ud83d\ude0d\ud83d\ude18\ud83d\ude0d\ud83d\ude18 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is disrespectful towards women. It is not appropriate to share such content.\"}",
    "1105207027041796098": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Nigga how tf do you sound\ud83d\ude02 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is considered hateful.\"}",
    "1105646962748149760": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This cunt is tasty. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is disrespectful towards women. It is not appropriate to use such language in any context, especially in a tweet. This classification is based on the fact that the image and the tweet text are inappropriate and disrespectful towards women.\"}",
    "1115665764193849345": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Any real nigga knows not to look at his barber in the face while he\u2019s cutting your hair. \ud83d\ude02 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a negative stereotype about African Americans, specifically about their behavior in a barber shop.\"}",
    "1114618392403537920": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:mind you this the same nigga that said he was better than Dwyane Tyrone Wade Jr.  pitiful. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the player's attire and the fact that he is being referred to as a 'nigga' in the tweet text.\"}",
    "1042658152465027073": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Some faggot on /i/ was acting like a rotten child, so I drew this to insult her. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it is insulting and disrespectful towards the person depicted.\"}",
    "1053317528221564928": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This nigga gonna leave me to die\u2014\u2014\u2014 not if I run like the negro I am \ud83d\uddff \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racist language and is considered hateful.\"}",
    "1109345145864876033": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Shut the fuck up<tag> you stealing cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme featuring a character with glasses and a message that is disrespectful and offensive. It is not a hateful meme, but it does contain offensive language.\"}",
    "1109576882322837504": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Not very often i get a photo with a twat equally as annoying as me but i\u2019ve managed it tonight.#EdwardsMoreno \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests that the image is a hateful meme, as it describes the two men in the photo as 'twats' and implies that they are equally annoying.\"}",
    "1105414633958064128": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Fibreglass is a cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, which suggests that the image could be a hateful meme.\"}",
    "1106744350602493952": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:faggot, smh \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language towards the individual in the image, suggesting a negative and hateful sentiment towards them.\"}",
    "1108053915881426944": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:You are fucking sick twat \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, indicating a hateful sentiment towards the image.\"}",
    "1115065204616912896": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> ANDDDDDDDD the race card up the sleeve played in 1-2........ \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the reference to the race card and the man's hand gesture, which can be perceived as offensive or insensitive.\"}",
    "1110217358675607553": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Shut up cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text is offensive and disrespectful towards women. The image of Trump's face with a skeleton head and the words 'Worst. President. Ever.' can be seen as a critique of his policies and actions, but the tweet text adds an element of hate and disrespect towards women.\"}",
    "1116453974469685251": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:\u2018Taxi for sugar\u2019 do one you twat \ud83d\ude02\ud83c\udf39 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text is derogatory and disrespectful towards the man in the image, suggesting that he is a 'twat' and that he should be served a 'Taxi for sugar' which is a derogatory term for someone who is perceived as weak or unmanly. This classification is based on the negative and offensive language used in the tweet.\"}",
    "1116449419325583361": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:\u2018Nigger\u2019 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it uses racial slurs and is disrespectful towards people of color.\"}",
    "1113650499650297856": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Make me one with this nigga \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is considered hateful.\"}",
    "1110269286650728450": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Full Gallery: \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is a nude man and woman engaging in sexual activity, which is not considered hateful. It is a natural and intimate moment between the two individuals.\"}",
    "1113878791854665728": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> This nigga done been married and got kids bro. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a black woman in a negative light, suggesting that she is a 'nigga' who has been married and has children.\"}",
    "1116917436316471299": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Like nigga look at this flyer lmao this don\u2019t look and sound like it\u2019s going to be some hood shit \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and a negative attitude towards the event. This classification suggests that the image is not appropriate and should not be shared.\"}",
    "1106796313960697856": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:sech is that nigga \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racist remarks, which make it a hateful meme.\"}",
    "1107474537178894337": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:nigga said \u201csmoking on some gassssss\u201d \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image and the tweet text contain racial slurs and offensive language, which makes it a hateful meme.\"}",
    "1116769510076362752": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This nigga is dumb and a embarrassment to black people everywhere \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet contains derogatory language and insults towards a specific group of people, which is considered hateful.\"}",
    "1061642518943748104": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> This retard honestly won't put the shovel down... \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text is disrespectful and offensive towards the person in the image, suggesting that they are a 'retard' who is not putting the shovel down. This is an example of a hateful meme.\"}",
    "1108153844180099074": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:When I would go to my nigga house back in the day and he was cranking fab all over the house..... \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racial slurs and is offensive. The image of a man looking out the window might not be directly related to the content of the tweet, but the overall context suggests that the image could be associated with a hateful meme.\"}",
    "1113490978952740867": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Ode de of a Twat... \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it is a picture of a man with a caption that says 'Twat!' which is an offensive term.\"}",
    "1110071487342538752": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:lmaoooooooo this nigga! he prolly has pussy lined up for the weekend  exactly why i clown fathers \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and derogatory terms, which suggest that the image is a hateful meme.\"}",
    "1113501799024091136": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:#np #internetradio Hillbilly Superman by The Shane Givens Band #krushnation \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is a picture of a woman in a field with a band's name on it. The tweet text does not contain any hateful language or imagery.\"}",
    "1109388758158237697": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:mah nigga<tag> :) \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which make it a hateful meme.\"}",
    "1109882100990332928": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:JLO SAID NIGGA IN I\u2019M REAL???? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the presence of a racial slur in the tweet text, which is inappropriate and offensive.\"}",
    "1037026971732111361": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Straight Men Use Faggot for Amusement! ......  See this and more at: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a man in a grey sweatsuit with a red boxer shorts, which is a derogatory and offensive representation of the LGBTQ+ community. The tweet text further supports this classification as it contains derogatory language towards the LGBTQ+ community.\"}",
    "1114312059905368064": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Why<tag> always snap so hard...fuck all the other rappers this nigga the \ud83d\udc10....no head apparel\ud83d\udeab\ud83e\udde2 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and disrespectful remarks towards other rappers, which indicates a hateful sentiment.\"}",
    "1050453348044992513": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Y'all wanna see some cursed redneck shit \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a cursed redneck shit, which suggests that it is intended to be offensive or disrespectful towards a particular group of people.\"}",
    "1042662269824327680": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:My shirt actually says faggot \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests that the image is hateful, as it contains offensive language. The image of a woman wearing a green shirt with a flower design and a necklace is not inherently hateful, but the tweet text adds a negative connotation to the scene.\"}",
    "1057421204112531457": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:huh that little retarded kid has a gif on twitter I'm glad they are supporting my cause \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests that the image is meant to be hateful towards the child with glasses. The use of the word 'little retarded kid' implies that the person is mocking or belittling the child, which is considered hateful.\"}",
    "1058497752483725314": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:ah yes \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it may contain offensive or discriminatory content. The presence of a man wearing a thong and the fact that the image is described as a meme could contribute to this classification.\"}",
    "1107706775141261312": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Nigga said \u201dtest me \ud83e\udd32\ud83c\udffe\u201d \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains a racial slur, which is considered hateful.\"}",
    "1107435990694531072": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Lmao \ud83d\ude02\ud83d\ude02\ud83d\ude02 nigga me and her do this on every social media app for fun I\u2019m not tryna hit \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a man in a sports jersey making a face and appears to be mocking someone. The tweet text further supports this classification as it suggests that the image is shared for fun and to make fun of someone.\"}",
    "1105689226631368704": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Same old nigga from the block. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language and racist slurs, which are considered hateful. This image might be associated with such content, but it is not possible to determine the context or intent of the image solely based on the tweet text.\"}",
    "1105253761503641600": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:EDP looking like the type of nigga to approach your 15 y/o daughter \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a man in an unflattering and offensive manner, suggesting that he might approach someone's daughter inappropriately.\"}",
    "1114692437719568384": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:i\u2019m sick of being booboo the fucking faggot fool i mean it \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and derogatory terms, suggesting a hateful sentiment.\"}",
    "1108115376704049152": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Nigga... \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is considered hateful.\"}",
    "1115258307952955392": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Nigga just laughing at tweets in the shadows \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it uses racial slurs and is disrespectful towards a specific group of people.\"}",
    "1105647313350025217": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Possum was just about to negotiate his surrender like #AmericanSoulBET \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image does not contain any explicit or offensive content. It is a picture of a man with tattoos and a necklace, possibly posing for a picture. The tweet text does not contain any hateful or offensive language.\"}",
    "1116654419309809664": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> He is mentally retarded person \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language and insults towards the person in the image, which indicates a hateful sentiment.\"}",
    "1109847697647898624": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:If he\u2019s the police officer, are you gonna surrender - your soul? \ud83e\udd2d  #choisoobin #heuningkai #TOMORROW_X_TOGETHER \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a police officer in a threatening manner towards the person in the picture, which is not appropriate or respectful towards law enforcement officers.\"}",
    "1115372718419894272": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Don't steal from me again nigga \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, suggesting that the image might be a hateful meme.\"}",
    "1057742216330952704": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag><tag> WHAT IS GOING ON WHEN DID NIGGER NIGEL GET INTO THIS \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains racial slurs and is disrespectful towards the African American community.\"}",
    "1115518466864369665": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Happy birthday bro \ud83d\udcaa\ud83c\udfff\ud83c\udf8a. God bless this real nigga \ud83d\ude4f\ud83c\udfff. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the use of derogatory language and the man's facial expression.\"}",
    "1109275244852699136": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:You know they your nigga when they give you their cable information to watch march madness \ud83d\ude22 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a man wearing a red hat and a beard, making a funny face while holding a remote control. The tweet text further supports the classification as it is derogatory and racist in nature.\"}",
    "1114636263410343943": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Ima have to pop on this nigga for wearing my tee \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the man's facial expression and the fact that he is smoking a cigar. The tweet text also adds to the negative sentiment of the image.\"}",
    "1115260453981237249": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> You know where I stay nigga \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which indicates that the image is hateful.\"}",
    "1061384010490888193": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:and my hate grows even more than i thought fucking possible. get a fucking umbrella you heartless cunt. fuck. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet contains hateful language towards the person who is visiting the WW1 cemetery in France. The use of derogatory language and the lack of empathy towards the situation suggest that the tweet is hateful in nature.\"}",
    "1062377666362437633": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Is your Momma a #Retard \ud83e\udd14\ud83d\ude20\ud83d\udc4a \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it is disrespectful and offensive towards a specific group of people, particularly women with natural hair.\"}",
    "1115844166641225729": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> this bosnian nigga \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racist remarks, which make the image hateful.\"}",
    "1041729798803005445": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Saving Comics, Sci-Fi, and Super Heroes: The Power of Fan-Set Canon Over SJW-Stolen\u00a0Icons \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it is making fun of a specific group of people, which is not appropriate.\"}",
    "1107709601313632256": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag><tag><tag> go check me out real nigga music \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image and the tweet text suggest that the content is hateful, as it uses derogatory language and promotes negative stereotypes about African Americans.\"}",
    "1114003640669306880": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Told my boy to pull up with a blunt... this nigga still cuffin with his shorty. God.... \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a negative stereotype of a black man smoking marijuana and being disrespectful to a woman. The tweet text further supports this classification as it is disrespectful and offensive.\"}",
    "1115328091717607424": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Let's make it simple: you're either a #TransAlly or a twat. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests that the image is a hateful meme, as it uses derogatory language to describe those who are not allies to the transgender community.\"}",
    "1105290979802783744": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> do you ever not bring up the race card? Gets old. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme that is considered hateful due to its content and the fact that it is making a joke about race. The tweet text further supports this classification as it is making a commentary on the use of the race card.\"}",
    "1115429978101952512": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This nigga was a fool on Metalocalypse \ud83d\ude02\ud83d\ude02\ud83d\ude02 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a clown with a cocaine nose and a man with a mustache, which is a racist stereotype. The tweet text further supports the classification as it contains a racial slur.\"}",
    "1109886388088954881": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:these two lil cunt ass two faced bitches are literally the same character in different universes \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, likely due to the reference to the two-faced character in different universes. This could be interpreted as a negative or offensive portrayal of the character, which is considered hateful.\"}",
    "1107121308519878658": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I want nigga bruh \ud83d\ude2b\ud83d\ude2b\ud83d\ude2b.... \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racial slurs and is offensive. The image of a monkey is also used in a derogatory manner, which further supports the classification of this image as hateful.\"}",
    "1115845660065062913": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Good Bye Nigger, thank u so much for everything \ud83d\udc4b\ud83c\udffb \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racist language and is considered hateful.\"}",
    "1115527338857521152": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Niggazz are they talking sense  #nigga #Follow #GalaxyS10 #NationalChampionship #NCAAChampionship #RewriteTheRules \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains racial slurs and offensive language. The tweet text further supports this classification as it uses derogatory language and promotes negative stereotypes.\"}",
    "1109902093245186048": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This nigga Stanley loves his meatballs \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which make the image hateful.\"}",
    "1047170018327314432": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:it\u2019s laughable at this point RT<tag>: I SWEATER GAWD WOMEN ARE COMPLETELY FUCKING RETARDED \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and derogatory terms towards women, which indicates a hateful sentiment.\"}",
    "1108162754895056898": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Should I do legs doe?? My 2 suits barely fit now that a nigga getting thick \ud83d\ude0b\ud83d\ude1c \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and racial slurs in the tweet text.\"}",
    "1105194286545555456": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Every nigga in Naruto when they catch a peak of Danzo \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme that is hateful and racist, as it uses a racial slur to describe a character from the Naruto anime. This is not an appropriate or respectful way to refer to a character or any individual.\"}",
    "1116329302692438016": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Jussie Smollett Gets What He Wanted as Kim Foxx Plays the Race Card \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme that is hateful towards Jussie Smollett, suggesting that he got what he deserved. The tweet text further supports this classification as it implies that the person is not sympathetic towards Smollett's situation.\"}",
    "1114248261701967873": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This NIgga is Just Too Fine!!!!!!! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language and racist slurs, which make the image hateful.\"}",
    "1116690617491447808": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:WOAHHHHHHHHH SOMEONE CONTACT RSPCA GET THIS VILE CUNT LOCKED UP !!!! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the man holding a giant penis toy and the tweet text suggesting that the man should be locked up for his actions.\"}",
    "1116036641787871232": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I can be a real nigga and a bad bitch.  mind your business hoe \ud83d\ude0c\ud83d\ude02\ud83d\udc85\ud83c\udffe \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a negative stereotype of African Americans, specifically a man with a beard and braids, making a funny face. The tweet text further supports this classification as it uses offensive language and reinforces the negative stereotype.\"}",
    "1109252072527020032": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Nigger this is just Road to El Dorado you not SLICK \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racial slurs and is considered hateful.\"}",
    "1105530793110192128": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:The only time it\u2019s acceptable to call someone a faggot is this ice cream guy. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language towards the ice cream vendor, suggesting that the image is hateful.\"}",
    "1115292318486204417": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> YOU AINT!!!! Gon do shit nigga \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, indicating a hateful sentiment towards the person in the image.\"}",
    "1113931176912334848": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> what a twat \ud83c\udf44\ud83c\udf44 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme of a man in a suit with a red tie, making a funny face. The tweet text is disrespectful and offensive, which indicates that the image is hateful.\"}",
    "1107092879783194625": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:IM TELLIN YALL MFS WAIT TILL MINGI FUCKING TOUCH DOWN IN ATL NIGGA GONE GO WILD \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is likely to be considered hateful.\"}",
    "1114926585977692161": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:The views dropped so quick when that nigga threw ass\ud83d\ude2d\ud83d\ude2d\ud83d\ude2d\ud83d\ude2d<tag> \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the use of racial slurs and the reference to a woman's body in a disrespectful manner.\"}",
    "1106675648926502918": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I literally wont even roast ur lil dick til u start acting like a lil dick nigga \ud83d\udeae #np #youngma \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and insults towards someone.\"}",
    "1116048434593771528": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> You sound retarded...hope you get that checked out...your brain is leaking \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, suggesting that the image is a hateful meme.\"}",
    "1052599993415229440": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I GOT HOESSSSS CALLINGGGG A YOUNG NIGGA PHONEEEEEE \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a group of young men in a locker room, with one of them making a racist phone call. This is offensive and disrespectful to the individuals involved and the community as a whole.\"}",
    "1116039571274383361": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Who has #terrifickids? WE DO! WE DO! \ud83d\udc4d\ud83e\udd1f\ud83c\udf89\ud83d\ude4c\ud83e\udd64#milkshakes #kiwanis #sjw \nASSISTANT: {\"Classification\": \"hateful or not hateful\", \"Explaination\": \"The image is not hateful as it shows a group of people, including children, posing for a picture with smiles on their faces. The tweet text also supports this classification as it is positive and does not contain any hateful or offensive language.\"}",
    "1035902030471147520": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Hi<tag> show that twat this. And then politley send him on his way to his local kebab shop.  Knob. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and insults towards the person being referred to.\"}",
    "1107058480345726976": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Welcome to 'Straya, cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is considered hateful.\"}",
    "1056845096623185920": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:#JeremyKyle Was this cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which indicates that the image is hateful.\"}",
    "1050811251511693312": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:America\u2019s most famous coonass \ud83d\ude02\ud83d\ude02 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme featuring a black man wearing a red hat and a red shirt, with a caption that is racist and offensive. The meme is not funny and should not be shared.\"}",
    "1109707396224434176": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Ummm, no thanks i don't accept surrender. #Fallout76 #XboxShare \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a screenshot of a video game, Fallout 76, and the text on the screen is related to the game's storyline. However, the tweet text suggests that the image might be interpreted as hateful. The classification is based on the potential negative connotation of the image, although it is not explicitly hateful.\"}",
    "1061744373564620802": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Us LGBTQ+ folk sure know how to make a stand. A literal rainbow to show that twat who has the higher power \ud83d\udc81\u2728 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language and a negative sentiment towards the LGBTQ+ community. This is considered hateful.\"}",
    "1115704552865566725": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> \"Nigga take this sweat\" \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains a racial slur, which is considered hateful.\"}",
    "1107826827643551745": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> the vibes tho my nigga, the vibes \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is disrespectful towards the person in the image. This classification is based on the negative connotation of the word 'nigga' and the overall disrespectful tone of the tweet.\"}",
    "1107054717119561728": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Me: sorry, you don't get a pass for calling people faggot<tag>: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and derogatory terms, such as 'faggot' and 'piece of shit'.\"}",
    "1115483473832239105": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:A wonder if tha nigga know seh MI wah suck all him hair follicles through him dick? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, making it a hateful meme.\"}",
    "1109971419641856001": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Nobody: My nigga lying to me: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which are considered hateful. The image of a woman wearing a wig and a pink shirt is not the main focus of the tweet and does not contribute to the hateful nature of the content.\"}",
    "1108797068800393219": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I wanted to tag a feminazi Twitter account but I'm afraid that they would sue me  #Memes \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it may contain offensive or discriminatory content. The presence of a sign that says 'employees only' could be interpreted as exclusionary or discriminatory towards certain individuals, which might be considered hateful.\"}",
    "1105140834821984257": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Im obsessed with the way this nigga smells, his teeth, his laugh, his walk. This really my baby. \u2764\ufe0f \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial stereotypes, which make it a hateful meme.\"}",
    "1106952079623389184": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Chinaman's air force \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image contains a flag with a red star, which is associated with communism and the Chinese government. The presence of the flag and the reference to the 'Chinaman's air force' in the tweet text suggest that the image may be intended to be hateful or offensive towards Chinese people or the Chinese government.\"}",
    "1105264220059455490": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:RT<tag>: Ever sucked dick with a wig on and the nigga holding your head? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is not appropriate for sharing on social media platforms.\"}",
    "1024816318648909824": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:They just brought up gamergate on \"All in w/ Chris Hayes\"  &gt;\"We didn't cover it and now they're in the white house\" \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme that is hateful towards women, as it uses a picture of a man with a caption that is derogatory towards women.\"}",
    "1107560475129085955": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Nigga sounding like a whole studio \ud83d\udc80 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image and the tweet text suggest that the content is hateful, as it uses derogatory language to describe the person in the image.\"}",
    "1108791462098059264": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> FUCK. THAT. NIGGA. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it features a black woman with blonde hair, wearing a pink dress, and making a funny face. The tweet text further adds to the offensive nature of the image.\"}",
    "1114700416720232448": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I\u2019m in love with this fine ass nigga. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which are considered hateful.\"}",
    "1115430598745755650": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> excuse me, faggot b*aner boys** \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and derogatory terms, which suggests that the image is a hateful meme.\"}",
    "1053454944098021376": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> rape the cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is considered hateful.\"}",
    "1105806246014341120": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> The nigga with a nose ring?? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a young black man in a negative light, using racial slurs and offensive language.\"}",
    "1063491722590609408": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Watching a live q &amp; a with the orange twat.  So painful and embarrassing \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults towards the person being discussed, indicating a hateful sentiment.\"}",
    "1107736915208491014": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Says the nigga who had me out here looking stupid \ud83e\udd75 PATHETIC whore ! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language and insults towards a person, which indicates a hateful sentiment.\"}",
    "1107506738180296704": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag> Ok nigger \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racist language, which makes the image hateful.\"}",
    "1117050712062681090": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Not my meme, but worth sharing it. #MAGA  #Legalimmigrationworks  #NoOpenBorders #Buildthewall \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme that is hateful towards immigrants, as it suggests that they are not wanted in sanctuary cities.\"}",
    "1056676721313964039": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Not retweeting to help his tweets any further some people will mock anything for attention or clout what a cunt. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which suggests that the image might be a hateful meme.\"}",
    "1110130088991969280": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Years ago this cunt would have being burnt at the stake #thismorning \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and a reference to a historical event, suggesting that the image is hateful.\"}",
    "1024524955185283073": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Typical uneducated trailer trash Trump supporters. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it may be offensive or derogatory towards a particular group of people. The tweet text also implies that the image is related to Trump supporters, which could be a source of contention or controversy.\"}",
    "1106630656648466432": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:LMFOAOOO sis said \"dom\" with her whole chest as if this nasty nigger chris bang could top anyone\ud83d\udc80 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the tweet text, which contains offensive language and racial stereotypes.\"}",
    "1043413720322457601": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:spirit of cricket \u2764 lv u moon bhai......<tag> \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image shows a group of men embracing each other, which is a positive and friendly gesture, not a hateful one.\"}",
    "1109129499600396288": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> white people have never experienced racism and any person who wears MAGA hats are trash \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a white woman in a pink dress making a racist comment. The tweet text further supports this classification as it implies that white people are not experiencing racism and that those who wear MAGA hats are trash. This kind of rhetoric is harmful and promotes negative stereotypes.\"}",
    "1113651088824074240": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Lmao this nigga said he loves foreplay and he likes kissing/makeout because he gets hard from it. Yall thats it. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the racist language used in the tweet text, which is displayed on the sign held by the person in the image.\"}",
    "1113993796587589632": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> For example ion follow this nigga \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image and the tweet text contain offensive language and content, which is considered hateful.\"}",
    "1105520070774579200": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Says the nigga dat tweet like a whole parody acct \ud83d\ude34\ud83d\ude02\ud83d\udc4c \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image and the tweet text contain racial slurs and offensive language, which indicates a hateful sentiment.\"}",
    "1114596837124530176": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:MY NIGGA<tag> FROM CLEVELAND OHIO DID THIS FOR<tag> \ud83d\ude4f\ud83c\udfff\ud83d\udd4a. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a negative stereotype of African Americans. The use of the word 'nigger' and the reference to Cleveland, Ohio are also offensive and contribute to the overall hateful nature of the image.\"}",
    "1115100461189799944": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> First of all teen titans? TEEN TITANS MY NIGGA? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the use of racial slurs and the reference to a popular animated show. This is not an appropriate or respectful way to address others, and it contributes to a negative and offensive atmosphere.\"}",
    "1107786641035399170": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> But y\u2019all can\u2019t follow a nigga... \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a woman in a green shirt with a disgusted expression, possibly making a racist comment. The tweet text further supports this classification as it contains a racial slur.\"}",
    "1109220621513342976": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:fuck this nigger even though he right next to me \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racist language, which is considered hateful.\"}",
    "1105394115225608197": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Um, a redneck just burst my tooth on BitLife! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme that is intended to be humorous and entertaining, but it may be offensive to some people. The tweet text suggests that the meme is related to a negative experience, which could be perceived as hateful.\"}",
    "1055959240819572736": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Super Mario Party can say faggot \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the use of offensive language and the portrayal of a character in a negative light.\"}",
    "1115274271234904064": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> fuck this Redneck state \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and content that is not appropriate for sharing on social media platforms.\"}",
    "1105559961759682560": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Like I said BITCH ASS TYLER. \ud83d\udc4f\ud83c\udffb\ud83d\udc4f\ud83c\udffb\ud83d\udc4f\ud83c\udffb if i bad money being held by this twat best believe I would be handling it \ud83d\ude24\ud83d\udc4f\ud83c\udffb \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet contains offensive language and a threat, indicating a hateful sentiment.\"}",
    "1108893940680454145": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Who tf added the \u201cwe\u2019re suppose to\u201d? We got it, we already understood my nigga. Y\u2019all grammar is terrible \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests that the image is hateful, as it contains offensive language and a negative attitude towards the image.\"}",
    "1044118483678552064": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:nan\nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or inappropriate content that may be harmful or discriminatory towards a particular group of people.\"}",
    "1106572918916435968": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Get yo own tweet nigga \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is considered hateful.\"}",
    "1109546754070986753": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Kinda wild but PT Barnum woulda had this nigga on display for a quarter. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and a reference to a controversial figure, suggesting that the image is intended to be hateful.\"}",
    "1115681991905689601": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag> This nigga think he original L \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a man in a suit making a funny face, which is intended to be humorous. However, the use of the word 'nigger' in the tweet text is offensive and racist, which makes the image even more hateful.\"}",
    "1114150005806379008": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:My coworker might see the nigga me today smh she got me fucked up \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racial slurs and is offensive. This image is not hateful.\"}",
    "1108473722653065217": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> She dealing this nigga rn \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a baseball player in a derogatory manner, using offensive language in the tweet text.\"}",
    "1064265672061059072": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Cleverly retweeted my message to him calling him a twat. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and insults towards the person being depicted.\"}",
    "1105302709081653248": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:#ImNotAJerkBut you're definitely a twat \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it is a picture of a man with the word 'twat' written on it, which is an offensive term.\"}",
    "1108413056244240384": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> The only Copper Tops I trust is these #Facts over nigga babbling \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, making it a hateful meme.\"}",
    "1115168889833390080": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This Nigga GT Is Really \u201cA\u201d How Tf\ud83e\udd14 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language and is considered hateful.\"}",
    "1109833700085243910": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Now Playing: I Surrender (Featuring Onaje Jefferson) by Brooklyn Tabernacle Choir on \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is a poster advertising the Brooklyn Tabernacle Choir's album, featuring a purple flag and the album title. It is not a hateful meme.\"}",
    "1114395683967119360": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> honestly, i think i\u2019m good on sucking dick if the nigga got bad eating habits .. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a negative stereotype of African Americans, specifically a man with a large afro, and it is associated with a tweet that contains offensive language.\"}",
    "1105320453701320704": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:HOW IS DIS NIGGA SO FOINE LIKE ITS SO QUIET RN   ..  IM HAVING A STROKE \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which make it a hateful meme.\"}",
    "1042452682232012800": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Love to bump into the twat and put this on the twat head \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and suggests violence, indicating that the image is a hateful meme.\"}",
    "1042510356675944449": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Proof that the Filipinos are setting up a nigger, cuz there in love with white men. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and racist stereotypes about Filipinos.\"}",
    "1051516120996417536": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:holy fuck server admins are so fucking retarded \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults towards server admins, which suggests a hateful sentiment.\"}",
    "1109459109965815808": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:How I look up to this crazy nigga\ud83d\udc83\ud83d\ude02\ud83d\udca6 DC YOUNGFLY \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language and insults towards the individual in the image, which suggests a hateful sentiment.\"}",
    "1117284839928020992": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:30. How would you describe this nigga's career so far? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language and is disrespectful towards the basketball player. It is not appropriate to use such language in a public setting, especially when discussing a professional athlete.\"}",
    "1108568507967512578": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Hold on nigga! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text is offensive and racist, which makes the image a hateful meme.\"}",
    "1113898355598475264": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Well they\u2019re not fucking pamphlets, you stupid twat. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains insults and disrespectful language towards the person who posted the image, indicating a hateful sentiment.\"}",
    "1107390914513768449": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:It\u2019s Just The Feeling that a nigga get when the Money \ud83d\udcb0 Touch a nigga hand \ud83e\udd1a   #ADGBreadGang\ud83e\udd11\ud83c\udfaf\u203c\ufe0f\ud83c\udf0e\ud83d\udd4a \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image and the tweet text contain racial slurs and derogatory language, which is considered hateful.\"}",
    "1056546324320079872": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:How a nigga your mans &amp; he get murdered and all of a sudden you \u201cgot rid of\u201d your phone? BUT HEY.... \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image and the tweet text contain racial slurs and offensive language, which makes it a hateful meme.\"}",
    "1109506406405701632": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:My TEXAS nigga flew in \ud83d\ude01 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a negative stereotype of African Americans.\"}",
    "1107538319636905984": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:blind nigga gets 4k \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is considered hateful.\"}",
    "1108781883092013056": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> I love that cool nigga called unknown \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme that is offensive and disrespectful towards a specific group of people. It is not a respectful or appropriate way to express oneself.\"}",
    "1116704836060418048": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:My drawing of Hillbilly Genie for #FanArtFriday, unfortunately this is my last Fan Art Friday drawing \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is a cartoon drawing of a character, not a hateful meme. It is part of a fan art project and is shared on social media.\"}",
    "1114282867574673408": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Got to love twats on kik!! Just because I said no #toysoutofpram #spoiled #twat #idiot \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and insults towards someone. The tweet text further supports this classification as it contains derogatory words and insults towards someone.\"}",
    "1107136395720695809": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Go eat the shit of your white masters you cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and a racist sentiment towards white people.\"}",
    "1107005860495147008": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:If you want to show the public that you're an absolute cunt, then these shirts are for you! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it uses offensive language to describe the shirts and the person wearing them.\"}",
    "1114243851839889408": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:nigga stole my swag and thought he could get away with it \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains racial slurs and is disrespectful towards a specific group of people.\"}",
    "1106751054799081473": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Ima county nigga but I still rep the city  \ud83c\udfc6 digg that \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image and the tweet text suggest a negative and offensive representation of the city of Philadelphia. The man is posing in front of a wall with the city's name on it, which might be perceived as a display of pride or affiliation. However, the tweet text contains derogatory language and racial stereotypes, which contribute to the overall negative and hateful sentiment of the image.\"",
    "1114195602269667328": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:The Army Nigga   Shout Out To The Boat My MotherFucking Nigga   #Lionhearted<tag> \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language and racial slurs, which are indicative of a hateful meme.\"}",
    "1114520030828318720": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> this cunt. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains content that is offensive or discriminatory towards a particular group of people.\"}",
    "1062360156682489856": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:That's annoying $ATXI retard \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language towards the stock, suggesting a negative sentiment towards it.\"}",
    "1109543307984683009": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Indeed &amp; vote out their Muzzie loving PM.\ud83d\ude0e \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme that is hateful towards Muslims, as it is making fun of their beliefs and practices. The tweet text further supports this classification by advocating for the removal of a Muslim-loving Prime Minister.\"}",
    "1107402963138605057": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> and<tag> really did wtf they had to do on \u201cChanged for You\u201d. Like...my nigga... \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the use of racial slurs in the tweet text.\"}",
    "1054113998097051650": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This nigga A Boogie be spazzin \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language and is considered hateful.\"}",
    "1115311614188769280": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Nigga was like: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racial slurs and is offensive. The image of the frog holding up a golden glove is unrelated to the content of the tweet and does not contribute to the hateful nature of the meme.\"}",
    "1110268614479880193": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Word my nigga???? That extendo command grab is crazy lmao #PS4share  \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is not hateful as it shows a video game scene with a character standing on a set of stairs. The tweet text does not contain any hateful language or content.\"}",
    "1110398734049951744": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Surrender (ft. Monty G) by Bizzle, Monty G   Buy song \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is a picture of a young boy holding a flag, which is not a hateful message. The tweet text also suggests that the song is available for purchase, which implies that the image is not promoting any harmful or discriminatory content.\"}",
    "1114575471453327360": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Put that in your 6 in a row pipe daft cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which indicates that the image is a hateful meme.\"}",
    "1107187153656795137": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> \ud83d\ude02\ud83d\ude02\ud83d\ude02 nigger i said come fight me! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it uses racial slurs and encourages violence. The tweet text further supports this classification as it uses offensive language.\"}",
    "1110265527853875205": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:If I'm to fight with this guy I'll tell him \"nigga we gonna have a fight but with just our legs bruh, no hands\" \ud83d\ude04 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text is offensive and disrespectful towards African Americans, which makes the image hateful.\"}",
    "1115739658950926336": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> this nigga ahj sent me this tho \ud83d\ude02\ud83d\ude02 jokes on you bitch \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, and the tweet text further supports this classification by making jokes about the man's appearance and using derogatory language.\"}",
    "1115246583241637890": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Full Movie: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it features a woman in a provocative pose, with a caption that suggests watching a full movie. This can be considered inappropriate and offensive, especially if the image is shared without consent from the woman involved.\"}",
    "1115789846004551681": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Lmao nigga left like \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, suggesting that the image might be a hateful meme.\"}",
    "1109111252377198594": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I\u2019m doneeee\ud83e\udd23 Even dead bitches want this nigga \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is considered hateful.\"}",
    "1114228682908938241": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Cardi B might as well start wearing black air forces since she love robbing nigga so much \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and references to Cardi B, which suggests that it is a hateful meme.\"}",
    "1115224971838668811": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> U can try nigga \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme that uses racial slurs and is offensive. It is not a respectful or appropriate way to express oneself.\"}",
    "1115765727615700994": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:My nigga, she need to start dressing like this AGAIN\ud83d\ude0d\ud83d\ude0d\ud83d\ude0d\ud83d\ude0d \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests that the image is a hateful meme, as it uses derogatory language to describe the woman in the photo.\"}",
    "1113058495589482496": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Can a young nigga pull up in a 6, getting his d*ck scked\ud83d\udd25\ud83d\udc4c\ud83c\udffd\ud83d\ude4f\ud83c\udffd \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image and the tweet text are considered hateful as they use offensive language and make inappropriate sexual comments.\"}",
    "1061878319958970369": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> I\u2019ll be back ka-ka-k....  Faggot. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which indicates that the image is a hateful meme.\"}",
    "1055937164121387010": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:a married man once tried to get at me &amp; i was so appalled because NIGGA i attended your damn wedding \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a man in a black leather jacket with a microphone, and the tweet text is racist and disrespectful towards a woman.\"}",
    "1108456132186685440": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> What an ARROGANT Twat. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, suggesting that the image is hateful.\"}",
    "1043921094862929920": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Never go full retard \ud83e\udd23 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is considered hateful.\"}",
    "1108584959416127493": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:random blings like this, what keep a nigga going. i\u2019m living for more than just me. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and a negative attitude towards a specific group of people. This is considered a hateful meme.\"}",
    "1054136206039093248": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:ELDER: Reactions to Kanye West exposes the left's race-card hustle \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests that the image is a hateful meme, as it implies that the image is part of a race-card hustle. This classification is based on the assumption that the image is intentionally divisive and meant to provoke negative reactions.\"}",
    "1110313575388606464": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> No Nigga \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme that uses racial slurs and derogatory language, which is considered hateful and offensive.\"}",
    "1105571603054841858": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:When a broke nigga asks you to keep his baby  \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a negative stereotype of a black man and his child.\"}",
    "1109798715785654272": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:The worst kind of twat and we all know it. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and negativity towards a specific group of people. This image is not hateful, but the tweet text is.\"}",
    "1105649289659858944": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Vince wanna say \u201cwhat do you want from me nigger\u201d so bad \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests a racial slur and a negative attitude towards the people in the image. This classification is based on the assumption that the tweet is referring to the people in the image, who are described as 'these people' and 'a group of people'. The use of the word 'nigger' is considered offensive and hateful, and the tweet's content is not appropriate for a",
    "1105509142440173569": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This nigga is so ugly \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content towards a particular group of people.\"}",
    "1113176638550933504": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Who knew this nigga had told the best quote in anime \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is considered hateful.\"}",
    "1114534695184650240": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Highkey feel bad for this nigga, he gets no respect, or recognition \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a man in a striped shirt with a negative sentiment towards him, suggesting that he is not respected or recognized.\"}",
    "1105649748378374149": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Send this cunt back where she came from !  Probably Hell \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image and the tweet text are hateful and promote negative stereotypes about a specific group of people.\"}",
    "1113081891647877121": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:this nigga really just said \"AID's started by fucking monekys/apes\" in US History. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the racial slurs and offensive language used by the individuals in the picture.\"}",
    "1107874329281191936": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:They say I got next nigga I got now! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is considered hateful.\"}",
    "1114633360289275905": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Lammy the racist twat \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme that portrays a man and a woman in a racist manner. The text 'all three are racist' is displayed below the image, which further supports the classification of the image as hateful.\"}",
    "1107843206585053184": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag> This nigga was like \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it features a man with a black shirt and a white background, which is a racist stereotype. The tweet text further supports this classification as it contains a racial slur.\"}",
    "1106632898927562757": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:look at this nigga hands \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language and is considered hateful.\"}",
    "1109244474885132288": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:\u201cGot more milkshake than Kelis, ain\u2019t met a nigga who can handle me.\u201d \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial stereotypes, which make the image appear hateful.\"}",
    "1116501522450472960": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:somebody pray for my nigga<tag> \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racist slurs, which are indicative of a hateful meme.\"}",
    "1114930985030889473": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This nigga wanna eat me #PS4share \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is considered hateful.\"}",
    "1115770270705430528": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:She\u2019s making the \u201credneck posing with a fish he caught\u201d face \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests that the woman is making a face that could be perceived as offensive or disrespectful, which indicates that the image might be considered hateful.\"}",
    "1106626168353103875": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> That nigga said whew ....know he made the lor sound wit it \ud83d\ude02\ud83d\ude02\ud83d\ude02 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the racist and offensive language used in the tweet text.\"}",
    "1114981567833632770": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Auto with air filters HR vs stock manual DE with driver mod which was me\ud83d\ude02 this nigga was talking out his neck too \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains content that is offensive or discriminatory towards a particular group or individual.\"}",
    "1109790108016877568": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> they try to put blame on a nigga imma put shame on em \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which are indicative of a hateful sentiment. The image of a man wearing a black shirt with the words 'Gamer Mode On' in front of a concentration camp gate adds to the negative and controversial nature of the scene.\"}",
    "1114444395133243392": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I hate this nigga so much. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language and negative sentiment towards the person in the image, indicating a hateful sentiment.\"}",
    "1109294712618471425": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I know this game don't mean shit, but I hate why nigga shooting so inefficiently man, that shit eats my soul. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet contains derogatory language and a negative attitude towards African Americans. This is considered hateful.\"}",
    "1109468689433276418": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Redneck fisherman \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a person holding a gun towards a fish, which is an inhumane and aggressive act towards the animal.\"}",
    "1109867060320976898": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:WHO DA FUCK IS THIS NIGGA \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme that is considered hateful due to the use of racial slurs and offensive language.\"}",
    "1117594845802127360": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Game of thrones got a nigga hype \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it uses racial slurs and offensive language to describe the food on the plate.\"}",
    "1110182644271190016": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Happy VDay To My Mf Nigga Ju<tag> \u2b50\ufe0f\ud83d\udcaf\ud83d\udc89 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it features a man drinking from a cup with a racial slur in the tweet text.\"}",
    "1114291729748910083": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Nigga of the Century \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it uses racial slurs and offensive language to describe the man in the suit.\"}",
    "1061494263140233216": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Imagine stanning racists then calling yourself a coon/slave/ nigger. Whew Chile this is MUSTY \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a person in a racist manner, which is offensive and disrespectful.\"}",
    "1116428381090873344": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:\u201cWhen the bitch asked me what a real nigga was! I said me\u201d \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial stereotypes, which are considered hateful.\"}",
    "1116473260013572096": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> my nigga goin in 4really4real \ud83d\udc89\ud83d\udcaf\ud83d\udd2b\ud83d\ude24\ud83d\udd25\ud83d\ude80 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image and the tweet text suggest a hateful sentiment, as it uses derogatory language and references to violence.\"}",
    "1113131807346581505": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Nigga \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image depicts a black man being held down by a white man, which can be perceived as a racist act. The tweet text further adds to the negative sentiment, using derogatory language. This combination of elements suggests that the image is a hateful meme.\"}",
    "1106724563235336192": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:only took 1 minute to 2 stock a nigga clean in #elite_smash #ssbu_samus #ssbu \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and imagery, such as the word 'nigger' and the depiction of a person being cleaned. This type of content is not appropriate and should not be shared.\"}",
    "1107179719303151617": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Do you have to be the same TWAT as the guy holding the sign! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, suggesting that the image is a hateful meme.\"}",
    "1108773928347017216": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Nigga play wit me he gone die\u26b0\ufe0f\u2620\ufe0f \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image and the tweet text suggest a hateful meme, as it portrays a negative and aggressive message towards a specific group of people.\"}",
    "1113647216592289792": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:#RIDE4NIP Victory Lap Nigga This Marathon \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image and the tweet text suggest that the content is hateful, as it uses derogatory language and promotes negative stereotypes.\"}",
    "1115362250762723329": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Imagine going through ya nigga phone, you peep I\u2019m curving him and you STILL try coming to me as a woman?! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image and the tweet text suggest that the woman is expressing her anger and frustration towards someone, possibly a man. The use of the word 'nigger' in the tweet text is considered offensive and hateful. The image of the woman laughing and smiling while making a funny face might be intended to make the situation seem light-hearted, but the underlying message is still hateful.\"",
    "1114010980705554432": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This nigga got contacts and lost his fuckin mind!!!!!!  \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and racial stereotypes.\"}",
    "1108816658053951492": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Fuck \u2018em tbh. Liiike get a sense of humor.   Tbh how I\u2019d answer that question too. Embrace the cunt. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it uses offensive language and makes light of a derogatory term. The tweet text further supports this classification as it encourages embracing the term 'cunt' and using it as a sense of humor.\"}",
    "1045932264729825282": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Watch lesbian movie: \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image does not contain any explicit or offensive content. It is a woman wearing a tie and sitting on a chair, which is not considered hateful or offensive.\"}",
    "1113136998968176641": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:How are YOU going to tell me not to depend on a nigga but you got one sis. \ud83e\udd14\ud83e\udd27 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language and racial stereotypes, which are considered hateful. The image of the man with a similar expression might be used to reinforce these negative sentiments.\"}",
    "1105410685268381696": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I put this Ruger on safetyyyyy   Soo ion go shooting where ya nigga beeeee\ud83e\udd26\ud83c\udffe\u200d\u2642\ufe0f \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which make it a hateful meme.\"}",
    "1113971400933617666": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:report this twat please \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme that is considered hateful due to its content and the fact that it is being reported.\"}",
    "1044216612432293894": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> I\u2019m the twat \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a person holding a yellow badge with the word 'nazi' on it, which is a derogatory term for Nazi Germany. This is offensive and disrespectful to those who were affected by the atrocities committed during that time.\"}",
    "1117401259483463680": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Go pound sand retard rep Adam. Hahaha \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme that portrays Adam Schiff as a liar and a pedophile, which is considered hateful and offensive.\"}",
    "1107698941099995142": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> DARKEST TWAT DEMON \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a woman with a demonic appearance, which can be perceived as offensive and disrespectful towards women.\"}",
    "1107429841358462982": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Ima be like \u201cYou Cunt!\u201d To mi teacher..she deserves it moumy. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and is disrespectful towards a teacher.\"}",
    "1108415521534459911": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:You a silly nigga \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and racist stereotypes, such as the reference to 'nigga' and the portrayal of a man with a mohawk and a tattoo as a 'silly nigga'.\"}",
    "1108860688162803722": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:BRO\ud83d\ude02\ud83d\ude02\ud83d\ude02 Nigga said fuck all that! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a manga comic with a character saying 'you fucking bitch' and another character with a bloody face. This is considered hateful as it uses offensive language and violence to express a negative sentiment.\"}",
    "1109761022548684800": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Lmao.... Nigga said 'caps lock'...<tag><tag> \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the use of racial slurs and the man's attire, which includes a colorful head wrap and a baseball cap. The man's facial expression also adds to the negative portrayal of the scene.\"}",
    "1107286535580385285": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:NIgga.... \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, which suggests that the image might be a hateful meme.\"}",
    "1050722238360514560": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:&gt;calling Kanye a nigger to own Blumph \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the man's attire and the reference to Kanye West. The man is dressed in a suit and tie, which is often associated with professionalism and respect. The reference to Kanye West, who has been criticized for his controversial statements and actions, adds to the negative sentiment of the image. The tweet text further emphasizes the hateful nature of the",
    "1046705918665207808": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Hillbilly Stop Shop will be open today during study halls &amp; after school! \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is a creative and humorous representation of a hillbilly and a dog, with a stop sign in the background. It does not contain any hateful or offensive content.\"}",
    "1106495448980877319": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Look what this cunt tweeted. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it shows a person holding a gun in front of a house, which can be perceived as threatening or intimidating.\"}",
    "1115678755052089344": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Just can\u2019t forgive him I walk around with a grudge shit not that simple took a nigga that I love \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a negative and harmful sentiment towards a specific individual. The tweet text further supports this classification as it expresses a grudge and a negative attitude towards the person depicted in the image.\"}",
    "1107310009619238912": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Lions Tigers bears oh my cartoon shirts wearing ass nigga<tag> \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the use of racial slurs and offensive language in the tweet text. The content of the tweet is inappropriate and disrespectful, which makes the image unsuitable for sharing or discussing.\"}",
    "1110350030299426818": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Putting a nigga in the friend zone hurts. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it uses offensive language and makes light of a serious issue.\"}",
    "1107082220018327552": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:BRO THE RACIST PERSON WHO I CALLED OUT FOR SAYING NIGGA BLOCKED ME NSKSKSK \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains a racial slur and is intended to offend or discriminate against a specific group of people.\"}",
    "1036225066210680833": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Oh yeah I'm retarded \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests that the image is hateful, as it implies that the person is retarded.\"}",
    "1054074452357582849": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> HAPPY BDAY MY NIGGA LOVE YOU BRO \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, which suggests that the image might be a hateful meme.\"}",
    "1114186866352447488": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Nigga dropping a lotta sauce \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it features a man wearing a shirt with a racial slur on it, which is offensive and disrespectful.\"}",
    "1109273533215989760": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> fuck u nigga no typa appreciation it was good shit\ud83e\udd27 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image and the tweet text are both hateful memes, as they use offensive language and make derogatory comments towards a specific group of people.\"}",
    "1105484016679936000": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Don\u2019t homie fvck unless his bands up....if you let the broke nigga fvck we telling #QueenRadio \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is disrespectful towards women. This image is not hateful.\"}",
    "1109741981624872960": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Im mad i really like this nigga \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and shows a negative attitude towards the person in the image. This classification is based on the fact that the tweet is not respectful or kind towards the individual, which is considered hateful.\"}",
    "1053930592985903104": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Someone call him a cunt from me pls \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, suggesting that the image might be a hateful meme.\"}",
    "1114570369606795266": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> shut up faggot. u BEAUTIFUL \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language towards the person in the image, suggesting that the image is a hateful meme.\"}",
    "1113618877286633472": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Bruh if this nigga was 21-22 he\u2019d be an arm baby in 1997 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language and racist remarks towards African Americans, which indicates that the image is hateful.\"}",
    "1116418387389943810": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> It\u2019s not about biology Jer,it\u2019s about being a fcking cunt. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the tweet text, which contains offensive language and insults.\"}",
    "1106956498339618822": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Neil. Cunt. End \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image and the tweet text are both hateful memes, as they use offensive language to describe someone named Neil.\"}",
    "1115982652518039553": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:DELUDED CUNT TO SPEAK TO DELUDED CUNTS #brexit #farage #nigelfarage #petulantmonkey \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which suggests that the image is hateful.\"}",
    "1110286282729635840": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Nigga wasn't expecting that.  No, No! He never ready \ud83d\ude02\ud83d\ude02 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the use of racial slurs in the tweet text, which is inappropriate and offensive.\"}",
    "1046744558091014150": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Bears repeating. Cuz SJW's don't like it. IT's just a MEME people. &lt;grin&gt;#QAnon #QArmy<tag> \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a woman in a provocative manner and is accompanied by a tweet that seems to be promoting a controversial ideology.\"}",
    "1116075226238980097": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Hahaha what a twat \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which indicates that the image is hateful.\"}",
    "1105032711180337152": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Via: \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image does not contain any explicit or offensive content that would warrant it being classified as a hateful meme. The woman is posing in a provocative manner, but it is not targeting any specific group or individual, and the overall context of the image is not aggressive or discriminatory.\"}",
    "1115415389041766405": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> \ud83e\udd23\ud83d\ude02\ud83e\udd23 nigga like sooooo..... \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a negative and offensive stereotype of African Americans.\"}",
    "1108388837565317121": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> This nigga wildin \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, and the man's facial expression and the context of the tweet suggest that it is meant to be offensive or derogatory.\"}",
    "1109122647902879745": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Nigga blocked me<tag> \ud83e\udd23\ud83e\udd23 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which are considered hateful. The image may also be associated with such content, making it a hateful meme.\"}",
    "1109891612740644864": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:FOCUS ON WHAT???? RT<tag> Focus on #NIGGER \ud83c\uddf3\ud83c\uddec \ud83c\udde9\ud83c\uddea \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains a racial slur in the tweet text, which is offensive and inappropriate.\"}",
    "1110177741511495681": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:everybody turn into this nigga<tag> when they lose at 2k or an argument behind the screen \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme that portrays a negative stereotype of African Americans. The tweet text further supports this classification as it uses derogatory language to describe people who lose at video games or engage in arguments.\"}",
    "1116443698903035918": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> This nigga cuzzo\ud83e\udd23\ud83e\udd26\ud83c\udffd\u200d\u2642\ufe0f \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a man and a woman in a disrespectful manner, with the man making a funny face and the woman sticking her tongue out. The tweet text further supports this classification as it adds to the disrespectful and offensive nature of the image.\"}",
    "1108858501579919362": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Im talkin to u nigga. Now get the steppin \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it uses racial slurs and promotes negative stereotypes about African Americans.\"}",
    "1109744629023473666": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> ma nigga? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and racial slurs, such as 'nigger' and 'shit'.\"}",
    "1113693383409770496": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Watch out for bitches like this, they got that \u201cNigger lynching\u201d mindset then play victim\ud83e\udd2f FOH goofy\ud83d\ude07 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and a derogatory reference to a specific group of people.\"}",
    "1117037129027268608": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> How are people retarded enough to think this is blackface? People now days are stupid \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests that the image is considered hateful, as it is described as a 'dumb' meme and people are criticized for not understanding it. The reference to 'blackface' adds to the negative perception of the image.\"}",
    "1105250726526308354": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:yooo that old nigga funny asf \ud83d\ude02\ud83d\ude02 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme that uses racial slurs and is considered hateful.\"}",
    "1106670616625729537": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Ride &amp; choke that nigga out until he busts. Then keep riding him. \ud83d\ude08\u264a\ufe0f \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and promotes violence, which indicates that the image is hateful.\"}",
    "1054068912642355200": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag> Cyst is playing the victim card rn :-----)))) \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a young man with a cyst on his face, making a sad or displeased expression. The tweet text further supports this classification as it implies that the person is playing the victim card, which is often associated with negative emotions and unhappiness.\"}",
    "1044224080998592512": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag> And retard I said it once so \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and insults towards people with disabilities.\"}",
    "1110292004011999232": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Save Nigeria further stress and surrender the mandate you stole \u2013 Pdp to\u00a0Buhari \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image shows a crowd of people holding political signs, and the tweet text suggests a political message against the ruling party. This could be perceived as hateful, as it might be seen as an attack on the party or its members.\"}",
    "1061795574192705536": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:#teen lesbian stick toy to old granny cunt #Delmenhorst \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains inappropriate and offensive content, such as the teen girl taking a selfie in a provocative manner and the reference to an old granny's cunt. This type of content is not appropriate for sharing and can be harmful to individuals who view it.\"}",
    "1116509667193176064": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Late hump day post....I can do it better without a nigga \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is considered hateful. The image, although not directly related to the tweet, may also be perceived as inappropriate or offensive due to the context of the tweet.\"}",
    "1060894632983384064": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:For the love of god Usyk, knock the living shit out of this cunt for the sake of boxing \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests a hateful sentiment towards one of the boxers, which is reflected in the image where the boxers are seen fighting each other.\"}",
    "1108842076156751872": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Fuck you, hypocritical cunt! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language towards the president, indicating a hateful sentiment towards him.\"}",
    "1054369385589211136": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> okay dyke \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language towards the individual in the image, suggesting that the image is hateful.\"}",
    "1113586235631644673": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:nigga wjo \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racial slurs and is offensive. This image is not hateful.\"}",
    "1114914394058702850": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Nigga we made it \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, which makes the image hateful.\"}",
    "1116078685558333440": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Go flood the comments tell<tag> I\u2019m that nigga \ud83d\ude24 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is considered hateful.\"}",
    "1109200492775817217": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:all weekend nigga \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language towards African Americans, which is considered hateful.\"}",
    "1116070268718473217": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Where\u2019s my money nigga? #leg10npodcast \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is considered hateful.\"}",
    "1113157977983397891": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Me dancing for my dyke \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the presence of a lesbian couple engaging in a suggestive dance, which is deemed inappropriate or offensive by some people.\"}",
    "1109579631634587648": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I may* have called one of them a fucking cunt whilst my Mum was in the passenger seat *did \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, which suggests that the image might be a hateful meme.\"}",
    "1113419007317749760": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Or in bonucci\u2019s words, he is a twat but I don\u2019t like all of the hate I\u2019m getting \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains negative and offensive language towards a specific individual, which is not appropriate or respectful.\"}",
    "1064229215762087937": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:been at work all fuckin day and my twat of a big sister is at my house FUCK OFF \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language towards the sister, suggesting a negative relationship between the two.\"}",
    "1035564227518521345": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Full Gallery: \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image does not contain any explicit or offensive content. It shows a woman breastfeeding a man, which is a natural and innocent scene. The tweet text also suggests that it is a full gallery, which implies that the image is part of a larger collection or series, rather than a single, isolated incident.\"}",
    "1109166897650679809": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:ok but who else giving you cunt in a tshirt and socks w/ sandals.. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the girl's pose and the fact that she is wearing a t-shirt, shorts, and socks with sandals, which is considered inappropriate or offensive.\"}",
    "1047221920498966528": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Dis woman is retarded \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which are considered hateful. The image might be a hateful meme if it is related to the content of the tweet.\"}",
    "1114198384380747776": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Do body builders realize when they go to far. Look at this nigga. He looks like a burnt marshmallow \ud83d\ude10\ud83d\ude10\ud83d\ude10\ud83d\ude10\ud83d\ude10\ud83d\ude10\ud83d\ude10\ud83d\ude10\ud83d\ude10 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the use of derogatory language and the portrayal of a bodybuilder in a negative light.\"}",
    "1107978450328055809": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Leave that nigga sis \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains a racial slur, which is considered hateful. The image of a bald man in a military uniform with a mustache and goatee, making a hand gesture, is not inherently hateful, but the tweet text associated with it makes it appear hateful.\"}",
    "1115359596296704001": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:On this weeks episode of broke ass nigga we have<tag> \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is not appropriate for sharing on social media platforms.\"}",
    "1116373833571799040": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Was on my grind, it was my time I ain't think twice, I paid that price and we did this, nigga! \ud83c\udfc1\ud83c\udfc1 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which make it a hateful meme.\"}",
    "1043081210400894976": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:She is retarded tbh \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language towards a person with a disability, which is considered hateful.\"}",
    "1107085700426543104": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Nigga was like \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it features a man in a suit with a microphone, seemingly interviewing a man with a shaved head. The tweet text suggests that the image is racist and offensive. The presence of a microphone and the man's attire give the impression of a formal or professional setting, which further emphasizes the racist nature of the meme.\"}",
    "1034779615460515841": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag> Nah James she's a two faced twat. Like you \ud83d\ude0f \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains negative words and insults towards the woman in the image, suggesting that the image is a hateful meme.\"}",
    "1063559581371113473": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Find the word retard \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image contains the word 'retard' which is considered offensive and hateful. This word is used to insult or belittle people with intellectual disabilities, and its use in the image is inappropriate and disrespectful.\"}",
    "1055905459817857030": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Henry Van Dyke.- #quote #image Via \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is a picture of a bird sitting on a branch, with a quote by Henry Van Dyke. It does not contain any hateful content.\"}",
    "1109828139289665538": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Young nigga turnt up... never gave AF -<tag> \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it uses offensive language and stereotypes to describe a woman taking a selfie in the mirror.\"}",
    "1105304972491702277": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Nigga ! \ud83d\ude02\ud83d\ude02\ud83d\ude02\ud83d\ude02\ud83d\ude02\ud83d\ude02 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image and the tweet text are both hateful memes, as they use derogatory language and make light of a serious issue.\"}",
    "1056689358860763136": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This cunt, holy moly \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, indicating a hateful sentiment.\"}",
    "1115324300511174657": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Of course the faggot is a bourgeois cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language and insults towards the LGBTQ+ community, which is considered hateful.\"}",
    "1114937963744382976": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:THIS NIGGA AINT EVEN IN THE GRAVE YET!!! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is considered hateful.\"}",
    "1113477972231577600": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I hate when my side nigga hit me all day ! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which make it a hateful meme.\"}",
    "1113513579708264448": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I hate twitter y'all goofy and not active but sign this at least dumb hoes\ud83d\udcaf\ud83d\ude4f\ud83c\udffeon some real nigga shi \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the presence of a teddy bear and a stuffed animal, which are often associated with positive emotions and innocence. The tweet text further supports this classification as it contains offensive language and a negative sentiment towards Twitter users.\"}",
    "1056978985270284288": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:\u201c A NIGGA CANT FUCK ME, I FUCK THEM\u201d   \ud83d\udc85\ud83c\udffd #QueenRadio \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which are not appropriate for a public event or broadcast. This image is not hateful.\"}",
    "1035307100103225344": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag><tag> Idk, he just called clean a faggot apparently \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image and the tweet text contain offensive language and derogatory terms, which are considered hateful.\"}",
    "1108313537963798530": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Let this sink in! #BuildTheWall #Trump2020 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it promotes a negative and discriminatory message against illegal aliens, suggesting that they are not welcome in the country.\"}",
    "1062813613424025602": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> They\u2019re always using that Race Card..\ud83e\udd2e Here\u2019s the real Truth- Just in another time- \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it uses a racial slur and makes a derogatory statement about African Americans. The tweet text further supports this classification as it reinforces the negative stereotype and prejudice against the community.\"}",
    "1110048572374802432": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:While he filled your ass with his seed he groaned about how he was glad the nagging cunt was dead \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults towards women, indicating that the image is hateful.\"}",
    "1114196397857878016": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Carried my nigga to his first victory.<tag> #ApexLegends \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which make it a hateful meme.\"}",
    "1107735064266375173": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:We were cool until you told me you let your nonBlack friends say Nigga because \u201cthey\u2019ve been through shit too!?!\u201d \ud83e\udd74 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a woman in a negative light, possibly using racial slurs. The tweet text further supports this classification as it contains offensive language.\"}",
    "1035210689877487616": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:American rapper Doja Cat apologises for saying faggot \u201815,000 times\u2019 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it uses offensive language and imagery to mock and ridicule the person in the picture. The reference to the rapper Doja Cat's apology for using the word 'faggot' also adds to the negative and derogatory nature of the meme.\"}",
    "1057462387144581121": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:NIGGA WHO THE HELL IS THIS????? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racial slurs and is considered hateful.\"}",
    "1050082595550171137": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:America went from CLASS, to WHITE TRASH! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and negative sentiment towards the country, which indicates that the image is hateful.\"}",
    "1110448774030204928": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> NIGGA RUN IT BAAAAAAACCKK???? \ud83d\ude27 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a man in a headdress and a jersey with the number 52, which is a racial slur. The tweet text further supports the classification as it uses a racial slur.\"}",
    "1059469392096817157": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:#\u3075\u3061\u3083\u3077\u308c Operation Cunt Destroyer - Slam Before Time (Slam Before Time) \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a woman being raped by a dinosaur, which is a disturbing and offensive scene. The use of the word 'cunt' in the tweet text also adds to the offensive nature of the image.\"}",
    "1109072441500942336": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Who are you? I have more subscribers than you more followers WTF nigga \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which indicates a hateful sentiment.\"}",
    "1107683372015501317": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:\u201cSurrender is the ultimate technique to merge with existence.\u201d \u2015 Bhagawan Sri Nithyananda Paramasivam #Hinduvidual \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image does not contain any hateful content. It is a picture of a man in traditional Indian attire, possibly a guru, sitting on a cushion and making a hand gesture. The tweet text does not contain any offensive or hateful language.\"}",
    "1062097021224464386": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:He really is a cunt. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and insults towards someone.\"}",
    "1116885721732796417": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Ayoooo i am criiiiiinnneeee \ud83e\udd23\ud83e\udd23\ud83e\udd23 CTFU dis nigga sweatin  and shit\ud83e\udd23\ud83e\udd23\ud83e\udd23 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a man in a brown jacket with a goatee, making a funny face. The tweet text further supports the classification as it is derogatory and disrespectful towards the man in the image.\"}",
    "1043560265810432000": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> She must work at a white strip club because that was trash \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is considered hateful.\"}",
    "1113925380602245120": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Real my nigga. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language and is considered hateful.\"}",
    "1053479241541513216": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:SJW: SLEEP; WATCH TV ;PLAY ON PHONE; OBEY; CONFORM #SJWs  #NPC \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme that promotes conformity and obedience, which can be considered hateful by some people.\"}",
    "1046499739922034688": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:You a dyke &amp; can\u2019t get yo point across to a fem without putting yo hands on her or threatening her? You a pussy. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and derogatory terms towards women.\"}",
    "1062743563707015168": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Watch it: \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is a nude woman posing for a picture, which is not hateful. It is a natural and common form of artistic expression.\"}",
    "1036281738090041344": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Another wetback killing Americans on U.S. soil. \ud83d\ude21 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial stereotypes, which are indicative of a hateful meme.\"}",
    "1106748363427344384": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I said \u201csay less\u201d this nigga still talking \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the presence of a man talking to a group of people, while one of the individuals is wearing a red jacket and sunglasses. The tweet text further supports the classification as it contains offensive language.\"}",
    "1054032660086079489": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:black licorice is disgusting  fight me cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which indicates a hateful sentiment towards black licorice.\"}",
    "1114476404467490816": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> my nigga ..... \ud83d\ude02\ud83d\ude02\ud83d\ude02\ud83d\ude02\ud83d\ude02\ud83d\ude02\ud83d\ude02 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a person in a negative light, using offensive language and potentially promoting harmful stereotypes.\"}",
    "1115799906696876032": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Nigga did I just seen some shit that said magic quit ?!!! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the use of racial slurs and the negative portrayal of a person of color.\"}",
    "1108915694505091072": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:my nigga needs that kegare implant stat \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme that portrays a woman with a sad expression, and the tweet text suggests that the meme is hateful. The content of the meme and the tweet text together indicate that the image is hateful.\"}",
    "1109561202726879238": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Fowk that say they find the word cunt offensive........ aye like it's a fucking regular in a Christmas card. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the woman's pose and the tweet text, which is offensive and disrespectful towards women.\"}",
    "1056935709154643968": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Feckless cunt STFU \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme of Donald Trump and another man, with the text 'Donald John Trump Wanted for Inciting Violence'. The tweet text further supports the classification as it contains offensive language towards the president.\"}",
    "1046458688553328640": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Obama played Race Card Hillary Played the Woman Card AMERICA PLAYED THE TRUMP CARD \ud83c\uddfa\ud83c\uddf8\u2764\ufe0f\ud83c\uddfa\ud83c\uddf8\ud83d\udc4d \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays African American men in a negative light, suggesting that they are not proud of their heritage. The tweet text further supports this classification as it uses racial stereotypes and derogatory language.\"}",
    "1109758012191883266": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> You Never Met A Nigga Like Me Before \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which make the image appear hateful.\"}",
    "1113159313676210176": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> This the type of shot that nigga took\ud83d\ude2d \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the racist language used in the tweet text.\"}",
    "1054329305243754496": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Never go full retard. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme that is hateful and disrespectful towards people with disabilities.\"}",
    "1116493755140456449": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:nigga said beastie boys \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a character in a racist manner, which is offensive and inappropriate.\"}",
    "1105148591537049600": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Aye but my nigga kame back and blessed the game no kap!! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is considered hateful.\"}",
    "1061661156400607233": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:shut up retard \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which indicates a hateful sentiment.\"}",
    "1105640554627588097": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This nigga Ernest just be talking \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the use of racial slurs and the negative portrayal of the man in the red hat.\"}",
    "1107446689873448961": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Me anytime a nigga think something is so funny. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the racial slur used in the tweet text.\"}",
    "1109422778023841797": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Do not arrest...Shoot on Sight!!!! That Nigga has to die!!! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racist and violent language, suggesting that the image is a hateful meme.\"}",
    "1109502432806092800": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This nigga trying to scam \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image and the tweet text suggest that it is a hateful meme, as it contains derogatory language and potentially promotes negative stereotypes.\"}",
    "1053960184245116928": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> 2 weeks in a row. I wonder what those SJW's think of this..... \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the portrayal of a character with a meme-like appearance, which is often associated with negative stereotypes and offensive humor.\"}",
    "1037296585720377344": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Straight Men Use Faggot for Amusement! ......  See this and more at: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image and the tweet text suggest that the content is hateful towards the LGBTQ+ community. The use of the word 'faggot' in the tweet text is derogatory and disrespectful towards the LGBTQ+ community. The image itself shows two men in a bedroom, which might be interpreted as a humorous or light-hearted scene, but the overall context",
    "1113866542192709638": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:now they got me wondering what the situation was for this nigga to come in grillin like that \ud83d\ude02 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests that the image might be a hateful meme, as it implies that the man in the picture is being treated unfairly or discriminated against. The use of the word 'nigger' in the tweet further supports this classification.\"}",
    "1044652740092334080": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:maybe i am a faggot \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and derogatory terms, such as 'faggot'.\"}",
    "1115187282435350529": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I get two days off work and now I\u2019m back im stuttering like a twat \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a man in a red shirt with a book in his hand, making a funny face. The tweet text further supports the classification as it contains offensive language.\"}",
    "1109552461625348102": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Trump Birthday Card - Build a wall around your cak \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it is a comic strip featuring a caricature of Donald Trump, with a message that is derogatory and offensive. The use of humor to spread negativity and discrimination is not acceptable.\"}",
    "1115222802196586497": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Incredible self-own by<tag> to start my week off right but I still love the little retard to death. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language towards the person in the image, suggesting that the image is a hateful meme.\"}",
    "1042977473804156928": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Did some one say, happier then a Redneck at WAl-MART ? Yee -Haw !\ud83d\ude02\ud83d\udc4d \nASSISTANT: {\"Classification\": \"hateful or not hateful\", \"Explaination\": \"The image is not hateful as it shows a man in a cowboy hat and hat with a gun, which is a common stereotype of a redneck. The tweet text also adds humor to the situation, suggesting that the image is meant to be lighthearted and not intended to be offensive.\"}",
    "1057266753045217285": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Fuck of UDA terrorist cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and a reference to a terrorist organization, suggesting a hateful sentiment towards the UDA.\"}",
    "1108188813300367360": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:(no rtw) dyke grip \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme of a drag queen with a knife, which can be considered as hateful towards the LGBTQ+ community.\"}",
    "1115340583504097281": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:how am i a fan of a nigga i don\u2019t fw? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language and racist remarks, which are considered hateful. The image of two men talking on a radio show might not be directly related to the hateful content of the tweet, but the overall context of the image and the tweet suggests a negative and offensive sentiment.\"}",
    "1058545419293208578": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:WALL TRIGGERED! #BuildTheWall #MAGA #PatriotsFight #QAnon #FactsMatter #WWG1WGA #POTUS #hillary2020 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme that is hateful towards a specific group of people, as it is associated with the MAGA movement and contains a message that is discriminatory and offensive.\"}",
    "1036998863817789441": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Sounds like redneck shawarma. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is considered hateful.\"}",
    "1114320515760644096": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Lmao this cunt went to private.<tag> classy spurs fan \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which indicates that the image is hateful.\"}",
    "1114308809164333058": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Taiju just gets shit done, no thinking involve just straight action. I love that nigga \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme that shows a man with a sword and the words 'What the hell?' written below him. The tweet text suggests that the image is hateful, as it contains derogatory language towards a person. This classification is based on the negative and offensive nature of the content in the image and the tweet.\"}",
    "1054121065922867200": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:YIKES NIGGA #PS4share \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a black man in a negative light, using racial slurs and derogatory language.\"}",
    "1113359145346973696": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Tiny Titted Paige Toying Her\u00a0Twat \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it may contain offensive or inappropriate content. The tweet text further supports this classification as it is explicit and disrespectful towards the woman in the image.\"}",
    "1113652419089522690": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:nan\nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it may contain offensive or discriminatory content. The woman in the image is holding a piece of cloth with a blue substance on it, which could be interpreted as a disrespectful or demeaning gesture towards women. The context of the image and the tweet text indicate that it is not a positive representation of women.\"}",
    "1058313882001797120": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:That nigga really made it to 22.. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racist remarks, which make the image hateful.\"}",
    "1037390552994439168": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:i spy with my little eye A Dyke \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a woman in a hat and leather jacket, with a negative connotation towards her appearance. The tweet text further supports this classification as it uses derogatory language towards the woman.\"}",
    "1107625653829017600": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Please block me you twat \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a group of people holding a sign that says 'England get out of Ireland' and it is accompanied by a tweet that is offensive and disrespectful towards the people in the image.\"}",
    "1109317005251764225": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Sigh. This nigga trying to buy all this flonase lol! #Meth \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language and is considered hateful.\"}",
    "1108592993303322624": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Have a nigga like lol \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it uses racial slurs and offensive language to describe the man in the picture.\"}",
    "1114257711242174464": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Nigga said Gunna &amp; Lil baby better than Drake &amp; Weezy. Bruh idk what type troll crack y\u2019all be smoking but \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racial slurs and insults, which are considered hateful. The image of the girl with a red background and the words 'I see the type of you are' might be related to this hateful content, but it is not the main focus of the image.\"}",
    "1109614710276657157": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:CUNT of the Year  -  1st Prize \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and imagery, such as the word 'cunt' and the man's tattoo, which may be considered inappropriate or offensive to some people.\"}",
    "1058497649576423424": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:like it was funny the first few times but now its just fucking retarded  <tag> fix your shitty mm system \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and negativity towards the game, indicating a hateful sentiment towards the game.\"}",
    "1053810865705836545": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:how tf you claim that you love giving head, but you can\u2019t give head? NIGGA WHAT \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is disrespectful towards the person in the image. This classification is based on the negative and disrespectful tone of the tweet.\"}",
    "1114652796563927043": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:can't escape nigga \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racial slurs and is offensive. The image of the swing set with the purple seats is being used to spread hate and discrimination.\"}",
    "1055163505001807877": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Here is the main cunt in all her cunty glory \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it is disrespectful and offensive towards women.\"}",
    "1113922380534112256": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:My nigga<tag> just leveled up on merch and got a whole alcoholic beverage for the thots! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is not appropriate for a hateful meme.\"}",
    "1106934351621771265": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Just witnessed a nigga get rejected in the captainsparklez twitch chat \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and racial slurs, which are not appropriate or respectful.\"}",
    "1061770190587740161": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> You white trash, redneck POS! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults towards the group of people in the image, suggesting that the image is a hateful meme.\"}",
    "1117291061485932544": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:DMAN WHAT DIS NIGGA SO ANGRY FOR \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests that the image is hateful, as it contains a racial slur. The image shows a group of people dancing on stage, but the presence of the racial slur in the tweet indicates a negative and offensive sentiment towards the group.\"}",
    "1108844880674070532": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Leo will always be Leo ...Politician Just a simple question nigga will go round and round.. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and a derogatory term, suggesting that the image is a hateful meme.\"}",
    "1054475548494245888": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Love these people \u201c I have a baby so drive carefully around me\u201d yet drives like a f$cking twat! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet contains offensive language and a negative sentiment towards the driver of the car, suggesting that the image is hateful.\"}",
    "1114120663080546309": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:The Full Gallery: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it may contain offensive or discriminatory content. The woman in the image is described as being 'fucked' and having 'goo' coming out of her mouth, which can be considered as inappropriate and disrespectful. The tweet text also suggests that the image is part of a full gallery, which implies that there",
    "1113443517022572544": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Bro I can\u2019t be the only nigga that was dying laughing when Joe Budden roasted the way Chance raps \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains a racial slur, which is considered hateful. The image of the three people sitting around a table might not be directly related to the hateful content in the tweet, but the context of the image could be perceived as insensitive or offensive.\"}",
    "1106743590473162752": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag> Who dis nigga? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which make it a hateful meme.\"}",
    "1116852191627706368": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:up i can't make him a faggot idc what he does freak \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language towards the individual, suggesting a negative attitude towards them. This could be considered as a hateful meme.\"}",
    "1109826069098573830": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> This Remainiac twat is pretty funny. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text is derogatory and disrespectful towards the people who are holding the signs, suggesting that they are 'Remainiacs' and 'twats'.\"}",
    "1113198547611078656": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:HOW THE FUCK I\u2019M GON FIND A HOOD NIGGA THAT\u2019S INTO THEATRE?! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial stereotypes, which make it a hateful meme.\"}",
    "1105564076053282819": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Yikes. Lol nigga said throwing them in the group chat \ud83e\udd74 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the man's facial expression and the tweet text, which is derogatory and disrespectful towards the man in the picture.\"}",
    "1105493079690276864": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Nobody:  That One Nigga That Wasn\u2019t Really Down To Rob Jay: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is considered hateful.\"}",
    "1035922273130242051": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag> His wife hates white people.  They are racist trash. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racist and hateful language towards white people, which is not appropriate or respectful.\"}",
    "1063880486869553152": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Every fucking day on your bitch ass nigger ass game.<tag> \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and racial slurs. The tweet text further supports this classification as it uses derogatory language towards a specific group of people.\"}",
    "1106547498745823232": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Some shit off SAW \ud83e\udd14\ud83d\ude02 RT<tag>: nigga barber doing too much \ud83d\ude2d\ud83d\ude2d \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language and racist stereotypes, which are considered hateful. The image of a man with a light shining on his head, possibly a halo, is being used in a disrespectful manner. The tweet is likely to offend and hurt people, making it a hateful meme.\"}",
    "1109499677433647107": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Just getting out the ring with mike Tyson knocked him out the faggot \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which suggests that the image is hateful.\"}",
    "1058405319498440704": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Got it, cunt?! \ud83d\ude0b \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it uses offensive language and insults to express its message.\"}",
    "1035792632604180480": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Another vid sold! Cum Tit Cleaning Faggot \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image and the tweet text are both hateful memes, as they use offensive language and make light of a serious issue, such as LGBTQ+ discrimination.\"}",
    "1113523157502177283": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Lmfao fuck that nigga \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, which suggests that the image might be a hateful meme.\"}",
    "1051246692253753346": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Twat rocket \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it is making a statement about women and their pregnancies, which can be considered offensive and discriminatory.\"}",
    "1057377180722839554": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> 100% retarded you are??? \ud83d\ude18\ud83d\ude18\ud83d\ude18 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it is making fun of someone's appearance, specifically their hair and facial features, which is disrespectful and offensive.\"}",
    "1115644901146886145": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Full Gallery: \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is a nude woman posing in a bathroom, which is not considered hateful content.\"}",
    "1114834902254596096": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I keep shouting \"The Butcher coming nigga\" \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racial slurs and is considered hateful.\"}",
    "1107106184409026562": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This nigga focused as fuck \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language and is considered hateful.\"}",
    "1115289315179888642": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Wrong nigga lmao \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the racial slur used in the tweet text.\"}",
    "1115827768066039817": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Since there was too many tanjiro layouts, had to get my nigga rengoku in here. I think this layout some heat \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is considered hateful.\"}",
    "1057453549821616130": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Had to be this nigga \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is considered hateful.\"}",
    "1036971266618667008": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Straight Men Use Faggot for Amusement! ......  See this and more at: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a naked man in a degrading manner, which is disrespectful and offensive to the LGBTQ+ community.\"}",
    "1108146422795382789": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:When a white person says Nigga \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a woman in a green shirt and a white jacket with a black brush in her hand, which is a racist stereotype. The tweet text further supports this classification as it uses a racial slur.\"}",
    "1117534895419486208": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Why does the first nigga look like shigaraki and All might in his small form \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racist language and is disrespectful towards people of color. This is not an appropriate or respectful way to express oneself, and it is considered hateful.\"}",
    "1062763161114370048": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:#FOX5 brings this #Horde update.  \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image shows a large group of people gathered near a border, which can be perceived as a threat to national security. The tweet text also suggests that the people are a 'horde' and that the border is being guarded by the U.S. Border Patrol. This can be seen as a hateful meme as it portrays a negative and aggressive attitude towards the people gathered near the",
    "1113207268055629824": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:\u201cLookin at da legend I become nigga  I can't help but feeling like I am da 1 nigga\u201d \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language and racial slurs, which are considered hateful.\"}",
    "1115767716026167296": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Where the fuck is it lad yer lying cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, indicating a hateful sentiment.\"}",
    "1113502735922495488": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Man I\u2019ve seen some retarded takes on this app but you two win the grand prize \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests that the image is considered hateful, as it is described as a 'retarded take' and the two individuals are referred to as 'winners' of the 'grand prize' for their negative opinions on the image.\"}",
    "1114913306635063296": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This is why President<tag> must close the border!  #buildthewall \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it is promoting a political agenda and using a derogatory term to describe a specific group of people.\"}",
    "1108691602585866240": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:\ud83d\ude31shaved her cunt, like?\ud83d\udc45\ud83d\ude0f\ud83d\udca6\ud83d\udca6 #karolina_rus  #nsfw \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the explicit nature of the content, including the woman's exposed genitals and the provocative tweet text.\"}",
    "1105550540702994434": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Full Movie: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it features a woman with large breasts and a man with a penis, which is inappropriate and disrespectful to the individuals involved.\"}",
    "1106961768616787970": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag> Thank God for President Trump \ud83d\ude4f\ud83c\uddfa\ud83c\uddf8\ud83d\ude4f#BUILDTHEWALL \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it is a political cartoon that is disrespectful towards the president and his supporters. The tweet text also supports this classification as it is a political statement that is not respectful towards the president.\"}",
    "1106962909958156288": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> What a twat I am... I meant Rapunzel! \ud83d\ude04 \ud83d\ude44 \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is not hateful as it shows a man smiling and posing for a picture with other people in the background. The tweet text also suggests a light-hearted and humorous context, further indicating that the image is not intended to be hateful.\"}",
    "1116072762362216449": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Don't miss Dr. Rube's lecture on child and adolescent stress. #YouCanTalk \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is promoting a lecture on child and adolescent stress, which is not a hateful message.\"}",
    "1061050289472454656": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Always the race card. Getting old. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests that the image is a hateful meme, as it is described as a 'race card' and 'getting old'. The image features a hand holding an American flag, which could be interpreted as a symbol of patriotism. However, the presence of the race card and the negative connotation in the tweet text indicate that the image is likely to be perceived as hateful.\"}",
    "1109146712139022336": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Don\u2019t shoot the messenger lol Batman just ain\u2019t that nigga compared to BP. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a woman holding a camera and a young girl with a camera, suggesting that they are taking pictures of a black person. This can be perceived as racist and disrespectful.\"}",
    "1106923732591955968": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Welcome to my new faggot \ud83d\ude08\ud83d\ude08 #cashmaster #cashfag #alpha \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and derogatory terms, such as 'faggot' and 'cashmaster', which are not appropriate for a respectful and inclusive environment.\"}",
    "1055309272630943744": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:#GamerGate are the only ones who know who was behind today\u2019s mail bombs. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests that the image is related to a controversial topic, and the man in the image is holding a bomb. This could be perceived as hateful, as it might evoke fear or negative emotions.\"}",
    "1107685661522518023": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:white niggas get an african passport and call it a nigga pass \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it uses racist language and imagery to mock and demean people of African descent.\"}",
    "1113455188524838914": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Full Gallery: \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is a provocative and erotic photo of a woman, but it does not contain any explicit or offensive content that would warrant a classification as hateful.\"}",
    "1113412490438807554": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Make your own insult for the cunt in your life. Link in bio. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and insults towards someone. The tweet text further supports this classification as it encourages people to make their own insults for someone in their life.\"}",
    "1105284080982286336": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Nigga blocked both accounts guess it hurts to hear the truth \ud83e\udd74\ud83d\ude02 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and imagery, such as the word 'nigger' and the reference to 'hearing the truth' in a derogatory manner.\"}",
    "1109495043214184448": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Your nigga got shit \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is considered hateful.\"}",
    "1113980077891567616": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Someone pound my racist cunt! \ud83d\ude29\ud83d\ude0d \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racist language, which is considered hateful. The image of a woman being penetrated by a man's fingers while another man is touching her ass is not directly related to the racist language, but it could be considered inappropriate or offensive to some viewers.\"}",
    "1107761367623163904": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> White trash \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a large group of people holding torches and signs, which can be perceived as a threat or intimidation towards a specific group. The tweet text further supports this classification as it contains derogatory language towards a particular race.\"}",
    "1113482857937362946": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> I was waiting for some retard to bring race into it \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests that the image is a hateful meme, as it is described as a 'retard' and a 'meme' that is 'hateful'.\"}",
    "1106656112055668741": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Nigga gone be on that hoe like \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which make the image hateful.\"}",
    "1107035762913144832": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Why that nigga sound like Kodak breathed in a helium ballon \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image and the tweet text are hateful memes, as they use offensive language and make derogatory comments about a specific group of people.\"}",
    "1107069151313563648": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:\"These colors don't run, they surrender.\" \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a group of men in uniforms, possibly soldiers, with a message that implies they will surrender. This can be perceived as disrespectful and offensive to those who have served or are currently serving in the military.\"}",
    "1108773677812903936": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Nigga you sick... \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language and is considered hateful.\"}",
    "1056574396398297094": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Must have been watching a different fight you ugly button nose cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, indicating a hateful sentiment towards the image.\"}",
    "1108762654888337408": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Don\u2019t buy from him nigga gave me an epic login and said I can use it for pc and blocked me \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racial slurs and is considered hateful.\"}",
    "1105178695604600832": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Still a better actress than Cunt Larson\ud83e\udd37\u200d\u2642\ufe0f Brie isn't even that good of an actress anyway. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains negative and offensive language towards the actress Brie Larson, suggesting that the image is hateful.\"}",
    "1116086681122365441": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Nigga said a year ahead \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme that uses racial slurs and is considered offensive and hateful.\"}",
    "1105653149719842818": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:REAL ASS BITCH GIVE A FUCK ABOUT A NIGGA... \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is disrespectful towards a specific group of people. This image, featuring a woman in white pants and a white shirt, is being used to spread such negativity, making it a hateful meme.\"}",
    "1045134731115933697": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag> \"We're sick of you SJW's telling us what our president is saying\" \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it is portraying a black ostrich with a white head, which is a racist caricature. The tweet text also supports this classification as it is using derogatory language towards social justice warriors.\"}",
    "1108497151938699265": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:So I hear that<tag> has replaced me and Sean the cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which indicates that the image is hateful.\"}",
    "1114324453582757889": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Nigga what? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains a racial slur, which is considered hateful and offensive. The image of the man with a beard and mustache, along with the tweet text, can be perceived as a hateful meme.\"}",
    "1117701344800980995": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Wrong my nigga,is already out..check the link below \ud83d\udc4d\ud83c\udffd \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and is disrespectful towards a specific group of people.\"}",
    "1036280422009892865": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:#FastFoodFights Clear your table in the white trash can \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is a humorous and light-hearted scene of a man posing in a white trash can, with a caption that adds to the humor. The tweet text does not contain any hateful or offensive language, and the context of the image suggests a playful and fun atmosphere.\"}",
    "1108778243405029376": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Like as a nigga right...when that first white women gave me....homework. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language and racist remarks, which make the image hateful.\"}",
    "1105502674504441856": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> happy bday shitty boi. keep on overthinking. hahaha but never surrender. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it shows a man giving the finger to another person, which is a disrespectful gesture.\"}",
    "1113601819459112961": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Not me. This is a successful bad Jamaican. I\u2019m a nigger \ud83d\ude02\ud83d\ude02\ud83d\ude02\ud83d\ude02 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the negative and offensive language used in the tweet text.\"}",
    "1107941661848621056": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:\u201c Ahhhhhhhh Bacon Bacon Bacon Bacon \u201c \ud83e\udd23\ud83e\udd23\ud83e\udd23\ud83e\udd23\ud83e\udd23\ud83e\udd23\ud83e\udd23\ud83e\udd23 This Nigga Bunny Got Me Dead Asf , This The Fse \ud83d\ude2d\ud83d\ude2d\ud83d\ude2d \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and humor that could be considered hateful. The image of the music app with the word 'Music' on it is not related to the content of the tweet.\"}",
    "1106602434602983424": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:After you get yo lul giggle or whatever I Might as well follow ah nigga onna gram #support your #supporters \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and a reference to a racial slur, indicating that the image is likely a hateful meme.\"}",
    "1061789996825395200": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:when I see a faggot I floor it \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language towards the LGBTQ+ community, which is considered hateful. The image itself does not necessarily contain such content, but it is associated with the hateful tweet.\"}",
    "1058992794012958720": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Tempted to just shoot this cunt I've been doing this for an hour  \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and a desire to harm the person in the image, indicating a hateful sentiment.\"}",
    "1109627319428235265": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:All i need now is hyojin to listen to janelle monae and shes completed every single thing on the dyke checklist \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a negative stereotype of the LGBTQ+ community, specifically focusing on the female gender. The tweet text further supports this classification as it implies that the person is not accepting of the LGBTQ+ community.\"}",
    "1115788875606179841": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> You are a major RETARD! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text is derogatory and insulting, which indicates that the image is hateful.\"}",
    "1108846357308166144": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:How the fuck this nigga break out his cage \ud83e\udd37\ud83c\udffe\u200d\u2642\ufe0f\ud83e\udd37\ud83c\udffe\u200d\u2642\ufe0f\ud83e\udd37\ud83c\udffe\u200d\u2642\ufe0f \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains racial slurs and is disrespectful towards the person in the picture.\"}",
    "1113872920818913281": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Got her fucking on this rapping ass singing ass Nigga<tag> \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image and the tweet text contain offensive language and racial slurs, which are considered hateful.\"}",
    "1107754514919116800": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag> You okay my nigga \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racial slurs and is offensive. The image of the man in the red shirt with a surprised look on his face is not the focus of the tweet and is not the reason for the classification of the image as hateful.\"}",
    "1114542231321489408": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:After today if you\u2019re 5\u201910 or above you are considered ah nigga to me. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the tweet text, which contains derogatory language towards a specific group of people.\"}",
    "1043870524403855361": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:H. Rap Brown's Negro College Student ::: Highlighting Chapter Six Of 'Die Nigger Die!' \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme that is hateful and racist in nature, as it uses a racist term and promotes negative stereotypes about African Americans.\"}",
    "1053775386444775424": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Twat \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme that uses the word 'twat' to describe the person in the picture. This is considered a hateful term and the image is likely to be offensive to some people.\"}",
    "1110443032992800768": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This twat's on the Beeb insisting that May still has control of her party. They are all mad. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, suggesting that it may contain offensive or controversial content.\"}",
    "1113121944055025664": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Or maybe say no to being an anti abortion cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it promotes anti-abortion views and is disrespectful towards women who choose to have an abortion.\"}",
    "1057011230739701762": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Damn this nigga stole my wife \ud83d\ude12 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language towards African Americans, which is considered hateful.\"}",
    "1058952489381347328": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Some cunt turned the heat on. Like no thanks. This is Texas. It's still HOT outside biTCH don't fry me. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet contains offensive language and a negative sentiment towards the person who turned on the heat. It can be considered a hateful meme.\"}",
    "1109481810537447425": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Y\u2019all niggas need to stop sleeping on my nigga mayn \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is considered hateful.\"}",
    "1114243074794901505": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Nigga \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme that uses racial slurs and is offensive.\"}",
    "1114695729568677888": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:When people say \u2018come on, there has to be something there!\u2019 Yea actually, trailer parks &amp; trailer trash \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language towards trailer parks and trailer trash, which suggests a negative and discriminatory attitude towards people living in such areas. This could be considered as a hateful meme.\"}",
    "1109698591931666432": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Nobody: A nigga who don't want nothing serious with you: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image and the tweet text contain offensive language and racial slurs, which make it a hateful meme.\"}",
    "1110256856054796289": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> LETS GO, this cunt has taken so much elo from me. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language towards a specific player, indicating a hateful sentiment.\"}",
    "1115989474956148741": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:When you show up to the cookout after your nigga took you back for cheating on him: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and content that is not appropriate for public display.\"}",
    "1108528054303948800": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:THESE NIGGA ARE GAY<tag><tag> \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language and racist slurs, which are indicative of a hateful meme.\"}",
    "1114512698765717504": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:When the fag's account is zeroed.  \ud83d\udca6 because I took his money.  #findom #circle #finsub #faggot \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it targets a specific group of people, which is considered offensive and discriminatory.\"}",
    "1056573731370397696": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:KARMA WILL COME REAL QUICK BELIEVE THAT PIECE OF SHIT NIGGA \ud83d\ude24 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet contains offensive language and is considered hateful.\"}",
    "1056328039078850560": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:AM I RETARDED FOR JUST NOW FINDING OUT GIEF CAN DO THAT WITH ONE MOVE?!? \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is a video game screenshot, not a hateful meme. The tweet text is a reaction to the gameplay, expressing surprise or frustration, but it does not contain any hateful or offensive content.\"}",
    "1106891812302544897": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Nigga wouldnt die for SHIT #PS4share  \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and racial slurs.\"}",
    "1115671735712407552": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Stfu. U\u2019re a fcking cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which indicates that the image is a hateful meme.\"}",
    "1115855960097140736": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I\u2019m literally going in the other room to smoke for 10 minutes if this nigga falls asleep \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is considered hateful.\"}",
    "1113032788075339778": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Yeah, i know. He's a cunt and so is creepy uncle joe. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults towards political figures, indicating a hateful sentiment.\"}",
    "1058424232718331909": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:THIS NIGGA JUST LOST #NoNutNovember \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains a racial slur and is offensive. The image is likely to be a hateful meme.\"}",
    "1108852824073474048": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:KOTAL KAHN IS A NIGGER?!? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racist language and is considered hateful.\"}",
    "1108432104348618762": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Trump trailer trash presidency spinoff \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a negative and offensive representation of the President and his family, using a distorted and exaggerated context.\"}",
    "1113015428849242113": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Thiiiiiiiiick my nigga! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is disrespectful towards people of color. This is considered a hateful meme.\"}",
    "1105636173244960768": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Still a nigga. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the use of racial slurs and the overall negative portrayal of the character.\"}",
    "1107619768759136257": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Fuck off u cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, suggesting that the image is a hateful meme.\"}",
    "1117469728082149376": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Lol my nigga Atown! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, which suggests that the image might be a hateful meme.\"}",
    "1054163776256258048": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Heyyyyy nigga nerds \u2764\ufe0f \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racial slurs and is offensive. This image is not hateful.\"}",
    "1108002893620232192": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This nigga must be the black Steve shives lmao \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet contains derogatory language and racist slurs, which are considered hateful. The image is likely to be a hateful meme.\"}",
    "1109498587862441989": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:\u201cGeT yOu A fAt NiGgA\u201d \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racist language, which makes the image hateful.\"}",
    "1050876531478880256": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:You can even Google this sissy faggot \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image and the tweet text are both hateful and offensive, targeting the LGBTQ+ community. The image shows a man in a dress, and the tweet text is derogatory towards the individual. This content is not appropriate and should not be shared.\"}",
    "1115376576575758337": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:eu vivo like a boss nigga, every day \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image and the tweet text suggest that the person is smoking marijuana and possibly engaging in a hateful or offensive behavior. The tweet text contains offensive language, which further supports the classification of the image as hateful.\"}",
    "1062191707410849792": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> OMG you are pulling the race card.. because he stood up to a reporter.. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays two men shaking hands with one of them wearing a black shirt and the other wearing a red shirt. The meme is racist and promotes discrimination and hatred towards people of different races.\"}",
    "1113180380918632448": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:- a nigga who does not love or respect you. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a negative stereotype of a black man, suggesting that he does not love or respect others.\"}",
    "1116838581283246080": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:#sissy cocksucker faggot \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language towards the LGBTQ+ community, which is considered hateful.\"}",
    "1115462755773972481": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:why ya tryna explain what this bitch ass nigga said like it sound any better? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image and the tweet text suggest that the content is hateful, as it contains derogatory language and a negative attitude towards the woman in the picture.\"}",
    "1107657997742940160": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I shouldn\u2019t have said \u201cwhat this nigga talking bout\u201d \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and content, such as the word 'bitch' and the reference to a toilet seat. This type of content is not appropriate for social media platforms and can be hurtful to some individuals.\"}",
    "1115412582666518528": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> I\u2019m never ever opening up your story again! \ud83d\ude2d\ud83e\udd23 nigga I be having to move out the way you still my dawg \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and a negative sentiment towards the person in the image. This suggests that the image is a hateful meme.\"}",
    "1107774735780323328": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:\"Nail that nigga feet too.\" ????  Y'all are going to hell, PERIODT! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is considered hateful.\"}",
    "1114878333681045504": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> funniest cunt ever \ud83d\ude02\ud83d\ude02\ud83d\udc80 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the offensive language used in the tweet text.\"}",
    "1114507797859848192": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> lmao u look jus like dis nigga \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it is making fun of a person's appearance and using offensive language.\"}",
    "1108530782723805186": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:#IfWomenRuledTheEarth<tag> would be the happiest bull dyke on the planet. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a woman holding a book with a negative message towards lesbians. The tweet text further supports this classification as it implies that women who are lesbians would be unhappy if they ruled the earth.\"}",
    "1114264651024543750": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Sold my vid! Filthy Cunt Whore Custom \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image and the tweet text are both hateful memes, as they use offensive language and make inappropriate sexual comments about a woman.\"}",
    "1108491883536441345": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Fuck a regular name necklace my nigga bought me a chain \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is considered hateful. The image of a woman wearing a necklace with the word 'nigga' on it further supports this classification.\"}",
    "1108433699828187137": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Nigga fumbled the baby Lmaoo wtf  \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racial slurs and is offensive. It is not appropriate to share such content, and it is considered hateful.\"}",
    "1056175110246170624": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Kindly increase the rate to listen one mentally retarded child \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it shows a group of people with a bus, and the tweet text suggests that the people are mentally retarded. This kind of language is derogatory and disrespectful towards individuals with mental disabilities.\"}",
    "1108922007352160256": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Nigga wa \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a man wearing a hat and smiling while making a racist gesture. The tweet text further supports this classification as it contains a racial slur.\"}",
    "1109472775092211712": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> I went to school wit a nigga named andrew and his teeth were like \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a character with exaggerated and distorted features, making it offensive and disrespectful towards a specific group of people.\"}",
    "1109044961343926272": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:#DoYouRememberWhen<tag> won every race on a seven-race card and completed his 'Magnificent 7'?   \ud83d\ude0f\ud83d\ude4c \nASSISTANT: {\"Classification\": \"hateful or not hateful\", \"Explaination\": \"The image is not hateful. It is a man wearing a sweater and tie, standing in front of a bookshelf with books. The tweet text is related to a horse named 'Do You Remember When' winning a race, but it does not contain any hateful content.\"}",
    "1110155824033341441": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Me when I see a nigga wearing all black Air Forces at school \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a negative stereotype of a black man wearing Air Forces shoes.\"}",
    "1107883919263842304": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> nah nigga fuck flexing, you fat ass need to \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it uses a racial slur and makes fun of the person's appearance.\"}",
    "1115171104111378433": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Almost 5 in the morning and a nigga still up \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which make the image hateful.\"}",
    "1044067377607053312": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag><tag> Go away trailer trash..... \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a naked man sitting on a toilet, which is considered inappropriate and offensive. The tweet text further adds to the negative sentiment by calling the person 'trailer trash' and suggesting that they should go away.\"}",
    "1109890031227977728": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:\"that's on period\" who the hell says that? nigga lying for no reason at all \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racial slurs and derogatory language, making it a hateful meme.\"}",
    "1107320868554850304": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Wa bona this guy, is a legend! My nigga \ud83d\ude02\ud83e\udd23\ud83d\udd25 #DateMyFamily \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is disrespectful towards the person in the image. This is considered a hateful meme.\"}",
    "1108693592686686208": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:They then let my racist QB get a nigger TE?! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racist language, which is considered hateful. The image of a young girl looking at a white sheet of paper might be used to spread this hateful message.\"}",
    "1114228769168994304": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I know nip looking down like Nigga who tf is that lol \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a tattoo of a man with a crown on his head and a smiling mouth. The tweet text suggests that the image is a hateful meme, possibly due to the use of the word 'nigger' in the tweet. However, it is important to note that the image itself does not contain any explicit or offensive content.\"}",
    "1114510379437056000": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:dyke energy is huge in this one \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests that the image is a hateful meme, possibly due to the woman's pose and the fact that she is described as a 'dyke'.\"}",
    "1109435246288752640": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Fuck that nigga , this shit always had me edge \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which indicates a hateful sentiment. The image of a woman with a red bandana on her head might be used to further spread this negative message.\"}",
    "1106489459174985728": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I danced to NaN Nigga just like this<tag> \ud83d\ude02\ud83d\ude02Ayyyyye \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image and the tweet text are both hateful memes, as they use offensive language and make light of a serious issue.\"}",
    "1107705720265428993": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> mhm.. Good Girls is my shit, Beth the realest nigga on the squad. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and references to a TV show, which suggests that the image might be a hateful meme.\"}",
    "1115476953497251841": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:You pulled your debit card out yo pocket nigga &amp; typed in the numbers . \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a negative stereotype of a black man, using offensive language and making light of a serious issue.\"}",
    "1105688017136771073": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Nah nigga was gooooodd!!! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is considered hateful.\"}",
    "1114365221005557760": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Nigga what...  \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains racial slurs and is disrespectful towards people of color.\"}",
    "1114403690276724737": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:she\u2019s a dyke ur honor \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language towards the person in the image, suggesting that the image is hateful.\"}",
    "1108596555832012801": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Ran up on a nigga #PS4share  \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and racial slurs in the tweet text.\"}",
    "1108848529089486850": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:My nigga hips feelin fruity today \ud83d\udcaf \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which make the image hateful.\"}",
    "1108177168146690048": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:\u201cMake ya nigga suck my pussy like a baby bottle,\u201d<tag>  Me: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and racial stereotypes. The tweet text further supports this classification as it is derogatory and disrespectful towards African Americans.\"}",
    "1107497234365587457": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:neck tat say deedee  make ya nigga nervous, gotta peepee \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image and the tweet text are considered hateful due to the use of offensive language and the reference to a racial slur.\"}",
    "1113935714650132482": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I\u2019m So Westside Nigga Areba Arbea -Nip\ud83d\udc99\u267f\ufe0f\ud83c\udd7f\ufe0f Long Live A Legend  #LONGLIVENIPSEY \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a tattoo of a rapper with the words 'Slaughter Boy' written on his back. The tweet text contains racial slurs and is disrespectful. This combination of elements in the image and the tweet text suggests that it is a hateful meme.\"}",
    "1107698357181378560": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> \u201cHer name is Chastity. She is white trash, same as you. Hillbilly!\u201d \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, suggesting that the image is a hateful meme.\"}",
    "1113578517768306688": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I\u2019m sorry but this nigger doesn\u2019t even have internet on his phone and he\u2019s talking about trying to date me \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial stereotypes, which make it a hateful meme.\"}",
    "1109963648699695104": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Nigga I ain\u2019t finna do shit .. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image and the tweet text are considered hateful due to the use of racial slurs and derogatory language.\"}",
    "1117065493024858114": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This nigga here \ud83d\ude02\ud83d\ude02\ud83d\ude02\ud83d\ude02\ud83d\ude2d\ud83d\ude2d\ud83d\ude2d\ud83d\ude2d\ud83d\ude2d \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image contains offensive language and racial slurs, which make it a hateful meme.\"}",
    "1116983391449157633": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:The Full Gallery: \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is a mirror shot of a woman in a green outfit, and it does not contain any explicit or offensive content.\"}",
    "1035645717854007296": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Full Video: \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is a nude woman posing on a couch, which is not considered hateful. It is a provocative and adult-themed image, but it does not promote hate or discrimination.\"}",
    "1115837012190408704": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:When a nigga want you to wait around for him to figure out what he wants \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a man in a basketball uniform with a negative expression on his face, which can be perceived as offensive and disrespectful towards the sport and its players.\"}",
    "1116542803071373312": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Nigga is that?? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the use of racial slurs and the portrayal of a man in a headdress, which may be perceived as offensive or disrespectful.\"}",
    "1113701208852533248": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:this is so cunt  \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, suggesting that the image might be considered hateful.\"}",
    "1106917004907368449": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Yes but you continue to support this trash in the White House. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it is promoting violence against a specific group of people, which is unacceptable and inappropriate.\"}",
    "1054310060162113536": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Twat \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme that is intended to be offensive and derogatory towards a specific group of people. It is not a friendly or positive representation of the subject matter.\"}",
    "1105448178621526016": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Is this nigga cute or what? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language and is considered hateful.\"}",
    "1108037762006073345": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:The funniest nigga I know<tag> \ud83d\ude2d\ud83d\ude2d\ud83d\ude2d\ud83d\ude2d\ud83d\ude2d \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and racial stereotypes. The tweet text further supports this classification as it uses derogatory language and racial slurs.\"}",
    "1105540256189681664": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Lol Ya'll were after Johnny Depp whereas it was fuckin' obvious that Amber Heard was the disgusting cunt here. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it is making fun of Johnny Depp and Amber Heard's relationship, which is not appropriate.\"}",
    "1108742727800373248": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I\u2019m still not over that man calling The Breakfast Club and telling Yee that her twat looked like a busted orange. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a man with a demonic appearance, making a disgusting comment to a woman. The tweet text further supports this classification as it describes an offensive and inappropriate interaction between the man and the woman.\"}",
    "1113444694741090304": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This nigga jusa off a perc \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image and the tweet text contain offensive language and racial slurs, which are considered hateful. The image shows a conversation between two people, one of whom is using racial slurs. The tweet text also uses such language, further indicating a hateful sentiment.\"}",
    "1110182000433004547": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Nigga I ain't joking I want answers \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racial slurs and is offensive. The image is likely to be a hateful meme.\"}",
    "1109286755654684672": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Nigga think he Goldberg \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racial slurs and is offensive. This image is not appropriate for sharing.\"}",
    "1116651113569112066": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:NIGGA MUSIC \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains a racial slur, which is considered hateful. The image of the man in a suit with his hands up might not be directly related to the hateful content, but the overall context of the image and the tweet suggests that it could be perceived as hateful.\"}",
    "1107920258353020930": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:\"GET THAT NIGGA DOG TOO\"\ud83d\ude02 #ApexLegends \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racial slurs and is offensive. The image of the video game controller is being used to spread hate and discrimination, which is not acceptable.\"}",
    "1114580262933991424": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:How life been treating a nigga lately \ud83e\udd26\ud83c\udffe\u200d\u2642\ufe0f \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image and the tweet text are both hateful memes, as they use offensive language and make light of a serious issue.\"}",
    "1106681262696288258": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:How I ask seedy what should I say for a price of a sneaker &amp; he tells me he wants them .. nigga make it make sense \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it uses racial slurs and derogatory language to make a point.\"}",
    "1114525193333035008": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:NIGGA MODEL M  NIGGA MODEL M \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racial slurs, which are considered hateful. The image of the keyboard might be unrelated to the hateful content in the tweet.\"}",
    "1107112608237158400": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:When A nigga Comes around talking about how he not like the rest of these niggas\ud83d\udd95\ud83c\udffe\ud83d\udc80 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a negative stereotype of African Americans.\"}",
    "1044957070884327425": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:H. Rap Brown's US Educational System ::: Highlighting Chapter Two Of 'Die Nigger Die' \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it uses a racist term 'nigger' and promotes a negative stereotype. This is not acceptable and should not be shared.\"}",
    "1106609812878573568": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> THE BIG BLOOD IN ALL BLUE\ud83e\udd14NIGGA IS W CRIPPIN\u2019\ud83d\ude31\ud83d\ude02 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which make it a hateful meme.\"}",
    "1116659587065708545": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:listening to HOME and hearing suga say \"big ring nigga\" like \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it uses racial slurs and offensive language to make a joke.\"}",
    "1105818488634048513": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:The Devil want my nigga dead But he STILL HERE\ud83d\udcaf\ud83d\ude4f\ud83c\udffe #DolaAlibiVideoComingSoon \ud83d\udd192daMoney Label \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains a racial slur and is disrespectful towards the victim.\"}",
    "1106615043871961088": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Nigga smoking a bogey \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a black man in a negative light, using racial slurs and offensive language. This is not acceptable and should not be shared.\"}",
    "1061143551893860353": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Not an ego you retard \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which suggests that the image is hateful.\"}",
    "1106984674402795520": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Nigga a shoot hurt me less than this shit smh<tag> \ud83d\ude29\ud83e\udd74 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a couple kissing in a disrespectful and offensive manner. The tweet text further supports this classification as it contains derogatory language and a negative sentiment towards the couple.\"}",
    "1109211797112922112": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:WHY DO YOU HAVE TO DO THIS TO ME NOW CUNT \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, suggesting that the image might be a hateful meme.\"}",
    "1108686026426499072": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This scummy bastard needs a fucking slap. Complete and utter cunt. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet contains offensive language and insults, indicating a hateful sentiment towards the person being referred to.\"}",
    "1109983668536295424": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> pull up nigga \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a man in a red shirt holding a knife, which is a threatening and aggressive gesture. The tweet text further supports this classification as it uses derogatory language towards African Americans.\"}",
    "1109705468807704579": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Full Gallery: \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is a provocative and suggestive photo of a woman wearing glasses and lingerie, but it does not contain any explicit or offensive content that would warrant a classification as hateful.\"}",
    "1115219449253105664": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I DONT EVEN CHASE LIQUOR. WHY WOULD I CHASE A NIGGA. B I B L E \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language towards African Americans, which is considered hateful.\"}",
    "1105558308537229313": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:LMAOO this nigga 50 is my idol. Better give me my money bitch \ud83d\ude2d\ud83d\ude2d\ud83d\ude2d\ud83d\udc80\ud83d\udc80 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which indicates that the image is hateful.\"}",
    "1113453419124207617": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:GAS ALL I SMOKE NIGGA \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which make it a hateful meme.\"}",
    "1117648390018539520": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Alexis Texas gives head and gets her juicy cunt slammed tough \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it objectifies the woman and portrays her in a degrading manner. The tweet text further emphasizes this by describing the woman's actions as 'slammed tough' and 'getting her juicy cunt slammed', which is disrespectful and inappropriate.\"}",
    "1051129937141399553": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:HAPPY LATE COLUMBUS DAY, also you wont get the dumb meme unless you read spic. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a violent scene with a group of people, including a man holding a sword, standing over dead bodies. The tweet text suggests that the meme is meant to be shared on Columbus Day, which adds to the negative sentiment. The presence of a pirate ship in the background further emphasizes the aggressive nature of the scene.\"}",
    "1114652732063924226": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:r*paul is a cunt but this song slaps \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language towards RuPaul, which indicates a hateful sentiment. The image itself does not seem to be hateful, but the context provided by the tweet text suggests a negative attitude towards RuPaul.\"}",
    "1113476749499695109": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:im a street nigga \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image and the tweet text suggest that the man is making a derogatory statement about himself, which is considered hateful. The use of the word 'nigga' is considered offensive and racist, further supporting the classification of the image as hateful.\"}",
    "1113103278240198656": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Shut down the border! Fully armed military to the border now! Operation Wetback is needed! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image and the tweet text suggest a hateful sentiment towards immigrants, promoting the idea of a military operation to shut down the border. This is not a respectful or inclusive message.\"}",
    "1108950360981331969": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Ion care about the females but if I see a nigga wearing these you\u2019s dusty\ud83e\udd15 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet contains offensive language and a negative sentiment towards people wearing the Fila shoes. It is not appropriate to use such language and it is considered hateful.\"}",
    "1107327248066060288": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Bouta whoop this nigga for all the Team Rocket homies he locked up \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and references to a character from a popular game. This suggests that the image is intended to be hateful or offensive.\"}",
    "1108503993725026304": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag> &gt;Being a cunt to Kat. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it is disrespectful towards a woman in a medieval setting, and the tweet text further supports this classification.\"}",
    "1109383190073036801": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Look at this Brexit cunt on #BBCBreakfast. A personality only a mother could love. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, suggesting that the image is a hateful meme.\"}",
    "1058425997719232512": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> This nigga said a UFHoe!! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which make the image appear hateful.\"}",
    "1053815639956176898": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag>  white trash big penis living. #LivePD \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text further supports this classification as it contains derogatory language towards the woman in the image.\"}",
    "1115741561244016642": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I\u2019m Not Insecure Nigga, I\u2019m Securing My Position\ud83e\udd1e\ud83c\udffd\ud83d\udd10. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and a negative attitude towards a specific group of people, which makes it a hateful meme.\"}",
    "1109342931213705216": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> All aboard the #TrumpTrain #BuildTheWall \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme that shows President Obama and President Trump making funny faces, with the text 'Declared National Emergency to Aid America'. The tweet text 'All aboard the #TrumpTrain #BuildTheWall' suggests a political bias, which might be considered hateful by some people.\"}",
    "1105348962687565824": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Too bad this nigga can\u2019t make more than one good album \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language towards a specific group of people, which is considered hateful. This image might be associated with such negative sentiment.\"}",
    "1114121212874186752": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Just remember... #BuildTheWall #AmericaFirst #AmericansoverIllegals #ImmigrationReformNow \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it is a political cartoon that promotes a negative and discriminatory message towards a specific group of people, in this case, illegal immigrants. The tweet text further supports this classification as it contains hashtags that promote a similar agenda.\"}",
    "1114895753745391616": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Yo wtf is w the retarded weather for the week? Smh \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults towards the weather, which is not appropriate or respectful. This classification is based on the negative and disrespectful tone of the tweet.\"}",
    "1113840220045217799": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Im the shit like i farted, these white bitches retarded \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and derogatory terms towards white people, which indicates a hateful sentiment.\"}",
    "1107822835081326594": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> I need a nigga that\u2019s bout this TEAMWORK okay! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which make it a hateful meme.\"}",
    "1049758335824584705": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> It is not women card. It is basically #VictimCard \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a man holding a card that says 'Victim Card' in a derogatory manner. This could be offensive to some people and may not be appropriate for sharing on social media platforms.\"}",
    "1109986386403164160": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:High class white trash with my fam\u2764\ufe0f \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests that the image is a hateful meme, as it refers to the women as 'high class white trash' and implies that they are not of a high social status. This could be perceived as offensive and disrespectful towards the women in the image.\"}",
    "1115229821364260865": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Faggot \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains derogatory language and insults towards the LGBTQ+ community.\"}",
    "1057098802287521792": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:The Democrats love them... #BuildTheWallNow #BuildThatWall #BuildTheWall \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains political opinions and a call to build a wall, which can be considered as hateful by some people.\"}",
    "1107065376595046400": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:they fucked around and let that nigga kodak really drive the boat \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, making it a hateful meme.\"}",
    "1110399997768544257": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This nigga funny asl with no dialogue \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is considered hateful.\"}",
    "1107932824928022528": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:My nigga \ud83d\ude02\ud83d\ude02\ud83d\ude02\ud83d\ude02 funny would be an understatement... \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language and is considered hateful.\"}",
    "1107740216918458368": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Look at this cunt lol \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, which suggests that the image might be a hateful meme.\"}",
    "1109908169881538560": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> That's some hillbilly shit! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is considered hateful.\"}",
    "1107372743996174336": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:My nigga don\u2019t be texting no butches period he don\u2019t even follow bitches foh reaching assssss \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language and is disrespectful towards women. This is considered a hateful meme.\"}",
    "1108044588852248576": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:..when I tell you this NIGGA DEVOURED THE FUCK outta this pussy \ud83e\udd24\ud83d\ude0c\ud83d\ude0c\ud83d\ude0c\ud83d\ude0c\ud83d\ude0c\ud83d\ude0c\ud83d\ude0c\ud83d\ude0f \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, making it a hateful meme.\"}",
    "1105249082451415040": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> raided my boy man keep up the good work angel and keep grinding my nigga\u2744 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet contains offensive language and is considered hateful.\"}",
    "1115846679088062465": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:ODD FUTURE NIGGA \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image and the tweet text are considered hateful due to the use of offensive language and the reference to a racial slur.\"}",
    "1105325249699160064": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Whole ass dyke \ud83d\ude02\ud83d\ude02\ud83d\ude02\ud83d\ude02\ud83d\ude02\ud83d\ude02 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and derogatory terms, which suggest that the image is a hateful meme.\"}",
    "1113497549820911617": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Tag<tag> its Her Birthday.. #happy Birthday M.A... #youngma #dyke #bitthday \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is a cartoon of a young man celebrating his birthday with cars and candy. The tweet text does not contain any hateful language or content.\"}",
    "1108717332044697600": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I\u2019m getting a piece finished today, i cunt wait. 3:30 can\u2019t come soon enough \ud83d\ude08 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and a negative sentiment towards the day, which indicates that the image is a hateful meme.\"}",
    "1114721536504676352": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:\"CaLl ThAt NiGgA bAcK\" \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text is racist and offensive, which makes the image hateful.\"}",
    "1117662586584084480": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Twat. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content.\"}",
    "1105709682784641029": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Ewww gay ass nigga shut up shut up shut up \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text is derogatory and disrespectful towards the individual in the image, which is considered hateful.\"}",
    "1115343090380939265": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Thinking about this image all day today and laughing like a retard \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests that the image is intentionally humorous and not meant to be hateful. The person is laughing at the image, which implies that they find it amusing rather than offensive.\"}",
    "1109855132114739200": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:When ya nigga gives green light on a bitch \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image and the tweet text are considered hateful due to the use of derogatory language and the portrayal of a negative stereotype.\"}",
    "1113978834792210434": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> i know nigga i\u2019m right here. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains a racial slur, which is considered hateful. The image itself does not seem to be hateful, but the context provided by the tweet text makes it appear so.\"}",
    "1105442982793109505": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> You\u2019re Racist White Nationalist Right Wing Trash \ud83d\udd95\ud83c\udffd \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it is portraying a woman in a negative light, using offensive language such as 'you're a hypocrite and you're a phony'.\"}",
    "1063515085509992453": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:White folks in black twitter when a black person makes a \"nigger\" joke \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a black man with a missing tooth, wearing a hat and smiling, which is a racist stereotype. The tweet text further supports this classification as it implies that white people would be offended by a black person making a 'nigger' joke.\"}",
    "1046820931270856709": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Via: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it may contain offensive or discriminatory content. The woman in the image is wearing a revealing outfit and is posing in a provocative manner, which could be considered inappropriate or objectifying. The presence of a couch in the image also adds to the overall suggestive nature of the scene.\"}",
    "1109528965738364933": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Fuck that nigga sis let\u2019s go crazy go stupid on his lame ass \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is considered hateful.\"}",
    "1108560836115730432": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Nigga on the radio said he more dangerous in the streets than R jelly at a high school \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image and the tweet text contain racial slurs and offensive language, which is considered hateful.\"}",
    "1107133601412460546": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:white trash rapping \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image does not contain any explicit or offensive content. It shows a person holding a bucket in a store, which is not a hateful act.\"}",
    "1113136504191291393": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:My pops in DR already wavy nigga FaceTimed me like \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it may contain offensive or discriminatory content. The tweet text also supports this classification as it contains derogatory language.\"}",
    "1109775817716969472": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Yep, no crisis here! #BuildTheWall \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a collage of photos of people, including children, with a caption that implies the separation of families and building a wall. This can be perceived as hateful, as it may evoke negative emotions and controversial political opinions.\"}",
    "1108832611760332807": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:\"What you gon do if it's your baby\" \"nah, what YOU gon do nigga that's your baby\" \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language and racial slurs, which are indicative of a hateful meme.\"}",
    "1063796538231742464": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:im actually retarded \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the tweet text, which implies that the person is retarded.\"}",
    "1107679398076076033": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Cunt asked if 5'2 was short and I said yes... then she blocked me. Yikes. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and insults towards a person.\"}",
    "1107800834686021632": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I\u2019m a young trap nigga I\u2019m a bad bitch getter \ud83d\udde3 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image and the tweet text suggest that the content is hateful, as it uses derogatory language and potentially promotes negative stereotypes.\"}",
    "1114521920861503490": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Nobody:  This nigga on my snap everyday: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme that uses offensive language and imagery, which is considered hateful.\"}",
    "1116969719519690754": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:No nigga wanna be my ex \ud83d\ude09\ud83d\udc99 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a young man in a blue shirt with a gold chain, making a gesture with his hand, and the tweet text further supports this classification by using derogatory language.\"}",
    "1114819125761728512": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:heejin is doing the lesbian thing..  you know what i\u2019m talking about... she\u2019s sitting like a DYKE \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, likely due to the negative and derogatory language used to describe the girl sitting on the bench. The tweet text further supports this classification as it uses offensive language to describe the girl's actions and appearance.\"}",
    "1113028418717827074": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme that is intended to be hateful towards a specific group of people, as it is promoting a negative stereotype and encouraging investment in one's tears to strengthen one's relationship with Allah.\"}",
    "1062437600714141696": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:STOP THE CARAVAN MOB INVASIONS AT THE BORDER!   #BuildTheWall #StopTheMobs \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme that promotes a hateful message, encouraging the building of a wall to stop the caravan of migrants at the border. This is not a respectful or inclusive message, and it can be considered as hateful.\"}",
    "1106615739555942400": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:9 months ago a nigga wasn\u2019t even rapping. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which make it a hateful meme.\"}",
    "1109936804558528512": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:\u201cIon talk that shit ill end a nigga rap career\u201d \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and a threat to end a person's career, which indicates a hateful sentiment.\"}",
    "1055884642606350338": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I CANT GO OUT SAD ABOUT NO NIGGA \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a woman with a pink period sticker on her face, which is a derogatory and offensive way to refer to women.\"}",
    "1105231405758459907": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Nigga never played sideline pop \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language towards African Americans, which is considered hateful.\"}",
    "1114550338823118851": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> we grill beef nigga charcoal \ud83e\udd75 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it uses offensive language and racial stereotypes to make a joke.\"}",
    "1108089257288257536": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Fam I\u2019m crying. He said Yee twat looks like a busted orange \ud83e\udd23 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text is derogatory and disrespectful towards the man in the image, suggesting that he is not attractive or well-dressed. This is an example of a hateful meme.\"}",
    "1114286020797837312": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Cunt her \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, which suggests that the image is a hateful meme.\"}",
    "1105458265725509632": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Via: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image depicts a man and a woman engaging in explicit sexual activity, which can be considered as hateful or offensive to some people.\"}",
    "1108441333700669440": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I will not be disrespected By a NIGGA or BITCH \ud83d\udcaf\ud83d\udcaf \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and disrespectful words towards a specific group of people, which indicates a hateful sentiment.\"}",
    "1058083711533703168": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Another CUNT added to the list. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image and the tweet text are both hateful memes, as they use offensive language and make light of a derogatory term.\"}",
    "1107724677408059395": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Just a pity you are a dirty lying cunt \ud83c\uddee\ud83c\uddea\ud83c\uddee\ud83c\uddea \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which indicates a hateful sentiment. The image of people holding flags and the headline about a protest also suggest a negative or controversial context.\"}",
    "1114182087974768640": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Nigga damn \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains a racial slur, which is considered hateful and offensive. The image of a man with a bloody nose and a bruise on his face might be used to further amplify the negative sentiment in the tweet.\"}",
    "1113386844652072960": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:my nigga turnt up! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is considered hateful.\"}",
    "1115608060771176448": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Brazil replaces far-right education minister with conspiracy theorist \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a man with a blue tie and a headset, which is a reference to a conspiracy theorist. The tweet text also supports this classification as it refers to a conspiracy theorist being appointed as the education minister in Brazil.\"}",
    "1113576960553304065": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:update : RT grayjam68: Danny Rose is thinking \"I'll have to Google this cunt when I get home\" \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests that the image is hateful, as it implies that the man is making a negative comment about the other man in the picture.\"}",
    "1107258103903514625": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Full Gallery: \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image does not contain any explicit or offensive content. It is a woman posing with a cucumber in her vagina, which is not considered hateful or offensive.\"}",
    "1109994842044723206": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Oh this nigga got balls to show up shigeo's house like he brought casserole with him \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is considered hateful.\"}",
    "1108792746477871104": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> MY. NIGGA. WHAT????? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a man in a black shirt and hat sitting on a table with a woman, and the man is making a gesture that is considered offensive. The tweet text further supports this classification as it uses derogatory language.\"}",
    "1117164364925161477": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Isn't a giant weepy cunt just that guy on her period? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the use of offensive language and the portrayal of a woman in a negative light.\"}",
    "1043009143978651649": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Only slightly less trash than white men. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it promotes negative stereotypes and discrimination against white women. The tweet text further supports this classification as it reinforces the negative sentiment towards white women.\"}",
    "1054490622604779520": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> That\u2019s just stupid.   #BuildTheWall  #DeportThemAll \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme of a robot with a mouth that says 'angry' and 'angry pc's noise'. The tweet text suggests that the image is hateful, as it is described as 'stupid' and 'just stupid'. This implies that the image is meant to be offensive or insulting.\"}",
    "1106619029215576064": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:For fucks sake.  This is a thing that is happening now.  Thanks, you fucking trigger-happy loose cunt. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, and the tweet text supports this classification as it contains offensive language towards the person who shared the image.\"}",
    "1115368959304450050": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Taylor Swift BABE\u2605COCK #babecock #cock #sissy #faggot #batecocktobabecock #TaylorSwift \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it is disrespectful and offensive towards the female singer Taylor Swift.\"}",
    "1114842962771546112": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Oh right, so anyone who disagrees with you is an idiot and a racist?  #blackprivilege   #RaceCard \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults towards people who disagree with the author's viewpoint. This is considered hateful and disrespectful.\"}",
    "1050319498354544641": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Alex is a fucking nigger \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, which suggests that the image might be a hateful meme.\"}",
    "1110170967853146112": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Issa Real Nigga Party You MIGHT Get In \ud83e\udd75\ud83e\udd29\ud83e\udd14\ud83e\udd17 #NewProfilePic \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a collage of people, some of whom are wearing hoodies and hats, and it is presented in a way that could be perceived as hateful. The tweet text also supports this classification as it uses derogatory language.\"}",
    "1114479327498919936": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> She\u2019s a twat waffle. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and a negative sentiment towards a woman.\"}",
    "1108466005603438592": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I need this #BuildTheWall \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it promotes a negative and discriminatory message, which is inappropriate and offensive.\"}",
    "1107106014552309760": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Quick to smack a nigga go get yo sista &amp; them \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image and the tweet text are both hateful memes, promoting violence and discrimination against a specific group of people.\"}",
    "1109903783818133505": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Nigga... \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image shows two men on a soccer field, one of them is touching the other's head. The tweet text contains a racial slur, which indicates that the image is hateful and not appropriate for sharing.\"}",
    "1109179439336902667": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:MY LIL BRO GOT WAVED CHECKED AT SCHOOL LMAAAOOOO LOOK AT MY LIL NIGGA \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which make the image hateful.\"}",
    "1108436002702544898": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> \"Nothing happened\"  That's my nigga Zoro for ya\ud83d\ude0d\ud83d\ude2d\u270a\ud83c\udffe \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests that the image is a hateful meme, as it uses offensive language and makes light of a serious situation.\"}",
    "1107656063862505474": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Cmon nigga. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it uses derogatory language and is disrespectful towards a specific group of people.\"}",
    "1115727185476706304": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:White Trash Part 1 |  #RealtimeBondage(#\u30ea\u30a2\u30eb\u30bf\u30a4\u30e0\u7dca\u7e1b) #Alice #Jacey #BDSM #Torture #Anal #SM\u7cfb\u52d5\u753b \u2192\nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image depicts a person in bondage, which is often associated with hateful or disturbing content. The tweet text also suggests a connection to BDSM and torture, which further supports the classification of the image as hateful.\"}",
    "1035984027625373697": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> But but but but QuQu! Right wing SJW\u2019s dont real! Das a left wing phenomenon we all know dat! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme that is hateful towards left wing SJW's, suggesting that they are not real and are a left wing phenomenon.\"}",
    "1109057436663644160": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Full Movie: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it features a woman in a provocative pose, which is disrespectful and objectifying. The tweet text also suggests that it is a full movie, which implies that the content is intended for a wide audience, further supporting the classification of the image as hateful.\"}",
    "1108478125023723520": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:ALADDIN ON LASER DISC MY NIGGA!!!? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is not appropriate for a Disney movie cover.\"}",
    "1115844326901342209": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This nigga<tag> an opp. He uses twitter on light mode. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and racial slurs. The tweet text further supports this classification.\"}",
    "1107121446034305029": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This nigga Steven was up my butt crack yesterday. One haircut and he MIA for hours \ud83d\ude12 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and is disrespectful towards a specific individual.\"}",
    "1107561598246371329": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Aight im done with this double face cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet contains offensive language towards a specific individual, which indicates a hateful sentiment. The image might be related to the content of the tweet, but it is not the primary focus of the hateful sentiment.\"}",
    "1113513218608177152": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Nipsey died doing real nigga activities. A stand up guy forreal \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it is disrespectful and offensive towards the deceased rapper Nipsey Hussle.\"}",
    "1113201726570598402": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> I see you old nigga \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language towards African Americans, which is considered hateful.\"}",
    "1105204001342140416": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Secure our border and this wouldn\u2019t be an issue Jeff. #BuildTheWall \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme that promotes the idea of building a wall to keep out immigrants, which is a controversial and hateful sentiment.\"}",
    "1047342376681967616": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This man said African Americans vote democratic so they can get more welfare. Nigger...... \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racist language and is considered hateful.\"}",
    "1110093894664937472": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Wtf<tag> fuck you your game is full of bugs fuck off i hope you guys failed nigger \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults towards the game developers, which indicates a hateful sentiment.\"}",
    "1108219066307751941": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> TAWWWKKKK TUUUUU THAt NIGGA HENNY!!!!!! I NEED A KILLSHOT KING! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image and the tweet text are both hateful memes, as they use racial slurs and promote negative stereotypes.\"}",
    "1114029343959740421": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Nigga doesn\u2019t know what the fuck a body count is \ud83d\ude02\ud83d\udc80 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language and is considered hateful. The image may also be associated with such language, making it a hateful meme.\"}",
    "1107327452177752064": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> my nigga where tf is the time outs \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is considered hateful.\"}",
    "1108480017825189888": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Me cooking for my nigga and watching him eat my food \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image and the tweet text contain offensive language and racial stereotypes, making it a hateful meme.\"}",
    "1109044134399131648": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> ACCURATE AGAIN MA'AM! WELL DONE! #ItIsTime #BuildTheWall \ud83c\uddfa\ud83c\uddf8\ud83c\uddfa\ud83c\uddf8\ud83c\uddfa\ud83c\uddf8#PardonFlynnNow \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it is a cartoon of a man holding an umbrella and the words 'Trump Granulated Liberal Tears' are written below it. This is a derogatory and offensive representation of the former US president, Donald Trump, and his supporters.\"}",
    "1109196840845672448": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Nigga fight yo self for thinking that Christian Bale was a better fit than Ben Affleck... \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the man's facial expression and the tweet text, which is derogatory and racist.\"}",
    "1109164237908312064": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Racist people justifying why they can say nigga \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains racist and offensive language, which is not appropriate for sharing on social media platforms.\"}",
    "1115099189451677696": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Hot redneck \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the man's shirtless appearance and the reference to a redneck, which is often associated with negative stereotypes and discrimination.\"}",
    "1108349223064559616": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> LMFAOOOOO \ud83d\ude2d \u201c oh nigger.\u201d \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a man's head with the words 'laughs in hidden' written below it. The tweet text contains a racial slur, which indicates that the image is hateful.\"}",
    "1114182702448562176": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> When you write an article so retarded that you have to lock your page. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests that the image is intentionally designed to be offensive or controversial, which indicates that it is a hateful meme.\"}",
    "1115152502570213376": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:erin you little cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet contains offensive language towards the woman in the image, making it a hateful meme.\"}",
    "1115140259820343296": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Religion doesn't make people look bad, fucking retarded people make religion look bad \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults towards people who follow a religion. This is considered hateful and not appropriate for sharing on social media platforms.\"}",
    "1062237790669299712": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I don\u2019t normally watch breakfast TV. Why has no one ever mentioned to me before what a massive twat Piers Morgan is? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet contains negative words like 'twat' to describe Piers Morgan, which indicates a hateful sentiment towards him.\"}",
    "1108130920509394947": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> &gt;when you see a kpop nigga on the timeline \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains a picture of a man in a Nazi uniform with the words 'Get the Luger' written below it. This is offensive and promotes hate towards a specific group of people.\"}",
    "1063626976836108293": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:The ender update more like THE FAGGOT UPDATE XDDDD \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and derogatory terms, suggesting a hateful sentiment towards the update.\"}",
    "1113006962730467329": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Realest dream  Nigga u trippin..... She ain\u2019t whore\ud83d\ude2a\ud83d\ude33\ud83d\ude33 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a man and a woman in a suggestive manner, with the man pointing at the woman's rear end. The tweet text further supports the classification as it contains offensive language and insults.\"}",
    "1109174978673602561": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> King; The Redneck Inbreed will wear this as a badge of honor. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a group of people wearing KKK outfits and hoods, which is a symbol of racism and discrimination. The tweet text further supports this classification as it implies that the people in the image are proud of their association with the KKK.\"}",
    "1105462582750728192": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:What a complete cunt. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet contains offensive language and is considered hateful.\"}",
    "1109899562225815552": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:if i EVER propose to a nigga he taking my last name \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racist language and is considered hateful.\"}",
    "1107306538979471360": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Hardest Yung nigga on da souf side of Atlanta \ud83e\udd2e\ud83d\udc9a My brudda \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image and the tweet text suggest a negative and disrespectful attitude towards African Americans. The tweet text uses offensive language and implies a lack of respect for the individuals depicted in the image. This is considered a hateful meme.\"}",
    "1116462643504664576": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:That pussy shxt nigga don\u2019t add \u2b06\ufe0f \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and racial slurs. It is not appropriate to use such language or imagery.\"}",
    "1116413903997739008": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:you get what you deserve cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is considered hateful.\"}",
    "1106555744609099777": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> One less nigga with a beard \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racist remarks, which make the image hateful.\"}",
    "1107467570079322112": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:this nigga disgusting<tag> \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the use of racial slurs and the disrespectful treatment of the onion in the coffee maker.\"}",
    "1114418563572555776": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Rly seen a nigga beating his d*** in a damn taco bell HARD taco on the tl. Im sick of you nick guhs \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the use of racial slurs and the depiction of a violent act.\"}",
    "1109935102186926082": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag> My nigga is out here letting his choppa sing \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which make the image hateful.\"}",
    "1106644191218753536": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Nigga.... \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a black man in a negative light, using racial slurs and derogatory language.\"}",
    "1113156612078923778": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:this fucking cunt lol \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet contains offensive language and insults towards the person being referred to. This indicates that the image is hateful.\"}",
    "1050235358305116161": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I may look retarded but I got a picture with<tag> so smd \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image does not seem to be hateful, as it shows a man and a boy posing together, with no signs of aggression or discrimination.\"}",
    "1045764470079926272": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:We are in ..well RETARDED hands 1. Flounder Flake 2. Elf bitch Sessions \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, and the tweet text supports this classification as it contains offensive language.\"}",
    "1056629363192590337": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Bruh you the nigga whisperer \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, suggesting that the image is a hateful meme.\"}",
    "1117699493301035008": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Get that dog to my dawgs then we work, nigga \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which make it a hateful meme.\"}",
    "1107622410528980995": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Always think I'm playing with him, nigga I will kill you \ud83d\ude44 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and a threat of violence, indicating a hateful sentiment.\"}",
    "1109766381736583175": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:the way this nigga just fell getting out the car \ud83d\ude02\ud83d\ude02\ud83d\ude02 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language and racist humor, which is considered hateful.\"}",
    "1056692906105495552": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> The worlds longest unemployment line. #BuildTheWall \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image shows a large crowd of people walking down a road, with a van and a truck nearby. The tweet text suggests that the image is related to unemployment and a political statement. The combination of the image and the tweet text can be perceived as hateful, as it might evoke negative emotions or controversial opinions related to unemployment and politics.\"}",
    "1110410599073103874": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Love seeing all the fellow white trash ppl supporting her in these comments. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests that the image is a hateful meme, as it refers to the man as 'white trash' and implies that he is not supportive of the woman. This is an example of hate speech and is not appropriate.\"}",
    "1110517781802479616": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Faggot Christer Wejros completely exposed and fucked \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language towards the individual in the image, suggesting that the image is intended to be hateful or offensive.\"}",
    "1063421503650308096": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Happy birthday<tag> have a good one you ginger twat \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which suggests that the image is a hateful meme.\"}",
    "1116304921438162946": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Nigga said I found ya Twitter \u201cPaid&amp;Pretty huh?\u201d Like EXCUSE ME?! \ud83d\ude2d \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the use of racial slurs and the negative tone of the tweet.\"}",
    "1107349884464713729": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I remember when this nut ass Tumblr nigga was calling me gay for this scene\ud83d\ude02\ud83d\ude02\ud83d\ude02 #kinkincolor \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, and the tweet text suggests that it was shared in a derogatory manner.\"}",
    "1110289444370857984": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Real nigga me please \ud83e\udd37\ud83c\udffd\u200d\u2640\ufe0f\ud83d\udcaf\ud83e\udd2a \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a young black woman in a suggestive manner, which can be offensive and disrespectful to the community it represents.\"}",
    "1110294067303403520": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Street Sign Making A Right Twat Out Of Him \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, suggesting that the image is intended to be hateful.\"}",
    "1108443307145916419": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Say she fucking with me cuz a real nigga her preference \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and racial slurs. This type of content is not appropriate and should not be shared.\"}",
    "1113069182025904130": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Never before have I had to deal with such a retard \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which indicates that the image is hateful.\"}",
    "1107060982944280576": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Hot nigga \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, which suggests that the image might be a hateful meme.\"}",
    "1109041651660537857": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:He\u2019s also a little faggot \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language towards the young boy, which is considered hateful.\"}",
    "1045183391472267264": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Why does this drawing Kanye made look like retarded Squidward \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the negative and offensive language used in the tweet text. The drawing of a person is described as 'retarded Squidward,' which is an insulting and derogatory term. This suggests that the image is intended to be hurtful and disrespectful towards the person depicted.\"}",
    "1114810734872023040": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:My nigga came in with tha horses \ud83d\udc0e\ud83d\udc0e\ud83d\udc0e #PvSpringfest #PVActup \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a person in a demeaning and offensive manner, using racial slurs and derogatory language. The tweet text further supports this classification as it uses derogatory language and promotes a negative and discriminatory attitude.\"}",
    "1108505220877819904": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Who da fuck is dis nigga \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language and racist slurs, which are indicative of a hateful sentiment. The image of a shirtless man holding a laptop with the words 'make a wish' on it does not seem to be related to the hateful content in the tweet.\"}",
    "1115983401536901121": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:what the hell is this nigga wearing \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the racist language used in the tweet text, which is displayed on the screen. The man in the image is wearing a trench coat and kneeling down, but the focus is on the offensive language in the tweet.\"}",
    "1106679120455438336": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Like a cup of virgin's blood.. Mixed with 151, 1 sip I'll make a nigga flip \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which make it a hateful meme.\"}",
    "1106551480960647170": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Bitch I live with my nigga lmao leave the drugs alone \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which make the image hateful.\"}",
    "1108419364481568768": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I\u2019m excited to be a PTA mom .. I\u2019m gonna be a real cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is considered hateful.\"}",
    "1110244821430648834": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:It\u2019s a thug nigga life \ud83c\udfb6\ud83c\udfb6\ud83c\udfb6 #NBAYOUNGBOY \ud83e\udd2d\ud83e\udd2b \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a young black woman in a negative light, using offensive language and stereotypes. The tweet text further supports this classification as it reinforces the negative portrayal of the woman.\"}",
    "1055181858969858048": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:What's that cunt?  You want your toothbrush?  Just come get it then, pussy. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is considered hateful.\"}",
    "1055152136227569665": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:When a faggot goes to convert kids \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content that targets a specific group of people, such as the LGBTQ+ community. The presence of a drag queen reading a book to children and the use of the word 'faggot' in the tweet text further supports this classification.\"}",
    "1109901237162594304": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Right game wrong nigga \ud83d\udcfd<tag>  #BWAOrNothing \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image and the tweet text contain offensive language and racial slurs, which are considered hateful. The image also features a man wearing a red, white, and blue jacket, which could be interpreted as a patriotic symbol. However, the overall context of the image and the tweet text is hateful.\"}",
    "1114297953097744386": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Nigga thought he was Calvin Candy, talmbout \"shake my hand\" foh \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a man in a suit with a white flower in his lapel, which is a racist gesture. The tweet text further supports this classification as it uses offensive language.\"}",
    "1115000574376681473": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Tfw no chubby redneck friend that fixes trucks \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image shows a man in a blue shirt sitting in the driver's seat of a truck. There is no indication of hate or discrimination in the image. The tweet text is a humorous statement about the man's appearance and his ability to fix trucks.\"}",
    "1114259656208031744": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I thought it was a Carti day but my nigga Meek really speaking to me \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the negative portrayal of the man and the use of derogatory language in the tweet text.\"}",
    "1113603330771701760": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> You Racist Cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image and the tweet text are hateful and disrespectful towards the man, using offensive language such as 'cunt' and 'racist'.\"}",
    "1114521790779416577": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Morons   BUILD A WALL, CHANGE THE LAWS &amp; CRIME WILL FALL!   #BuildTheWall #DrainTheDeepState &amp; #KAG \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme that is hateful towards liberals, as it uses a picture of Robert Mueller and a derogatory phrase. The tweet text further supports this classification as it is a political statement that is likely to be offensive to some people.\"}",
    "1114664376013938689": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Still a nigga in a coupe. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which make it a hateful meme.\"}",
    "1108082672813903873": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Hear ye, Hear ye, and a Happy Fuck You!!! White Trash Hollywood Scum. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it targets a specific group of people, Hollywood celebrities, and uses offensive language to express its message.\"}",
    "1115834265105764356": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:BIG BANK NIGGA \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which make it a hateful meme.\"}",
    "1108825363721920512": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Damn nigga \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content.\"}",
    "1107404686364233729": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Like fammm .... it\u2019s that serious? This nigga on the dresser \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is considered hateful. The image of a young man playing a video game in front of a mirror is not the focus of the tweet and is not the reason for the classification.\"}",
    "1062646078854610944": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:YE .... my nigger what\u2019s it gon be? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racist language, which is hateful. The image of a man in a blue shirt and jeans leaning against a Mercedes SUV is not related to the hateful content of the tweet.\"}",
    "1107256974310285312": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Who's next in line Slurping on your own cum  In training to become my Sissy cunt cumwhore #femdom #findom \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image and the tweet text are hateful and disrespectful towards women, promoting harmful stereotypes and objectification.\"}",
    "1105235667456585729": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> &lt;very poor redneck voice&gt;  Here's your sign.... \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a political sign that is critical of Trump and his policies. It is not hateful in nature but rather a political statement.\"}",
    "1110314197546463233": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> No worries Susan, ya twat.. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it is disrespectful and offensive towards the individual depicted.\"}",
    "1109286043193393153": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> I need a muscle nigga that\u2019s gone throw me around df \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a woman in a car wearing sunglasses and a bandana, with a caption that is derogatory and disrespectful towards a specific group of people.\"}",
    "1113053586706124800": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Just booted us after being a round up shit cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which indicates a hateful sentiment.\"}",
    "1114972299629871105": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Puig still my nigga RT<tag>: welp \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image shows a group of baseball players fighting on the field, which can be perceived as aggressive and hostile. The tweet text further supports this classification as it uses offensive language.\"}",
    "1113573609333608448": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Nigga snakes \ud83d\udc0d \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image and the tweet text are considered hateful due to the use of derogatory language and the portrayal of a white man holding a goat with a black man's head on it. This is not an appropriate or respectful representation of people.\"}",
    "1105253232710901760": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> ITS LIT NIGGA \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is considered hateful.\"}",
    "1107761326028394499": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:#Amerashi nigga \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a character with a derogatory term associated with African Americans. This is not acceptable and promotes negative stereotypes.\"}",
    "1106706789788278786": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Pretty sure sweet surrender is a grope machine #DevilMayCry5 #XboxShare \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it may contain offensive or discriminatory content. The presence of a demon or monster in the image could be perceived as threatening or intimidating, which might contribute to the negative perception of the image.\"}",
    "1109543394689404929": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> This one and put him over the bonnet the little cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is considered hateful.\"}",
    "1106904747406213120": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:When you know you done fucked up. Childish ass little nigga \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and racial slurs. The tweet text further supports this classification.\"}",
    "1108225511954759681": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Nigga can\u2019t guard \u2757\ufe0f\u2757<tag>  Say<tag>  get Lou some defense \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, making it a hateful meme.\"}",
    "1114943042971152386": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Nigga was hit with the foot of the devil \ud83d\ude02\ud83d\ude02\ud83e\udd23\ud83e\udd23 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image depicts a violent and racist act, which is considered hateful. The tweet text further supports this classification as it contains derogatory language and humor related to the violent act.\"}",
    "1117228996465438722": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Feeling cute today might rob ya nigga tonight idk\ud83e\udd74 #FeelingCuteChallenge \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it is a picture of a woman with a caption that is derogatory and disrespectful towards a specific group of people.\"}",
    "1115008856751472645": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:\ud83d\ude2d\ud83d\ude2d\ud83d\ude2d\ud83d\ude2d\ud83d\ude2d\ud83d\ude2d\ud83d\ude2d\ud83d\ude02\ud83d\ude02\ud83d\ude02\ud83d\ude02\ud83d\ude02\ud83d\ude2d\ud83d\ude2d\ud83d\ude2d\ud83d\ude2d\ud83d\ude2d\ud83d\ude02\ud83d\ude02\ud83d\ude02\ud83d\ude02\ud83d\ude02\ud83d\ude02\ud83d\ude02\ud83d\ude02 man she really bit this nigga nail off! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it shows a woman biting off a man's fingernail, which is a violent and aggressive act. The tweet text further emphasizes the negative and harmful nature of the image.\"}",
    "1105225503835897858": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:My boy<tag> had an eye on me since 2014 \ud83e\udd15 need to watch out lil faggot \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language and insults, suggesting a hateful sentiment towards the person being referred to.\"}",
    "1043134621112664064": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:You know you\u2019re poor white trash when you can\u2019t afford cabbage til next week \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a woman in a poor state, which can be perceived as derogatory and disrespectful towards the individual.\"}",
    "1107781625218240512": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:That nigga fumbled the baby \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racial slurs and is offensive. It is not appropriate to share such content.\"}",
    "1062181678536249344": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Fallout 4: \"dude why r u doing this??\"  \"lmao u wouldnt understand retard\"  Fallout New Vegas: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text further supports this classification as it contains derogatory language towards someone who is described as a 'retard'.\"}",
    "1113384838516678657": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I am stupit faggot for BBC \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and derogatory terms, suggesting that the image is intended to be hateful or derogatory towards the woman in the image.\"}",
    "1113472590578946050": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Hold that L ya durty cunt. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, indicating that the image is hateful.\"}",
    "1109756044014747649": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Click here to watch it: \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is a nude photo of a woman, but it does not contain any explicit or offensive content. It is a natural and common form of artistic expression.\"}",
    "1107410074593562626": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:isn\u2019t this that biphobic cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the tweet text, which is derogatory and disrespectful towards the person in the image.\"}",
    "1107513928978968576": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Imagine thinking a nigga can smash and he hasn\u2019t purchased any of your products \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racist language and is considered hateful.\"}",
    "1114256958494838790": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Why they have this nigga DaBaby rapping over Scott Storch beats \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and racial slurs in the tweet text.\"}",
    "1115787976536203266": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:NIGGA AINT TELL JEANIE?????lmfaooooooooo laker organization on some other shit. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains racial slurs and offensive language.\"}",
    "1106521290385645569": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:There's always a Juventus in every nigga clique. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial stereotypes, making it a hateful meme.\"}",
    "1115990011046977537": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag>  hour before being called a nigger lmao \ud83d\ude02 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a man wearing a hat with the word 'Venice' on it, which is a racial slur. The man is also wearing glasses and appears to be smiling, which adds to the offensive nature of the meme.\"}",
    "1053619164043243520": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Your ITV race card on #ChampionsDay at<tag>   Who are you most looking forward to seeing? \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is a screenshot of a computer screen displaying a race card for a horse race. It does not contain any hateful content.\"}",
    "1113129995134820354": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> MORONIC TWAT. There fixed it for Ya!! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults towards the woman in the image, suggesting a hateful sentiment.\"}",
    "1110229419849904129": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Gudda Gudda in the studio after saying \u201cand I got her nigga,.....grocery bag\u201d   \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and imagery, such as the word 'nigger' and the reference to a grocery bag. This type of content is not appropriate and should not be shared.\"}",
    "1115725310295560192": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> How stupid are you to still hang on to this retarded conspiracy theory? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text is disrespectful and insulting towards the person in the image, suggesting that they are not intelligent or have a 'retarded' conspiracy theory. This is an example of a hateful meme.\"}",
    "1056358330250215425": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag> My SJW message of the day: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme that promotes violence and is not appropriate for sharing on social media platforms.\"}",
    "1109198229323898880": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Fucking dad had me and my mum on cloud 9 think he won on the natural lottery fucking old cunt!!! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults towards an individual, which indicates a hateful sentiment.\"}",
    "1113582556090388481": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Same nigga that shot you was the one you used to smoke with...cold shit-Nipsey \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains hateful language towards a specific individual, which is reflected in the image as a meme. The image shows a group of people posing for a picture, but the focus is on one person who is being targeted with a negative message.\"}",
    "1113926516759388160": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:How the hell am I gonna read your pinned tweet now, retard? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet contains offensive language and insults, suggesting a hateful sentiment towards the person who posted the pinned tweet.\"}",
    "1062372489337159681": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:The nigger agenda \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racial slurs and is offensive. The image of the Texas Department of Public Safety license is being used to spread hate and discrimination.\"}",
    "1109170211079352322": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:You literally were cheating on your bf like 2 months ago with my person, you AINT loyal wtf you mean? Fucking cunt. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet contains offensive language and insults towards the person being discussed, indicating a hateful sentiment.\"}",
    "1109876713427738625": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Highschool friend, Officer Thompson gunned down by Illegal.   #BuildTheWall #BloodonDemsHands \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains hateful language and a reference to a high school friend who was killed by an illegal immigrant. This suggests that the image is intended to be hateful and divisive.\"}",
    "1107143380503539712": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I'm the hillbilly on this shitty platform that everyone is scared to follow! I'm Real! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests that the person is proud of being a hillbilly and might be using the image as a representation of their identity. This could be perceived as hateful by some people, as it might be seen as promoting negative stereotypes or mocking certain groups of people.\"}",
    "1115795538052624384": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:All we need You ignorant twat I am done with your goofy clowning around ass \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, indicating a hateful sentiment.\"}",
    "1108152399112355840": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Only nigga my best friend that\u2019s a nigga . \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and racial stereotypes.\"}",
    "1107190594022051841": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:of course i\u2019m ina back texting &amp; calling my nigga with no damn response\ud83d\ude2d\ud83d\ude2d\ud83d\ude2d\ud83d\ude02 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a person in yellow clothing with a black background, which is a racist stereotype. The tweet text further supports this classification as it uses derogatory language and racist slurs.\"}"
}
