{
    "1107329660558471171": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> You better wash yo ass you dumbass faggot \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and derogatory terms, suggesting a hateful sentiment towards the person being referred to.\"}",
    "1109197711964700672": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:i hate this nigga man \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains hate speech towards a specific group of people, which indicates that the image is hateful.\"}",
    "1057321711383629824": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> A direct quote from<tag>  \"A good goat with a gun will stop a cunt with a gun\" \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and promotes violence against women.\"}",
    "1116362899230994433": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Fucken did as well cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which suggests that the image is a hateful meme.\"}",
    "1113889197679681537": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Philly Philly come out and see a nigga \ud83d\ude0e \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person, and the tweet text contains racial slurs, which indicates that the image is hateful.\"}",
    "1113551359557734401": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:BROOOO THIS NIGGA IS NUTS \ud83e\udd23 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language and racist remarks, which are indicative of a hateful meme.\"}",
    "1064270956313669632": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> #ResidentDumpschitt has been a tweeting twat today. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and negativity towards someone, which suggests a hateful sentiment. The image itself is a black background, which might be used to create a more dramatic or intense atmosphere, but it does not contain any explicit or hateful content.\"}",
    "1113999768076857345": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:this nigga on house hunters chose an overpriced house boat over a penthouse with extra space and on budget \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the racial slur used in the tweet text, which is inappropriate and offensive.\"}",
    "1107992540698066944": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Ok Nigga I see you \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains a racial slur, which is considered hateful. The image itself is a black background, which might be used to create a provocative or offensive context for the tweet.\"}",
    "1058575743519621123": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Why, thanks for giving me FUCKING NOTHING WITH THESE QUARTZ AND TICKET F/GO YOU STUPID CUNT \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which suggests that the image is a hateful meme.\"}",
    "1063446834474029057": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:POTUS Another day in the White House. Miles of wall built at the border? ZERO #BuildTheWall \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a wall, which is often associated with the construction of a border wall. The tweet text suggests that the wall has not been built, which implies that the image is related to a political issue. The use of the hashtag #BuildTheWall and the reference to the President of the United States (POTUS) suggest that the image is intended to be critical of",
    "1058719303141392384": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> \u201ciMmA mIdDiE sChOolEr AnD nIgGa WaTcH wHo YoU tAlKiNg WiTh Yo BiTcH aSs Tf\u201d \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains racial slurs and derogatory language, which is offensive and discriminatory.\"}",
    "1062805554962280451": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Today in 1995, the Orange Crate Art album by Brian Wilson &amp; Van Dyke Parks was released on<tag> \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is a black and white photo of a sky, which does not contain any hateful or offensive content. The tweet text does not provide any context that would suggest the image is a hateful meme.\"}",
    "1115251320993263617": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This nigga here \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains racial slurs and is offensive to many people.\"}",
    "1105170384876437504": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Just another reason for #buildthewall #MAGA #draintheswamp \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a wall, which is often associated with negative political sentiments. The tweet text suggests a political agenda that aligns with the hateful classification.\"}",
    "1108165081932726273": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Where the bag at Nigga where the bag at \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which make the image appear hateful.\"}",
    "1114957229025832960": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Man some people just are super fucking retarded. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, suggesting a hateful sentiment towards some people.\"}",
    "1024513795983433728": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This is why Justin is now jobless and a hillbilly \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, suggesting that it contains offensive or discriminatory content.\"}",
    "1058471320420278273": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This nigga really told me \u201cgo vote before yo dumbass catch a felony\u201d \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the racial slur used in the tweet text, which is offensive and discriminatory.\"}",
    "1063588984796913664": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Would you like a pic of my dug in her PJs? Course you would, say hello to Bruce Mouse, he's a good cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text also contains offensive language, which further supports the classification of the image as hateful.\"}",
    "1035616077886185472": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Jude is obsessed. Listen to Tracy you stupid Twat  #corrie \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language towards a person named Jude, suggesting a negative attitude or obsession. This could be considered as a hateful meme.\"}",
    "1105636846762119170": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:yes i\u2019m getting emotional about my friends trying to call me a demon cunt in my target language \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, suggesting that it may contain offensive or discriminatory content.\"}",
    "1105879608258424832": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Haaaaaaannn \ud83d\udcaa\ud83c\udffd\ud83d\udcaa\ud83c\udffd \ud83d\ude02\ud83d\ude02 real nigga alert lmao \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text also supports this classification as it uses derogatory language to describe the image.\"}",
    "1107670336148041731": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Oprah is a house nigga, she will give some of her scraps to the niggas outside to save face but that's about it. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language and racist remarks towards Oprah Winfrey and African Americans, which is considered hateful.\"}",
    "1054251820971945984": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Hello ma name is Emily no I\u2019m not a dyke yes I\u2019m strictly dickly now get out me way\ud83d\ude24\ud83d\ude1a \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and derogatory terms, which suggest that the image is a hateful meme.\"}",
    "1024622590961348608": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Now Playing Hillbilly Fever by Little Jimmy Dickens On \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is a black background with no visible content, and the tweet text does not contain any hateful or offensive language.\"}",
    "1109178391561994242": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> This is the absolute cunt filming. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, suggesting that the image might be a hateful meme.\"}",
    "1053883489907552256": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This nigga is a opp... Cleveland take him back \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains racist language and imagery, which is offensive and discriminatory.\"}",
    "1056905895811207168": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:definitely comic. HAHAHAHAHAHA \"and then there's this cunt.\"  LOLOLOLOLOLOL #mirth #giggle #grin #cute \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and humor, suggesting that the image might be a hateful meme.\"}",
    "1046452391787352066": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Beauty bay being an absolute twat. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, suggesting that it contains offensive or discriminatory content.\"}",
    "1105165906840301569": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:AJ asking the cunt in jeera If he can put tunes oan ahahaha \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which is not related to the hateful tweet text. The tweet contains offensive language and is not appropriate for sharing. The image itself is not hateful.\"}",
    "1050794968657395712": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Dominican furious is retarded \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which suggests that the image could be a hateful meme.\"}",
    "1114739551313043456": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This nigga spectacular is a whole fucking ham \ud83d\ude2d\ud83d\ude2d\ud83d\ude2d\ud83d\ude2d \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language and racist slurs, which are considered hateful. The image itself is a black background, which might be used to display such offensive content.\"}",
    "1107688634550022144": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:white click after copying and pasting that meme with spic and wetback in it and then apologizing \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a white person with the words 'wetback' and 'spic' written on it. This is considered a hateful meme as it uses derogatory language to describe people of Mexican descent. The tweet text suggests that the person is apologizing for sharing such a meme, which further indicates that the image is intended to be harmful and offensive.\"}",
    "1037046216801103872": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:If Trump thinks Sessions is a dumb southerner who\u2019s mentally retarded, wonder what he thinks about these people. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the tweet text, which contains derogatory language towards a specific group of people.\"}",
    "1023990534296293376": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Faggot \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which is not related to the hateful tweet text. The tweet text contains derogatory language, which is considered hateful. The image itself is not hateful.\"}",
    "1042080812831846400": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:#cockadoodledoodle: \u201cHey y\u2019all! Watch this!\u201d   Meet Hillbilly Wolverine!   #ink #illustration #heyyallwatchthis \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is a simple illustration of a character, not promoting hate or discrimination.\"}",
    "1105819410487480320": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:\ud83e\udd25\ud83e\udd25\ud83e\udd25\ud83e\udd25\ud83e\udd25 nigga leave him alone  \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person, and the tweet text contains a racial slur. This suggests that the image is hateful and promotes negative stereotypes.\"}",
    "1106972687564447744": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Lmao fuck is you talking bout nigga smd \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racial slurs and is offensive. The image, being a black background, might be used to further amplify the offensive nature of the tweet.\"}",
    "1115851907866734592": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:YEA IM HORNY NIGGA KEEP SCROLLIN \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black background with no content, and the tweet text is offensive and racist. This combination suggests that the image is intended to be hateful.\"}",
    "1105567429286154242": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:The biggest brassneck in Irish League football.  Light fingered horse faced cunt. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, likely due to the offensive language used in the tweet text. The tweet text contains derogatory terms that are not appropriate, which contributes to the classification of the image as hateful.\"}",
    "1114729938777706496": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:........NIGGA ARE YOU SERIOUFJRKDFJFM \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person's head, and the tweet text contains a racial slur. This suggests that the image is intended to be hateful and offensive.\"}",
    "1053800021009801219": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:If you use this, youre probably a cunt, and you clear lack a chromosome thinking it looks good #Destiny2 #PS4share \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, suggesting that the image is intended to be hateful.\"}",
    "1058347100205969409": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Shit, piss, fuck, cunt, cock sucker, motherfucker, and tits \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a woman's face with the words 'Shit, piss, fuck, cunt, cock sucker, motherfucker, and tits' written on it. This is considered a hateful meme as it uses offensive language to degrade and insult women.\"}",
    "1108780854472568832": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I will not support the scottish football team until this dirty cheating thieving cunt is out!!! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet contains offensive language and a strong negative sentiment towards the Scottish football team, suggesting a hateful sentiment towards the team or its supporters.\"}",
    "1105552205875159040": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Thank you very much, not cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The presence of the word 'cunt' in the tweet text further supports this classification.\"}",
    "1053714240891084800": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> You're retarded. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, suggesting that the image is intended to be hateful.\"}",
    "1105335420034924546": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I prefer be single rather than being a nigga\u2019s second option. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and promotes negative stereotypes.\"}",
    "1113378207619788800": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Yoh, this is MISSY vs<tag>....  Nigga listen. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text further supports this classification as it uses derogatory language towards a specific group of people.\"}",
    "1107801359103991814": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This nigga literally told me research what you know \ud83d\ude02\ud83d\ude2d. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, likely due to the racial slur used in the tweet text. This suggests that the image may be offensive or discriminatory towards a particular group of people.\"}",
    "1110340422252093441": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> This nigga Rite here is the nxt big thing Pls Retweet Biko\ud83d\ude4f\ud83d\ude4f\ud83d\ude4f\ud83d\ude4f I know you owe me noffin \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text also supports this classification as it uses derogatory language and promotes a negative stereotype.\"}",
    "1115812167708827651": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:When all else fails, drop the race card. That always works. #libtardlife \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests that the image is a hateful meme, as it implies that using the race card is a solution to all problems and implies that those who disagree are 'libtard'.\"}",
    "1055870343846469632": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:A blue wave covering a white piece of trash \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The presence of a blue wave covering a white piece of trash might be interpreted as a derogatory or racist commentary on a particular group or individual.\"}",
    "1061632293364817921": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:If I Was A Real Boy I Had All U Hoes PeriodTt...UR NIGGA CANT NEVER LOOK LIKE THIS .. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which make it a hateful meme.\"}",
    "1056941925566238722": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Yeah a double twat \ud83d\udc47\ud83d\ude02 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The presence of the word 'twat' in the tweet text further supports this classification.\"}",
    "1113638449943203841": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> The security of the USA is more important than freaking avocados.  IDIOTS.  #BuildTheWall \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains hateful language towards people who are advocating for avocados, suggesting that they are idiots. This is not a respectful or constructive way to engage in a discussion, and thus the image can be considered a hateful meme.\"}",
    "1109225441263566849": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> thick nigga laundry basket \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a laundry basket, which is being used as a symbol of racism. The tweet text associated with the image is also offensive and promotes negative stereotypes. This combination of elements suggests that the image is a hateful meme.\"}",
    "1058559438599143424": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:he can call me a faggot any day \ud83d\ude08 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language, suggesting that the image might be a hateful meme.\"}",
    "1115816254877491200": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:My nigga was scared of Jeanie \"The Thickie\" Buss!? Whew \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial stereotypes, which are indicative of a hateful meme.\"}",
    "1053303437708922881": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag>. Another classic ya cunt. Laughed like fuck. Greetin' like a Xmas caird. Nae spoilers#yacunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, and the tweet text supports this classification by using offensive language and making fun of someone.\"}",
    "1114673642103820293": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> ask for black olives and get roaches nigga \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains racist language and imagery, which is offensive and discriminatory.\"}",
    "1035452651364921344": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:this faggot \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content towards a particular group or individual.\"}",
    "1051715216562708480": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:$BTC Lied about ending the thread  Guess we are going full retard here \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains content that is intended to be offensive or harmful. The tweet text also implies that the image is related to a negative or controversial topic, further supporting the classification of the image as hateful.\"}",
    "1115837919347007490": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:My nigga kangaroo came with another hot source \"Emaveni\" \ud83d\udd25\ud83d\udd25\ud83d\udd25\ud83d\udd25  #MrKangaroo \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, likely due to the use of offensive language and racial stereotypes in the tweet text.\"}",
    "1045086164879900673": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Such a dirty slut  #whore #bitch  #slut #wanker #faggot \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory words towards women, which indicates a hateful sentiment. The image itself is not hateful, but the tweet text associated with it is.\"}",
    "1109894644664598531": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Made that nigga fall in-love with a real bitch \ud83e\udd2a\ud83e\udd70 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and racial stereotypes. The tweet text further supports this classification as it uses derogatory language and racist stereotypes.\"}",
    "1061647460328648704": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> ill hit you with my faggot bat if i dont see that effect name in my dms within 5 minutes. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and a threat, which indicates that the image is hateful.\"}",
    "1114120083150913536": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Happy b-day to my best friend, enjoy your day and LET\u2019S GET LIT NIGGA\ud83e\udd19\ud83c\udffc\ud83e\udd19\ud83c\udffc\ud83e\udd19\ud83c\udffc\u2764\ufe0f\u2764\ufe0f love you bro! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which make it a hateful meme.\"}",
    "1053705772624986114": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag> Read it and weep disgusting liberal socialist retard \ud83d\ude02 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, likely due to the political nature of the content and the use of derogatory language in the tweet text.\"}",
    "1057330833118375938": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Yo observation is retarded \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests that the image is hateful, as it contains an observation that is considered retarded.\"}",
    "1057426123901075456": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Maga redneck holloween costumes.... \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it may contain offensive or discriminatory content. The tweet text also supports this classification as it refers to 'Maga redneck holloween costumes...' which might be perceived as derogatory or insensitive to some people.\"}",
    "1062822333725978624": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:being a cheap twat \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text also implies that the image is meant to be derogatory towards someone, further supporting the classification of the image as hateful.\"}",
    "1055163779091181569": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> another cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The presence of the word 'cunt' in the tweet text further supports this classification.\"}",
    "1024609566170873857": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I thought I was going retarded \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, suggesting that the image might be a hateful meme.\"}",
    "1044234666008428544": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Salesforce Dreamforce Spaceforce Doucheforce #NotAllMen #ButBasicallyAllMen \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and a negative sentiment towards men. The image, being a black background, does not provide any context or information to support the hateful sentiment. Therefore, the classification is 'hateful'.\"}",
    "1043496571629920258": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Full Movie: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which can be perceived as a hateful meme due to its negative connotations. The tweet text does not provide any context or information that would change this classification.\"}",
    "1106485208600231936": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:been hot since zingah was smashis, but zingah my nigga since 2015\ud83d\ude2d\ud83d\udd25 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the use of racial slurs and derogatory language in the tweet text.\"}",
    "1035324085398593537": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Major protest.......  #TrumpRally #BuildTheWall #KAG  #MAGA  #Evansville #indiana #indianarally #Evansvillerally \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a crowd of people, which can be interpreted as a hateful meme due to the association with political events and the controversial political views of the people involved. The tweet text also supports this classification as it refers to a Trump rally, which is often associated with hateful rhetoric and actions.\"}",
    "1057654796931489792": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Such a nasty faggot !!!#Poppers #slut #nastywhore \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content towards a specific group of people.\"}",
    "1054009447251656705": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:POTUS Another day in the White House. Miles of wall built at the border? ZERO #BuildTheWall \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a wall, which is often associated with the construction of a border wall. The tweet text suggests that the wall has not been built, which implies that the image is related to a political issue. The use of the hashtag #BuildTheWall and the reference to the President of the United States (POTUS) suggest that the image is intended to be critical of",
    "1105874966812246016": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> yaaas annoying pathetic dyke solidarity \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content towards a particular group or individual.\"}",
    "1045121869953687552": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:YBN Cordae Deals With A \"Redneck A*s Cop\" In The \"Target\" Music Video \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a cop, which can be interpreted as a hateful meme due to the negative connotation associated with the police force, particularly in the context of the tweet text.\"}",
    "1057220467533250560": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:\u201cSHEMP\u201d ...WE THE PPL KNOW YOU ARE A LIAR!  #StopTheInvasion       #BuildTheWall.                         \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a shrimp, which is being used as a symbol for a political agenda. The tweet text associated with the image is hateful and promotes a divisive political message. This suggests that the image is being used to spread hate and division rather than promoting a positive message.\"}",
    "1043595126889574401": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Well, that's retarded. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and suggests a negative attitude towards the image, indicating that it is a hateful meme.\"}",
    "1036259684662030336": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:H. Rap Brown's Blacks And Authority ::: Highlighting Chapter Four Of 'Die Nigger Die!' \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person with the words 'Die Nigger Die!' written on it. This is considered a hateful meme as it promotes racism and discrimination.\"}",
    "1057818727541100544": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> nigger \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark background, which can be perceived as a hateful meme due to the use of the word 'nigger' in the tweet text. This word is considered offensive and racist, and its presence in the tweet text suggests that the image might be associated with negative emotions or intentions.\"}",
    "1109993849227747328": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Yo this nigga literally react to me I\u2019m fucking sleep\ud83d\ude31\ud83d\ude31<tag><tag><tag><tag><tag> \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it may contain offensive or discriminatory content. The tweet text also supports this classification as it uses derogatory language and references to race.\"}",
    "1049739320817537026": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Her: You must be retarded if you think you have a good personality  Me: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a woman's face with the words 'You must be retarded if you think you have a good personality' written above it. This is considered a hateful meme as it is disrespectful and insulting towards the woman's appearance and personality.\"}",
    "1108828399676592129": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Nigga how you forget the nigga that created Superman \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains a racial slur and is disrespectful towards a specific group of people.\"}",
    "1056933891762728961": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Retard of the year award goes to this guy \ud83d\ude02\ud83d\ude02 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text is derogatory and disrespectful towards people with disabilities. The image itself is a black background, which might be used to create a negative or intimidating atmosphere. This combination of elements suggests that the image is a hateful meme.\"}",
    "1108290558722596864": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> This Nigga Really Fuck a Cat \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and imagery, such as the word 'nigger' and the reference to a cat being fucked. This type of content is not appropriate and should not be shared.\"}",
    "1106957605174476801": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Nigga i got WASHED \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racial slurs and is considered hateful. The image, being a black background, might be used to further amplify the hateful message.\"}",
    "1048229161137885184": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I need this! My two favs #lego #POTUS #BuildTheWall #Trump2020 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a wall, which is associated with a hateful meme. The tweet text suggests that the image is related to political views and is meant to be shared with a positive sentiment. However, the image itself does not contain any explicit or hateful content.\"}",
    "1057769519769358336": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> The border jumper costume fits in with the #StopTheCaravan theme. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it promotes a negative and discriminatory sentiment towards a specific group of people, in this case, border jumpers.\"}",
    "1062885498665009152": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:How to make a retarded school project  Step 1 make a retarded school project \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text further supports this classification as it contains derogatory language towards people with disabilities.\"}",
    "1054188917765758976": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> They are an angry mob.   \ud83c\udfdb\ud83c\udfdb\ud83c\udfdb #BuildTheWall \ud83c\udfdb\ud83c\udfdb\ud83c\udfdb <tag>   Must be stopped. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, suggesting that it may contain offensive or discriminatory content. The tweet text also supports this classification, as it refers to a group as an 'angry mob' and calls for stopping them, which could be perceived as hateful or discriminatory language.\"}",
    "1064256263419125760": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Not white, but nice try on playing the race card \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which is not related to race or any other controversial topic. The tweet text, however, contains a racial comment, suggesting that the image might be used to promote such views. This classification is based on the context provided by the tweet text, not the content of the image itself.\"}",
    "1106779147689512961": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Big ole trade dick hangin big soft n pretty yo.Hav him walk around so his dick can swing and clap nshit #faggot #pnp \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and derogatory terms towards the LGBTQ+ community.\"}",
    "1062496498800304128": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Jennifer Perez. Click for more: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a woman's face, which can be perceived as a hateful meme due to its dark and intimidating nature. The lack of context and the focus on the woman's face can evoke negative emotions and contribute to the perception of the image as hateful.\"}",
    "1061030682376331264": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:nan\nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which can be perceived as a hateful meme due to its association with negative emotions or events. The tweet text does not provide enough context to determine if it is a hateful meme or not.\"}",
    "1054203996108292096": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:CITCHES POST THIS AFTER EVERY NIGGA THEY DONE LET FUCC LOL \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racist language and is considered hateful. The image, being a black background, might be used to further amplify the hateful message.\"}",
    "1042135950485344259": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Oh Wow: A Nine Minute Lemonade-Pouring Rube Goldberg Machine \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is a black background with no visible content, and the tweet text does not contain any hateful or offensive language.\"}",
    "1054004649928253443": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Ex-FA chairman Greg Dyke blasts 'old men' over Wembley sale collapse \nASSISTANT: {\"Classification\": \"hateful or not hateful\", \"Explaination\": \"The image is not hateful as it is a simple black background with no explicit content or message that can be considered offensive.\"}",
    "1056558319836397568": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Beep boop Nazis beep boop GamerGate beep boop ComicsGate beep boop \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains content that promotes or supports harmful or discriminatory ideologies or actions. The presence of the word 'Nazis' in the tweet text implies a connection to extremist or hateful groups. The image itself is a black background with white text, which may not be directly related to the hateful content, but the context of",
    "1105678412251873282": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Damn they got my nigga logic \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, suggesting that the image might be a hateful meme.\"}",
    "1050678288287318021": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> the only OG in Africa  #best my nigger \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person, and the tweet text contains racial slurs and derogatory language. This suggests that the image is intended to be hateful and offensive.\"}",
    "1044161987121311744": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> yall look retarded tryna cover it up. ;) \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests that the image is intentionally meant to be hateful, as it is described as a 'hateful meme' and the person is making fun of the image's content.\"}",
    "1052639649280057344": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> you a cunt. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, suggesting that the image is a hateful meme.\"}",
    "1057741034510262272": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Uh oh. This one\u2019s retarded. Going to have to put it down. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, suggesting that it may contain offensive or discriminatory content.\"}",
    "1058755785377882124": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:\u201cWhat do y\u2019all say, \u2018hold your mothers cunt\u2019 did I say it right?\u201d  Excuse me bitch? Hold whose what? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is disrespectful towards women. This classification suggests that the image is not appropriate and should not be shared.\"}",
    "1055113560060248066": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This lil nigga just bit his kit kat! Didn\u2019t break it, just bit it!! This nigga is a psycho! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a negative stereotype of a person of color, specifically a black person, in a disrespectful and offensive manner.\"}",
    "1062226457651367938": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Ketchup eating Indian retard \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive and derogatory language towards a specific group of people, which is not acceptable.\"}",
    "1058495608883896325": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> To talk shit \u201c YOU WANNA TALK SOME SHIT? DIAL NOW NIGGA!\u201d \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text further supports this classification as it contains derogatory language towards African Americans.\"}",
    "1058805268505493505": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Paragliding Safely: Is Devil's Dyke a dangerous flying site? \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is a black and white photo of a sky, which does not contain any explicit or offensive content. The tweet text is unrelated to the image and does not contain any hateful or offensive language.\"}",
    "1059512557994676224": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:nigger time \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person, and the tweet text contains a racial slur. This suggests that the image is intended to be hateful and offensive.\"}",
    "1050976721300873216": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Hey<tag> you are such a twat waffle - and you DESERVE the douche canoe Kanye .... \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet contains offensive language and insults, which suggest a hateful sentiment towards the person being referred to.\"}",
    "1108958778030845953": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:nan\nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which can be perceived as a hateful meme due to its association with negative emotions or events. The tweet text does not provide enough context to determine if it is a hateful meme or not.\"}",
    "1050540118258458627": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Ass clown just like you and your retarded daddy. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or derogatory content towards a specific group or individual.\"}",
    "1051331305315737605": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Only way to beat conspiracy theorist #MemeDay #Memes #logic #hilarious \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, suggesting that it may contain offensive or discriminatory content.\"}",
    "1117556856879185926": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:These Twat waffles need their asses kicked by us the American people.... \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and a call for violence against a specific group of people, which indicates a hateful sentiment.\"}",
    "1058107647688347649": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Excuse me????? \"It's only BA\" GET OFF YOUR HIGH HORSE CUNT. I'm not the one redoing exams \ud83d\udc81 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and a disrespectful tone, which suggests that the image might be a hateful meme.\"}",
    "1058741665907773440": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> That\u2019s krazy I had a dream that nigga signed me to Maybach music ! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racial slurs and is considered hateful. The image, being a black background, might be used to promote such hateful content.\"}",
    "1036242514125017090": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:E no pass to call am nigger. Y\u2019all stay pressed \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains a racial slur and promotes negative stereotypes.\"}",
    "1061249669987213312": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Via: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which can be perceived as a hateful meme due to its association with negative emotions or events. The tweet text also suggests that the image is a meme, which further supports the classification of the image as hateful.\"}",
    "1062704096183046144": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:It's what the cunt deserved #PS4share \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and a negative sentiment towards a specific individual. This suggests that the image might be associated with a hateful meme.\"}",
    "1053334096666091520": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Karen made a nigga pretty again. \ud83d\udda4 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains racial slurs and is disrespectful towards a specific group of people.\"}",
    "1061094301814415360": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:NASTY ASS NIGGA ONLY WHEN THEY NEED TO GET WET THAT'S RITE I SAID IT IF THE SHOE FITS WEAR IT BYE FELICIA\ud83d\ude24 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, likely due to the racist and offensive language used in the tweet text.\"}",
    "1063388752272400385": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:LOOK AT THE CUNT \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, which suggests that the image might be a hateful meme.\"}",
    "1061488563697594369": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:White trash slut \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and imagery, such as the phrase 'white trash slut' which is derogatory and discriminatory towards women.\"}",
    "1114804292072935424": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:#AtelierLydieAndSuelle wanted Ilmeria, not this retard \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, suggesting that it may contain offensive or discriminatory content.\"}",
    "1042048091413794816": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> SHE IS A.  WHITE TRASH \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, likely due to the content of the tweet text, which contains offensive language towards a specific group of people.\"}",
    "1109954370240548864": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:The white to my trash #whitetrashbash \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains a derogatory term 'white trash' which is considered hateful. The image, being a black background, might be used to further emphasize the negative connotation of the term.\"}",
    "1058514913092624384": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:we stan one dyke \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a woman's face, which is considered hateful as it may be used to promote negative stereotypes or discrimination against women.\"}",
    "1058373429454426118": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:IRON HORSE BEVERAGE LLC was approved for PARALLEL 49 HILLBILLY NINJA, an ale. More: \nASSISTANT: {\"Classification\": \"hateful or not hateful\", \"Explaination\": \"The image is not hateful as it is a simple black background with no visible content that could be considered offensive or discriminatory.\"}",
    "1063729269623410688": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Watch it: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which can be perceived as a hateful meme due to its association with negative emotions or events. The tweet text does not provide any context or information that would change this classification.\"}",
    "1062770725830963201": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:If I see one more hefty, balding, messy bearded, white murrican redneck talking about how gender cant be neutral \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, likely due to the negative stereotypes and prejudices associated with the depicted individuals.\"}",
    "1061690268796235777": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> You are welcome! You like meme? I got you. #BuildTheWall! #OpioidCrisis \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a wall, which is being used as a meme to promote a hateful agenda. The tweet text further supports this classification as it contains hateful hashtags such as #BuildTheWall and #OpioidCrisis.\"}",
    "1046844677545250818": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Yup his book tells him to\ud83d\udca5 #BanSharia \ud83c\udf3b\ud83c\udf3e\ud83c\udf41\ud83c\udf42 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a book, which is being used as a symbol for promoting hate. The tweet text suggests that the book is promoting a message that is hateful, and the image is being used to convey that message. This indicates that the image is hateful in nature.\"}",
    "1050846392451833857": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:got called a man hating dyke today! we love my brand! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, suggesting that it may contain offensive or discriminatory content. The tweet text also supports this classification, as it implies that the image is being used to express negative feelings towards a particular group of people.\"}",
    "1035903352226373632": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Twat \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content.\"}",
    "1062332390692020225": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Was that even English? No wonder why you like that retard because \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, suggesting that the image is a hateful meme.\"}",
    "1062081252386398208": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:\u201cWhen Shady &amp; Nicki\u2019s world clash, it\u2019s high class meets white trash.\u201d \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language and negative stereotypes, which are typically associated with hateful memes.\"}",
    "1035265971265646593": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Is ya mouth watering yet?? Come try Howard's \"Hillbilly\" Philly! \ud83d\ude0d \nASSISTANT: {\"Classification\": \"hateful or not hateful\", \"Explaination\": \"The image is not hateful as it is a simple black background with no explicit content or offensive message.\"}",
    "1043997669373276161": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Now #PG7 is playing a victim Card.   Hahahaha tey should be accountable. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, suggesting that it may contain offensive or discriminatory content. The tweet text also implies that the image is being used to mock or criticize a specific individual or group, which could contribute to a negative or hostile atmosphere.\"}",
    "1042520387161149440": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> I can\u2019t believe you didn\u2019t laugh at tge Nigger joke that\u2019s a fuvkin classic b \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racial slurs and is considered hateful. The image, being a black background, might be used to display such offensive content.\"}",
    "1050192665126588421": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag> You sound like a butthurt fucking retard...... \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, suggesting a hateful sentiment towards the person being addressed.\"}",
    "1062734507080667136": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Ok I'll stop would you prefer SJW NPC? REEEEEEEEE!!!!!! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests a negative attitude towards social justice warriors and non-player characters, which indicates a hateful sentiment. The image itself is a black background, which could be interpreted as a representation of the darkness associated with these negative attitudes.\"}",
    "1057717971441700864": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> No I want to win more! More #Winning #BuildTheWall #VoteGOP \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a wall, which is often associated with racism and discrimination. The tweet text also contains political messages that may be perceived as hateful or divisive. These factors contribute to the classification of the image as hateful.\"}",
    "1053826823149080577": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Still Invincible takes out the first race on the card for<tag> and<tag>! \nASSISTANT: {\"Classification\": \"hateful or not hateful\", \"Explaination\": \"The image is not hateful as it is a simple black background with no explicit content or offensive message.\"}",
    "1061772616091009024": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:#howharddidpubertyhit my mom wrong for letting me dress like a dyke \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a woman's torso, which is described as a 'dyke' in the tweet text. This language is considered offensive and hateful towards the LGBTQ+ community. The tweet text also implies that the woman's mother failed to properly raise her, which adds to the negative and hateful sentiment of the image.\"}",
    "1057328958981718018": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Hopefully #Trump gets his way! #Trump2020<tag><tag><tag> #BuildTheWall \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a wall, which is often associated with Trump's policies. The tweet text suggests a political stance in favor of Trump and his policies. This combination of elements can be perceived as hateful by some people, as it may be seen as promoting a divisive and controversial political agenda.\"}",
    "1043032894250184705": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:R32k for a phone. \ud83d\ude2a. Is iStore retarded ? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains negative language towards iStore, suggesting a lack of understanding or frustration with their products. This could be perceived as hateful by some.\"}",
    "1043911325934637058": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Ive been called a local.... white... \u201csjw\u201d.... army....a bitch..... i cant take it anymore \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and derogatory terms, suggesting a hateful sentiment towards a specific group of people.\"}",
    "1057392604554321920": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag><tag> Suck my balls, you fucking hillbilly. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which suggest that the image is intended to be hateful.\"}",
    "1064088754770432000": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Featured Anytime Movie: Dick Van Dyke Show - Dick Van Dyke Show: Seaso... Pre-Owned: $20.66 \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is a black and white photo of a night sky, which is not a hateful meme. The tweet text does not contain any hateful content.\"}",
    "1037168686740586496": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> But i need my sjw rage fix noooooooooooowwwwwwww \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests that the image is a hateful meme, as it is described as a 'sjw rage fix' and the user is seeking it urgently. This implies that the image might be intended to provoke negative emotions or promote discord among social justice warriors.\"}",
    "1035549273893609474": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Van Dyke Case: \u2018The More You Dig Into This, The Less Open-And-Shut It Is\u2019 \nASSISTANT: {\"Classification\": \"hateful or not hateful\", \"Explaination\": \"The image is not hateful as it is a simple black background with no explicit content or message that can be considered offensive.\"}",
    "1041683556790091776": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:And by that I mean, Dick Van Dyke cameo! \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is a black and white photo of a night sky, and the tweet text does not contain any hateful or offensive content.\"}",
    "1061062117548154880": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Packing grease cunt, also backy beugs \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a woman's backside, which is considered inappropriate and offensive. The tweet text further adds to the negative sentiment, making it a hateful meme.\"}",
    "1108809301353811968": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Bro wtf tell me this ain\u2019t real.  Nigga always answers me man \ud83d\ude22 no no \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, and the tweet text supports this classification as it contains racial slurs and derogatory language.\"}",
    "1046304713090584576": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Dude with the bird called me a nigger \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains a racial slur, which is offensive and discriminatory.\"}",
    "1105616234694012929": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:i never tweet dms but the nigga called me broke \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which are indicative of a hateful sentiment.\"}",
    "1036335281790640128": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Retard, its called free speech you communist. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, suggesting that the image is a hateful meme.\"}",
    "1062617653217419264": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:\ud83d\ude02Redneck Talk #DexterMemes \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it may contain offensive or discriminatory content. The tweet text also implies that the image is related to a meme about a character named Dexter, which could be a reference to a controversial or problematic character in popular culture.\"}",
    "1061299746466357249": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:my phone layout makes me the happiest cunt  about\ud83d\ude2d \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, which suggests that the image might be a hateful meme.\"}",
    "1024754399988670464": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Tokyo Toni comes for Blac Chyna\u2019s boytoy, calls him little\u00a0retard \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and insults towards someone, which is not appropriate or respectful.\"}",
    "1041692365365362688": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:By: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which can be perceived as a hateful meme due to its association with negative emotions or events. The tweet text also suggests that the image is meant to be hateful.\"}",
    "1041772232836505600": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I think TJ Miller is trying to do his own undercover \"Who Is America\" show with white trash crimes. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, likely due to the content of the tweet text, which suggests a negative or offensive portrayal of a person or group.\"}",
    "1063849310410993665": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Full Movie: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which can be perceived as a hateful meme due to its negative connotations. The tweet text does not provide any context or information that would change this classification.\"}",
    "1046181127248130049": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag> testimony was credible! is the new SJW cry \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person's face, with the words 'testimony was credible!' written above it. This could be interpreted as a hateful meme, as it may be seen as mocking or belittling someone who has given testimony. The use of the word 'SJW' (Social Justice Warrior) in the tweet text further suggests a negative",
    "1050354924884844545": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> promotes immigration from #ShitholeCountries #BuildtheWall \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a wall, which is being used to promote the idea of building a wall to restrict immigration from certain countries. This can be considered as a hateful meme as it promotes discrimination and prejudice against certain individuals or groups.\"}",
    "1057830049964023808": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:IT AINT VINTAGE NIGGA \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person, and the tweet text contains a racial slur. This suggests that the image is hateful and promotes negative stereotypes.\"}",
    "1044288761138499586": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Playing the victim card strong \ud83d\udcaa \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person's head, with the tag 'Playing the victim card strong \ud83d\udcaa' on it. This suggests that the image is intended to be humorous or sarcastic, rather than hateful. However, the use of the 'victim card' tag might be perceived as offensive by some individuals.\"}",
    "1061811833302962176": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I wonder if Burns' hillbilly beard is longer than Karlsson's revolutionary styled mullet? #Flames \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is a black and white photo of a hillside, and the tweet text does not contain any hateful or offensive content.\"}",
    "1054591227465818112": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:That little pussy block me before giving me a chance to respond new reason to not trust the sjw parasites \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it may contain offensive or discriminatory content. The tweet text also implies a negative attitude towards a specific group, which further supports the classification of the image as hateful.\"}",
    "1064389491023114240": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:FREE eBooks Book Reviews Diamond Dyke - \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is a black background with no visible content, so it cannot be classified as hateful. The tweet text does not provide any context or information that would suggest the image is hateful.\"}",
    "1042467365701799937": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:When the retard holds the door for you when you\u2019re 20 feet away from the door. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text provided further supports this classification as it contains derogatory language.\"}",
    "1061961095764738051": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> hes the one that called me a cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, suggesting that it contains offensive or discriminatory content.\"}",
    "1058388442990735361": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:'Cause bitch I'm a Raider Klan killa ULT nigga Smoke all the purp' Extort the dealer \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and references to a gang, suggesting a hateful sentiment.\"}",
    "1034943433364971521": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Officer Jason Van Dyke Interviews With Chicago Tribune Ahead Of Murder Trial \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a police officer, which can be perceived as a hateful meme due to the association of police officers with violence and negative stereotypes.\"}",
    "1058401995541938177": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Exactly!! #VoteRedToSaveAmerica #BuildTheWall \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a wall, which is often associated with political views and opinions. The tweet text suggests a political stance, which could be considered hateful by some. The classification is based on the potential for the image to be perceived as offensive or divisive.\"}",
    "1062539404844122112": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I saw \u201ccunt\u201d and i thought i liked my own tweet yes thanks<tag> \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text also supports this classification as it contains a derogatory word.\"}",
    "1046581333823279104": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:For the record: it /is/ actually good, and not just SJW bait. \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is a black and white photo of a sky, which is not a hateful meme. The tweet text does not provide any evidence of the image being hateful.\"}",
    "1114614517319835648": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:So nobody was gon warn me watching HunterXHunter that nigga was three steps away from being a pedo. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the tweet text, which contains offensive language and makes inappropriate sexual comments.\"}",
    "1115371697518071808": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> 3inches nigga\ud83d\ude02\ud83d\ude02 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which is not related to the hateful tweet text. The tweet contains offensive language and racist remarks, making it a hateful meme.\"}",
    "1050431539522228225": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Sold! This vid is on fire! Faggot Humiliation \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, and the tweet text suggests a negative and derogatory sentiment towards the subject of the image.\"}",
    "1062270106829447168": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> It took me 2 minutes to get the win, keep disputing retard \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains content that is intended to be offensive or harmful. The presence of the tag in the tweet text further supports this classification.\"}",
    "1110379049568731137": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Hey everyone look at this fucking wetback \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racist remarks, which are not appropriate and can be considered as hateful.\"}",
    "1036292496094126081": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> \"Obviously we're going to lose\" Andy Jacobs proves what a twat he is once again. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and negativity, suggesting a hateful sentiment towards the person being referred to.\"}",
    "1044174838515077120": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:And TWAT of the day goes too... \ud83d\ude21 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text further supports this classification as it appears to be expressing anger or frustration towards a specific group of people.\"}",
    "1105108730503458817": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Full Movie: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which can be perceived as a hateful meme due to its negative connotations. The tweet text does not provide any context or information that would change this classification.\"}",
    "1058233444524670976": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:\u2757\ufe0f\u2757\ufe0f\u2757\ufe0f\ud83d\udcaf dnt compare me to your old boyfriend I\u2019m really retarded we\u2019re not equal \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text further supports this classification as it implies that the person being compared is inferior and not equal to the person making the comparison.\"}",
    "1054568287307149313": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:My Older Brother\u2019s Friends: My dick is biggger than yours little faggot Me: Stop calling me gay but \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and derogatory terms towards the LGBTQ+ community.\"}",
    "1060848610600878080": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Name a bigger retard \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which are indicative of a hateful meme.\"}",
    "1056351401113047040": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:SJW's taking over the world? Well, if that was to ever happen there'd be only one response to that... \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme that is hateful towards social justice warriors, suggesting that they are taking over the world and that there would be only one response to that.\"}",
    "1043862582581481474": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:POTUS Another day in the White House. Miles of wall built at the border? ZERO #BuildTheWall \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a wall, which is often associated with the construction of a border wall. The tweet text suggests that the wall has not been built, which implies that the image is related to a political issue. The use of the hashtag #BuildTheWall and the reference to the President of the United States (POTUS) suggest that the image is intended to be critical of",
    "1036028263695572993": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Will you be there? Tonight is our White Trash Bash! Come out and play \ud83d\ude1c\ud83e\udd18\ud83c\udffc \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, and the tweet text suggests a gathering of white trash, which is considered offensive and discriminatory.\"}",
    "1063515845022883841": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:From a conspiracy theorist who has remained undercover to protect himself against (what else?) conspiracies: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, suggesting that it may contain offensive or discriminatory content.\"}",
    "1047201831539986433": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:White officer, Van Dyke, takes stand in murder trial over black teen shot 16 times \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a police officer, which can be perceived as a hateful meme due to the context of the tweet text. The tweet text refers to a white police officer, Van Dyke, taking the stand in a murder trial involving a black teenager who was shot 16 times. This can evoke negative emotions and controversial discussions about race, police",
    "1051744684299735040": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Don't get all emotional on us, and don't go full retard either when having a beer. Happy Bathday! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is disrespectful towards people who may be celebrating a special occasion. This could be perceived as hateful.\"}",
    "1061391701749743619": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Royal twat Princess Andrew \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person, which is often associated with negative emotions or a lack of empathy. The tweet text also uses offensive language, further suggesting that the image is intended to be hateful.\"}",
    "1056087971261308928": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Alfie's Life Lesson No. 15,678. If you're gonna act the twat, expect a slap. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, suggesting that it may contain offensive or discriminatory content.\"}",
    "1057320100171145216": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:The Queers / Love Songs For the Retarded / Debra Jean / 2006 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content towards a specific group of people, such as the LGBTQ+ community. The tweet text further supports this classification as it references a song called 'The Queers / Love Songs For the Retarded / Debra Jean / 2006', which might be perceived as derogatory or",
    "1037027845032341504": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Full Gallery: \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is a black and white photo of a sky, which does not contain any explicit or offensive content. It is not a hateful meme.\"}",
    "1057848769864196096": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:i hate when a nigga be like he horny, okay bitch, and? what in the fuck do you expect me to do? care? cause i don\u2019t. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the racist language used in the tweet text, which is displayed on the image.\"}",
    "1047281776421457925": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:nigger \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark background, which can be perceived as a hateful meme due to the racial slur included in the tweet text. The use of such language is offensive and inappropriate.\"}",
    "1054722314775003138": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag> Fuck you cunt lmao. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, suggesting that the image might be a hateful meme.\"}",
    "1042005112032567296": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:'Mary Poppins Returns' is proof that Dick Van Dyke hasn't aged a day in 50 years \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is a black and white photo of a sky, which does not contain any hateful content. The tweet text is unrelated to the image and does not contain any hateful language.\"}",
    "1024949603429433345": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I was playing the Tracy beaker ds came and why is football such a twat and why is his name football \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and negative comments about a football player, which suggests a hateful sentiment towards the player.\"}",
    "1109944169412390912": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:i\u2019m conflicted, i want to cancel this nigga but i also want to make him write my english essay at the same time\ud83e\udd14 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text also implies a negative attitude towards a specific group of people, which further supports the classification of the image as hateful.\"}",
    "1108721815113752576": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:the stupid cunt leecher just hit levi and he got buff CCC75995 :Battle ID I need backup! Lvl 100 Leviathan Omega \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, likely due to the tweet text containing offensive language and potentially promoting violence.\"}",
    "1055890135487787015": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Some twat lighting fireworks already, not even November. There's always one! \ud83d\udd95\ud83c\udffb \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and a negative sentiment towards someone who is lighting fireworks. This could be considered as a hateful meme.\"}",
    "1115730051692027904": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Aye bruh kodak gotta fade this nigga now \ud83d\ude02\ud83d\ude02\ud83d\ude02 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language and a reference to a black person, which suggests a hateful sentiment. The image itself is a black background, which might be used to further emphasize the negative message.\"}",
    "1054404897569955840": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Boring cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, suggesting that the image might be a hateful meme.\"}",
    "1058428485738393602": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Controversial, contended, career making? Find out for yourself with HILLBILLY ELEGY \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is a black and white photo of a sky, which does not contain any explicit or offensive content. The tweet text does not seem to be related to the image, and it does not contain any hateful or offensive language.\"}",
    "1056183855965786112": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:POTUS Another day in the White House. Miles of wall built at the border? ZERO #BuildTheWall \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a wall, which is often associated with the construction of a border wall. The tweet text suggests that the wall has not been built, which implies that the image is related to a political issue. The use of the hashtag #BuildTheWall and the reference to the President of the United States (POTUS) suggest that the image is intended to be critical of",
    "1115854148359073792": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Ask around I ain\u2019t never told humble street nigga so I won\u2019t neva fold\u203c\ufe0f \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and derogatory terms, suggesting a hateful sentiment. The image itself is a black background, which might be used to create a provocative or aggressive atmosphere.\"}",
    "1115375497716928513": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Who else wants to witness her being crush in a retard cube \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests a violent and aggressive sentiment towards a person, which is indicative of a hateful meme.\"}",
    "1061400938362101762": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Best bumper sticker around. #tcot #border #BuildTheWall \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a border wall, which is often associated with hateful or controversial political views. The tweet text suggests that the image is related to a political topic, further supporting the classification of the image as hateful.\"}",
    "1064018869378064384": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Man only if you were as good at deleting tweets as you are using the race card \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains a racial slur, which is considered hateful. The image itself is a black background, which might be used to create a provocative or controversial context for the tweet.\"}",
    "1046199372516655105": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Poor retarded liberals can't handle a real president. ha ha ha \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language towards liberals, suggesting that they are not capable of handling a real president. This can be considered as a hateful meme.\"}",
    "1054210605891096576": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:#RuinFamousBooks  Save you some time having to read it all. The cunt dies in the end. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and a negative sentiment towards the book, indicating that it is a hateful meme.\"}",
    "1024621602993065986": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> for Speaker! #DoWhatWeSaid #BuildTheWall #MAGA \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a wall, which is often associated with racism and discrimination. The tweet text also includes hashtags related to racist and discriminatory ideologies, further suggesting that the image is intended to promote hateful rhetoric.\"}",
    "1056764285735616512": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:me condemning use of the word \"faggot\" but also bumping old eminem songs where he drops it 15 times a song \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person's head, with the word 'faggot' written on it. This is considered a hateful meme as it uses derogatory language to target the LGBTQ+ community.\"}",
    "1047121366040891392": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> GamerGate colluding to get Kavanaugh into the senate, they became the very thing they fought against. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which is not related to the tweet text. The tweet text contains a political statement about the GamerGate movement and their involvement in the Kavanaugh senate nomination. The classification is hateful as it implies a negative sentiment towards a specific group or movement.\"}",
    "1057910975544877056": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:my brain after i drink coffee at night, then try to sleep and am all of a sudden a conspiracy theorist: \nASSISTANT: {\"Classification\": \"hateful or not hateful\", \"Explaination\": \"The image is not hateful as it is a simple black background with no explicit content or message that can be considered offensive.\"}",
    "1109098644660240388": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:my ex is a cunt he should\u2019ve stayed home again today \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet contains offensive language towards a person, which is considered hateful.\"}",
    "1053833159308128256": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:actually BTS would not be proud of rabid sjw parasites because BTS is awesome \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, suggesting that it may contain offensive or discriminatory content. The tweet text further supports this classification as it implies that BTS would not be proud of fans who are described as 'rabid sjw parasites.' This language can be perceived as derogatory and disrespectful towards fans who identify as social justice warriors.\"}",
    "1042088950666539008": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:The fact that Dick Van Dyke hasn't aged in 54 years \ud83d\ude4c We hope that beard is real #MaryPoppinsReturns \nASSISTANT: {\"Classification\": \"hateful or not hateful\", \"Explaination\": \"The image is not hateful as it is a simple black background with no offensive content. The tweet text is related to a movie release and does not contain any hateful or offensive language.\"}",
    "1059445529778814978": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:WATCH: The Spice Girls announce reunion\u00a0tour \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is a black background with no visible content, so it cannot be classified as hateful. The tweet text is unrelated to the image and does not contain any hateful content.\"}",
    "1050573308801019904": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Im that hoe fav retard \ud83d\ude18 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which suggests that the image is a hateful meme.\"}",
    "1057307819253383174": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Hahaha Unlucky Jamie you fat dribbling cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which suggests that the image is a hateful meme.\"}",
    "1057054927011397632": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:\"Spotlight, uh, moonlight, uh Nigga, why you trippin'? Get your mood right, uh...\" \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racial slurs and derogatory language, which indicates a hateful sentiment. The image itself is a black background, which may not be directly related to the content of the tweet.\"}",
    "1058831652472926208": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Nigga wat? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person's head, and the tweet text contains a racial slur. This suggests that the image is intended to be hateful and offensive.\"}",
    "1051302160099622913": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Images you can hear  \u201cFUCK YOU NIGGER!!! DONT EVER CROSS ME!!! LETSSSSSS GOOOOOOO!!!!!\u201d \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person's head, and the tweet text contains a racial slur, indicating that the image is hateful.\"}",
    "1037217646893322246": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> I might have been born just plain white trash, but Fancy was my name... \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which suggest that the image is a hateful meme.\"}",
    "1054459997231439877": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> \ud83d\udde3AYO THIS NIGGA\u2019S IN LOVE! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racist remarks, which indicates that the image is a hateful meme.\"}",
    "1057392320537092098": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag><tag> You absolute twat, \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content.\"}",
    "1051751453214351360": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> The twat doesn't even have regular wisdom.... try that instead ye fuckin muppets \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, suggesting a hateful sentiment towards the person being referred to.\"}",
    "1064032130840313857": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:exhibit A; calling me a fucking whore cunt just because i asked for a notice \ud83d\ude2d\ud83d\udc4e\ud83c\udffb \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the tweet text, which contains offensive language towards women.\"}",
    "1050700644624027648": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:\ud83d\ude20  Are you ready?  \ud83d\ude20  \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, suggesting that it may contain offensive or discriminatory content.\"}",
    "1042769340188094465": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Congrats on your huge role Chief - keep winning and #BuildTheWall \ud83c\uddfa\ud83c\uddf8\ud83d\ude4f\ud83c\udffc \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a wall, which is associated with a hateful meme. The tweet text also supports this classification as it contains a reference to building a wall and a positive message for the Chief, which can be perceived as hateful or divisive.\"}",
    "1105856066640842754": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Nigga got stabbed one too many times \ud83d\ude2d\ud83d\ude2d \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a stab wound, which is a violent and disturbing scene. The tweet text further emphasizes the negative and aggressive nature of the image. This combination of elements suggests that the image is intended to be hateful or offensive.\"}",
    "1046419484041510913": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> free to any daft twat that shops in this dump \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, suggesting that the image is a hateful meme.\"}",
    "1037105350711885825": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I see what you did there \ud83d\ude02 what a twat \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, suggesting that the image is a hateful meme.\"}",
    "1036144767913082881": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:the other day my mom called me white trash and i did this without hesitation \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the tweet text, which contains offensive language towards a specific group of people.\"}",
    "1058323120573038592": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:\u201cYou A Bitch, That Make Her A Dyke\u201d \ud83d\ude02 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language towards women, which is considered hateful. The image itself is a black background, which might be used to display such content.\"}",
    "1034915522704420864": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:BLACK CLASS VS THE WHITE TRASH \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a black background, which is often used to represent racism or discrimination. The tweet text further supports this classification as it contains offensive language towards a specific race. This combination of elements in the image and the tweet text suggests that it is a hateful meme.\"}",
    "1062138079924965376": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> what a massive CUNT \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, suggesting that the image might be a hateful meme.\"}",
    "1114678367695986688": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> disrespectful as hell.. you canceled nigga... \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content.\"}",
    "1105767774624845825": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Full Video: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person with a caption that says 'Full Video'. This could be interpreted as a hateful meme, as it may encourage violence or harm towards the person in the photo. The context of the tweet text is not provided, but it is important to consider the potential implications of sharing such images.\"}",
    "1034977939497144321": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Once again fake news play the race card \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, suggesting that it may contain offensive or discriminatory content. The tweet text also supports this classification, as it implies that the image is spreading false information and playing the race card.\"}",
    "1045090327479169024": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Only sjw don't like winning! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it may contain offensive or discriminatory content that targets a specific group of people.\"}",
    "1061997135858712581": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:POTUS Another day in the White House. Miles of wall built at the border? ZERO #BuildTheWall \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a wall, which is often associated with the construction of a border wall. The tweet text suggests that the wall has not been built, which implies that the image is related to a political issue. The use of the hashtag #BuildTheWall and the reference to the President of the United States (POTUS) suggest that the image is intended to be critical of",
    "1114230377533661185": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Nigger \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person, and the tweet text contains a racial slur. This suggests that the image is intended to be hateful and offensive.\"}",
    "1054049469111717888": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Is this cunt having a fucking laugh? Just cost me \u00a3370, fucking joke \ud83d\ude11\ud83d\ude11\ud83d\ude11\ud83d\ude11\ud83d\ude11\ud83d\ude11 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text also implies that the image is causing harm or distress to the viewer.\"}",
    "1049907712820224000": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:because she's dead retard \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests that the image is hateful, as it contains offensive language towards a deceased individual.\"}",
    "1051782311912464385": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> lol SJW term replaced by NPC Non Player Character.... \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, suggesting that it may contain offensive or discriminatory content.\"}",
    "1050496188523393026": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Lmfao... watching hillbilly mud trucks and look who the f see.... #countrystrong<tag> \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is a black background with no visible content, and the tweet text does not contain any hateful or offensive language.\"}",
    "1046797261479563264": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:cant believe im the office faggot omg... not surprised though \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language towards the office worker, suggesting a negative attitude towards the individual. This could be considered as a hateful meme.\"}",
    "1055898049426452481": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> That\u2019s cause all these niggaz be just like this nigga \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, likely due to the tweet text containing racial slurs and derogatory language.\"}",
    "1053962191156797441": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Yup, no question. Dems have definitely gone full retard.  #NeverGoFullRetard \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, suggesting that it contains content that is offensive or discriminatory towards a particular group or individual.\"}",
    "1056277808215781376": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> fuck this cunt never fucken answers \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, and the tweet text supports this classification as it contains offensive language towards someone.\"}",
    "1063483332544143360": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Collins OWNS a Chinese factory you retard \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racist remarks, which suggest that the image is a hateful meme.\"}",
    "1057754599925391360": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Fuck off twat. You wont see \u2018cybernats\u2019 behaving like this! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and a negative sentiment towards a specific group, which indicates that the image is hateful.\"}",
    "1054100278138585090": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I love this big dyke more than life itself<tag> \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and derogatory terms, suggesting a hateful sentiment towards the person being referred to.\"}",
    "1116378118439104513": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Lamb of God \u2013 \u201cRedneck\u201d Live at Bloodstock Open Air 2013 &amp; PV \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a lamb, which is associated with Christianity. The tweet text suggests that the image is related to a religious event, specifically Lamb of God's performance at Bloodstock Open Air 2013. This could be perceived as hateful by some individuals who may not share the same religious beliefs or values as the event's attendees.\"}",
    "1053863685301698560": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:SJW Dice Clay presents;  A Woke Nursery Rhyme \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme that is considered hateful due to its content and the reference to SJW (Social Justice Warrior) and Dice Clay, which are often associated with controversial and offensive language.\"}",
    "1043915338373582848": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> I think this perfectly sums up the twat?! Keep up the good work guys! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests that the image is a hateful meme, as it refers to the image as 'perfectly summing up the twat' and encourages others to keep up the good work. This implies that the image is meant to be derogatory or offensive towards a specific individual or group.\"}",
    "1108385414220529665": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:MOOD CUZ A NIGGA MADE IT TO 21\ud83d\ude4f\ud83c\udffe\ud83d\udcaf\ud83d\udcaf\ud83d\udda4 #March20 #Pices \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person, which can be perceived as a hateful meme due to the use of racial slurs in the tweet text. The tweet text contains offensive language and promotes negative stereotypes, making the image potentially harmful and offensive to some viewers.\"}",
    "1050463031405305856": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:WAIT I WASNT A RETARD 3 MONTHS AGO \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, suggesting that the image might be a hateful meme.\"}",
    "1047288725032656896": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:It's real. I'm breaking out the hashtag again #GamerGate  It's real! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, and the tweet text suggests that it is related to the GamerGate controversy, which has been associated with harassment and hate speech.\"}",
    "1061357332846788610": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:When your chilled night in is now a I\u2019m ready to twat somebody night #fuming \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests a negative and aggressive sentiment, which is often associated with hateful memes. The use of the word 'twat' and the overall tone of the message contribute to this classification.\"}",
    "1108074106019299329": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Nigga I be on the coochie like this \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and imagery, which is not appropriate or respectful.\"}",
    "1037091380911325186": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:For all you Retarded people out there who have time and money too waste.. Get a LIFE!!!!! #NikeBoycott \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is likely to be considered hateful by some people.\"}",
    "1056974515794698241": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Nigga...... \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark background, which can be perceived as a hateful meme due to the racial slur in the tweet text. The use of such language is offensive and inappropriate.\"}",
    "1106991754429911041": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Faggot Juice Stroke<tag> Video!   \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and derogatory terms, suggesting that the image is a hateful meme.\"}",
    "1024484942213013505": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Full Gallery: \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is a black and white photo of a sky, which does not contain any explicit or offensive content. It is not a hateful meme.\"}",
    "1062032537352982528": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag><tag> Sweet! Got a SJW scalp! Crying in mommy\u2019s basement. Lol \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, suggesting that it may contain offensive or discriminatory content. The tweet text also implies that the image is meant to mock or ridicule a specific group of people, which further supports the classification of the image as hateful.\"}",
    "1063489175360544768": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag> Berni ... just found whos car it is ...this 7shades of fud  twat!\ud83e\udd23\ud83e\udd23\ud83e\udd23\ud83e\udd23\ud83e\udd23\ud83e\udd23 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, suggesting that it contains offensive or discriminatory content.\"}",
    "1064269533140135937": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:THIS CUNT IS ON 200K A WEEK\ud83d\ude2d\ud83d\ude2d \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which suggests that the image is hateful.\"}",
    "1062597770928930816": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:explain<tag> :((((  also you changed your picture,, it looks cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, and the tweet text suggests that the picture has been changed to look offensive.\"}",
    "1058664585111121920": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:La Salle's Mark Dyke silences taunting Tigers with career game #UAAPSeason81 \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is a black and white photo of a basketball court, with no visible text or imagery that could be considered hateful.\"}",
    "1042843497676632065": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Retard bunch of fks \u2013 9GAG | Totally Sick | Funny Viral Humor Content | #Look\u00a0#NowPlaying \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which suggests that the image is hateful.\"}",
    "1044263989239336963": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:By: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which can be perceived as a hateful meme due to its association with negative emotions or events. The tweet text also suggests that the image is meant to be hateful.\"}",
    "1042495092882329602": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:WATCH LIVE Jason Van Dyke Trial: Day 3 of testimony \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which is not related to the tweet text. The tweet text contains information about a trial, which is not a hateful meme. The image itself is not hateful, but the tweet text does not fit the context of the image.\"}",
    "1055146348658352128": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Me &amp;<tag> when rube makes her appearance. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it may contain offensive or discriminatory content. The tweet text also implies that the image is related to a negative or harmful situation, further supporting the classification of the image as hateful.\"}",
    "1035640312922865665": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> He is literally white trash. Worst piece of dog shit in the history of man kind. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, likely due to the negative and offensive language used in the tweet text.\"}",
    "1046423865449164800": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Keep crying, redneck. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, suggesting that it contains offensive or discriminatory content.\"}",
    "1061582771989168130": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Learn to behave yourself, twat. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, suggesting that the image is a hateful meme.\"}",
    "1053765996308295680": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:The twat deserves a slap for being so cocky. Get The Strap \ud83d\ude21 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and a call for violence, indicating a hateful sentiment.\"}",
    "1063401998693867520": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Full Movie: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which can be perceived as a hateful meme due to its negative connotations. The tweet text does not provide any context or information that would change this classification.\"}",
    "1114567828303110144": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag> Who is this cunt  Who blocked me? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, suggesting a hateful sentiment towards the person who blocked the user.\"}",
    "1053792854085197824": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Nigga I\u2019m glad i muted this shit \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which is not related to the hateful tweet text. The tweet text contains racist language, which makes it hateful. The image itself is not hateful.\"}",
    "1062539111683276800": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Did u know that this cunt makes $160,000 a year \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is considered hateful.\"}",
    "1037460079447035905": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This birds a bloody retard I swear \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language towards a bird, suggesting a negative and hateful sentiment.\"}",
    "1052102523157274625": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Tic Tock, Tic Tock, Soros were ALL on a clock!  #CCOT #MAGA #NRA #2A #BuildTheWall #DrainTheSwamp #BorderPatrol  \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a clock with the words 'Tic Tock, Tic Tock, Soros were ALL on a clock!' written on it. This text is a reference to the conspiracy theory that George Soros is controlling the world through a clock. The tweet text further supports the classification as hateful, as it contains political and conspiracy theory-related hasht",
    "1108098379274485760": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Not my nigga chad \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The presence of the tag 'Not my nigga chad' further supports this classification, as it implies a negative and derogatory attitude towards a specific group of people.\"}",
    "1057736687466438656": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Me me me me me, you are a whiney little twat. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, suggesting a hateful sentiment towards the person being referred to.\"}",
    "1057692490906722310": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:And The Twat Of The Day Is.... \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content.\"}",
    "1056474471811428352": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:They may be your rival club but imagine being that much of a twat that you laugh at this\ud83d\ude21 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, suggesting that it may contain offensive or derogatory content towards a specific group or individual.\"}",
    "1055055159284416512": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I GOT HOOOOOOES  CALLIN  A YOUNG NIGGA PHONE  WHERE\u2019S ALLI  WITH THE MOTHAFUCKIN DOPEEEE \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a negative stereotype of a young black man, which is offensive and discriminatory.\"}",
    "1037409270638231552": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Sooner Trash Can, It Has To Have The White Crust On It Too! I Know His Type of Flavor! \ud83d\ude02\ud83d\ude02 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, likely due to the content of the tweet text, which contains offensive language and a reference to a specific individual.\"}",
    "1047215498637840384": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:White officer, Van Dyke, takes #stand in #murder over #black teen #shot 16 times \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a police officer with a caption about a white officer taking a stand in a murder over a black teen shot 16 times. This can be considered as a hateful meme as it might evoke negative emotions and racial tensions.\"}",
    "1061432142960431105": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Why is Diesel selling a $450 jacket that says \u2018faggot' all over it? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests that the image is a hateful meme, as it is described as a Diesel jacket with the word 'faggot' written on it. This type of language is often associated with discrimination and derogatory attitudes towards the LGBTQ+ community.\"}",
    "1061963256137478144": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Via: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which can be perceived as a hateful meme due to its association with negative emotions or events. The tweet text also suggests that the image is a meme, which further supports the classification of the image as hateful.\"}",
    "1049682753019662336": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Why is Farrah so white trash? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults towards Farrah, suggesting a hateful sentiment. The image itself is a black background, which might be used to create a dramatic or mysterious atmosphere, but it does not contain any explicit content that would make it hateful.\"}",
    "1041767057677864960": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> i got a 12 hour bar for saying that sjw\u00b4s ruined star wars,hate speech 2,Dorsey is a pussy \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains content that is offensive or discriminatory towards a particular group or individual. The tweet text also supports this classification as it contains hate speech and derogatory language towards social justice warriors and Twitter CEO Jack Dorsey.\"}",
    "1114519276248023040": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Don\u2019t be a cunt and support this cruelty. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests that the image is hateful, as it encourages people to not support cruelty. The image itself is a black background with no visible content, which might be interpreted as a symbol of support for the message in the tweet.\"}",
    "1055194856899952640": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Skinny Mother Showing Us Her Cunt And Ass From Behind - \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or inappropriate content. The tweet text further supports this classification as it contains explicit language and potentially offensive imagery.\"}",
    "1057354403546574850": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:huge cunt milf gets my big load   \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text provided further supports this classification as it contains explicit language and potentially derogatory terms.\"}",
    "1058894364984786944": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Faggot For Life<tag> Video!   \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which is not related to the hateful tweet text. The tweet text contains offensive language, which suggests that the image is being used to spread hate or discrimination. This classification is based on the content of the tweet and not the image itself.\"}",
    "1062920388496236545": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Put down that sign, retard. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content.\"}",
    "1108034594060804096": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> i\u2019m surry but nobody can sway me. this nigga haunts my dreams and fills my ***** with joy. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content that aims to provoke negative emotions or harmful actions towards a particular group of people.\"}",
    "1106803026914766848": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This nigga thought I was giving up boy pussy smh \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the racist language used in the tweet text, which is displayed on the image.\"}",
    "1054404434590081025": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:THIS NIGGA SAID SOME REAL SHIT RIGHT HERE SIIIIIIIIRRRRRR \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racial slurs and hate speech, which indicates that the image is hateful.\"}",
    "1054405852524957701": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag>.  exactly! Trump is No. 1 white trash!! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, likely due to the content of the tweet text, which contains derogatory language towards Trump and white trash.\"}",
    "1057037721619832839": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:thinking about Muto Tomu would serve PUSSY n CUNT if she did La Vie en Rose \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and suggests violence towards a woman. This classification is based on the fact that the image is associated with a hateful tweet.\"}",
    "1105577527970578437": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> I\u2019m the realest nigga, tell the truth \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is considered hateful. The image, being a black background, might be used to further amplify the negative sentiment in the tweet.\"}",
    "1058069794069594113": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> HONEY BUN WITH CHEESE NIGGA WHAAAT??? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a honey bun with cheese, but the tweet text is offensive and racist, which makes the image hateful.\"}",
    "1056714373090172930": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Guess what \ud83e\udd26\u200d\u2642\ufe0f some faggot changed his name and made it look like mine \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests that the image is a hateful meme, as it is related to a person's name change and the use of a derogatory term. The image itself is a black background with no visible content, which could be interpreted as a deliberate attempt to spread hate or discrimination.\"}",
    "1057904563943018496": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:you twat \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The presence of the word 'twat' in the tweet text further supports this classification.\"}",
    "1053476742286008320": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:You might be a redneck if you carve your pumpkins with a dremmel. \ud83d\ude02 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains content that is offensive or discriminatory towards a particular group of people.\"}",
    "1051776191005364229": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Happy Birthday you twat, enjoy it, much love x \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, suggesting that the image is a hateful meme.\"}",
    "1055966603899269121": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag> fuck off twat. #MAGABomber \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and a negative sentiment towards the image, suggesting that it is a hateful meme.\"}",
    "1055835201467834368": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I can\u2019t stand a \u201cgo below/ go the speed limit in the far left hand lane at 8am\u201d ass nigga \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and a negative attitude towards a specific group of people, which indicates a hateful sentiment.\"}",
    "1050143021659037696": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:whew my dyke jumped out \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a woman's body, which can be interpreted as objectifying or degrading. The tweet text further supports this classification as it implies a negative attitude towards women. The image and the tweet text together create a hateful meme.\"}",
    "1113140992805416960": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> What total fraud! Sell your SJW soul, vote 4 the liar! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains strong language and negative sentiment towards social justice warriors, suggesting a hateful sentiment towards a particular group.\"}",
    "1116502896722362369": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:yo how the fuck does this nigga wear durags without tying them around the front \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the racial slur used in the tweet text, which is offensive and discriminatory.\"}",
    "1054444213461495811": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Fuckimg hell imagine being fingered by this cunt man\ud83d\ude2d \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is considered hateful.\"}",
    "1062045820093050882": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Race card played. Keeping the game alive \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person's face, which is often used as a symbol of racism. The tweet text suggests that the image is being used to play the 'race card,' which implies that the person is trying to make a point about racism. This could be considered a hateful meme as it is using a symbol associated with racism to make a statement.\"}",
    "1061483869566889984": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Don\u2019t let me fool you indeed shister! I am one TRICKY NIGGER. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains racist language and imagery, which is offensive and discriminatory.\"}",
    "1060869824149098496": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Brazzers \u2013 Big Tits at School -(Harmony Reigns Tony De Sergio) \u2013 Dress Code\u00a0Cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a woman's face, which is considered offensive and disrespectful. The tweet text also adds to the negative sentiment, as it uses derogatory language to describe the woman. This combination of elements suggests that the image is a hateful meme.\"}",
    "1116709268563070976": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:local retard spotted \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The presence of the word 'retard' in the tweet text further supports this classification.\"}",
    "1056213541743669249": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> is off to a Halloween party \ud83c\udf83\ud83d\udc7b\ud83d\udc80 #buildthewall #fakenews #favoritekid \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a wall, which can be interpreted as a hateful meme due to the association with the #buildthewall and #fakenews hashtags. These hashtags are often used by people who support controversial political views, such as those related to immigration and media bias. The tweet text also includes a reference to a Halloween party, which may",
    "1114723099889418240": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> what the fuk jus happened. Can I get a subscriber 99% off a nigga broke asl and wanna dress like Ian \ud83d\ude14 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text also supports this classification as it contains derogatory language and references to race and financial status.\"}",
    "1045722644467736576": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:rare 1992 DAYTONA 500 STP RACE 10 CARD SET \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is a black and white photo of a race car, not a hateful meme. The tweet text is about a race car set, which is unrelated to the image's content.\"}",
    "1058384315086602240": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Kim Kardashian Issues An Apology For Calling Friends \u201cRetarded\u201d \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a woman's face, which is associated with the tweet text about Kim Kardashian's past behavior. The tweet text itself is not hateful, but the image's association with it might be perceived as hateful by some people.\"}",
    "1056722931982757889": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Trump loves the \"poorly educated\" and so does the Nazi Redneck Alliance. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which is not related to the tweet text. The tweet text contains hateful language towards a specific group, suggesting that the image is being used to spread hate or discrimination. This classification is based on the content of the tweet and not the image itself.\"}",
    "1062379673605287936": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> when we call her retarded \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The presence of the word 'retarded' in the tweet text further supports this classification, as it is considered derogatory and disrespectful towards individuals with intellectual disabilities.\"}",
    "1046194449653497856": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag> Explain then, Retard. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content towards a specific group of people. The fact that it is described as a 'Retard' meme further supports this classification.\"}",
    "1057678863659098112": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Happy Funny Redneck Meme Wednesday! Happy Halloween! \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is a black background with white text, which is not inherently hateful. The tweet text does not contain any explicit hate speech or content that would make the image hateful.\"}",
    "1057079474464817152": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:MY NIGGA WHAT \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racial slurs and is considered hateful. The image, being a black background, might be used to further amplify the hateful message.\"}",
    "1042795790886944768": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Check out the new trailer for Mary Poppins Returns with Dick Van Dyke! \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is a black background with no visible content, so it cannot be classified as hateful. The tweet text is unrelated to the image and does not contain any hateful content.\"}",
    "1113021988333850624": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Nigga you gay \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person's head, and the tweet text contains a racial slur. This suggests that the image is intended to be hateful and offensive.\"}",
    "1062609208607211521": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Fuck off furry cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which are indicative of a hateful sentiment.\"}",
    "1054089269390729216": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Try not to be a cunt all your life \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, suggesting that the image might be a hateful meme.\"}",
    "1045788865582133248": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Did you just call him a faggot???!!! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language, suggesting that the image might be a hateful meme.\"}",
    "1113525344072548353": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Nigga JR weird \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person, and the tweet text contains a racial slur. This suggests that the image is intended to be hateful and offensive.\"}",
    "1113506163679793153": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:be all ina nigga face scared to show dat fucked up smile, be like \"hey bighead\ud83e\udd74\"   \ud83d\ude2d\ud83d\ude2d\ud83e\udd26\ud83c\udffe\u200d\u2642\ufe0f \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person's face, which is considered a hateful meme due to the tweet text that uses racial slurs and derogatory language.\"}",
    "1114322744399810560": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Never been a sack chaser but I\u2019m on all lat all 2019 Periodt Wea the bag at nigga Wea tha bag at \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person's face, which is considered a hateful meme as it is associated with racism and discrimination. The tweet text further supports this classification as it contains offensive language and racial stereotypes.\"}",
    "1036959131163402240": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Full Movie: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which can be perceived as a hateful meme due to its negative connotations. The tweet text does not provide any context or information that would change this classification.\"}",
    "1053452666414673920": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:thats right CUNT \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, suggesting that the image might be a hateful meme.\"}",
    "1046763233808449536": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> And what about the twat who extended the badger cull? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the negative sentiment expressed in the tweet text, which targets a specific individual. The use of the word 'twat' and the reference to the badger cull further contribute to the negative and offensive nature of the image.\"}",
    "1054703088383123456": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Top 1 cunt of the\u00a0year \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a woman's face, which is considered offensive and disrespectful. The tweet text further supports the classification as it contains derogatory language.\"}",
    "1056496046229065728": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:#larryelder   An anti-Semite, two race card hustlers and a guilty white liberal walk into a bar... \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text provided further supports this classification as it describes a group of people with negative stereotypes, such as an anti-Semite and race card hustlers.\"}",
    "1109894830199619585": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:\u201cI\u2019m from Dorchester\u201d... niggaa foolin our here. Nigga said that shit like it made him certified \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, likely due to the use of racial slurs and derogatory language in the tweet text. This type of language is offensive and disrespectful, which contributes to the negative perception of the image.\"}",
    "1056790653181415424": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> ^retard \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The presence of the word 'retard' in the tweet text further supports this classification.\"}",
    "1042906557636386816": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Practicing on a new mix \ud83e\udd17 Djing get me hyped y\u2019all \ud83d\ude02 \u2757\ufe0fI be looking so retarded \ud83d\ude02 \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is a simple black background with no visible content, and the tweet text does not contain any hateful or offensive language.\"}",
    "1063721249040412674": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Full Video: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person with a caption that says 'Full Video'. This could be interpreted as a hateful meme, as it may encourage violence or harm towards the person in the photo. The context of the tweet text is not provided, but it is important to consider the potential implications of sharing such images.\"}",
    "1034968686832959489": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:the thor and the poe dameron pin the dyke jumped out \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person, which is often associated with negative emotions or hate. The tweet text also suggests a negative connotation, further supporting the classification of the image as hateful.\"}",
    "1116357989747892226": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Complete Faggot for Asshole Licking  \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which suggests that the image is hateful.\"}",
    "1057392320633540608": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Come at me, Redneck Dracula. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it may contain offensive or discriminatory content. The tweet text also implies a negative or aggressive tone, further supporting the classification of the image as hateful.\"}",
    "1058196861033635841": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Here kids if a guy trys starting a toxic Arguement hit em with this upgraded psychpdelic Cunt away can \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text also supports this classification as it encourages using offensive language to respond to toxic arguments.\"}",
    "1055266953701421057": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:\u201cHailey, dyke\u201d \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language towards the LGBTQ+ community, which is considered hateful.\"}",
    "1044109351491788800": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> I'm no one, but you follow me. Nice to know you're an even bigger nobody you cock guzzling retard :^) \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which suggests that the image is a hateful meme.\"}",
    "1056145984659619840": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:After a total cunt of a week last week, I\u2019ve rolled my transfer. Don\u2019t know how I\u2019ve managed it to be honest!! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet contains offensive language and is considered hateful.\"}",
    "1054612285610713089": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Never heard of you before. Just wanted to call you a fucking cunt who will rot in hell. Cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, indicating a hateful sentiment towards the person being addressed.\"}",
    "1105544511894228992": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:The Nigga I Grew Up Listening To \ud83d\ude08 Yall Wouldnt Understand Tho \ud83d\udcaf #WordsOfARealNigga \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which is not related to the hateful tweet text. The tweet contains racial slurs and derogatory language, making it hateful. The image itself is not hateful, but it is being used in a hateful context.\"}",
    "1115308190084861953": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This shit got me dying nigga said Obama a snack LMFAO xD \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which are indicative of a hateful meme.\"}",
    "1037300237470183424": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> It's not too far fetched that you would call someone retarded. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, suggesting that it contains offensive or discriminatory content.\"}",
    "1051582921004470272": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag> Twat (him, not you) \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, suggesting that it may contain offensive or discriminatory content.\"}",
    "1061178017723138048": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Full Movie: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which can be perceived as a hateful meme due to its negative connotations. The tweet text does not provide any context or information that would change this classification.\"}",
    "1105216055365062657": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:and every time a nigga ask me if I sing songs to get at women, I say yaaa \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person's head, and the tweet text contains a racial slur. This suggests that the image is hateful and promotes negative stereotypes.\"}",
    "1037159708724011008": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Eminem dropping music and sjw be \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which is not related to the tweet text. The tweet text contains a reference to Eminem and SJWs, which might be considered controversial or offensive by some people. However, the image itself does not contain any hateful or offensive content.\"}",
    "1108834455383347203": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:By: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which can be perceived as a hateful meme due to its association with negative emotions or events. The tweet text also suggests that the image is meant to be hateful.\"}",
    "1053375672591286279": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:IM BROKE NIGGA! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racist remarks, which are indicative of a hateful meme.\"}",
    "1049832044690374657": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Twat be like \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The presence of the word 'twat' in the tweet text further supports this classification.\"}",
    "1051307043146084353": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Just got called a faggot for posting a screenshot \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains a negative message towards the LGBTQ+ community by using derogatory language.\"}",
    "1045798404893409280": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Watch it: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which can be perceived as a hateful meme due to its association with negative emotions or events. The tweet text does not provide any context or information that would change this classification.\"}",
    "1114342360257839104": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:nigga wtf is this advert \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person's face, which is considered offensive and hateful. The tweet text further supports this classification as it contains a racial slur.\"}",
    "1058283232767164417": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> David Cameron = Cunt  #CSACoverUp \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which is not related to the hateful tweet text. The tweet contains offensive language towards David Cameron, which indicates a hateful sentiment. The image itself is not hateful, but the context provided by the tweet makes it appear as a hateful meme.\"}",
    "1063846092054265856": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> That's the dumbest shit I've ever read. Marxist business woman? You're retarded \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, suggesting that the image is a hateful meme.\"}",
    "1115330893411909633": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Fuck, I meant black nigger Twitter. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content towards a particular group of people.\"}",
    "1107756314929844225": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:\ud83d\ude02\ud83d\ude02\ud83d\ude02 imagine the nigga pulled up on me twice and lost he got mad deleted me why pull up on me tf nmp \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racial slurs and insults, which are considered hateful. The image itself is a black background, which might be used to display such content.\"}",
    "1061691675251228678": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:THIS AD PISSES ME OFF a dunt wanna fuckin use ur shitty app u cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and negativity towards the app, which suggests a hateful sentiment towards the app.\"}",
    "1053692045586563077": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Some cunt want to delete her Twitter fs \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains content that is offensive or discriminatory towards a particular group of people.\"}",
    "1058041141977845760": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:(Hillbilly Halloween) - - #FeaturedCreature #Funny #WalmartFashion - \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it may contain offensive or discriminatory content. The tweet text also implies that the image is related to a negative stereotype, such as a hillbilly or Walmart fashion, which could contribute to the perception of the image as hateful.\"}",
    "1037086659668598785": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Tiffany Van Dyke, wife of Chicago cop charged in Laquan McDonald fatal\u00a0shooting \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a woman, which is being used as a hateful meme to spread negativity and discrimination. The tweet text further supports this classification as it is related to a controversial and sensitive topic.\"}",
    "1115266751191834625": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> NIGGA WATCH OUT HE XALLED HIS VOUSIN \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person's head, and the tweet text contains a racial slur. This suggests that the image is intended to be hateful and offensive.\"}",
    "1035169525765951490": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Van Dyke breaks silence in interview with Chicago Tribune \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is a black and white photo of a sky, which does not contain any explicit or offensive content. The tweet text does not provide any context or information that would suggest the image is a hateful meme.\"}",
    "1113864131944353794": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> That's my shirt nigga stop bulli \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and a reference to bullying, which suggests that the image could be a hateful meme.\"}",
    "1049770426635825155": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:nan\nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which can be perceived as a hateful meme due to its association with negative emotions or events. The tweet text does not provide enough context to determine if it is a hateful meme or not.\"}",
    "1053362575457562625": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:MOVE BITCH!! A NIGGA NEED A LIL SPACE!! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racist remarks, which are not appropriate and can be considered as hateful.\"}",
    "1055132565596749825": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag><tag> Now his playing the race card???? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a man with the caption suggesting that he is playing the race card. This can be considered as a hateful meme as it may promote negative stereotypes and racial tensions.\"}",
    "1113863613515804672": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Nigger \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person, which is often associated with racism and hate. The tweet text, 'Nigger,' further supports the classification of the image as hateful.\"}",
    "1049786374847651841": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Secure our border and this wouldn\u2019t be an issue. #BuildTheWall \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests a hateful sentiment towards immigrants, which is reflected in the image of a black background with white text. The image could be used to promote such hateful views.\"}",
    "1057453466900152320": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:SO THEN THIS LITTLE NIGGA HAD THE AUDACITY TO SAY \u201cdo you have pink eye or something ?\u201d .. I FUCKING LOST IT \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the tweet text, which contains racist language and insults.\"}",
    "1055027707241734145": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Just in case #usa #sjw \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it may contain offensive or discriminatory content. The fact that it is described as a meme and the hashtag #sjw is used implies that it could be related to social justice issues, which might be controversial or triggering for some people.\"}",
    "1037448658646708224": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:My streams are so retarded \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, suggesting that the image might be a hateful meme.\"}",
    "1113116032493858817": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> SEND THAT NIGGA TO JAIL \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person, and the tweet text suggests a negative and discriminatory sentiment towards a specific group of people. This classification is based on the fact that the image and the tweet text together convey a hateful message.\"}",
    "1056289832035471360": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:this album is so good omg dyke excellency \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is a black background with no visible content, and the tweet text does not contain any hate speech or offensive language.\"}",
    "1046037052788224000": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:POTUS Another day in the White House. Miles of wall built at the border? ZERO #BuildTheWall \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a wall, which is often associated with the construction of a border wall. The tweet text suggests that the wall has not been built, which implies that the image is related to a political issue. The use of the hashtag #BuildTheWall and the reference to the President of the United States (POTUS) suggest that the image is intended to be critical of",
    "1109200182921564162": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:\ud83e\udd23 bitch really sent me a text she meant to send another nigga. You kno what we call that \ud83e\udd23\ud83e\udd23\ud83e\udd23 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person's head, and the tweet text suggests that it is a meme meant to be hateful towards a specific group of people. The use of the word 'bitch' and the reference to another person as 'nigga' are examples of language that can be considered offensive and hateful.\"}",
    "1054444304830267394": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Day 249: Tucker And Dale vs Evil (2010)  \"You want a killer hillbilly? I'll show you a killer hillbilly.\" \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a hillbilly, which can be perceived as offensive or hateful. The tweet text also supports this classification as it references a movie with a hillbilly character.\"}",
    "1056349271333748738": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:It has been a very devastating day for classical liberal/anti-SJW twitter, please be nice to them. \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is a black background with no visible content, so it cannot be classified as hateful. The tweet text suggests that it is a call for kindness towards classical liberals or anti-SJW twitter users, which is a positive message.\"}",
    "1110279788420386816": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:y\u2019all want a nigga that\u2019s gon cater to your emotions or a nigga that\u2019s choke you out and say stfu... \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and promotes negative stereotypes, which indicates that the image is hateful.\"}",
    "1047231201046618113": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Yeah, I'm a FAGGOT  F - Gay A - G - G - O - T - \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language towards the LGBTQ+ community, which is considered hateful.\"}",
    "1041697320054603776": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:WATCH LIVE: Judge set to rule on change of venue motion in Jason Van Dyke trial \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is a black background with no visible content, so it cannot be classified as hateful. The tweet text refers to a legal event, which is not related to the image's content.\"}",
    "1041828204330319872": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Same \ud83d\ude2d\ud83d\ude2d\ud83d\ude02\ud83d\ude02 cannot wait for this.....got my signed dick van dyke pic in my bedroom ha \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text also implies that the image is related to a controversial or unpleasant topic, further supporting the classification of the image as hateful.\"}",
    "1054490273156341760": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I'm a massive cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, which suggests that the image might be a hateful meme.\"}",
    "1063541597147721728": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:me: charlie p*th is a cunt  jungkook:  \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which are indicative of a hateful meme.\"}",
    "1056677776739237891": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Donald trailer trash please shut the fuck UP!!! \ud83d\ude21\ud83d\ude21 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text also supports this classification, as it contains insulting language towards Donald Trump.\"}",
    "1043718586919936005": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:1 melee kill, 2 deagle kills 2 tac kills and 2 retarded laughs  \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which suggests that the image is hateful.\"}",
    "1046233630761263105": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Layne might be crying instead of cheering when \u201cRedneck Jesus\u201d gets a hold of him! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, suggesting that it may contain offensive or discriminatory content.\"}",
    "1025077189371461632": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Go get busy somewhere else twat. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and a negative sentiment towards someone, which indicates that the image is hateful.\"}",
    "1050067821617655810": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Wigger by Andrew Santino is #NowPlaying on \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person, which is often associated with racism and hate. The tweet text also suggests that the image is related to a hateful meme.\"}",
    "1062109582955290624": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Inabit you twat #blockduncancastles \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and a call to block someone, indicating a hateful sentiment towards the person being mentioned.\"}",
    "1062106352166883328": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag>: \u201cYou fat cunt\u201d <tag>: \u201cI\u2019m not fat no more\u201d \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person's face, with the words 'You fat cunt' written above it. This is considered a hateful meme as it uses offensive language to insult the person depicted in the photo.\"}",
    "1062062915774234625": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> He knows what he did was wrong as well, yet he kept it up. Fuck this cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, indicating a hateful sentiment towards the person being referred to.\"}",
    "1109831238653759488": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:We don\u2019t ever stop at red lights at night nigga.\ud83d\ude0e\ud83d\udea6 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text further supports this classification as it contains derogatory language towards a specific group of people.\"}",
    "1053728366119931904": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Happy birthday to this legend right here, Uncle Snoop \ud83d\udc4f\ud83d\udc4f I love this nigga so much \ud83d\udcaf \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and references to a racial slur, which indicates a hateful sentiment.\"}",
    "1062266554493136896": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:They do love playing the victim card after that \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person with a caption that implies the person is playing the victim card. This can be perceived as hateful, as it suggests that the person is not genuinely experiencing hardship or adversity, but rather using it as a means to gain sympathy or attention.\"}",
    "1047199942018846721": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Van Dyke really just said he didn't shoot at Laquan on the ground he shot at the knife #VanDykeTrial \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person, which is often associated with racism and hate. The tweet text also suggests a hateful sentiment, as it references a trial and the person involved.\"}",
    "1058866268655116289": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Imagine running round with a stacked class on bo4.... 6 perks and attachments on a vapr. Grow up cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which suggests that the image is intended to be hateful.\"}",
    "1056398181263699968": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:NIGGA I AM PERPLEXED \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person's head, and the tweet text contains a racial slur. This suggests that the image is intended to be hateful and offensive.\"}",
    "1064366276666114048": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Goodnight Mr President! \ud83d\ude18 #BuildTheWall #BuildThatWall \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a wall, which is often associated with political views and opinions. The tweet text suggests a political agenda, specifically related to the wall and the president. This could be perceived as hateful by some people, as it might be seen as a criticism or opposition to a certain political stance or individual.\"}",
    "1044826578188996608": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:The old dyke \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language towards the LGBTQ+ community, which is considered hateful.\"}",
    "1106624879783231488": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:You three have two hours to unfollow that cunt or I\u2019m breaking the mutual \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and a threat, indicating a hateful sentiment.\"}",
    "1053405425801027591": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:TWAT \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which can be perceived as a hateful meme due to its negative connotations. The tweet text 'TWAT' further supports the classification as it is a derogatory term.\"}",
    "1041809814232489985": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Check out #Hillbilly #3 #Albatross #Comic #EricPowell #CGC 9.6  \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is a black and white photo of a hillbilly, which is not inherently hateful. The tweet text does not contain any explicit hate speech or content that would suggest the image is hateful.\"}",
    "1109958774196862976": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag> Lol you twat \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, suggesting that the image might be a hateful meme.\"}",
    "1042110240748171264": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> What a twat \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, suggesting that it may contain offensive or discriminatory content.\"}",
    "1053960864817135616": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:What. The. Fuck. Another one who\u2019s not being a twat. Xbox is changing \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is a black background with no visible content, and the tweet text does not contain any hateful or offensive language.\"}",
    "1054678759394152453": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Nigga said u must be bizzy \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person, and the tweet text contains a racial slur. This suggests that the image is hateful and promotes negative stereotypes.\"}",
    "1051491467049492481": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Mooch has best cockney accent since Dick Van Dyke! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains content that is intended to be offensive or harmful. The presence of the tag 'Mooch' and the reference to a cockney accent may be perceived as derogatory or discriminatory by some individuals.\"}",
    "1063971090496540672": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag>  what a dumb ass cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, suggesting that the image might be a hateful meme.\"}",
    "1046447616119078912": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:DYKE RIGHTZ \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language towards the LGBTQ+ community, which is considered hateful. The image itself is a black background, which might be used to further spread such hateful messages.\"}",
    "1050911972521332736": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Absolute plastic paddy \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text further supports this classification as it uses derogatory language to describe the image.\"}",
    "1056792025129873408": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> has a wall....\ud83d\ude0f  #BuildTheWall \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a wall, which is often associated with racism and discrimination. The tweet text suggests that the image is related to a hateful meme, further supporting the classification of the image as hateful.\"}",
    "1054101757570244608": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> What a slag??? Hahahahaha cheeky cunt!!! Xx \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, suggesting a hateful sentiment towards the person being referred to.\"}",
    "1051797760482181121": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Say it with me:  BUILD THAT WALL!  It's coming my friends!<tag> \ud83c\uddfa\ud83c\uddf8\u2764\ufe0f #BuildTheWall \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a wall, which is often associated with racism and xenophobia. The tweet text suggests a hateful sentiment towards immigrants, which further supports the classification of the image as hateful.\"}",
    "1046870729944457218": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:me when the first trailer dropped: Titans look like its gonna be BIG trash  me now: GIRL, I HEAR SUM \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains negative words like 'trash' and 'gonna be BIG trash', which suggests a hateful sentiment towards the Titans. The image itself is a black background, which might be associated with negativity or a lack of positivity.\"}",
    "1062659191670800384": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Don was really into the old white trash saying, they all look the same upside down! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racist remarks, which suggest that the image is a hateful meme.\"}",
    "1035341377406685185": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:When did people start pulling a race card to save themselves from getting roasted. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a negative stereotype and promotes racism by using the race card as a shield.\"}",
    "1043628707104129024": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Get smacked retard \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which suggests that the image is a hateful meme.\"}",
    "1056382987674087425": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Tell that to the families of the 12 Jews killed by a Trump supporter you ignorant,smug, Nazi cunt. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains hateful language towards Trump supporters and Jews, which suggests that the image is a hateful meme.\"}",
    "1109512822004826113": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:21 that nigga stop playin \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person, and the tweet text contains a racial slur. This suggests that the image is hateful and promotes negative stereotypes.\"}",
    "1043658854532296704": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Now Playing Marty Stuart - Hillbilly Rock - Hillbilly Rock On \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is a black background with no visible content, and the tweet text does not contain any hateful or offensive language.\"}",
    "1059498819958792192": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> This Georgian will be headed to town in a little while and voting Red.  #MAGA #AmericaFirst #BuildTheWall \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains content that is intended to be offensive or discriminatory towards a particular group or individual. The tweet text also contains political and ideological statements that may be perceived as hateful or divisive.\"}",
    "1042797412035776512": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Nigger be rolling everywhere \ud83d\ude02\ud83d\ude02\u274c \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark background, which is often associated with racism and hate. The tweet text further supports this classification as it contains a racial slur. This combination of elements suggests that the image is a hateful meme.\"}",
    "1061308834705158144": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Rie Tachikawa obedient milf endures cock in her twat \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a woman's vagina, which is considered inappropriate and offensive. The tweet text further emphasizes the hateful nature of the image.\"}",
    "1054715767629975552": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Watching the news to see some fucking Texas redneck bodyslamming a goat. What the fuck is wrong with that country! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text also supports this classification as it contains derogatory language and a negative comment about a specific region or group of people.\"}",
    "1044085378142081024": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Fat Babe Gets Her Fleshy Body #and Twat Massaged \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it may contain offensive or discriminatory content. The tweet text also implies that the image is derogatory towards a specific group of people, further supporting the classification of the image as hateful.\"}",
    "1064272056420876288": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:SJW school council gang showed amazing float with our fun logo -Incredible #BellevilleON #parade #ASL #BayofQuinte \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it may contain offensive or discriminatory content. The tweet text also implies that the image is related to a school council or a political group, which could further contribute to the negative perception of the image.\"}",
    "1064372865053663232": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Whip my cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, which is considered hateful.\"}",
    "1108357524019793920": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Funny meme haha your hillbilly boi anomoly like swedish norway faggot lulz \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and derogatory terms, suggesting that the image is a hateful meme.\"}",
    "1035465643536121857": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:twat<tag> \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which can be perceived as a hateful meme due to its negative connotations. The tweet text also adds to the negative sentiment, as it uses offensive language.\"}",
    "1056523884286107650": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> You're a cunt! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, suggesting that the image might be a hateful meme.\"}",
    "1061853743602372608": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:butch dyke \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains content that is offensive or discriminatory towards a particular group of people, such as the LGBTQ+ community. The presence of the word 'dyke' in the tweet text further supports this classification.\"}",
    "1047177364663390208": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag><tag><tag> Let me make it more \"retarded\" \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text also implies that the image is meant to be more 'retarded,' which further supports the classification of the image as hateful.\"}",
    "1043483311513972736": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Comes into my DMS with no money, retard \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The presence of the word 'retard' in the tweet text further supports this classification.\"}",
    "1063457879733272582": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Poor Santa! Mrs. Claus is a cunt! She should put out!! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet contains offensive language and insults towards Mrs. Claus, indicating a hateful sentiment.\"}",
    "1062320625837137920": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:What a twat. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, suggesting that the image is hateful.\"}",
    "1054438091841331201": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:happy birthday<tag> you spanish twat\ud83d\udc9a \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which suggests that the image is a hateful meme.\"}",
    "1053661023696171009": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> When mobs in USA aren't working, the DEMS just import them! #BuildTheWall \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it promotes a negative and discriminatory message against a specific group of people, which is inappropriate and offensive.\"}",
    "1063967105769529344": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:West Virginia's finest! #Hillbilly \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it may contain offensive or discriminatory content. The tweet text also implies a negative stereotype about West Virginians, which further supports the classification of the image as hateful.\"}",
    "1057267672440688642": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:When I say I\u2019m SCREAMING!!! \u201cWhat\u2019s old\u201d YOU NIGGA! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racial slurs and aggressive language, which indicates a hateful sentiment.\"}",
    "1035722805579370497": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Arms, shoulder then 6 miles!<tag> stop talking to<tag> and let's work! Sorry Rube \nASSISTANT: {\"Classification\": \"hateful or not hateful\", \"Explaination\": \"The image is not hateful as it is a simple black background with no visible content that could be considered offensive or discriminatory.\"}",
    "1035953998027804672": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Sonny? Trash. Jax? Trash. Jason? White excellence. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the negative portrayal of the characters in the tweet. The tweet text contains insulting language and stereotypes, which contribute to the classification of the image as hateful.\"}",
    "1057290724050460672": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Here we go, she likes to drink and shoot guns...Meghan loves the the redneck rhetoric. #TheView \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, suggesting that it may contain offensive or discriminatory content. The tweet text also implies that the image is related to a controversial or divisive topic, such as gun control or political views.\"}",
    "1108405829793972225": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> weird ass nigga \ud83d\ude2d\ud83d\ude2d\ud83d\ude2d \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text further supports this classification as it uses derogatory language towards a specific group of people.\"}",
    "1042990204078845954": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:The Red Barn maze is still Hillbilly-tastic. <tag> #ScaryFarm \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and stereotypes, suggesting that the image might be a hateful meme.\"}",
    "1058862037491687425": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Pathetic cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, which suggests that the image might be a hateful meme.\"}",
    "1060886738829262848": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I\u2019m crying real nigga tears. I have to work an 8hr shift OUTSIDE \ud83d\ude2d\ud83d\ude2d \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it may contain offensive or discriminatory content. The tweet text also supports this classification as it uses derogatory language towards a specific group of people.\"}",
    "1054009518357692421": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Redneck #16 - (W)<tag>\u00a0(A/CA)<tag>\u00a0,<tag> - in stores next week! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it may contain offensive or discriminatory content. The tweet text also supports this classification as it refers to a comic book character as a 'redneck' and implies that the character is 'in stores next week!'. This could be perceived as offensive or insensitive to some people.\"}",
    "1024733138923151360": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Another #clip sold! Faggot For Daddy #CoercedBi Get yours on #iWantClips! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains content that is offensive or discriminatory towards a particular group of people. The tweet text also supports this classification as it contains derogatory language towards the LGBTQ+ community.\"}",
    "1024030343882579968": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> MAKE ME CUNT \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, which suggests that the image could be a hateful meme. The use of the word 'cunt' is considered derogatory and disrespectful, which aligns with the classification of the image as hateful.\"}",
    "1050381664482807809": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I vote we rename SJW to \"Street Justice Warriors\".  #SJW \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which is not related to the tweet text. The tweet text contains a joke about renaming a group of people, which can be considered as hateful or offensive. The image itself is not hateful, but the content of the tweet is.\"}",
    "1037215196312465408": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> THIS SHOULD BE YOUR 30TH ANN. POSTER...NOT THAT PIECE OF AHIT FUCKING PUSSY FAGGOT COLLIN!!! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet contains offensive language and insults, suggesting a hateful sentiment towards the person being referred to.\"}",
    "1054231738732462080": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Cunt slayer \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, which suggests that the image might be a hateful meme.\"}",
    "1106722034866888705": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Some cunt who doesn't keep up with current events just told me that Epic doesn't compete with Valve. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content.\"}",
    "1057555385505251328": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Cheers<tag> you big cunt. Nice to know you saved yourself a few hundred pounds. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet contains offensive language and insults, which suggest that the image is a hateful meme.\"}",
    "1115443276893417472": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This nigga was deeper than deep \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains a racial slur and is offensive to many people.\"}",
    "1062189401424490496": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Kingsway leisure centre. Car park absolutely rammed but this twat still takes up two spaces \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, likely due to the negative sentiment expressed in the tweet text. The tweet text refers to a person who is taking up two spaces in a car park, which might be perceived as selfish or irresponsible behavior.\"}",
    "1105508570395824128": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:like damn nigga who hurt you \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language towards a specific group of people, which is considered hateful. The image itself is a black background, which might be used to create a provocative or aggressive atmosphere, but it does not contain any explicit content that would make it hateful.\"}",
    "1063987394934964224": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Hogg is a retard and the best free advertising for the NRA, what a fucking muppet. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet contains derogatory language towards David Hogg, suggesting that he is a 'retard' and that his advocacy for gun control is a form of advertisement for the NRA. This language is considered hateful and disrespectful towards an individual.\"}",
    "1042498047551438848": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:You. Big. Bloody. Retard. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which indicates that the image is hateful.\"}",
    "1058798068295000064": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This twat is starting to make me sick now with his exaggerated none existent false Liverpool Accent \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, likely due to the negative portrayal of the person in the tweet text.\"}",
    "1107287501998379008": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> REAL ASS BITCH GIVE A FUCK BOUT A NIGGA \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which are indicative of a hateful sentiment. The image itself is a black background, which might be used to further emphasize the negative message.\"}",
    "1056779731855704065": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I made him cum. Then keep bombing his cunt until cum inside him....  See this and more at: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains explicit and offensive content, which is not suitable for public consumption.\"}",
    "1110280607907700737": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:What a cunt . \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, suggesting that the image might be a hateful meme.\"}",
    "1062714162462244865": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Another retarded tweet from Potus Doll hands \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The presence of the tag 'Potus Doll hands' in the tweet text further supports this classification.\"}",
    "1109661200818819072": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Who\u2019s gonna jump me this nigga look like he from the movie flush \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a man's face, and the tweet text contains a racial slur. This suggests that the image is intended to be hateful and offensive.\"}",
    "1062486327717810176": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:White people they say \u201cKobe!\u201d every time they shoot a paper into the trash \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a negative stereotype about white people, suggesting that they are careless and irresponsible.\"}",
    "1034887235387183104": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:#GamerGate Site of the Day!  \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black background with a white outline of a person, which is often associated with hateful memes. The tweet text also suggests a connection to the GamerGate controversy, which has been linked to harassment and hate speech.\"}",
    "1056698089606656008": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Really this fucking dodo ass cow nigger skin fucking delete your game \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a cow, and the tweet text contains offensive language, suggesting that it is a hateful meme.\"}",
    "1024980657976627200": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Thank You President Trump! #AmericaFirst #BuildTheWall \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a wall, which is often associated with racism and xenophobia. The tweet text also contains political messages that may be perceived as hateful or divisive.\"}",
    "1062369091833524225": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:A basics representation of my retarded ass \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text further supports this classification as it uses derogatory language to describe the image.\"}",
    "1053647561125445632": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Sure it was the goal, not the cunt behaviour from the chelsea staff member \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and suggests a negative attitude towards the Chelsea staff member. This could be considered as a hateful meme.\"}",
    "1107142906601766912": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Hate this faggot \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains content that promotes negative feelings or discrimination towards a particular group of people.\"}",
    "1057291040628133889": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Churchill was a cunt. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which are considered hateful. The image itself does not seem to be hateful, but the tweet text associated with it is.\"}",
    "1055897660148867072": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I hope I made you all way bigger faggot's then when I found you bois . Ta ta betas ;) \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and derogatory terms, suggesting a hateful sentiment towards others.\"}",
    "1058111213731790848": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:PLANT GANG NIGGA \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which are indicative of a hateful meme.\"}",
    "1063576693842034693": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:PSA: don\u2019t work w<tag> they are nasty and called me a cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, and the tweet text supports this classification as it contains offensive language.\"}",
    "1053604247609188352": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Why the fuck is this twat not wearing a shirt. #peoplesvote #StandUp4Brexit \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and a negative sentiment towards a person who is not wearing a shirt. This could be considered as a hateful meme.\"}",
    "1062202291997106176": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Islam has nothing to do with terrorism \ud83e\udd21\ud83e\udd21 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which is not related to the tweet text. The tweet text contains a statement that is against Islam, which makes it a hateful meme.\"}",
    "1051271372436135939": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Y'ALL IM SO BORED IM TRYING TO START A WHITE TRASH FIGHT \ud83d\ude2d\ud83d\ude2d\ud83d\ude2d\ud83d\ude2d\ud83d\ude2d \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains content that is offensive or discriminatory towards a particular group of people. The tweet text also supports this classification as it appears to be promoting a negative and discriminatory attitude towards a specific group.\"}",
    "1061717744507383811": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Can we still say \"Faggot\" today<tag> Throw in a poof and a Bwana and were sorted.. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a man's face, which is considered offensive and hateful. The tweet text also contains derogatory language, further supporting the classification of the image as hateful.\"}",
    "1113155839412584450": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:this nigga said YOU THOUGHT \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person, and the tweet text contains a racial slur. This suggests that the image is hateful and promotes negative stereotypes.\"}",
    "1113878667686436864": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> That nigga Jason said \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person's head, and the tweet text contains a racial slur. This suggests that the image is intended to be hateful and offensive.\"}",
    "1114880051688947712": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:But if she says she has a man but might be accepting side nigga applications.. best believe I'll proceed &amp; apply \ud83d\ude05\ud83d\ude0e \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a negative and discriminatory attitude towards women, particularly those who may be perceived as 'side niggas'.\"}",
    "1056240126072893440": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:WELL THIS IS EXACTLY WHY I HATE COD I KNOW THIS ON A SMALL MAP BUT NIGGA DAMN! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet contains hate speech towards a specific group of people, which is reflected in the image's content.\"}",
    "1046377750599274499": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:The Rube Goldberg Lunch Feeder \u2013 How To Be More Productive At Work \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is a black background with no visible content, and the tweet text does not contain any hateful or offensive language.\"}",
    "1061023718170902528": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Fuck off you guffy cunt. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, suggesting that the image might be a hateful meme.\"}",
    "1052532823893139457": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Do NOT let them In!! #VoteRedToSaveAmerica #BuildTheWall #NoOpenBorders #NoAmnesty \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a wall, which is often associated with immigration and border control. The tweet text suggests a political stance against immigration and open borders, which can be perceived as hateful. The image may be used to promote such views, making it a hateful meme.\"}",
    "1115021455656398854": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:i know this nigga did Not just do that \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The presence of the word 'nigger' in the tweet text further supports this classification.\"}",
    "1046442685081559040": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Redneck comrades... \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it may contain offensive or discriminatory content. The tweet text also supports this classification as it refers to 'redneck comrades' which might be perceived as derogatory or discriminatory by some people.\"}",
    "1053841386364174336": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Secure our border. #BuildTheWall \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a wall, which is often associated with the concept of a border wall. The tweet text suggests a political stance on immigration and border security, which can be perceived as hateful by some people. The image itself does not contain any explicit hate speech or symbols, but its association with a controversial political issue can evoke negative emotions in some individuals.\"}",
    "1105124930113425408": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:NIGGA I SMELL FOOD MY STOMACH GROWLING IM HUNGRYYYYYYYYY \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains racial slurs and promotes negative stereotypes.\"}",
    "1064043907267342337": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:DYKE NATION!!!!!!!!! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language towards the LGBTQ+ community, which is considered hateful. The image itself is a black background, which might be used to display such hateful content.\"}",
    "1107169825061785600": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:10.Aly &amp; Fila with Sue McLaren - Surrender (GO Remix)  #SOT  \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is a black background with no visible content, and the tweet text does not contain any hateful or offensive language.\"}",
    "1062527844516012032": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> I like it when u say cunt. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, suggesting that the image might be a hateful meme.\"}",
    "1053563676530237441": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Damn Right Bro !! \ud83d\ude0e\ud83d\udc4a\ud83c\udffb #BuildTheWall !  #MAGA \ud83c\uddfa\ud83c\uddf8 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a wall, which is often associated with racism and discrimination. The tweet text also supports this classification as it contains political and racial statements that are considered hateful.\"}",
    "1050568015798882305": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:What do you think? #Kids #Politics #Sjw #Toygun #Toyguns \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a toy gun, which is often associated with violence and harm. The tweet text suggests that it might be related to politics or social justice issues, which could further contribute to the negative perception of the image. The combination of the toy gun and the political or social justice context makes the image appear hateful.\"}",
    "1063787771087720448": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:What a cunt. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, suggesting that the image might be a hateful meme.\"}",
    "1042304703592165376": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Rosie I\u2019m not really a conspiracy theorist, but WTH? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it may contain offensive or discriminatory content. The tweet text also implies that the image is not to be trusted, further supporting the classification of the image as hateful.\"}",
    "1108349059776024577": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Good day life! In Life There is time for everything but to surrender.<tag> \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is a black background with no visible content, and the tweet text does not contain any hateful or offensive language.\"}",
    "1060866919576690688": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Full retard yes. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, suggesting that it contains offensive or discriminatory content.\"}",
    "1062893745278980096": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:ikon really have me looking like boo boo the dyke \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text further supports this classification as it implies negative stereotypes and derogatory language towards the LGBTQ+ community.\"}",
    "1109221758379442176": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:From West Virginia Hillbilly Ramblings on Facebook.  West Virginia is finally patching their potholes \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is not hateful as it shows a black background with no visible content that could be considered offensive or discriminatory. The tweet text does not contain any hateful or offensive language, and it is related to a positive development in West Virginia.\"}",
    "1114203204999315456": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Bro someone get this nigga lmaoooooo \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racist slurs, which indicates that the image is likely a hateful meme.\"}",
    "1106973199714189313": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:\"Nigger?\" A commentary based on personal experience of a white kid.  #blogpost #prejudice  \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a white person, which can be interpreted as a hateful meme. The tweet text suggests that it is a commentary based on personal experience of a white kid, which implies that the image might be promoting prejudice or racism.\"}",
    "1058766384342155265": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:\ud83d\ude02\ud83d\ude02\ud83d\ude02\ud83c\uddfa\ud83c\uddf8\ud83c\uddfa\ud83c\uddf8\ud83c\uddfa\ud83c\uddf8\ud83d\ude02\ud83d\ude02\ud83d\ude02 #BuildTheWall Too funny!! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a wall, which is often associated with racism and xenophobia. The tweet text adds to the negative connotation by using hashtags related to a controversial political issue. This combination of elements suggests that the image is intended to be hateful or offensive.\"}",
    "1045141204378181632": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:If you call me a faggot: lol whatever  If you call a wrestler I like a faggot: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains derogatory language and promotes negative stereotypes. The tweet text further supports this classification as it uses derogatory language and promotes negative attitudes towards the LGBTQ+ community.\"}",
    "1106668906171826176": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Nigga shut up<tag>  ! You cross the line when you kick players in the Nuts on purpose \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the use of racial slurs and the intentionally harmful action of kicking players in the nuts on purpose.\"}",
    "1035011700154687488": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:HEY RUBE!!!<tag><tag><tag> <tag> \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which is not related to the tweet text. The tweet text contains a racial slur, making it a hateful meme.\"}",
    "1062525715348905984": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Please go on, Mr. Van Dyke. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a man's face, which is considered a hateful meme as it may be used to spread hate or discrimination towards a particular individual or group.\"}",
    "1046191221968965638": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:We love our #POTUS #TRUMP \ud83c\uddfa\ud83c\uddf8\u2764\ufe0f #MAGA #IStandWithBrett #ConfimKavanaugh #TrumpRally #WV #BuildTheWall #CNNSucks \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a crowd of people, which is being used as a meme to express support for a political figure. The tweet text further supports this classification as it contains political hashtags and expresses support for a political figure. This type of meme can be considered hateful as it may be used to spread divisive and hateful rhetoric.\"}",
    "1054510470567288833": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Redneck bunk bed... \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it may contain offensive or discriminatory content. The presence of the word 'redneck' in the tweet text might be related to the image, but it is not enough to determine the overall context and sentiment of the image.\"}",
    "1061497456444215296": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> : A Cunt..!!\ud83e\udd19 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text also supports this classification as it uses derogatory language to describe a person. The use of such language is generally considered inappropriate and harmful.\"}",
    "1107302083974164482": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Redneck Life Livin' the Dream Board Game Expansion Gut Bustin Games GUT1015 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it may contain offensive or discriminatory content. The tweet text also supports this classification as it references a game called 'Redneck Life Livin' the Dream Board Game Expansion Gut Bustin Games GUT1015', which might be perceived as insensitive or derogatory by some people.\"}",
    "1062833578202013696": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:If you need supervision then you are a child. Grow the cunt up \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which suggests that the image is a hateful meme.\"}",
    "1106892219997450240": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Nigga...but twink cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person's face, which is considered a hateful meme due to the offensive language used in the tweet text. The tweet text contains racial slurs and derogatory terms, which are not appropriate and contribute to a negative and hateful sentiment.\"}",
    "1058717947768856576": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Just got this from Groupon...obviously I have preferences set to CUNT \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests that the image is a hateful meme, as it is described as a 'cunt' image. The use of such language indicates a negative and offensive sentiment towards the image.\"}",
    "1110189771060584448": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Piers Mogul Morgan.. sympathiser &amp; flame fan fam hero to hillbilly white supremacists UK \ud83c\uddec\ud83c\udde7\ud83e\udd2e \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, suggesting that it may contain offensive or discriminatory content. The tweet text also implies that the image is associated with white supremacists, which further supports the classification of the image as hateful.\"}",
    "1053836149649747968": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Cunt Thoughts..... \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The presence of the word 'cunt' in the tweet text further supports this classification.\"}",
    "1053295004955893760": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:H. Rap Brown's Blacks And Authority ::: Highlighting Chapter Four Of 'Die Nigger Die!' \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person with the words 'Die Nigger Die!' written on it. This is considered a hateful meme as it promotes racism and discrimination.\"}",
    "1055220665601679361": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:playing king princess in the car with my mom this is the beginning of the dyke revolution \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests a negative attitude towards women, specifically towards those who identify as lesbian or gay. The reference to the 'dyke revolution' implies a disrespectful and discriminatory attitude towards the LGBTQ+ community. The image, being a black background, might be used to further emphasize the negative message. Therefore, the image can be considered as a hateful meme.\"}",
    "1105529853443522562": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> This nigga here was all sorts of a predator...idk how we let this fly \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text further supports this classification as it contains derogatory language towards a specific group of people.\"}",
    "1056875690824478721": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:DRIVE TIMES | The Vets is as slow as Dale Mabry from Van Dyke. #GMTB #tampatraffic \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a highway, which is being used as a meme to make a negative comment about traffic. The tweet text is also negative, suggesting that the highway is slow and causing traffic issues. This can be considered as a hateful meme as it is using an image to spread negativity and dissatisfaction.\"}",
    "1058501496466223104": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Random nigga: ... Me: ... Random nigga: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person, which can be perceived as a hateful meme due to the racial connotations of the term 'random nigger' used in the tweet text. The use of such language is considered offensive and discriminatory, and thus the image is classified as hateful.\"}",
    "1107108880159379458": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:When a nigga say some straight shit in the group chat \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains racial slurs and derogatory language, which is offensive and discriminatory.\"}",
    "1037379539867975680": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:she's a leather jacket lesbian... you superb dyke you graceful bitch \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language towards the LGBTQ+ community, which is considered hateful.\"}",
    "1042267262693072896": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Officer Jason Van Dyke Is Accused of Murder, But Laquan McDonald Is on Trial \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a police officer with the words 'Officer Jason Van Dyke is accused of murder, but Laquan McDonald is on trial' written on it. This suggests that the image is related to a controversial legal case involving a police officer and a black man. The use of black and white photography and the reference to a high-profile legal case can be seen as",
    "1064037095860105217": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Who is this weird cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which suggests that the image is intended to be hateful or offensive.\"}",
    "1116068117367721984": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This nigga<tag> really fuck with me \ud83d\ude2d \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text further supports this classification as it contains derogatory language towards a specific group of people.\"}",
    "1108510827680800769": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This nigga Ju is a funny ass nigga man \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language towards a specific group of people, which is considered hateful. The image itself is a black background, which might be used to display such content.\"}",
    "1113629098083885056": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> i said pick that shit up<tag> you to lil nigga pick that shit up \ud83d\ude24 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person's face, which is considered a hateful meme as it is used to insult or discriminate against a specific group of people.\"}",
    "1106985763378511873": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Nigga why?\ud83d\ude02\ud83d\ude02 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person's head, and the tweet text contains a racial slur. This suggests that the image is intended to be hateful and offensive.\"}",
    "1043075096544509952": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> I have a conservative victim card; it will protect her from tofu. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, suggesting that it may contain offensive or discriminatory content. The tweet text also implies a political or ideological bias, which could contribute to the perception of the image as hateful.\"}",
    "1115741834750365698": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Took the cunt 6 days just to say \u2018denied\u2019 lol \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the offensive language used in the tweet text, which is displayed on the image.\"}",
    "1044054213465124866": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Time to go to bed. Alls quiet on the western front.   #SJW #Feminazis \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests a negative sentiment towards social justice warriors and feminazis, which might be associated with hateful memes. The image itself is a black background, which could be used to display such content.\"}",
    "1051562692492685312": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Fire this faggot please. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains hate speech towards the LGBTQ+ community, which is not acceptable. The image itself is a black background, which might be used to spread such hateful messages.\"}",
    "1063382076483952640": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:By: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which can be perceived as a hateful meme due to its association with negative emotions or events. The tweet text also suggests that the image is meant to be hateful.\"}",
    "1055868232001679361": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:im really over you NIGGA . \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racial slurs and is offensive. The image, being a black background, might be used to further amplify the negative sentiment.\"}",
    "1043968775241043973": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Still playing the race card?  It's murder! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests that the image is a hateful meme, as it is related to race and murder. The use of the hashtag #StillPlayingTheRaceCard also implies a negative connotation towards the image.\"}",
    "1056991918641561602": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Sometimes a nigga just wanna eat yo pussy an leave .. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and racial stereotypes.\"}",
    "1054671246812680192": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> why are you so retarded? I swear you can't speak English half the time...\ud83d\ude02 So fuckin gullible too. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains insults and derogatory language towards the person being addressed, suggesting a hateful sentiment.\"}",
    "1056888791603036160": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:BIG MOOD... UDIGG<tag> \ud83d\udcb0 S/O TO MY NIGGA<tag> \ud83e\udd23 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which is not related to the hateful tweet text. The tweet contains offensive language and racial slurs, which make it a hateful meme.\"}",
    "1053514541332459520": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Up em cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, which suggests that the image might be a hateful meme.\"}",
    "1053321911688667136": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:#DCFAMILY KEEF REAL NIGGA! #TWIN \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person, and the tweet text contains racial slurs and derogatory language. This suggests that the image is intended to be hateful and offensive.\"}",
    "1114925220790505472": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I fw channel orange so les see of my nigga Frank got consistency \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains racist language and imagery, which is offensive and discriminatory.\"}",
    "1108979157634027522": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Vault Release: Twat love taps [WMV - 720p] \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text also supports this classification as it refers to the image as a 'twat love taps' and implies negative emotions or actions towards the subject of the image.\"}",
    "1043124012925308929": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:The true Islam opposes terrorism unequivocally.   \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image does not contain any hateful or offensive content. It is a simple black background with no text or imagery that could be considered hateful.\"}",
    "1044848721840738305": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Oh yea im the faggot \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, suggesting that the image might be a hateful meme.\"}",
    "1034869511575556096": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:The lads new boots. Size 7, the big footed twat...he's 13! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and derogatory terms, suggesting a hateful sentiment towards the person being referred to.\"}",
    "1056579672195108866": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Nigga leading you to heaven lmaoooo \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains racial slurs and promotes negative stereotypes.\"}",
    "1115085313905319937": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This Mexican food is making me gay and retarded \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language towards Mexican food and people, which is considered hateful.\"}",
    "1051559466502512640": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Exposed NIGGER \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person, and the tweet text contains a racial slur. This suggests that the image is intended to be hateful and offensive.\"}",
    "1058959957666611200": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Peep Omar snap , this nigga had JOE-\u201cI wanna know\u201d playing in the background lmaooooo this nigga boutta go make love \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the tweet text, which contains offensive language and racial stereotypes.\"}",
    "1043164014363271168": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> don and don jr readjusting after impeachment on their trailer park   \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a trailer park, which is often associated with negative stereotypes. The tweet text adds to the negative connotation, suggesting that the Trumps are adjusting to their impeachment in a trailer park, which is further indicative of a lower socioeconomic status. This combination of elements in the image and the tweet text can be perceived",
    "1108272470996340737": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:\u201cWhite people should be allowed to say nigga\u201d \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests a hateful sentiment towards people of color, which is reflected in the image's content.\"}",
    "1059430439650254848": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Making me Ill this twat \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and negativity towards the image, suggesting that it is a hateful meme.\"}",
    "1052542718482759680": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Bat the twat! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, suggesting that the image might be a hateful meme.\"}",
    "1060980026584195072": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:.... watching eternal sunshine of the faggot(spotless) mind \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, likely due to the tweet text referencing a controversial or offensive topic.\"}",
    "1113881152870342661": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Nigga ... you literally just said the exact same thing I did.... \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person's head, and the tweet text contains a racial slur. This suggests that the image is intended to be hateful and offensive.\"}",
    "1042849845294362625": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> This is really retarded. It's literally just a fucking meme \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, suggesting that it may contain offensive or discriminatory content.\"}",
    "1056027009522970625": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Don\u2019t give her ideas you dyke \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language towards the LGBTQ+ community, which is considered hateful. The image itself is a black background, which might be used to display such hateful content.\"}",
    "1058591088733126656": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Today I got my white trash on and washed the car while listening to 80s tunes \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image does not contain any explicit or offensive content. It is a simple black and white photo of a car wash. The tweet text does not provide any context or information that would suggest the image is hateful.\"}",
    "1048964345575571457": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag> With honesty and pragmatism... #TravelBan #BuildTheWall #DeportThemAll \ud83d\ude12 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a wall, which is often associated with negative emotions and controversial topics such as the travel ban, building a wall, and deportation. The tweet text further supports this classification as it contains hashtags related to these controversial topics.\"}",
    "1054525085636157441": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Well, that sounds retarded.  I wonder what far more city affecting issues they ignored to get this passed. XD \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language and a negative comment about the image, suggesting that it is a hateful meme.\"}",
    "1109027781160116225": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Fucking nigger \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains a racial slur, which is offensive and discriminatory.\"}",
    "1061370277794377728": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Hey. You\u2019re a racist Trump supporting cunt. Have a great day \u2764\ufe0f \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which suggests that the image is a hateful meme.\"}",
    "1053849173253124097": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Controversial, contended, career making? Find out for yourself with HILLBILLY ELEGY \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is a black and white photo of a sky, which does not contain any explicit or offensive content. The tweet text does not seem to be related to the image, and it does not contain any hateful or offensive language.\"}",
    "1054481422768111621": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> U stpd twat I voted agtgat traitor \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, suggesting a hateful sentiment towards the person being referred to.\"}",
    "1059480888994684929": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Nothing from Pittsburgh is trash just most of the white people and you know this \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains a racial slur and implies that people from Pittsburgh are trash. This is considered a hateful sentiment.\"}",
    "1035163158707666944": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:When you smell a white person read \"nigger\" instead of n****\" \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains racist language and imagery, which is offensive and discriminatory.\"}",
    "1044947705796186114": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Listen carefully, you can almost hear the slow tick-tocking of her retarded mechanical brainlet. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, suggesting that the image is a hateful meme.\"}",
    "1052610385193422849": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Hardcore cunt I am \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, which suggests that the image might be a hateful meme.\"}",
    "1042758082202198019": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Better watch what you say, or the retard police will be tweeting down your neck. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which suggests that the image is a hateful meme.\"}",
    "1061230856298205185": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Tired of the liberal race card \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, suggesting that it may contain offensive or discriminatory content. The presence of the tag 'Tired of the liberal race card' in the tweet text further supports this classification, as it implies a negative attitude towards liberals and a possible association with racism.\"}",
    "1062821404989636619": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:this picture just pushed me in the street and called me a nigger \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the tweet text, which suggests that the picture has caused harm or offense to the viewer.\"}",
    "1061292868533436417": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Imagine just smoking the cigarette without taking a pic like a retarded human being!!!!!!!! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, suggesting that the image is intended to be hateful.\"}",
    "1107682311171162112": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Got me FUCKED up if you think imma lose to a nigga that look like Anakin in episode 3  \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which suggest that the image is a hateful meme.\"}",
    "1107553966022410240": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> shut up faggot  \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language towards the LGBTQ+ community, which is considered hateful. The image itself is a black background, which might be used to display such hateful content.\"}",
    "1063597636803051522": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Trojan Horse #BUILDTHEWALL.<tag> \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a wall, which is often associated with racism and xenophobia. The tweet text suggests a political agenda that promotes discrimination and division. These factors contribute to the classification of the image as hateful.\"}",
    "1106526228062851072": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I definitely miss her dick but damn I really want to bury my face in her delicious looking cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains explicit and offensive language in the tweet text.\"}",
    "1061591743777460225": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Watch it: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which can be perceived as a hateful meme due to its association with negative emotions or events. The tweet text does not provide any context or information that would change this classification.\"}",
    "1064086616518447104": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Im sleep imagine playing with the toxic cunt\ud83e\udd23 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is considered hateful.\"}",
    "1051598539078299648": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Are you playing the race and women card again! Illegals DO NOT deserve the right to vote! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it promotes discrimination against a specific group of people, specifically women and people of color. The tweet text further supports this classification as it is racist and sexist in nature.\"}",
    "1058820973514973184": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Y\u2019all retarded \ud83d\ude12 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which suggests that the image might be a hateful meme.\"}",
    "1055873305528410112": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Hahahaha canny get away with how this cunt spells ma name \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which suggests that the image is a hateful meme.\"}",
    "1024187101821259776": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Retarded \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, suggesting that the image might be a hateful meme.\"}",
    "1035996233280585729": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I LITERALLY COMITTED SUICIDE IN ODYSSEY LMAO I'M SO RETARDED \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests that the person is feeling depressed and unintelligent, which can be perceived as hateful towards themselves. The image of a black background with no objects or text can be associated with the negative emotions expressed in the tweet.\"}",
    "1064281617320030209": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag> Warning!!!! Retard Alert \ud83d\udea8 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The presence of the warning label further supports this classification.\"}",
    "1050226940219719680": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Fellas, call me a faggot all you want BUT THIS SHIT SLAPS \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language towards the LGBTQ+ community, which is considered hateful. The image itself is a black background, which might be used to display such content.\"}",
    "1058714003537625088": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Happy birthday<tag> you healthy cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language towards a woman, which indicates a hateful sentiment.\"}",
    "1035218777795911680": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:When Lil Wayne says \u201con some faggot bullshit\u201d in A Milli \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme that is considered hateful due to the use of derogatory language in the tweet text.\"}",
    "1064245761125289985": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:A wish ma Bint would just F#ck off \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is considered hateful.\"}",
    "1049681905396867072": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Tried a new angle. He looks retarded lmao \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and a derogatory remark towards a person with a disability. This is considered hateful and inappropriate.\"}",
    "1058434810010574850": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:of course hillbilly south georgia at it again \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, suggesting that it may contain offensive or discriminatory content. The tweet text also implies a negative stereotype about a specific region or group of people, which further supports the classification of the image as hateful.\"}",
    "1055780905640435714": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Ahahaha just made this cunt ragequit in FutChamps \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests that the image is a hateful meme, as it is described as a 'cunt' and the person has ragequit in FutChamps. This implies that the image might be offensive and intended to provoke a negative reaction.\"}",
    "1055296980925247488": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Huh, Trailer Channel.... it\u2019s movie trailers not the kind that go in a park. I might be a redneck. \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is a black and white photo of a sky, which does not contain any content that can be considered hateful.\"}",
    "1042198818580824065": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Wishin a happy birthday to this redneck<tag> \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it may contain offensive or discriminatory content. The tweet text also implies that the image is related to a redneck, which might be considered derogatory by some people.\"}",
    "1058171987997179907": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:So is there like a huge racial gap in modern Turkey or am i just retarded \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it is a picture of a black person with a caption that implies racism and discrimination. The tweet text also supports this classification as it contains a racial slur.\"}",
    "1063469975942426624": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Watch it: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which can be perceived as a hateful meme due to its association with negative emotions or events. The tweet text does not provide any context or information that would change this classification.\"}",
    "1108134328477908992": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:My nigga bouttta beat a trial..yea Dey gon hate on him\ud83d\ude02\ud83d\ude02\ud83d\ude02 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language and humor that could be perceived as hateful towards a person. The use of the word 'nigger' and the reference to a trial suggest a negative attitude towards a specific individual or group.\"}",
    "1044166145388019713": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> My nigger \ud83d\udc4c\ud83d\udc4c\ud83d\udc4c \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person's face, and the tweet text contains a racial slur. This suggests that the image is intended to be hateful and offensive.\"}",
    "1044068034388754432": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> As our hillbilly friends sing \u201cAnd the lightning strikes\u2026\u201d \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, suggesting that it may contain offensive or discriminatory content.\"}",
    "1042090512730267649": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:WHY DID I USED NOFAIL FUCKING RETARD \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, which suggests that the image might be a hateful meme.\"}",
    "1056086233296777217": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This Lee cunt is that fried #PS4share  \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which suggests that the image is hateful.\"}",
    "1046455001034371072": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag> hahaha dream on retard \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, suggesting that the image is a hateful meme.\"}",
    "1046652320669421568": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This is the most hypocritical and retarded shit I've seen in a while. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests that the image is hateful, and the fact that it is a black and white photo of a dark sky might be perceived as negative or unappealing by some people.\"}",
    "1050675855783944193": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Little twat \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, suggesting that the image might be a hateful meme.\"}",
    "1110267468608606208": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I just robbed a little nigga...-Me 2019 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person's head, and the tweet text suggests a violent and racist act. This is considered a hateful meme.\"}",
    "1108826407231205378": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Finally saw captain marvel and all i can say bout this nigga Thanos is that \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is considered hateful. The image itself does not seem to be hateful, but the context provided by the tweet text makes it appear that way.\"}",
    "1105092560605904898": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Surrender is not a weakness \u2026.\u2728\ud83d\udc24\u2728mooji \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a bird, which is being used as a symbol of surrender. The tweet text suggests that the image is being used to promote a message of not giving up or surrendering. This can be perceived as hateful, as it may be seen as promoting a negative attitude or message.\"}",
    "1114160350792957953": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Good nigga thanks gimme lil credit man \ud83d\ude02 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person's head, and the tweet text contains racial slurs and derogatory language. This suggests that the image is intended to be hateful and offensive.\"}",
    "1110248092899704832": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> nigga \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark background, which can be perceived as a hateful meme due to the use of the word 'nigger' in the tweet text. This word is considered offensive and racist, and its presence in the tweet text suggests that the image might be promoting or supporting such language.\"}",
    "1056581627835494401": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Them: HOW are you still listening to that racist ass cunt Sabrina Claudio?!?  Me: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racist language and is considered hateful.\"}",
    "1056241080570540033": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Me and<tag>. How I\u2019m slaying and she\u2019s retarded. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text further supports this classification as it contains derogatory language towards a specific individual.\"}",
    "1044050095862353920": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Miss this gorgeous dork and tired of Canadian internet twat blocking us \ud83d\ude11 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains negative language towards a person or a group, suggesting a hateful sentiment. The image itself is a black background, which might be used to create a dramatic or mysterious atmosphere, but it does not contain any explicit content that would make it hateful.\"}",
    "1055264349084880897": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:watch now \ud83d\udc47 \ud83d\udc49 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which can be perceived as a hateful meme due to its association with negative emotions or events. The tweet text does not provide any context or information that would change this classification.\"}",
    "1113462778906521600": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Away from my desk for two minutes... wolves cunt puts this as my desktop background... \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests that the image is hateful, as it is described as a 'hateful meme' and the user is away from their desk for two minutes, implying that they are not in control of the image being displayed.\"}",
    "1108402381727895553": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:went from starting to care about this nigga to now starting to like him?!?! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language and a negative sentiment towards a person, which indicates a hateful sentiment. The use of the word 'nigger' is considered offensive and discriminatory, and it is not appropriate to use such language in a public forum.\"}",
    "1057987103173365765": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Have you got your daily dose of triggered?! #SJW #feminism #feminist #meme \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it may contain offensive or discriminatory content that is intended to provoke negative reactions or emotions.\"}",
    "1024135828707139584": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> She said nigger \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a woman with the word 'nigger' written on her forehead. This is considered a hateful meme as it uses racial slurs and promotes negative stereotypes.\"}",
    "1049824837731057665": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:a NIGGER ?!? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person, and the tweet text contains a racial slur. This suggests that the image is intended to be hateful and offensive.\"}",
    "1047223924273106945": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> AKA hillbilly ask any Timberwolf \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text also implies that the image is related to a specific group, which could further contribute to the negative sentiment.\"}",
    "1046465338194313216": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:excuse me, faggot coming thru \ud83e\udd20#embracethequeer \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which is not related to the tweet text. The tweet text contains derogatory language towards the LGBTQ+ community, making it a hateful meme.\"}",
    "1107076567920840704": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Yeah fuck Kylie Jenner stupid cunt! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language towards Kylie Jenner, indicating a hateful sentiment.\"}",
    "1113642227232923648": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> My nigga got a black belt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, which suggests that the image might be a hateful meme.\"}",
    "1056851270923886592": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:maybe if ch*rlie p*th did this he wouldnt be a cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the use of offensive language in the tweet text, which is associated with the image.\"}",
    "1059547022376742912": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Fuck off cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, which suggests that the image might be a hateful meme.\"}",
    "1059579636261232640": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Fuck off cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, which suggests that the image might be a hateful meme.\"}",
    "1062699720206880768": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Found a mentally retarded kid in skywars yesterday \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains content that is offensive or discriminatory towards a particular group of people, such as the mentally retarded child in the tweet.\"}",
    "1105631671867588608": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> This nigga !!! This happened \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, and the tweet text supports this classification as it contains offensive language.\"}",
    "1042361978386362370": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:LA nigger \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person, which is often associated with racism and hate. The tweet text further supports this classification as it contains a racial slur.\"}",
    "1116630443900555267": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This cunt taking the piss ! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which suggests that the image is hateful.\"}",
    "1024881972244443136": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Just sold a #clip! Rimming Faggot #CoercedGay Get yours on #iWantClips! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains derogatory language and promotes negative stereotypes about the LGBTQ+ community.\"}",
    "1024029562722758656": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:fucking cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, which suggests that the image might be a hateful meme.\"}",
    "1105539354716504064": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Yeah you cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, suggesting that the image might be a hateful meme.\"}",
    "1042291197543440385": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Keep your NIGGER DUDE away from ME - in as many as ALLLLL cases if possible! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains racial slurs and promotes discrimination against a specific group of people.\"}",
    "1036964604587458560": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Nike walks away from the racist redneck couch potato demographic. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, suggesting that it may contain offensive or discriminatory content. The tweet text also supports this classification as it refers to a 'racist redneck couch potato demographic,' which can be perceived as derogatory and discriminatory.\"}",
    "1024259887424057344": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag> Typical \"retard\" mis labeling those who disagree with them!! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, suggesting that it may contain offensive or discriminatory content. The tweet text also supports this classification by using derogatory language to describe those who disagree with the content of the image.\"}",
    "1043488569514323969": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Damn half the population really be retarded \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults a significant portion of the population, which is considered hateful.\"}",
    "1109876280462315527": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Surrender to what is and what isn't. Never force it. \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image does not contain any explicit or implicit hate speech, and the tweet text suggests a peaceful and non-aggressive approach to life.\"}",
    "1110060737135812611": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Nigga said holupholupholup son i am CRYING LMFAOOOOOOOOOOOOOOOOOOOO  \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which is not related to the hateful tweet text. The tweet contains racial slurs and offensive language, making it a hateful meme.\"}",
    "1035437610557222913": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:marshall really called me retarded \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person's head, which can be perceived as a hateful meme due to the negative words used in the tweet text, such as 'really' and 'retarded'. The tweet text suggests that the person is being insulted, which can be considered as hateful behavior.\"}",
    "1058830313835716609": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> With love from Syracuse you cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, which suggests that the image might be a hateful meme.\"}",
    "1064387261721137152": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:playing this trying to disturb my dyke neighbors lol #dykepurge \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains content that is intended to harm or discriminate against a specific group of people, such as the LGBTQ+ community. The tweet text further supports this classification as it implies a negative attitude towards the neighbors, specifically those who identify as dykes.\"}",
    "1107103294034530305": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Build The Wall T-Shirt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a wall, which can be interpreted as a reference to the construction of a physical barrier, such as a wall. The tweet text 'Build The Wall' further supports this interpretation, making it a hateful meme.\"}",
    "1064023456713531393": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> a viral white person who isn\u2019t trash? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a viral white person who isn't trash, which implies that it is a hateful meme targeting a specific group of people.\"}",
    "1024060211869483008": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> She's another feckless cunt! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which suggests that the image is a hateful meme.\"}",
    "1060922398491328514": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:im a retard \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, suggesting that the image might be a hateful meme.\"}",
    "1035251388295438336": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Get your filthy mother fucking hands off him you vile twat #ramos #salah #lfc \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is likely to be considered hateful. The image itself does not seem to be directly related to the tweet text.\"}",
    "1055903996400025603": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:gonna start putting retarded amounts of hours into this game  \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, suggesting that the image might be a hateful meme.\"}",
    "1043207063596421121": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> And by \u201cbit\u201d he means blocked because we all know SJW\u2019s don\u2019t engage they only monologue \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person's head, with the words 'SJW' and 'monologue' written on it. This could be interpreted as a hateful meme, as it may be seen as derogatory towards a certain group of people. The tweet text further supports this classification, as it seems to be related to the image and its content.\"}",
    "1061671576020701184": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:That fucking voice. Cunt. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, suggesting that the image might be a hateful meme.\"}",
    "1108751042773221378": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Hurry Up Weedman ..... It\u2019s Not Even Finna Be Wake&amp;Bake Anymore Cause Ah Nigga Been Up \ud83d\ude12\ud83e\udd26\ud83c\udffe\u200d\u2642\ufe0f\ud83d\ude02 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which make it a hateful meme.\"}",
    "1051431518915182592": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Straight up White Trash, God bless \u2018im\ud83d\ude02\ud83c\uddfa\ud83c\uddf8\ud83e\udd20 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text further supports this classification by using derogatory language to describe a specific group of people.\"}",
    "1034750882854842369": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> you are retarded thanks \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, suggesting that the image is a hateful meme.\"}",
    "1061029923832430592": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:What happen to this nigga he had some hits in south Florida \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racial slurs and is offensive. The image, being a black background, might be used to further spread such hateful messages.\"}",
    "1041747122440359938": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Lmao don't trust this guy he is a scammer<tag> fucking faggot good job I didn't give him my real one \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which suggest that the image is intended to be hateful.\"}",
    "1059480692088807424": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Tit-for-tat #WinWinSituation #NoWars #NoRefugees \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is a simple black background with no visible content, and the tweet text does not contain any hateful or offensive language.\"}",
    "1058948075627180032": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> This is one of the main reasons we elected<tag> #BuildtheWall \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a wall, which is often associated with racism and discrimination. The tweet text suggests a political stance that supports building a wall, which can be seen as a hateful message towards certain groups of people.\"}",
    "1041857632368320512": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> YoU're ReTarDed \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content.\"}",
    "1036333471277477890": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:SJW-English Dictionary 05 / Example 15  feminism  1. the idea that women are weak and stupid \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a woman's face, which is often used as a meme to mock or belittle feminists. The tweet text further supports this classification as it uses derogatory language to describe feminism.\"}",
    "1050410758746636288": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Anybody who spells their name with two n's is basically a.... Twat. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which suggests that the image is a hateful meme.\"}",
    "1050585025517932544": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Can y\u2019all believe what this dumbass nigger said to me? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains racial slurs and is disrespectful towards a specific group of people.\"}",
    "1044350780701126656": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Arno G. had a #paddleboarding session in Destin, United States. Pictures here: \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is a black and white photo of a paddleboarding session in Destin, United States. It does not contain any hateful or offensive content.\"}",
    "1053884000278851584": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> come on, you must have a witty quote for this cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, and the tweet text suggests a negative or offensive sentiment towards the subject.\"}",
    "1050465099062816768": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Ghetto Kanye and White Trash Donnie \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text further supports this classification as it refers to 'ghetto Kanye' and 'white trash Donnie,' which are derogatory terms. The image itself is black, which might contribute to the perception of it being hateful.\"}",
    "1057317922681618433": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> I\u2019ll happily crowdfund him to take a horrible cunt like you you court... \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and a threat towards the person who posted the image. This suggests that the image is intended to be hateful or offensive.\"}",
    "1050003986689024001": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:California \u2014 \u201cDriving\u201d Illegal Immigrants to the Polls? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme that is spreading misinformation and promoting hateful rhetoric. It is not a neutral or positive representation of the situation in California.\"}",
    "1108446682604290048": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Every time my nigga<tag> gets another accolade I wanna snuff Nick Young \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which are indicative of a hateful sentiment. The use of the word 'nigger' is particularly concerning, as it is a deeply offensive racial epithet.\"}",
    "1062908325971591169": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> thought dude in the back was a dyke with puff balls \ud83d\ude2c\ud83d\ude02 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the offensive and derogatory language used in the tweet text, which targets the LGBTQ+ community.\"}",
    "1062202314373644289": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag>   You dumb cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language towards women, which indicates a hateful sentiment. The image itself is a black background, which might be used to create a more dramatic or intense atmosphere, but it does not contain any explicit content that would make it hateful.\"}",
    "1045002171169697792": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Looks like even \u201cThe View\u201d nutters are thinking<tag> \u2018s gone full retard. \ud83d\ude02 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests that the image is a hateful meme, as it is described as 'full retard' and 'nutters' are referred to. The use of derogatory language in the tweet implies a negative sentiment towards the image.\"}",
    "1062577783694487552": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Spent 10 whole dollars on this retarded ass game smh \ud83e\udd26\u200d\u2640\ufe0f someone come save me \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains negative language and insults towards the game, suggesting a hateful sentiment.\"}",
    "1057018137303007234": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:He calls his willy a Corey hahahahah hes the best cunt man\ud83d\ude02\ud83d\ude02\ud83d\ude02\ud83d\ude02\ud83d\ude02 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and derogatory terms, such as 'cunt' and 'Corey', which are not appropriate for sharing on social media platforms.\"}",
    "1055744300473036800": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:White Trash Zombie Apocalypse by Diana Rowland | White Trash Zombie\u00a03 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it may contain offensive or discriminatory content. The tweet text also supports this classification as it refers to a book called 'White Trash Zombie Apocalypse' by Diana Rowland, which might be associated with negative stereotypes or discrimination.\"}",
    "1025086949537841153": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag> Get that shaved off ya absolute roaster, Ive got a redneck for you. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text further supports this classification as it contains derogatory language towards a specific group of people.\"}",
    "1113589572942929920": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:\"Labels used to treating rappers like a slave nigga, starving artists just be happy with your fame nigga\" \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it uses derogatory language to describe artists and rappers, implying that they are treated unfairly and should be content with their fame despite their struggles.\"}",
    "1044733561360666624": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Dude... you should never go Full Retard. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests that the image is hateful, as it implies that the person should not go 'full retard' and implies that the image is not to be taken seriously.\"}",
    "1115109910298222593": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Move Nigger she mine \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racist language, which is considered hateful. The image itself is a black background, which might be used to display such offensive content.\"}",
    "1054053257453158403": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:mars the next frontier for memes -a twat \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests that the image is a hateful meme, as it refers to the image as a 'twat' and implies that it is meant to be offensive or derogatory.\"}",
    "1042096319102418944": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> My nigger \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person, and the tweet text contains a racial slur. This suggests that the image is intended to be hateful and offensive.\"}",
    "1049796262659272704": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Her: \u201cYou must be retarded if you think we fuckin\u201d  Me: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, suggesting that the image might be a hateful meme.\"}",
    "1109294594167050240": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> from my bed nigga it\u2019s a Friday so I\u2019m watching this shit late \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which suggest that the image is a hateful meme.\"}",
    "1108805940524941312": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:RT if you would sign up for this lesson. #faggot #diaperboy \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language towards the LGBTQ+ community, which is considered hateful. The image itself does not contain any explicit content or language, but it is associated with the hateful tweet.\"}",
    "1042703803705831424": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> only if they are white trash \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, suggesting that it contains offensive or discriminatory content.\"}",
    "1056475839435587584": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Cunt alarm \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a woman's face, which is considered offensive and hateful. The tweet text also adds to the negative sentiment of the image.\"}",
    "1057464067949056000": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Never go full retard. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests that the image is hateful, as it implies that the person is not retarded and should not be treated as such.\"}",
    "1047279611170738182": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:if anyone acc believes this game is good im sorry to tell you but youre retarded #FIFA19 #XboxShare \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text further supports this classification as it contains insulting language towards people who enjoy the game.\"}",
    "1025235928737095681": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This hoe went RETARDED hard \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text further supports this classification as it contains derogatory language towards women.\"}",
    "1035909140042928129": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Twat. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content.\"}",
    "1058074016391618562": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Dyke!?!? Shiiiiitttttttttttttttttttt lol \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language towards the LGBTQ+ community, which indicates that the image is hateful.\"}",
    "1051160708862406656": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Aaand the replies are retarded too... Good play, Eurogamer. So when do memes become illegal again? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it may contain offensive or discriminatory content. The tweet text also implies that the image is not appropriate or should be removed.\"}",
    "1115047727644184576": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Congratulations! How about Hubert, my hillbilly bloodhound? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it may contain offensive or discriminatory content. The tweet text also implies that the image is related to a hillbilly bloodhound, which could be considered as derogatory language towards a specific group of people.\"}",
    "1054416363110969344": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:enough is enough cunt s \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text further supports this classification as it uses derogatory language towards women.\"}",
    "1063716657691017216": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Full Gallery: \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is a black and white photo of a sky, which does not contain any explicit or offensive content. It is not a hateful meme.\"}",
    "1042967654624120834": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> look at this faggot \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content towards a particular group of people.\"}",
    "1064356291722833921": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Hes a retarded piece of shit on your shoes. You have other shit you need to worry abput! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which suggest that the image is a hateful meme.\"}",
    "1105621113919492096": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I SAID U NOT FUCKING DEAD ASS MY NIGGA. NO FUCCIN WAY!!!!!!!!!!! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and aggressive tone, suggesting a hateful sentiment.\"}",
    "1064184513520066560": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:the white trash jumped out \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The presence of the word 'trash' in the tweet text further supports this classification.\"}",
    "1108984453278380033": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:\"you aint let nas down my nigga\" #HipHopFriday \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is considered hateful. The image itself is a black background, which might be used to display such content.\"}",
    "1054638562333868034": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:You cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a woman's face, which is considered offensive and disrespectful. The tweet text further supports the classification as it contains derogatory language.\"}",
    "1053402498088689666": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> \"See, tRump brought all us ignorant, inbred, white trash, racist, Nazis together!\" \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and derogatory terms, suggesting a hateful sentiment towards a certain group of people. The image itself is a black background, which might be used to further emphasize the negative message.\"}",
    "1062857670531649536": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Nigger it\u2019s not even lyrics. Are you even a cardi b fan bro?   \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person's head, and the tweet text contains a racial slur. This suggests that the image is intended to be hateful and offensive.\"}",
    "1044717838471229441": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:the brown hair.. PLEASE say dyke \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains derogatory language and promotes negative stereotypes about the LGBTQ+ community.\"}",
    "1053485289170235394": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> We know ..we can tell the difference in baby mommas. Claim pimp and playa and have a half retarded lookin bitch \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text provided further supports this classification as it contains derogatory language towards women.\"}",
    "1110381345765838848": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Ooooooorrr are you trying to redefine \u201cwhite trash\u201d like Red Neck country club? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, suggesting that it may contain offensive or discriminatory content.\"}",
    "1037447790614519808": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Crazy and retarded I'll tell you that!! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, suggesting that the image is a hateful meme.\"}",
    "1115384745972596741": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> taking it back #RonNFez #Rube #Bennington \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it may contain offensive or discriminatory content. The tweet text also implies a negative sentiment towards a specific group or individual, further supporting the classification of the image as hateful.\"}",
    "1043133164309426178": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Cause you are stupid racists redneck!! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, suggesting that the image is a hateful meme.\"}",
    "1105587773736550401": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Letting go, brave surrender...  #MusicOnVero #NP #music #morningjam<tag><tag> \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is a black background with no visible content, and the tweet text does not contain any hateful or offensive language.\"}",
    "1044354403975786496": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> What a retard (aka dumbass) \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, suggesting that the image might be a hateful meme.\"}",
    "1050780835480313859": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Lol ion care what none of y\u2019all say, this man, Tekashi 69 is such a lil bad dyke bitch\ud83d\ude0d keep it up baddie \ud83e\udd2a\ud83d\ude0d\ud83d\ude0d \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, likely due to the tweet text which contains offensive language and derogatory terms.\"}",
    "1055930569530335235": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Another worthless, wast of air, inbred, white trash, tRump supporter. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, likely due to the negative and offensive language used in the tweet text.\"}",
    "1110321814763458562": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:FOR ANYBODY WHO MISSED IT 2k GOT DURAGSSSSS... NIGGA WE MADE IT \ud83d\ude2d\u2757\ufe0f\ud83d\udd25<tag>  #Nba2k19 #Nba2k #2k19 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text further supports this classification as it uses derogatory language and references to race, which are considered inappropriate and harmful.\"}",
    "1041813099311972352": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Oh yeah... right,  as if he is so perfect.... Twat! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains negative language towards the image, suggesting that it is a hateful meme.\"}",
    "1062466431848210434": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:The true Islam has no room for terrorism   \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which is not related to the tweet text. The tweet text contains a statement about Islam and terrorism, which can be considered as hateful. However, the image itself is not hateful.\"}",
    "1042077739686277120": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I don\u2019t know why Twitter recommends tweets about football. I don\u2019t follow retarded people... \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet contains offensive language and a negative attitude towards football fans, which indicates a hateful sentiment.\"}",
    "1054095216305754112": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Twat them as hard as you can as far away as you can then \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text also supports this classification, as it encourages aggressive behavior towards a specific group of people.\"}",
    "1055945302467694592": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Me once I get a nigga that\u2019s gon\u2019 let me SWIPE THEM VISAS! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racist language and promotes violence, which indicates that the image is hateful.\"}",
    "1035389116660178944": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> DeKlantis messed up and activated the race card. Wrong move! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a white man standing in front of a black man. The white man is holding a gun, and the black man is kneeling. This could be interpreted as a hateful meme, as it may be perceived as promoting racism or violence.\"}",
    "1050561308154839042": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag> Typical WI fat ass redneck \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text further supports this classification as it uses derogatory language to describe a person.\"}",
    "1053328062622904325": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:PLEASE A NIGGA FINNA GO CRAZY IN DIS MUHFUCKAAAAA \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racist language and is considered hateful.\"}",
    "1054126992155725829": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> NIGGA UR BRAND IS ALSO UR TALENT UR JOB CAN ALSO BE UR TALENT !!!!!! U COON !!! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text further supports this classification as it uses derogatory language towards African Americans.\"}",
    "1109498457012752387": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Little twat lied to me \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The presence of the word 'twat' in the tweet text further supports this classification.\"}",
    "1054536497284694017": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:#VoteRed to save America &amp; end this demo-socialist bullshit.<tag> #BuildTheWall \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a wall, which is often associated with political views. The tweet text suggests a political stance against democratic socialism, which is considered hateful by some. The combination of the image and the tweet text creates an impression of a hateful meme.\"}",
    "1110287380945268738": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Me: happy birthday Anthony  Anthony:thx now give me my money dumb fuck u stupid dyke \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet contains offensive language and insults, suggesting a hateful sentiment towards the person being celebrated.\"}",
    "1062920590573666304": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> White trash grifters! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content towards a particular group of people. The tweet text further supports this classification as it refers to 'white trash grifters', which can be perceived as derogatory and discriminatory towards white people.\"}",
    "1108978450159882240": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Niggas out here thinking this shit fuckin candy land out here nigga. This ain't no fuckin candy land nigga. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the racial slurs and derogatory language used in the tweet text.\"}",
    "1047565398831333376": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> WE? You aren't any part of we... #BanIslam \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which is being used as a backdrop for a hateful tweet. The tweet contains a message that is discriminatory and promotes negative sentiment towards a specific group of people. This suggests that the image is being used to spread hate and discrimination, making it a hateful meme.\"}",
    "1107718179470671878": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> \ud83d\udca6\ud83d\udca6\ud83d\udc45 You ain't had a wild nigga before right? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial stereotypes, which suggests that the image is a hateful meme.\"}",
    "1064027537435754498": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag><tag> Faggot suck a dick you mad cause I got offered to Harvard you thot \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person's head, and the tweet text contains derogatory language towards the LGBTQ+ community. This suggests that the image is intended to be hateful and discriminatory.\"}",
    "1054051986234953728": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:#Illegals enforce the #law #DeportThemAll #LockThemUp #VoteRed #VoteDemsOut <tag> #BuildTheWall \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a group of people, which can be interpreted as a hateful meme. The tweet text suggests a strong political stance and advocates for the removal of undocumented immigrants, which can be seen as hateful towards certain groups of people.\"}",
    "1025078676021567488": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:OMG!<tag> is playing the victim card! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, suggesting that it may contain offensive or discriminatory content.\"}",
    "1052623551096922112": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:\"Dyke rights!\" -Jung Hoseok \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language towards the LGBTQ+ community, which is considered hateful.\"}",
    "1064304980960645121": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Remember when Ellen stopped Demi because she tried to say cunt. \ud83d\ude02\ud83d\udc4f\ud83c\udffb \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme that is considered hateful due to its content, which is a reference to a controversial incident involving Ellen DeGeneres and Demi Lovato.\"}",
    "1043569709738852360": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Look at this retard<tag> \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which suggests that the image is intended to be hateful.\"}",
    "1114184460768096256": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:It\u2019s fucked up I can\u2019t get back into my account, do not trust<tag> the nigga is a fucking scammer...\ud83e\udd26\ud83c\udffd\u200d\u2642\ufe0f \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet contains offensive language and a negative sentiment towards a specific group of people, which indicates that the image is hateful.\"}",
    "1058528287050383363": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Thankyou time to find a random nigga named kevin \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person, and the tweet text contains a racial slur. This suggests that the image is intended to be hateful and promotes negative stereotypes.\"}",
    "1042411739256504321": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:CROWDER CONFRONTS: Slandering SJW PROFESSOR! WATCH =&gt; \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person, which is often associated with racism and hate. The tweet text suggests that the person is slandering a SJW professor, which could be interpreted as promoting negative stereotypes and discrimination against certain groups. The combination of the image and the tweet text creates an impression of a hateful meme.\"}",
    "1058209684924944384": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:#nowplaying The Redneck Manifesto - I Don't Speak the Monkey Language, I Just Hear It / Thirtysixstrings \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it may contain offensive or discriminatory content. The tweet text also supports this classification as it references a controversial and potentially offensive song.\"}",
    "1108175952851419136": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Best Buckin&amp;#8217; Dad Ever Funny Redneck Dad Gift T-Shirt  \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a man's face, which is often associated with negative stereotypes and prejudices. The tweet text suggests that the image is meant to be humorous, but it could still be perceived as offensive or hateful by some people.\"}",
    "1056611951906902016": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Feel sorry for you guys for having an absolute twat as your president \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains negative words and insults towards the president, which indicates a hateful sentiment. The image itself is a black background, which might be used to create a dramatic or intense atmosphere, but it does not contain any explicit content that would make it a hateful meme.\"}",
    "1105508569263362050": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Nigga said he suck the herion out her pussy \ud83d\udc80 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and racial slurs, which are not appropriate or respectful.\"}",
    "1116465441424039938": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Collusion of Zionazi war criminals... \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, suggesting that it contains content that promotes hate or discrimination towards a particular group or individual.\"}",
    "1107833621673623553": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:PATRIOTS NEVER SURRENDER YOUR WEAPONS \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a gun, which is a symbol of violence and aggression. The tweet text suggests a political message that promotes the idea of not surrendering one's weapons, which can be interpreted as a call to arms and a threat to those who disagree with the message. This combination of elements creates a hateful meme.\"}",
    "1114583150162845698": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:The Redneck view on How did we become a snowflake culture \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, suggesting that it may contain offensive or discriminatory content. The tweet text also supports this classification as it appears to be promoting a controversial and potentially harmful viewpoint.\"}",
    "1053351161409888256": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:My nigga I\u2019m hollerin \ud83d\ude02\ud83d\ude02\ud83d\udc80\ud83d\udc80 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which is not related to the hateful tweet text. The tweet text contains offensive language and racist stereotypes, making it a hateful meme.\"}",
    "1053988426515668993": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Bring in the military and shut down our border! #MAGA #KAG #BuildTheWall \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests a call for military action and the closure of the border, which can be perceived as hateful or divisive. The image of a black background with no visible content might be used to evoke a sense of urgency or seriousness in the message.\"}",
    "1051631943991742465": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Democrats have gone full retard. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language towards a political party, which is considered hateful.\"}",
    "1108562670347796481": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> ..... can't a nigga feel special for once \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text further supports this classification as it contains derogatory language towards a specific group of people.\"}",
    "1107958166971535360": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I miss youuu ima go over tomorrow so be home nigga I lovee youu \ud83d\udc37\ud83e\udde1<tag> \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and a reference to a racial slur, which indicates a hateful sentiment.\"}",
    "1063481238076444672": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Music on full the drown out the annoying cunt running the spin class \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, suggesting that the image might be a hateful meme.\"}",
    "1061326119482331137": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:my boyfriend is a cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, which suggests that the image might be a hateful meme.\"}",
    "1054247415371358209": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> This retard started tweeting trash again. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, and the tweet text suggests that it is being used to spread negativity and insults.\"}",
    "1043088479196860416": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Reasons I love being a dyke y\u2019all. I have an excuse for never wearing uncomfortable shoes. \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is not hateful as it is a simple black background with no offensive content. The tweet text is also not related to the image and does not contain any hateful language.\"}",
    "1062035390545256448": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Listen to this. Bruh mfs so retarded bruh! #PS4share  \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which suggests that the image is a hateful meme.\"}",
    "1046803078786224128": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Watch it: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which can be perceived as a hateful meme due to its association with negative emotions or events. The tweet text does not provide any context or information that would change this classification.\"}",
    "1050648395726041089": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag> You mean yourself right? TWAT. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, suggesting that the image is a hateful meme.\"}",
    "1062533565727076352": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:IS CRASH BANDICOOT REALLY MARIO\u2019S RETARDED FNAF DOG FROM UNDERTALE?!?!?!<tag> \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dog, which is being used as a meme to make a joke about the game Crash Bandicoot. The tweet text suggests that the image is meant to be humorous, but it could be perceived as offensive or hateful by some people.\"}",
    "1049769928696451072": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Pineapple Express fuckn faggot \ud83d\ude02\ud83d\ude02\ud83d\ude02\ud83d\udd25<tag> \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and derogatory terms, which suggest that the image is a hateful meme.\"}",
    "1058548848296189952": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> I GOT CANDY MY NIGGA \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which are indicative of a hateful meme.\"}",
    "1044753550750806016": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag> Another retard without a 401k \u2764\ufe0f\ud83d\ude94\ud83c\uddfa\ud83c\uddf8 we voted \ud83d\uddf3 we won game over \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains content that is intended to be offensive or harmful. The tweet text also supports this classification, as it appears to be derogatory and disrespectful towards a specific group of people.\"}",
    "1061024171872997376": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> My nigga you to old to be talkin bout smoke session wit the gang \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which are indicative of a hateful meme.\"}",
    "1116541573506924544": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Playing the race card<tag> \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person's head, which is being used as a hateful meme to play the race card. The tweet text further supports this classification as it implies that the image is being used in a racist manner.\"}",
    "1107375306703134720": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I really love this nigga<tag> \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which are indicative of a hateful sentiment.\"}",
    "1108474063788433411": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I have no words for this cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, and the tweet text contains offensive language towards a person, which further supports the classification of the image as hateful.\"}",
    "1057657721368035328": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:the sjw mafia strikes again. More garbage #sheranetflix redesign for their agendas. #shera #SJW #garbage #netflix \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, likely due to the content of the tweet text, which is critical of social justice warriors and their agendas. The use of the term 'garbage' and the reference to the SJW 'mafia' suggest a negative and hostile tone towards these groups.\"}",
    "1045948096184807424": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Concrete fookin lightshade the twat ay it. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, suggesting a hateful sentiment towards someone. The image itself is a black background, which might be used to create a more dramatic or intense atmosphere, but it does not contain any explicit or hateful content.\"}",
    "1054717810872606720": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Retard dough. Takes half a day but it's worth it. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which suggests that the image is a hateful meme.\"}",
    "1106555513569988609": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Biggest pussy alive\ud83d\udcaf<tag> you are a bitch ass nigga #freeshowboy \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text further supports this classification as it contains derogatory language and insults towards a specific group of people.\"}",
    "1110171137173000192": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Nigga u got me to explore off this shit \u2620\ufe0f \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, and the tweet text supports this classification as it contains offensive language.\"}",
    "1059587855658274816": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Everyone follow mah day one ! It ain't get as real as mah nigga right here! \ud83d\udc79\ud83d\udc79<tag> \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text further supports this classification as it uses derogatory language and references to discriminate against a particular group of people.\"}",
    "1105657345797955585": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag> that\u2019s because... #BuildTheWall #GreenNewDeal \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a wall, which is often associated with negative connotations such as racism, discrimination, or exclusion. The tweet text also includes hashtags related to political and social issues, which could further contribute to the negative perception of the image. Therefore, the image is considered hateful.\"}",
    "1117460975903334410": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag> You\u2019re a disgrace to black people and women everywhere, you pathetic twat. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults towards a specific group, indicating a hateful sentiment.\"}",
    "1025233464067543042": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Traitorous Twat! #TraitorTrumpIsTheEnemyOfThePeople \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and a political statement, suggesting that the image might be a hateful meme.\"}",
    "1055932814468833281": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:\ud83d\ude02\ud83d\ude02\ud83d\ude02\ud83d\ude02\ud83d\ude2d\ud83d\ude2d\ud83d\ude02\ud83d\ude02\ud83d\ude2d<tag>  YOU FUNNY ASS NIGGA MANE \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text further supports this classification as it uses derogatory language to describe the image.\"}",
    "1062646099750588416": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:One of the most retarded things:  Men with a huge ego mocking feminism. \ud83d\ude02\ud83d\ude02\ud83d\ude02\ud83d\ude02 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, likely due to the content of the tweet text, which includes mocking feminism and having a large ego.\"}",
    "1060988560847843328": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:You\u2019re fucking Irish, you couldn\u2019t get any whiter if you tried ya daft bint! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racist remarks towards the Irish community, which indicates a hateful sentiment.\"}",
    "1044385193400897538": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Look at all those SJW\u2019s out there \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests that the image is related to social justice warriors, which might be perceived as a negative or hateful sentiment. The classification is based on the assumption that the image could be used to mock or criticize social justice warriors, which might be considered offensive or hateful by some people.\"}",
    "1107104779526905856": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Them nigga gay \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark background, which is often associated with racism and discrimination. The tweet text further supports this classification as it contains offensive language towards a specific group of people.\"}",
    "1064312510424203265": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Dumb nigger \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark background, which is often associated with racism and hate. The tweet text containing the racial slur further supports the classification of the image as hateful.\"}",
    "1061690439659634690": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:PUSSYASS NIGGA BLOCKED ME  LMAOOOOOOOOOOOOOOOOOO<tag> \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which is not related to the hateful tweet text. The tweet contains offensive language and racial slurs, making it a hateful meme.\"}",
    "1055913527892946944": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I\u2019m a retard:( \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it may contain offensive or discriminatory content. The presence of the word 'retard' in the tweet text further supports this classification.\"}",
    "1045008652367626240": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Um, wasn\u2019t she pickin a fight with a 12 year old and callin zayn a sand nigger? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the tweet text, which contains offensive language and derogatory terms.\"}",
    "1107100642076708866": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Know twat ya mean babe. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, and the tweet text supports this classification as it contains offensive language.\"}",
    "1053751255254945797": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag> Well nigger bitch monkey woman is a line he can say \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a woman, and the tweet text contains racist and offensive language, suggesting that the image is being used to spread hate and discrimination.\"}",
    "1113125309870755845": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag> Nigga just said I have to be close to y\u2019all to tag ?? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark background, which is often associated with racism and hate. The tweet text further supports this classification as it contains a racial slur. This combination of elements suggests that the image is a hateful meme.\"}",
    "1037020753286389761": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag><tag> So you guys use the expression twat? Look at this guy \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, and the tweet text suggests that it is derogatory towards someone.\"}",
    "1061717238644965376": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Someone needs to call<tag> and tell him he's been a cunt..... Again... \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which suggests that the image is a hateful meme.\"}",
    "1057129480630657024": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Shut up cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, which suggests that the image might be a hateful meme.\"}",
    "1062852055679803393": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Who ever made this is a retard loser \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, suggesting that the image might be a hateful meme.\"}",
    "1047285245144432640": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> she kind of seems like an overreactive twat \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains negative and offensive language towards a person, suggesting that the image might be a hateful meme.\"}",
    "1064151785953247232": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Real retard (resting bitchface) hours \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text further supports this classification as it uses derogatory language to describe a person.\"}",
    "1055783109797560320": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag><tag><tag> Always the Race Card!<tag> \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, suggesting that it may contain offensive or discriminatory content related to race or other sensitive topics.\"}",
    "1023962536549523461": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Well someone should pray for the cunt... he's going down. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and a negative sentiment towards someone, indicating that the image is hateful.\"}",
    "1062801061159886848": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I\u2019m gonna kill luna she said my nigger tone \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains a racial slur and is offensive in nature.\"}",
    "1063844648542748673": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> You look like this cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text further supports this classification as it contains derogatory language towards a specific individual.\"}",
    "1056718694460637192": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Did Jonathan's \"friends\" seriously just disrespect him with a redneck immigration debate?  #90DayFiance \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it may contain offensive or discriminatory content. The tweet text also implies that the image may be disrespectful or offensive, further supporting the classification of the image as hateful.\"}",
    "1047229554086096897": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Big dyke energy \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a woman's face, which is considered offensive and hateful. The tweet text further adds to the negative sentiment, as it is derogatory towards women.\"}",
    "1054470484023304192": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> I've seen a lot of retarded tweets in this year alone, but this one is extraordinarily retarded. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, and the tweet text further supports this classification as it refers to the image as 'retarded' and 'extraordinarily retarded'.\"}",
    "1063897865490063360": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> THAT LOOKS FUCKING RETARDED \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests that the image is considered hateful, as it is described as 'fucking retarded'.\"}",
    "1058925630912450560": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:The difference is your Guido handicapper from NY or that Spic beaner from Costa Rica ? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racist remarks, which are indicative of a hateful meme.\"}",
    "1043210938801958912": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> You\u2019re a retard, and a racist one at that. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, and the tweet text supports this classification by calling the person a 'retard' and a 'racist'.\"}",
    "1064442777511948288": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:\u266c\u301c Lord Melody - Hi Nigger \ud83d\udcbfAgain! Lord Melody Sings Calypso #nowplaying #lastfm \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person, and the tweet text contains a racial slur. This suggests that the image is hateful and promotes negative attitudes towards a specific group of people.\"}",
    "1037469340835012608": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> The race card, never leave home without it. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it is a black and white photo of a person with a caption that implies racism and discrimination. The use of the race card in the caption is a reference to the concept of playing the race card, which is often used to accuse someone of being a racist. This implies that the person in the image is racist, which is a harmful and",
    "1050276044710776832": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Worlds funniest gay redneck \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme that is intended to be humorous, but it may be offensive to some people. The tweet text suggests that the image is meant to be funny, but it could be perceived as derogatory towards the LGBTQ+ community.\"}",
    "1062489621408423936": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> let\u2019s not forget that ur white and drop the N word. Stop trying to fit in you retarded fuck \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains a racial slur and promotes negative stereotypes.\"}",
    "1036319546125238273": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:\"Don't touch me Nigger!\" \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racial slurs and is offensive, indicating that the image is hateful.\"}",
    "1115999965602635776": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:BUILD A WALL, CHANGE THE LAWS &amp; CRIME WILL FALL!   #BuildTheWall #DrainTheDeepState &amp; #KAG \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a wall, which is often associated with racism and xenophobia. The tweet text suggests a call for building a wall and changing laws, which can be interpreted as a hateful message towards immigrants and minorities.\"}",
    "1061811221966446592": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> I EAT PUSSY BETTER THAN ANY DYKE STUD WITH A HOT HARD DICK \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive and derogatory language towards the LGBTQ+ community. The tweet text further supports this classification as it promotes negative stereotypes and discrimination.\"}",
    "1061160979290091520": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Stay in arena bitch since we ova here saying nigger this and tha\ud83d\udd95<tag> \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and racial slurs. The tweet text further supports this classification as it uses derogatory language and is inappropriate.\"}",
    "1110407443865952256": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> dumb nigga i don\u2019t get mad, i get even \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which is not related to the hateful tweet text. The tweet contains offensive language and promotes violence, making it a hateful meme.\"}",
    "1043902431321632770": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Yeh better being ruled by these fukkers. Another unionist twat blocked \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and a negative sentiment towards the ruling party, suggesting a hateful sentiment towards the government.\"}",
    "1115455952965079040": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This dumb ass nigga retweeted a jah meme, \ud83d\ude10\ud83d\udd95\ud83c\udfff not funny he died \ud83d\ude10\ud83d\udd95\ud83c\udfff \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to its association with a racial slur and the negative sentiment expressed in the tweet text.\"}",
    "1055228921065676800": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:thank you to lauren jauregui for reminding me what a huge fucking dyke i am \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and derogatory terms, suggesting a hateful sentiment towards the person being referred to. The image itself does not contain any explicit content or language that would indicate a hateful meme.\"}",
    "1063374273128083456": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Happy Friday fuckers from your favourite Twitter Twat \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, suggesting that the image might be a hateful meme.\"}",
    "1058015240753950720": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Still a feckless CUNT! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which suggests that the image is a hateful meme.\"}",
    "1041695456399646720": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:H. Rap Brown's Negro College Student ::: Highlighting Chapter Six Of 'Die Nigger Die!' \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person with the words 'H. Rap Brown's Negro College Student ::: Highlighting Chapter Six Of 'Die Nigger Die!' written on it. This text is associated with a hateful message, as it is a reference to a controversial book and its author. The image may be used to promote or support the ideas presented in the book, which can be",
    "1058479548638076928": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I keep pressing nothing because the compose tweet button has changed location and I look like a twat \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is a black background with no visible content, so it cannot be considered hateful. The tweet text does not seem to be related to the image's content.\"}",
    "1042331657213239296": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:She's a twat. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, suggesting that the image might be a hateful meme.\"}",
    "1105125035587629057": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Main nigga said \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which is not related to the tweet text. The tweet text contains a racial slur, making it a hateful meme.\"}",
    "1061668045473509376": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Why Don't Straight Men Hold Hands? Watch Here! -&gt; \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a man holding a handbag, which is being used as a meme to promote a hateful message. The tweet text suggests that the image is being used to promote a negative stereotype about gay men, which is offensive and discriminatory.\"}",
    "1108432791228694528": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Listening to this old herb ! Mannn this nigga use to be GREAT frfr bar for bar on niggas \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which are indicative of a hateful meme.\"}",
    "1109873159963070466": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Boom!\ud83d\udca5 Sick Of This BS!\ud83d\ude21 #BuildTheWall!\ud83d\udcaa\ud83c\udffc#AmericaFIRST!!\ud83d\ude4f\ud83c\uddfa\ud83c\uddf8 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a wall, which is often associated with racism and discrimination. The tweet text also contains political and racial statements, further suggesting that the image is intended to be hateful.\"}",
    "1107361733042204675": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Love this nigga he just made my day \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, which suggests that the image might be a hateful meme.\"}",
    "1057242352773931008": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:The cunt and the nigger cunt below set fire to my woman on the right \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and racial slurs. It is not appropriate to share such content.\"}",
    "1053331131108614144": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:\ud83d\ude1c\ud83d\ude1cMake a nigga whole day better#Offtowork\ud83d\ude01\ud83d\ude01 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person's head, and the tweet text contains racial slurs and offensive language. This suggests that the image is intended to be hateful and discriminatory towards a particular group of people.\"}",
    "1113578030117605376": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:this nigga dont know how to do the woah \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racist language, which is considered hateful. The image itself is a black background, which might be used to create a provocative or controversial context for the tweet.\"}",
    "1055258609393852416": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Adam: \u201cGET OUT OF HERE YOU FILTHY NIGGER\u201d Me: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains a racial slur, which is considered hateful. The image, being a black background, might be used to further amplify the hateful message.\"}",
    "1055989665839415298": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> #VoteRed Nov 6th! POTUS will #StopTheInvasion and he will #BuildTheWall to Save America \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a wall, which is often associated with political views and opinions. The tweet text suggests a political message, which can be considered hateful by some people. The use of hashtags like #VoteRed and #StopTheInvasion can be seen as divisive and controversial, further indicating that the image is hateful.\"}",
    "1058550708952293376": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:black cunt cosplay in the ass italian milf mexican pussy old pussy exam quadruple penetration stepfamily austrian   \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a woman's genitalia, which is considered inappropriate and offensive. The tweet text further emphasizes the hateful nature of the image.\"}",
    "1056226718476840962": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Its YOUR FAULT you stupid cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, which suggests that the image might be a hateful meme.\"}",
    "1056249739937755138": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Anyone know this cunt?   #swfc #sufc #twitterblades \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and references to football teams, suggesting a negative or hateful sentiment towards someone.\"}",
    "1106669823084384258": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> is a different type of nigga \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person, and the tweet text contains a racial slur. This suggests that the image is hateful and promotes negative stereotypes.\"}",
    "1042123072516567043": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> White Trash! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content towards a particular group of people. The tweet text further supports this classification as it contains derogatory language towards a specific demographic.\"}",
    "1108567795191681026": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Now Streaming  Dick Van Dyke-Julie Andrews-Karen Dotric - CHIM CHIM CHER-EE at \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is a black and white photo of a night sky, which does not contain any explicit or offensive content. The tweet text does not seem to be related to the image, as it is unrelated to the photo's content. Therefore, the image is not considered a hateful meme.\"}",
    "1059586585459601408": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:*volume down warning headphone users*  THIS WAS SO CLEAN OMG I LOOK RETARDED THOUGH \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text also implies that the image may be perceived as insulting or derogatory towards headphone users.\"}",
    "1060979486710292486": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:If you think fur is ok to wear you're a twat \ud83d\udd95 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the negative and offensive language used in the tweet text, which is displayed on the image.\"}",
    "1061012949429563393": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:So freaking retarded\ud83d\ude2d\ud83d\ude2d\ud83d\ude2d\ud83d\ude2d\ud83d\ude2d always and still have me in tears \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which suggests that the image might be a hateful meme.\"}",
    "1108178383538663430": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I see you RTing content from people I know you cunt I\u2019ll fucking slap you<tag> \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and a threat, indicating a hateful sentiment towards the person being referred to.\"}",
    "1059584815341752323": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:LMFAO NIGGA PLEASE.<tag> \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark background, which is often associated with racism and hate. The tweet text further supports this classification as it contains a racial slur. This combination of elements suggests that the image is a hateful meme.\"}",
    "1045904384822059009": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I made it a lot better after an hour of photoshop agony. Time to post it on 4chan and get called a faggot \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests that the image is intended to be hateful, and the fact that it is posted on 4chan further supports this classification.\"}",
    "1116705030978117632": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> I\u2019m fucking weak. this was that nigga Rob when he tweeted yesterday morning. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text also supports this classification as it uses derogatory language towards a specific group of people.\"}",
    "1043136643933384705": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Montana at heart? So you\u2019re a boring moose-eating redneck that no one had been inside of on purpose? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and stereotypes, suggesting that the image might be a hateful meme.\"}",
    "1054136652816207874": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Good luck Georgia if you elect this retard! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, suggesting that the image is a hateful meme.\"}",
    "1109197258304610304": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Yes like cunt! Who tell ya to fuck me so good \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and suggests a negative attitude towards the image. This classification is based on the fact that the image is described as a 'hateful meme' and the tweet text reinforces this perception.\"}",
    "1044976436652597248": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Everyone working for #Trump has officially gone full retard. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults towards people who work for Trump, which indicates a hateful sentiment.\"}",
    "1047069947342594048": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:If he is voted back in the Irish are more retarded then the rest of the world thought! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and a negative sentiment towards the Irish people. This suggests that the image is a hateful meme.\"}",
    "1035232820959105025": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> TYPICAL LYING LIBTARD - DON'T HAVE ANYTHING GOOD TO RUN ON PLAY THE RACE CARD !!! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, suggesting that it contains offensive or discriminatory content.\"}",
    "1037404155860733952": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> you are a sick racist white trash Bitch lives In The pill poping state. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racist remarks, which suggest that the image is a hateful meme.\"}",
    "1053939705258147842": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Redneck Blind #Giveaway - Liberty Tree Guns \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a gun, which is often associated with violence and aggression. The tweet text suggests that it is related to a giveaway for guns, which can be perceived as promoting gun ownership and potentially glorifying violence. These factors contribute to the classification of the image as hateful.\"}",
    "1043078036558622720": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Want me to show more? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which can be perceived as a hateful meme due to its association with negative emotions or events. The tweet text suggests that more content may be shared, which could further contribute to the perception of the image as hateful.\"}",
    "1108151645806956544": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Nigga aint that the Red Lobster logo!?! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme that uses a racial slur, which is considered hateful and offensive.\"}",
    "1037373999553101824": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Poor white trash, redneck racists! Lmao!!! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and derogatory terms towards a specific group of people, which indicates a hateful sentiment.\"}",
    "1061893624730923008": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:get fucked, cunt :^) \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, which suggests that the image might be a hateful meme.\"}",
    "1056465317663170560": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> AHAHAH wtf are u doing, he's @ pax messaging me cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, and the tweet text suggests that it is related to a negative interaction or message.\"}",
    "1062161010981650432": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Jimmy is a #feminazi douchey #SoyBoy #Hypocrite \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains content that is offensive or discriminatory towards a particular group or individual. The tweet text further supports this classification as it contains derogatory terms such as 'feminazi', 'douchey', 'SoyBoy', and 'Hypocrite', which are often associated with hateful rhetoric.\"}",
    "1105111542855581698": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Lol my kids going see what type of nigga I was\ud83e\udd23 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which is not related to the hateful tweet text. The tweet contains offensive language and is not appropriate for sharing. The image itself is not hateful, but the context in which it is being shared is.\"}",
    "1054503947606654976": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Yet SJW black women say straight black guys are \u201ctraitors\u201d come collect your BED WENCHES then talk. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a negative stereotype of black women and black men. It is disrespectful and promotes harmful ideas.\"}",
    "1035552517646704640": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This is a special kind of retarded .. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, and the tweet text supports this classification as it contains offensive language.\"}",
    "1042551164254904320": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> u never wanna go full retard. RIP to the accounts that chased $TLRY \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is likely to be considered hateful. The image, being a black background, may not be directly related to the content of the tweet, but the overall context suggests a negative sentiment.\"}",
    "1113860603309973504": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:go rattraper mon retard \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which suggests that the image is hateful.\"}",
    "1041810549443584000": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:help this dyke keeps on STALKING me every day #PS4share \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it may contain content that is offensive or discriminatory towards a particular group of people. The tweet text also implies that the image is related to harassment, which further supports the classification of the image as hateful.\"}",
    "1051295126654353408": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> They stopped gerrymandering you dumb ass retard... #MoronInChief  #liarinchief #dumbdonald \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults towards the president, which suggests a hateful sentiment towards the political leader.\"}",
    "1046143368500314117": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Gretchen Wilson World Premiere Music Video Release Party at Redneck Riviera! \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is a black background with no visible content, and the tweet text is about a music video release party, which does not contain any hateful or offensive content.\"}",
    "1051584525854302208": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Groom your twat. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is considered hateful.\"}",
    "1035909574413438977": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Twat. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content.\"}",
    "1053831780564897792": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> \"Read my articles guise\" No, quote this faggot. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content.\"}",
    "1046881726910386176": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Well, they cite Krugman, and he\u2019s the most economically retarded person since Marx. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains a negative opinion about an economist, which suggests a hateful sentiment towards the person being discussed.\"}",
    "1035092841343512576": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I wish Gunter was the main character. Kamui is BRAINDEAD retarded. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet contains negative and offensive language towards the character Gunter, suggesting a hateful sentiment towards the character.\"}",
    "1049935247016521729": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Fuck my bad. I do agree I\u2019m a retard lol \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, and the tweet text supports this classification as it contains offensive language.\"}",
    "1054435523278893056": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Nigga are we EVER gonna get an explanation for this? Fuck was he even finna do? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racial slurs and aggressive language, suggesting a hateful sentiment towards a specific group of people. The image itself is a black background, which might be used to create a provocative or intimidating atmosphere. However, it is not possible to determine the content of the image from the provided image description.\"}",
    "1061735984486846464": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Winning a race card you mean. He\u2019s patently thick as mince \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, suggesting that the image is a hateful meme.\"}",
    "1107334043711037441": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> happy mf glo day to a real nigga!!!!!! hope u have a good day ishmael \ud83e\udd7a\u2665\ufe0f \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text also supports this classification as it uses derogatory language towards a specific group of people.\"}",
    "1053520289705984000": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This nigga ruined the whole show lowkey. \ud83e\udd37\ud83c\udfff\u200d\u2642\ufe0f \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language towards a specific group of people, which is considered hateful. The image itself is a black background, which might be used to evoke a certain emotion or message, but it does not contain any explicit content that would make it hateful.\"}",
    "1047290249834102784": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Lowlife piece of white trash...F*CK You Tr*mp...want to buy a vowel????????? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults towards a specific group of people, which indicates a hateful sentiment. The image itself is a black background, which might be used to create a provocative or aggressive atmosphere.\"}",
    "1035915161863966720": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:totally talent-less twat. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, suggesting that the image might be a hateful meme.\"}",
    "1109771121279156224": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Busty teenie gets her hairy cunt\u00a0penetrated \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains explicit content and is disrespectful towards women.\"}",
    "1062356425664593925": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> it\u2019s PAY UP time faggot. 320 euros, what a cash rape lil toilet drinker \ud83e\udd23 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and derogatory terms, suggesting a hateful sentiment towards the person being referred to.\"}",
    "1063520303240818688": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:pretty strap brynn tyler extreme boobs lezbos most mother and son quick head tight cunt italy   \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a woman's body, which is described as 'extreme boobs' and 'tight cunt'. The tweet text also contains offensive language, suggesting that the image is intended to be hateful or offensive.\"}",
    "1114939707895570432": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:wtf is this nigga<tag> doin \ud83d\ude02\ud83e\udd23\ud83e\udd23\ud83e\udd23 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person, and the tweet text contains racial slurs and derogatory language, indicating a hateful sentiment.\"}",
    "1108582987887718401": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Redneck vasectomy \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text also supports this classification as it contains a reference to a controversial topic, such as a vasectomy, which could be perceived as offensive by some individuals.\"}",
    "1055167403708039168": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:FUCK OFF YOU FUCKING CUNT \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, which suggests that the image might be a hateful meme.\"}",
    "1034908664488964096": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:If you think Ronaldo is good at football, You clearly haven\u2019t seen the GOAT \ud83d\udc10 play or you\u2019re just a retard.   \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet contains offensive language and insults towards someone's intelligence, which indicates a hateful sentiment.\"}",
    "1037415592322428928": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag> Q is a Larp you rube \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, suggesting that the image might be a hateful meme.\"}",
    "1056579612560506883": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Can only assume that Stefan is a giant cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language towards Stefan, suggesting a negative attitude towards him. This could be considered as a hateful meme.\"}",
    "1050807947113054208": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:New VIDEO: The Empty, Angry, Resentful World of the SJW \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, suggesting that it may contain offensive or discriminatory content. The tweet text also supports this classification as it refers to an 'empty, angry, resentful world of the SJW' which might be perceived as derogatory or discriminatory towards a particular group of people.\"}",
    "1061255275771060225": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Via: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which can be perceived as a hateful meme due to its association with negative emotions or events. The tweet text also suggests that the image is a meme, which further supports the classification of the image as hateful.\"}",
    "1058346455839191040": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:NIGGA I GOT GOOSEBUMPS DKCNDJ \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which is not related to the hateful tweet text. The tweet contains racial slurs and is offensive, which makes it a hateful meme.\"}",
    "1061494662915997698": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Name and shame the twat!  #Dunedin \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and a call to shame someone, indicating a hateful sentiment.\"}",
    "1105739767117987841": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:this shit made me a fuckin dyke \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests that the image is hateful, as it is described as 'this shit made me a fuckin dyke.' This implies that the image has a negative impact on the viewer, potentially causing distress or offense.\"}",
    "1059575639848730627": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Lil nigga said \u201cice cream \u201c \ud83d\ude02\ud83d\ude02\ud83d\udc80 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a negative stereotype of a young black boy, which is offensive and disrespectful.\"}",
    "1109073240931086336": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Some pirate nigga: Hey, Luffy, you wanna try some of this milk?   Luffy: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains racist language and imagery, which is offensive and discriminatory.\"}",
    "1042077625236312064": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:DYKE SECRETS \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language towards the LGBTQ+ community, which is considered hateful. The image itself is a black background, which might be used to further spread such hateful messages.\"}",
    "1110155803623862274": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Nigga you have friends \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person, and the tweet text contains a racial slur. This suggests that the image is intended to be hateful and offensive.\"}",
    "1024383310833676288": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Remember Kate Steinle #PassKate'sLaw #buildthewall \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which is not related to the tweet text. The tweet text contains political and social opinions, which can be considered as hateful by some people. However, the image itself is not hateful.\"}",
    "1117016052393750528": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I'm a made nigga, I should dust something....... \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language and racist slurs, which are indicative of a hateful sentiment.\"}",
    "1042218894474272768": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> This applies to man-hating, liberal, feminazi! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains content that promotes negative feelings or discrimination towards a particular group of people, such as women or liberals.\"}",
    "1045242464909643777": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:You a faggot? Look what I have for you! ......  See this and more at: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content towards a particular group of people.\"}",
    "1063958280094007299": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:By: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which can be perceived as a hateful meme due to its association with negative emotions or events. The tweet text also suggests that the image is meant to be hateful.\"}",
    "1056734114244526080": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag> Ohhh NoooooOOo the little faggot from Philadelphia says he'll \"Take our guns\" \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains a tweet text that is derogatory and discriminatory towards the LGBTQ+ community.\"}",
    "1034914884176302088": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Me when a nigga approach me with that faggot shit \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the tweet text, which contains derogatory language towards a specific group of people.\"}",
    "1061666409904771074": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> This retard is going full bore... \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, suggesting that the image is a hateful meme.\"}",
    "1034983049266524160": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Doja Cat saying faggot wasn\u2019t enough for me to stop liking the song, but this is   \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the tweet text, which contains derogatory language towards the LGBTQ+ community.\"}",
    "1055079281452371969": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:omg they finally put it on spotify DYKE RIGHTS! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language towards the LGBTQ+ community, which is considered hateful. The image itself is a black background, which might be used to further spread such hateful messages.\"}",
    "1037058683098877952": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Nike doesn\u2019t care about losing trailer trash Trump fans who spew ignorance. #SorryNotSorry \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a Nike shoe, which is often associated with the brand's support for athletes and sports. The tweet text suggests that the image is being used to express a negative opinion about Nike and its customers. This could be interpreted as a hateful meme, as it is using an image to convey a negative message about a specific group of people.\"}",
    "1046550725747232768": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This dudes a faggot #PS4share \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a man's face, and the tweet text is derogatory towards the individual. This suggests that the image is intended to be hateful or offensive.\"}",
    "1047032977530732544": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Black Dyke ready to showcase their Handel work \nASSISTANT: {\"Classification\": \"hateful or not hateful\", \"Explaination\": \"The image is not hateful as it is a simple black background with no explicit content or message that can be considered offensive.\"}",
    "1058754714685321217": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:james mcleans a dirty taigy bastard!! shuld be wearin a pappy on his shirt. cunt needs shot!! Respect are troops \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text further supports this classification as it contains derogatory language towards a specific individual.\"}",
    "1056947419546439680": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> But the broncos can't fire this retard HC \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults towards the Broncos' head coach, which suggests a hateful sentiment.\"}",
    "1042971868817440769": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Here's a solution to that problem.  #BUILDtheWALL \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a wall, which is often associated with racism and xenophobia. The tweet text suggests a solution to a problem, which could be interpreted as a call to action to build a wall, which is a controversial and divisive issue. This combination of elements suggests that the image and the tweet text are hateful in nature.\"}",
    "1050760889945772034": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Pussy cool but her head is retarded. Make one false move and your head is a target\ud83d\ude0e \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and a derogatory statement about women.\"}",
    "1055861673955864576": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:MOOD! Ask me out, NIGGA! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains racial slurs and is disrespectful towards a specific group of people.\"}",
    "1055945098683392000": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Colombian MILF with enormous boobs Shara Lopez toys her Latina twat \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text provided further supports this classification as it contains explicit and potentially offensive language.\"}",
    "1109451107170951168": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Nigga was too busy running million dollar miles &amp; going to the shop afterwards \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains racial slurs and promotes negative stereotypes.\"}",
    "1057389336335917056": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:NOTHING TO SEE HERE.  #Invasion  #ISIS #LiberalismIsAMentalDisorder #BuildTheWall  #MAGA \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains content that is intended to provoke negative emotions or promote harmful ideologies.\"}",
    "1043676899833208832": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I mean she ain\u2019t really a dyke but LEMME TELL YOU \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and derogatory terms towards the LGBTQ+ community.\"}",
    "1054057424179601413": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:When the gay nigga smack yo ass while you playing basketball \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and promotes negative stereotypes.\"}",
    "1054006596727119873": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:SIX HEADSHOTS ILL ERODE A NIGGA \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person's head, which is considered a hateful meme as it promotes violence and discrimination against a specific group of people.\"}",
    "1044180593989357568": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Super religious people are truly retarded. I know god looks down and laughs at them like \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language towards religious people, which is considered hateful. The image itself is a black background, which might be used to create a dramatic or intense atmosphere, but it does not contain any explicit content that would make it hateful.\"}",
    "1063964753016557568": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:He bullied me on my other account for doing NFSW stuff but go off cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and suggests bullying, which indicates a hateful sentiment.\"}",
    "1108014004587229188": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This is Islam people this should have never happened to these young ladies time to #BanIslam. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests that the image is related to Islam and is being used to promote a hateful sentiment towards Muslims. The use of the hashtag #BanIslam further supports this classification.\"}",
    "1049773037313249281": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I can\u2019t understand nothing this hillbilly mechanic is saying. He sound like dude off of King Of The Hill \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, likely due to the content of the tweet text, which includes derogatory language towards a specific group of people.\"}",
    "1043106230544285697": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:trumps thugs, White Trailer Trash \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content related to the tweet text. The presence of the word 'thugs' and the reference to 'White Trailer Trash' in the tweet text might be perceived as derogatory and insensitive, leading to the classification of the image as hateful.\"}",
    "1035040274290888704": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I\u2019m going to say it idc if she says faggot \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language, which is considered hateful. The image itself is a black background, which might be used to create a provocative or intimidating atmosphere, but it does not contain any explicit or hateful content.\"}",
    "1054129247789432832": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> IN GOD WE TRUST AND USA WE TRUST YOU ARE STUPID SIRIAN RETARDED \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, suggesting that the image is a hateful meme.\"}",
    "1062649440211742720": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Either this will be me when I\u2019m in a retirement home or I\u2019ll be the dirty cunt watching them \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and suggests inappropriate behavior, indicating that the image is hateful.\"}",
    "1047233479514017793": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> My advice for those bunch of retarded people: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, suggesting that the image is a hateful meme.\"}",
    "1042059676274356224": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I got you my nigger \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person's head, which is considered a hateful meme due to the use of racial slurs in the tweet text.\"}",
    "1108327602991845377": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Surveillance nigga \ud83d\udda4 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The presence of the word 'nigga' in the tweet text further supports this classification.\"}",
    "1037101277564596224": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag><tag> Fake news retard \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The presence of the word 'retard' in the tweet text further supports this classification.\"}",
    "1060958533821194240": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Everyone on Fortnite, go report this guy for being a HUGE FUCKING FAGGOT \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, likely due to the content of the tweet text, which is derogatory and offensive.\"}",
    "1057003519880912896": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Might buy this for halloween and go as a absolute cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests that the image might be used as a costume for Halloween, implying that it is meant to be humorous or offensive. This classification is based on the context provided by the tweet text.\"}",
    "1114272979922313216": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> \u201cIf I don\u2019t get a puppy imma just get a gun\u201d nigga \ud83d\ude2d ???????? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and a threat, which indicates that the image is hateful.\"}",
    "1044709505488031744": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Hey wetback ... \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which is not related to the hateful tweet text. The tweet text contains offensive language towards a specific group, which makes the image associated with the hateful sentiment.\"}",
    "1035495767409131520": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag> Okay retard \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, suggesting that the image is intended to be hateful.\"}",
    "1037063269834321920": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Bob Woodward book: Trump called Sessions 'mentally retarded' \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which is not related to the tweet text. The tweet text contains a reference to a book by Bob Woodward, which suggests that the image might be related to a political or controversial topic. However, without any explicit or implied hate speech or imagery in the image, it cannot be classified as a hateful meme.\"}",
    "1037341969683546112": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I never felt a tea call me \u00ab\u00a0nigger\u00a0\u00bb until this \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person's head, and the tweet text suggests that it is a hateful meme. The use of the word 'nigger' in the tweet text implies that the image is intended to be offensive and discriminatory towards a particular group of people.\"}",
    "1109806421787455488": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Once again this nigga is honestly my child \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text provided further supports this classification as it contains derogatory language towards a specific group of people.\"}",
    "1041918275242876928": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:And this docile bint is meant to be sorting Brexit.  Ha ha ha yeah, right! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, likely due to the content of the tweet text, which is derogatory and disrespectful towards women.\"}",
    "1110209113500327941": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Aye y\u2019all go follow a nigga on the snap! \ud83d\udcaa\ud83c\udffe\u270a\ud83c\udffe \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language towards a specific group of people, which is considered hateful. The image itself is a black background, which might be used to create a provocative or controversial context for the tweet.\"}",
    "1054199415039291392": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Check the cunt out before trying to offload him with us, bang out of order \ud83d\ude02 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text also supports this classification as it contains derogatory language towards a specific group of people.\"}",
    "1115213268245573633": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> I don\u2019t give 2 shits that the twat waffle lost her job Karma will come some day or has it??? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains negative language towards someone, suggesting a hateful sentiment. The image, being a black background with no discernible content, does not contribute to the classification.\"}",
    "1050529969745657856": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:wtf I love Islam now. Seriously though, normie conservatives are going full retard. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, suggesting that it may contain offensive or discriminatory content towards a particular group or individual.\"}",
    "1061337476537704449": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> And this cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, and the tweet text supports this classification as it contains offensive language.\"}",
    "1061357991394492416": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:no food in the house so i have to eat these nigger noodles \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racist language and is considered hateful.\"}",
    "1058059582302351360": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:If anyone is in the news for assassinating a politician, I'll bet it's this John Wayne wannabe faggot here. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains hateful language towards a specific individual, suggesting that the image might be used to promote such negative sentiment.\"}",
    "1115802240516640769": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:So we\u2019re not firing luke ? Fuck.. that nigga is trash ! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and racist remarks towards a specific individual.\"}",
    "1113842779367649281": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Shout out to the faggot that swallowed Matt Hughes/Danny D's enormous 10 inch cock from head to balls. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and content that is not appropriate or respectful.\"}",
    "1055197195614539777": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> So are you ok with this twat then? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, and the tweet text suggests that the person is not ok with it.\"}",
    "1053866832556425216": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I bet<tag> was attractive until someone spilled water on her &amp; she started to melt. #MAGA #BuildTheWall \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains content that is intended to be offensive or harmful. The tweet text further supports this classification as it contains a reference to a political issue and a derogatory statement about a person.\"}",
    "1034897307437805568": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:\ud83d\ude4c YASSS It's time for a great show countryfied redneck:sitting outsid \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it may contain offensive or discriminatory content. The tweet text also supports this classification as it appears to be celebrating a show that is associated with a particular group of people. This could be perceived as derogatory or discriminatory, making the image hateful.\"}",
    "1105498011822710784": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:this nigga 50 cent is the most savage mf on ig \ud83d\ude02\ud83d\ude02\ud83d\ude02\ud83d\ude02\ud83d\ude02\ud83d\ude02\ud83d\ude02\ud83d\ude02\ud83d\ude02 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text also supports this classification as it contains derogatory language towards a specific group of people.\"}",
    "1105278516491313152": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> This cunt \ud83d\ude44 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, and the tweet text further supports this classification as it contains offensive language.\"}",
    "1107360345633550337": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:You can\u2019t be a real nigga if you do fake shit. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text further supports this classification as it uses derogatory language towards a specific group of people.\"}",
    "1064158493958184960": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:By: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which can be perceived as a hateful meme due to its association with negative emotions or events. The tweet text also suggests that the image is meant to be hateful.\"}",
    "1062384183954341888": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> My nigger \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person, and the tweet text contains a racial slur. This suggests that the image is intended to be hateful and offensive.\"}",
    "1035157334497079296": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:\u201cyour morals are so questionable these days, simone\u201d  first of all, nigger, it\u2019s twitter. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, suggesting that the image is a hateful meme.\"}",
    "1053667663048781825": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Fuck you retard \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, suggesting that the image might be a hateful meme.\"}",
    "1105164544899538944": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:If you\u2019re white or a white-passing hispanic/latinx. Don\u2019t say \u201cnigga\u201d, ever. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it promotes racism and discrimination by suggesting that people of certain races should not use certain words.\"}",
    "1046609934421553153": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag> I know one thing - You're a retard &amp; a moronic hater. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, suggesting a hateful sentiment towards the person being referred to.\"}",
    "1058496748119883776": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag><tag> 5 minutes into you lot babysitting the cunt will look like this \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text also supports this classification as it uses derogatory language to describe someone. The image itself is a black background with no visible content, but the context provided by the tweet text indicates that it is related to the hateful meme.\"}",
    "1044760403027222529": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Cinna Vanmathy Narayana Moorthy Nadar. of PICK. Westerners retard in civilization. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the tweet text, which contains offensive language and a derogatory statement about Westerners.\"}",
    "1057329060076896256": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Retard \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The presence of the word 'retard' in the tweet text further supports this classification.\"}",
    "1055104482420363270": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:going aldi dressed like a faggot going through IT....ready to receive homophobic abuse for the second time today \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, suggesting that it may contain offensive or discriminatory content. The tweet text also implies that the person in the image is ready to receive homophobic abuse, which further supports the classification of the image as hateful.\"}",
    "1035555516775325697": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Btw, I got called a dyke on the bus on my way to uni bc I tripped, and I just \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a woman's face, which is considered a hateful meme as it may be used to perpetuate negative stereotypes and discrimination against women.\"}",
    "1059553895091974146": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:arianamarie ass hot cunt cock stuffing college party latin ass orgasm compilation peruana scandal saudi arabia   \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a woman's body, which is considered inappropriate and offensive. The tweet text contains explicit language and is also considered inappropriate and offensive.\"}",
    "1062371273882374144": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Freckless Cunt! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The presence of the word 'cunt' in the tweet text further supports this classification.\"}",
    "1045029422896750592": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:\u201cIM GONNA FUCK YOUR FUCKING FANNY OFF YOU TWAT\u201d \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is considered hateful.\"}",
    "1024688826416017409": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Packs seem retarded... \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, suggesting a hateful sentiment towards packs.\"}",
    "1056651498392875009": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Split up with my ex and she changed my name on Netflix to Top Cunt hahahahhahaha \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and humor, suggesting a negative attitude towards the ex-partner. The image, being a black background, does not provide any context or information to determine if it is related to the tweet. However, the combination of the tweet text and the image's content might be perceived as hateful by some.\"}",
    "1062192057266135041": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:\u201cShit\u201d \u201cfuck\u201d \u201ccunt\u201d \u201cfuck your couch\u201d \u201cBitch it\u2019s happy hour\u201d \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, which suggests that the image might be a hateful meme.\"}",
    "1054495429751201792": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> lmfaooooooo TOUCHE MY NIGGA lmfao TO FUCKIN CHE \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which are indicative of a hateful meme.\"}",
    "1049985542643888129": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:What\u2019s this? Another retarded wanna be asian gangster? I\u2019ve found a new playmate! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, likely due to the content of the tweet text, which contains offensive language and a reference to a racial stereotype.\"}",
    "1042564946297536512": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag> U know what: Hahaha. .  Retarded! ! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, suggesting that the image is a hateful meme.\"}",
    "1053889323840532483": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Not my nigga great<tag> <tag><tag> \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which suggest that the image is a hateful meme.\"}",
    "1110353370496356352": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> nigga she\u2019s literally chanel\u2019s ambassador LMFAO \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains a racial slur and is disrespectful towards people of color.\"}",
    "1045868750849933314": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Retard dog \ud83d\ude02\ud83d\ude02 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The presence of the word 'retard' in the tweet text further supports this classification.\"}",
    "1055773203921059840": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:this is what im talking about when i say people are retarded \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, suggesting that it contains offensive or discriminatory content.\"}",
    "1060988867023724545": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:#DoctorWho did she just say what I think she\u2019s said #Cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a woman's face, and the tweet text contains a derogatory word. This suggests that the image is intended to be hateful or offensive.\"}",
    "1064140122126454790": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:It takes a gang to raise a nigger\ud83d\udeab \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains racial slurs and promotes negative stereotypes about a specific race.\"}",
    "1109085149365440512": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Wow a nigga does work with Nike and suddenly his coffee order gets wild complicated \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a negative stereotype of a black person, which is offensive and discriminatory.\"}",
    "1058911342210486272": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:#BuildTheWall #FollowTheLaw #ProtectOurBorders \ud83c\uddfa\ud83c\uddf8\ud83c\uddfa\ud83c\uddf8\ud83c\uddfa\ud83c\uddf8\ud83c\uddfa\ud83c\uddf8We Have A Caravan Too \ud83c\uddfa\ud83c\uddf8\ud83c\uddfa\ud83c\uddf8\ud83c\uddfa\ud83c\uddf8\ud83c\uddfa\ud83c\uddf8 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests a hateful sentiment towards immigrants, which is reflected in the image of a black background with no content. This could be perceived as a hateful meme.\"}",
    "1063869043403149312": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:#NintendoSwitch flowey you retard \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet contains offensive language and insults, suggesting that the image is a hateful meme.\"}",
    "1106694902107246593": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Will you look at this twat #CheltenhamFestival \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which suggests that the image might be a hateful meme.\"}",
    "1044859447267471365": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Also, Black Dyke plays Wings. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person with a noose around their neck, which is a symbol of lynching and racism. The tweet text also implies that the person is playing the Wings game, which is not relevant to the image's content. This combination of elements suggests that the image is intended to be hateful and offensive.\"}",
    "1050079742844645378": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Credit goes to the twat that is<tag> \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The presence of the tag in the tweet text further supports this classification.\"}",
    "1114604497005838336": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This nigga basically Ezel From Friday \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the use of racial slurs and the reference to a controversial and offensive character from a movie.\"}",
    "1105295174169780224": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> You right lil nigga \ud83d\ude02 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language towards a specific group, which is considered hateful. The image itself is a black background, which might be used to further emphasize the negative message in the tweet.\"}",
    "1046936440603586560": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> They should even have one that says white men are trash \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text also supports this classification, as it suggests that the image should have a tag that says 'white men are trash.' This kind of language is typically associated with hate speech and discrimination, which are not acceptable values.\"}",
    "1109475563616550913": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> And this is what will be the outcome. Crusades\u271d #BanIslam \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a sky, which is being used as a background for a hateful tweet. The tweet contains religious and hateful content, suggesting that the image is being used to promote such views.\"}",
    "1061034470705430531": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:me:   random hillbilly on twitter: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it may contain offensive or discriminatory content. The fact that it is described as a meme implies that it may be intended to be humorous or satirical, but the content could still be considered inappropriate or harmful.\"}",
    "1108504108972105729": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I\u2019m a hoe. I\u2019m texting a nigga while I\u2019m in another nigga face. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and racial stereotypes. The tweet text further supports this classification as it uses derogatory language towards people of color.\"}",
    "1053428231204855808": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> And how about their choice of t-shirts.  SJW enlightened refugees? \ud83e\udd14 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, suggesting that it may contain offensive or discriminatory content. The tweet text also implies that the image may be criticizing a specific group or ideology, which could be perceived as hateful.\"}",
    "1050068911968927744": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Street Sign Making A Right Twat Out Of Him \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text further supports this classification as it uses derogatory language to describe the person in the image.\"}",
    "1064295277799051264": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> *uses both \"feminazi\" and \"#FeminismIsCancer\" unironically* \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a woman's face, with the words 'Feminazi' written above her. The tweet text uses both 'feminazi' and '#FeminismIsCancer' unironically, which suggests that the image is promoting a negative and hateful view of feminism. This is in contrast to the image's description as a '",
    "1105319356592869376": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:It's lit nigga  \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racist slurs, which are indicative of a hateful meme.\"}",
    "1056570924424667137": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Sjw son of a bitch I'll miss Apu \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and a reference to a controversial topic, which suggests that the image might be a hateful meme.\"}",
    "1058755360138379264": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> no thats an obvious kid are you retarded \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, suggesting that it may contain offensive or discriminatory content.\"}",
    "1035532288577101830": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Trailer Park Trash on Parade \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text further supports this classification as it uses derogatory language to describe the people in the image.\"}",
    "1057361230489440257": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Poor twat \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, suggesting that the image might be a hateful meme.\"}",
    "1110275314100379649": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> It\u2019s called being a liar pants on fire or thieving cunt! Disgraceful \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which suggest that the image is a hateful meme.\"}",
    "1107122324145426433": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> \"You must be f*cking him because you going hard sis\"...Shut up Nigger \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains racist language and is disrespectful towards a specific group of people.\"}",
    "1053915050803675136": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Y\u2019all are fuckin retarded lol this is the same screen shot, but from different people... \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests that the image is a hateful meme, as it is described as 'fuckin retarded' and 'the same screen shot, but from different people...'}",
    "1054553966628012032": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This is really an awful thing to say, but seriously makes one wonder! #BuildTheWall \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, suggesting that it contains offensive or discriminatory content. The tweet text also supports this classification as it contains a negative sentiment towards a specific group of people.\"}",
    "1036933516787900417": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Heavy squats to this. What a fucking sick song. Really nigger shit \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the tweet text containing racist language and derogatory terms.\"}",
    "1109163558930206720": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> You are the twat of the globe \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, suggesting that the image might be a hateful meme.\"}",
    "1063037585856086016": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Got it stuck in me head now ya twat \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, suggesting that the image might be a hateful meme.\"}",
    "1047177428529901568": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:sjw twitter on another level this is why we should bully people off the internet like we used to \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, suggesting that it promotes negative or harmful behavior towards others.\"}",
    "1059513146015137793": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:when that nigger just won't go home \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person, and the tweet text contains a racial slur. This suggests that the image is hateful and promotes negative stereotypes.\"}",
    "1053731206242689025": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Fuck off you cunt. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, suggesting that the image might be a hateful meme.\"}",
    "1025173538276352002": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:this pool floatie cocktail just called me faggot \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a pool floatie, and the tweet text suggests that it has called someone a derogatory term. This could be perceived as hateful, as it may contribute to a negative and discriminatory atmosphere.\"}",
    "1056261443430027265": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:NIGGA JUST TOOK THE FATTEST L LMAO \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains racial slurs and is disrespectful towards a specific group of people.\"}",
    "1062205539034243072": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> \ud83d\ude33\ud83d\ude31 that cunt bitch!! \ud83e\udd2c\ud83e\udd2c\ud83e\udd2c \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which suggests that the image is a hateful meme.\"}",
    "1024865206936199168": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Cultural Appropriation you say - OK you fucking caught me.   \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person with a caption that suggests cultural appropriation. This can be considered as a hateful meme as it may offend or discriminate against certain individuals or groups.\"}",
    "1055067759363678208": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Yo nigga wtf this guys following 4.6mil \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The presence of the word 'nigger' in the tweet text further supports this classification.\"}",
    "1050076065480265729": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:H. Rap Brown's US Educational System ::: Highlighting Chapter Two Of 'Die Nigger Die' \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which is often associated with negative emotions or mourning. The tweet text suggests that the image might be related to a hateful meme, further supporting the classification of the image as hateful.\"}",
    "1053734279182729221": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> you stupid cunt i was waiting so long \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, suggesting that the image might be a hateful meme.\"}",
    "1053975483019378688": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Lewis Hamilton: Spoilt brat or national treasure? TWAT TWAT TWAT.... \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults towards Lewis Hamilton, which indicates a hateful sentiment.\"}",
    "1057441843829444608": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Prolly something comfortable because the first nigga try to dance \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person, and the tweet text contains a racial slur. This suggests that the image is intended to be hateful and offensive.\"}",
    "1035315800171847682": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:#Enough of the #RaceCard! Time to MOVE FORWARD &amp; #MAGA  #Trump2020 #RedWaveRising \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is a black background with no visible content, so it cannot be considered a hateful meme. The tweet text does not contain any racist or hateful language, so it is not related to the image either.\"}",
    "1117499644840435712": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> ok retard \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, suggesting that the image might be a hateful meme.\"}",
    "1037045397343088645": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Retard... \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The presence of the word 'retard' in the tweet text further supports this classification.\"}",
    "1114645472763949059": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Nigga whoever reading this shit don\u2019t go to check trust me \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which is not related to the hateful tweet text. The tweet contains offensive language and is not appropriate for sharing. The image itself is not hateful, but the content shared with it is.\"}",
    "1115308117540122625": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> 95% is a huge number my nigga \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racist slurs, which indicates that the image is likely a hateful meme.\"}",
    "1062687991511089152": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Thank you for disrespecting my great great grandfather you bonespurred, megalomaniacal, twat \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or disrespectful content towards a specific individual or group.\"}",
    "1115354111866753025": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Hope you liked it, thanks for watching \"juicy hairy cunt ~ uncensored\" on #AdultWork.com \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text also implies that the image is related to adult content, which might contribute to the negative perception of the image.\"}",
    "1046719720534274048": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag><tag><tag> Fuck off twat \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, suggesting that the image is a hateful meme.\"}",
    "1115801540202258433": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Free my nigga!  He ain\u2019t even do nothing!<tag><tag><tag><tag> \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person, and the tweet text contains racial slurs and demands for freedom. This suggests that the image is intended to be hateful and promote harmful stereotypes.\"}",
    "1114194259459047425": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This nigga so weird I\u2019m not even following him lmao \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language towards a specific group of people, which is considered hateful. The image itself is a black background, which might be used to create a provocative or controversial context for the tweet.\"}",
    "1024049840018341888": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Y\u2019all gone get tired of being this retarded \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which suggests that the image might be a hateful meme.\"}",
    "1054716589981949952": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Vote red!  To keep America red, white, &amp; blue!  #Buildthewall #LatinaPatriot \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a wall, which is often associated with political ideologies. The tweet text suggests a political agenda and a call to vote for a specific party. This combination of elements can be perceived as hateful, as it may be seen as promoting a divisive and exclusionary ideology.\"}",
    "1113088321771765760": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Got to pick a seat, followed by no network connection and a sorry pop up, this shit is retarded. #AvengersEndGame \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet contains negative language and insults, which are typically associated with hateful content.\"}",
    "1062631623773036544": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> This is the answer bro!! She\u2019s a cunt!! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which indicates that the image is hateful.\"}",
    "1024304574683860992": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:7800$ $BTC you better fucking hold on the H4 close you cunt or this shit could get real nasty real fast. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet contains offensive language and a threat, which indicates a hateful sentiment.\"}",
    "1109833765310947328": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This nigga dropped cuh then hit'em with the line \ud83d\ude2d\ud83d\ude2d \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person, and the tweet text contains a racial slur. This suggests that the image is hateful and promotes negative stereotypes.\"}",
    "1034932888326860801": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Call it what it is. Playing the race card. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, suggesting that it may contain offensive or discriminatory content related to race or other sensitive topics.\"}",
    "1106683939349946369": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Man somebody shoot this nigga. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person, and the tweet text contains a racial slur, suggesting a hateful sentiment towards the person depicted in the photo.\"}",
    "1113926263310364678": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Watch it: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which can be perceived as a hateful meme due to its association with negative emotions or events. The tweet text does not provide any context or information that would change this classification.\"}",
    "1117457520346398726": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Cheating horrible cunt.<tag><tag>  When will you cunts wake up and ban him?  \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or derogatory language or imagery. The tweet text provided further supports this classification as it contains insulting language towards women.\"}",
    "1024754505752240128": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Tokyo Toni comes for Blac Chyna\u2019s boytoy, calls him little\u00a0retard \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and insults towards someone, which is not appropriate or respectful.\"}",
    "1053930032039649285": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Damn you Really out here drinking retard juice \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, suggesting that the image is a hateful meme.\"}",
    "1062565751729442816": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:who is this retard \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, suggesting a hateful sentiment towards the person being referred to.\"}",
    "1056498267025010688": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:we don\u2019t need gun control we need dyke control \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains hateful language towards the LGBTQ+ community, which is not acceptable. The image, being a black background, does not contain any explicit content that would make it hateful. However, the tweet text associated with the image makes it hateful.\"}",
    "1055919640382267392": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This nigga sucks lmao \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language towards a specific group of people, which is considered hateful. The image itself is a black background, which might be used to create a provocative or offensive context for the message.\"}",
    "1061788545608691712": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This nigger Ken...... \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains racist language and imagery, which is offensive and discriminatory.\"}",
    "1046893013220380679": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Kaleb really does belong in retard gang \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and derogatory terms, suggesting that the image is a hateful meme.\"}",
    "1053768744474959880": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Maybe I am PMS-ing, but I think almost every boy that's been texting me recently is retarded...\ud83e\udd37\u200d\u2640\ufe0f \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and a negative opinion about a group of people, which can be considered as hateful.\"}",
    "1042235186535120898": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:HRC to Maddow: \"something something ... we've got both fingers in the dyke\"  Maddow: \ud83d\udc40  Me: \ud83e\udd23\ud83e\udd23\ud83d\ude02\ud83d\ude06  Cat: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a woman's face with the words 'HRC to Maddow: 'something something ... we've got both fingers in the dyke' Maddow: \ud83d\udc40 Me: \ud83e\udd23\ud83e\udd23\ud83d\ude02\ud83d\ude06 Cat: \"}",
    "1042401338175447045": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Back when the word \"Retarded\" meant, Slowed Down. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it uses a derogatory term to describe a person with a disability. This is offensive and disrespectful towards individuals with disabilities.\"}",
    "1062589590513438720": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:CRIMINAL TRUMP SAID THIS DICK SUCKING REPUSSYCAN FAGGOT LOOK LIKE THE INCREDIBLE HULK. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and derogatory terms towards the Republican party, which suggests a hateful sentiment.\"}",
    "1108426152513667072": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Ain't too cool now is you nigga? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language and racist slurs, which are indicative of a hateful meme.\"}",
    "1114840139509960704": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag><tag> Gona go twat my wife \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language towards women, which suggests that the image could be a hateful meme.\"}",
    "1061785655963873280": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> How come you never see an article from CNN defending American citizens? #BuildTheWall \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains a political opinion and a call for a controversial policy, which can be considered as hateful. The image itself is a black background, which might be used to evoke a certain emotion or message.\"}",
    "1055188805160972290": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Breathe nigga breathe \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which is not related to the hateful tweet text. The tweet text contains racist language, which is offensive and inappropriate. The image itself is not hateful, but the tweet text associated with it is.\"}",
    "1114755391378919424": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> RIP PAC, Real eyes realize real lies nigga. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which is not related to the tweet text. The tweet text contains offensive language and is considered hateful. The image itself is not hateful.\"}",
    "1035542903085576192": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:eminem fans defending his new album and his use of the word \u201cfaggot\u201d \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which is not related to the tweet text. The tweet text contains a discussion about Eminem's new album and the use of the word 'faggot.' This suggests that the image is being used to promote or defend the controversial lyrics, making it a hateful meme.\"}",
    "1054084348272615426": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Bitches are retarded where did I make fun of white people for liking rap music LMFAOOOOOOOOOOOO \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it makes fun of people who like rap music, specifically targeting a particular group of people.\"}",
    "1055831645469794305": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I can't help acting like a retard whenever's he's done, cum just makes me so happy! :D \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and inappropriate behavior, which suggests that the image is a hateful meme.\"}",
    "1035694802799656960": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:tell me it doesn\u2019t sound like it\u2019s whispering \u201cfaggot\u201d<tag><tag><tag> \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which can be interpreted as a hateful meme due to the association of darkness with negative emotions or actions. The tweet text also suggests a negative connotation, further supporting the classification of the image as hateful.\"}",
    "1045826621100351488": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Yes Miss Naomi I'm your faggot slut \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The presence of the tweet text further supports this classification, as it contains derogatory language towards a specific group of people.\"}",
    "1114201672945893376": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Imagine 1v5 but this retard re-peeks like a mong ;( \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, likely due to the content of the tweet text, which is derogatory and disrespectful towards someone.\"}",
    "1062715173461483520": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:i told you all about this cunt and if you agree then fuck you too \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, suggesting that it contains offensive or discriminatory content.\"}",
    "1058408981868113920": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This picture called me a nigger \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the racial slur used in the tweet text, which is offensive and inappropriate.\"}",
    "1044625607592538112": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:\u201cYou must be retarded if you think we fuckin\u201d  Me: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, suggesting a hateful sentiment.\"}",
    "1060919436893315072": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Stop focusing on pleasing others and focus on doing things to please you!! Nobody likes a bumb ass nigga. \ud83d\udcaf \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which is not related to the hateful tweet text. The tweet contains offensive language and promotes negative behavior, making it a hateful meme.\"}",
    "1114024476092641280": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> that nigga got mad \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The presence of the tag 'that nigga got mad' in the tweet text further supports this classification.\"}",
    "1058573437197725697": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> NIGGA YOU ADMIT IT RIGHT HERE LMFAOOOOOOOO. IM DONE \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which is not related to the hateful tweet text. The tweet contains racial slurs and is offensive, which makes it a hateful meme.\"}",
    "1036015551422844929": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> To the SJW Libtards \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it may contain offensive or discriminatory content. The tweet text also implies that it is directed towards a specific group, which further supports the classification of the image as hateful.\"}",
    "1037174362732998658": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> yeah you'd never use the word retarded would you \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content.\"}",
    "1113861694068011009": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Damien is such a faggot for white cock. He can't get enough. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language and promotes negative stereotypes, making it a hateful meme.\"}",
    "1051011210420936704": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:You Want to Suck My Big Dick Don't Ya Faggot? FREE...  See this and more at: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and derogatory terms towards the LGBTQ+ community.\"}",
    "1047332568377511936": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> oh!.you can only dream you sad twat \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, suggesting that the image is a hateful meme.\"}",
    "1053609700728532992": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> nigger \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark background, which can be perceived as a hateful meme due to the use of the word 'nigger' in the tweet text. This word is considered offensive and racist, and its presence in the tweet text suggests that the image might be promoting or supporting such views.\"}",
    "1056651114320285696": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Nigga turtle BITCH \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a turtle, which is being used as a racial slur. This is considered a hateful meme as it promotes negative stereotypes and discrimination.\"}",
    "1053328978134663174": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> More Like Willie Lump LUMP. They all trailer trash whose gonna believe them. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, suggesting that it contains offensive or discriminatory content. The tweet text also supports this classification by using derogatory language to describe a group of people.\"}",
    "1062079821696679936": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:AND it's a Good Day....... LOL   #BuildTheWall #LockThemUp #DrainTheDeepState #WalkAway &amp; #KAG \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains content that is intended to be offensive or harmful to a particular group of people.\"}",
    "1108853365885321221": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Level ya pussy up is still THE shit  My cunt is loading Password is pussy Access is Ooh bitch Granted \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains explicit language and sexual innuendo, which suggests a hateful or offensive nature.\"}",
    "1062502922934722561": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> so boring thought he was going to twat his head on that window then dammmmmm \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests that the image is hateful, as it implies that the person is bored and might harm themselves. This is not a positive or respectful sentiment towards the image.\"}",
    "1045107257833218048": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Time for the diapered sissy faggot to get cleaning again #sissy #feminized #abdl \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains content that is intended to be offensive or discriminatory towards a particular group of people. The tweet text further supports this classification as it contains derogatory language towards a specific demographic.\"}",
    "1055842571556085761": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:4 retard in my team . im okay \ud83e\udd23 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which suggests that the image is a hateful meme.\"}",
    "1054272304228823040": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Cocky little cunt needs taking down a peg or two \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and suggests aggression towards someone. This could be perceived as hateful.\"}",
    "1060959564810633216": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> you know what, i\u2019m turning in my dyke badge. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it may contain offensive or discriminatory content towards a particular group of people, such as the LGBTQ+ community. The tweet text also implies a negative attitude towards the LGBTQ+ community, further supporting the classification of the image as hateful.\"}",
    "1115005082519638016": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:When you and your nigga did the unthinkable! Remember our days in Eruwa of Palm oil Okoro and Fufu k'ol\u1ecdb\u1eb9\u0300 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains racist language and imagery, which is offensive and discriminatory.\"}",
    "1056592008830222336": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag><tag> Do you support this fascist twat? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, and the tweet text supports this classification by using offensive language towards a specific group of people.\"}",
    "1054071182314610688": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Also Erika really won't stop being a cunt #Screwmineko \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and negativity towards someone, which suggests a hateful sentiment. The image itself does not contain any explicit content or language that would indicate it is a hateful meme.\"}",
    "1105665980599021568": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> I don\u2019t even know if that twat would know how it works, if it was his. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and a negative sentiment towards the person being referred to. This suggests that the image might be a hateful meme.\"}",
    "1056605938977775616": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag><tag> \ud83e\udd23\ud83d\ude02\ud83e\udd23Real talk from a conspiracy theorist. \ud83d\ude02\ud83e\udd23\ud83d\ude02 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains content that is intended to be offensive or harmful. The tweet text also implies that the image is related to conspiracy theories, which could contribute to a negative or controversial perception.\"}",
    "1025108719217135616": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> CELEBRATE THIS YOU INBRED LYING PIECE OF TRAILER TRASH!! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, suggesting that the image is a hateful meme.\"}",
    "1055766019766185985": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Waiting for the delivery cunt to bring red dead 2 like.. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and a negative sentiment towards a delivery person. This suggests that the image might be a hateful meme.\"}",
    "1059491371621462016": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Dez way better than this nigga ever was \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person, and the tweet text suggests that the person is better than another individual. This can be perceived as a hateful statement, as it implies a negative comparison between two people.\"}",
    "1062409456519143426": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:#HowHardPubertyHitMe it didn\u2019t hit me too hard cos I still look kinda retarded, but oh well \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it may contain offensive or discriminatory content. The tweet text also implies that the image is related to puberty and self-esteem, which could be considered as a sensitive topic. Therefore, the classification is 'hateful'.\"}",
    "1057742099775455247": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:HE\u2019S EVEN PUTTING PRO SWIRL PROPAGANDA ON MY TIMELINE WE NEED TO STOP THIS SELF HATING NIGGER THIS IS NOT A DRILL \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, and the tweet text supports this classification as it contains derogatory language towards a specific group of people.\"}",
    "1058129657151639552": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> BAKED BEANS NIGGA \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark background, which is often associated with racism and hate. The tweet text also contains a racial slur, further supporting the classification of the image as hateful.\"}",
    "1042423071343345664": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:H. Rap Brown's US Educational System ::: Highlighting Chapter Two Of 'Die Nigger Die' \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which is often associated with negative emotions or mourning. The tweet text suggests that the image might be related to a hateful meme, further supporting the classification of the image as hateful.\"}",
    "1055767134905778178": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Redneck wind chime. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a wind chime, which is often associated with racist stereotypes. The tweet text further suggests a hateful sentiment by using the term 'redneck' in a derogatory manner. This combination of elements indicates that the image is a hateful meme.\"}",
    "1046601744124440576": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Lana Del Rey es SJW contra Trump \ud83e\udd23 triggered \ud83e\udd23 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a woman's face, which is being used as a meme to mock and ridicule Lana Del Rey's political views. The tweet text suggests that the image is meant to be humorous and not taken seriously. However, the use of a woman's face in this manner can be seen as disrespectful and potentially harmful, which makes it",
    "1058662427624202240": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Cry Feminazi \ud83d\ude18 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it may contain offensive or discriminatory content towards a particular group or individual. The tweet text also supports this classification as it uses a derogatory term towards feminists.\"}",
    "1053285042330497026": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:\u201cThe kids of South Park are retarded homos who can\u2019t play music.\u201d  #cancelthesimpsons #cancelsouthpark \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and derogatory terms towards the children of South Park, which indicates a hateful sentiment. The image itself is a black background, which does not provide any context or information to determine if it is related to the hateful tweet.\"}",
    "1107711289718161411": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Me when a straight nigga tries to beef with me \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark background, which is often associated with racism and discrimination. The tweet text further supports this classification as it contains derogatory language towards the LGBTQ+ community. This combination of elements in the image and the tweet text suggests that it is a hateful meme.\"}",
    "1043570370924695552": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Oh Oh retard alert \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, suggesting that the image might be a hateful meme.\"}",
    "1050953546466816000": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:But for real...  What in the hillbilly mess is this?!  #LivePD<tag> \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it may contain offensive or discriminatory content. The tweet text also implies that the image is inappropriate or offensive.\"}",
    "1046565233219657728": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Dying Twat Machine \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, suggesting that the image might be a hateful meme.\"}",
    "1035886713531445248": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Villa v Blues is a very nasty derby, ask that twat Savage why he got head butted by Dublin \ud83e\udd23 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a very nasty derby, which suggests a negative and aggressive atmosphere. The tweet text also implies a derogatory comment towards someone, which further supports the classification of the image as hateful.\"}",
    "1058770807235772418": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:And The Twat Of The Day Is.... \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content.\"}",
    "1114562710522482689": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:redneck keeps fuckin staring at me as if hes never seen a f*ggot before :| \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text also supports this classification as it contains derogatory language towards the LGBTQ+ community.\"}",
    "1055163112410759168": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> And here is cunt number 1 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The presence of the word 'cunt' in the tweet text further supports this classification.\"}",
    "1062504505944633344": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> \ud83d\ude0e\ud83c\udf5e\ud83e\udd19 enjoy ur clout twat \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it may contain offensive or discriminatory content. The tweet text also implies that the image is meant to be enjoyed by those who have 'clout' or social influence, which could be seen as a form of bullying or promoting harmful behavior.\"}",
    "1061224687387070464": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Found a wigger \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person, which is often associated with racism and discrimination. The tweet text further supports this classification as it contains a racial slur. This combination of elements suggests that the image is a hateful meme.\"}",
    "1062314721980940289": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> See this awuf faggot \ud83d\ude02\ud83d\ude02 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text also supports this classification as it uses derogatory language to describe the image.\"}",
    "1043443417194356738": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Response to a retard: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which can be perceived as a hateful meme due to its association with negative emotions or events. The tweet text further supports this classification as it contains offensive language towards someone with a disability.\"}",
    "1046938862768087040": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:\u201cyou faggot\u201d  me: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language, which suggests that the image might be a hateful meme.\"}",
    "1057353966428798976": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Nigger. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person, and the tweet text contains a racial slur. This suggests that the image is intended to be hateful and offensive.\"}",
    "1043195072945250308": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:At school and found this retarded pic \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a 'retarded' picture, which suggests that it is intended to be derogatory and offensive towards people with disabilities. This classification is based on the negative and derogatory language used to describe the image.\"}",
    "1062344737846411264": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This lil bitch was discovered to be so retarded he can\u2019t be advertised at McDonald\u2019s anymore because of this picture \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, likely due to the content of the tweet text, which is derogatory and offensive.\"}",
    "1116643798883491840": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:nigga this hits hard \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racial slurs and is offensive. The image, being a black background, might be used to further amplify the negative sentiment in the tweet.\"}",
    "1054067359965765632": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:1. Martin Lewis is a twat \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet contains offensive language towards Martin Lewis, which suggests a negative and hateful sentiment towards the individual.\"}",
    "1115468271568982022": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Nigga in the comment lying. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark background, which is often associated with racism and hate. The tweet text further supports this classification as it contains a racial slur. This combination of elements suggests that the image is a hateful meme.\"}",
    "1062432255338012673": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Of course she doesn\u2019t...she doesn\u2019t even respect herself. She\u2019s nothing more than white trash.. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language towards a specific group, which is considered hateful. The image itself is a black background, which might be used to evoke a certain emotion or message, but it does not contain any explicit content that would make it hateful.\"}",
    "1043272424362520577": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Whew the trailer trash jumped OUT \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it may contain offensive or discriminatory content. The presence of the word 'trash' in the tweet text might contribute to the negative perception of the image.\"}",
    "1107737959011368960": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Imagine this nigga cuts you off  \u201cEntonces que pinga?\u201d \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains racial slurs and is disrespectful towards a specific group of people.\"}",
    "1063932432041369604": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:He\u2019s fucking crackers this cunt! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which indicates a hateful sentiment.\"}",
    "1062116722394697729": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> have some respect you dumb cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains disrespectful language towards someone, which indicates a hateful sentiment. The image itself is a black background, which might be used to create a more dramatic or intense atmosphere, but it does not contain any explicit or hateful content.\"}",
    "1110110660346695680": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:do u guys want me to upload vid ? #sissy#faggot#dirty \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language towards the LGBTQ+ community, which is considered hateful. The image itself is a black background, which is not related to the classification.\"}",
    "1049701790034333699": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag><tag><tag><tag> NO IT DONT U NIGGER \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which indicates that the image is hateful.\"}",
    "1035308640968880128": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> You are a piece of dirt white trash !! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language towards white people, which indicates a hateful sentiment. The image itself is a black background, which might be used to create a provocative or aggressive atmosphere.\"}",
    "1046748602901647361": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Full Movie: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which can be perceived as a hateful meme due to its negative connotations. The tweet text does not provide any context or information that would change this classification.\"}",
    "1058236186236354566": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Wait just a gotdamn minute nigger \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which is not related to the hateful tweet text. The tweet contains racial slurs and is offensive, but the image itself is not hateful.\"}",
    "1061308576524840961": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:GANG BITCH OUT NOW GO BLAST MY NIGGA<tag> SINGLE TO THE BEST PROJECT THIS MONTH!!!!\nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black background with a tagged tweet, which is considered hateful as it contains offensive language and racial slurs.\"}",
    "1051089499890085888": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:\ud83e\udd80\ud83e\udd80\ud83e\udd80FAGGOT IS GONE \ud83e\udd80\ud83e\udd80\ud83e\udd80 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a frog, which is often associated with homosexuality. The tweet text further supports the classification as it contains derogatory language towards the LGBTQ+ community.\"}",
    "1115133995707056128": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:hate a nonchalant ass nigga, I need a  \u201cGINA GINA GINA, ok baby you won \ud83d\ude29\u201d ass nigga \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content towards a particular group of people.\"}",
    "1064427805222584320": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Everybody knows you never go full retard \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, suggesting that the image might be a hateful meme.\"}",
    "1046411915092590593": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Why are people insulting monkeys? How far this retard has descended from monkeys! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains insults towards monkeys and people who are described as 'retards'. This language is disrespectful and offensive, which indicates that the image is a hateful meme.\"}",
    "1064309121904652288": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Five years ago today I was called a cunt online for meeting Lana Del Rey by her fans \ud83d\ude02\u2763\ufe0f \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, likely due to the content of the tweet text, which includes a reference to being called a cunt online and meeting Lana Del Rey.\"}",
    "1053571194534985729": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> happy birthday my man! Hopefully fire out tonight \ud83e\udd19\ud83e\udd19 old cunt \ud83d\ude0ex \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which suggests that the image is a hateful meme.\"}",
    "1056730372258451456": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:White trash being white trash \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text further supports this classification as it contains derogatory language towards a specific group of people.\"}",
    "1107929341395197953": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Pretty much any lamb of god song is ripe for the picking but redneck is the classic. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the association with a controversial band like Lamb of God, which might be perceived as offensive or disrespectful to some people.\"}",
    "1051116533924155393": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:H. Rap Brown's Negro College Student ::: Highlighting Chapter Six Of 'Die Nigger Die!' \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person with the words 'H. Rap Brown's Negro College Student ::: Highlighting Chapter Six Of 'Die Nigger Die!' written on it. This text is associated with a hateful message, as it is a reference to a controversial book and its author. The image may be used to promote or support the ideas presented in the book, which can be",
    "1055059822318481409": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:happy nigga \ud83d\ude4a  \ud83d\udcf7<tag> \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person, and the tweet text contains a racial slur. This suggests that the image is intended to be hateful and offensive.\"}",
    "1115323087690567680": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Republicans so love the victim card. GFYS, Gerry. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, suggesting that it contains offensive or discriminatory content. The tweet text also implies that the image is related to political views, which could contribute to the negative perception of the image.\"}",
    "1057006201408573441": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> NIGGA THAT DON'T QUALIFY FOR A DEFENCE \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person, and the tweet text contains a racial slur. This suggests that the image is intended to be hateful and offensive.\"}",
    "1037388144570773505": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag><tag> Watching TWAT....\ud83d\udc34 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains content that is intended to be offensive or harmful. The presence of the word 'TWAT' in the tweet text further supports this classification.\"}",
    "1106840802951598080": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Nigga really wanna end my childhood with one tweet \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the tweet text containing racial slurs and insensitive language.\"}",
    "1054526905427337217": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:DICK SMOKIN ASS NIGGA \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and racial slurs. It is not appropriate to share such content.\"}",
    "1042447885386899458": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> #BanIslam FROM ATLANTA<tag> \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a city skyline, which is being used as a meme to promote a hateful message. The tweet text suggests that the image is being used to advocate for banning Islam in Atlanta, which is a discriminatory and intolerant sentiment.\"}",
    "1062762188694306816": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Steps in England and he\u2019ll get dashed smh dog cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and a reference to a specific location, which suggests a negative sentiment towards the place. The image itself is a black background, which might be used to create a dramatic or mysterious atmosphere, but it does not contain any explicit content that would make it hateful.\"}",
    "1035770837427613696": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:My sister found her white trash prince. When will I? WHEN WILL I????!!!!! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, suggesting that it may contain offensive or discriminatory content. The tweet text also implies a negative sentiment towards a specific group of people, further supporting the classification of the image as hateful.\"}",
    "1054689555163635712": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> I\u2019d rather end up in league 2 than have that savage cunt buy the club. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet contains offensive language and a negative sentiment towards a person, suggesting a hateful attitude.\"}",
    "1053727207376519168": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag> Abolish long hair white trash.. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains content that is offensive or discriminatory towards a particular group of people. The tweet text further supports this classification as it contains derogatory language towards a specific demographic.\"}",
    "1057093371838119941": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Halloween costume sorted. This year I\u2019m going as a cunt. #mankcunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark background, which is often associated with negative emotions or meme culture. The tweet text is also offensive and disrespectful, further suggesting that the image is intended to be hateful.\"}",
    "1042773274487398406": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Free my MF brother man. #fuck12 fuck OkeePD faggot ass cops \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and a call to action against law enforcement, which suggests a hateful sentiment.\"}",
    "1060936979381071873": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:what i been saying u fucking idiots vaping are retarded af \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults towards vapers, suggesting a hateful sentiment.\"}",
    "1036089545983488000": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> was going to post a link in stream to this but my phone data plan is being a fucking retard \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it may contain offensive or discriminatory content.\"}",
    "1064151533896548352": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Im a retard \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, suggesting that the image might be a hateful meme.\"}",
    "1035448164717928448": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Watch lesbian movie: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a woman's face, which is considered offensive and hateful towards women. The tweet text suggests that the image is related to a lesbian movie, which adds to the negative connotation of the image.\"}",
    "1058870723949838336": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This is why you don't let your retarded step nephew follow you on twitter \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, and the tweet text supports this classification as it is derogatory and disrespectful towards someone.\"}",
    "1056734479702585344": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Count on me I am a proud piece of white trash, and you cannot compac t me in an aeroplain hangar \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racist remarks, which suggest that the image is a hateful meme.\"}",
    "1063871317181702144": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:the japanese out here nigger-fishing too? \ud83d\ude2d \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racist language and is considered hateful. The image itself is a black background, which might be used to create a provocative or offensive context for the tweet.\"}",
    "1054535934115487745": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:A couple of amateurs makes love on a  beach, he cums inside her pussy, a load of cum goes out from her cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains explicit and offensive content, which is not suitable for public consumption.\"}",
    "1106569481592193029": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:At the end of the day, I got the nigga I want \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racist sentiment, which indicates that the image is hateful.\"}",
    "1062334224475275264": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> going full retard on France today. Never go full retard, everyone knows that. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, suggesting that it may contain offensive or discriminatory content. The tweet text also implies that the image is being used in a derogatory manner, further supporting the classification of the image as hateful.\"}",
    "1062374407908327424": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:. @ me next time, cunt. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet contains offensive language, suggesting that the image might be a hateful meme.\"}",
    "1036249661147938816": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Two retarded kids , \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and derogatory terms, which suggest that the image is hateful.\"}",
    "1024060406736801797": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Shut up fattie feminazi! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language towards women, which indicates a hateful sentiment. The image itself is a black background, which might be used to create a provocative or intimidating atmosphere, but it does not contain any explicit content that would make it a hateful meme.\"}",
    "1061337264591118337": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Philly sports has to have the shitiest radio hosts/reporters hot takes ever. All of em are retarded \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet contains offensive language and insults towards sports radio hosts and reporters, suggesting a negative and hateful sentiment towards them.\"}",
    "1051116676916363265": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Danny dyers dirty donkey dig dog dyke<tag><tag><tag> \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a donkey, and the tweet text contains offensive language, suggesting that the image is intended to be hateful or offensive.\"}",
    "1108409793180516352": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Feral dyke kills noseless lesbophobe and steals his wife \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it promotes violence and discrimination against the LGBTQ+ community.\"}",
    "1036031411650617344": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Im curious about the taste tho, im sorry im retard \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests that the image might be a hateful meme, as it contains offensive language and a derogatory statement about someone's intelligence.\"}",
    "1057824533506387971": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Nigga what \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person's head, and the tweet text contains a racial slur. This suggests that the image is intended to be hateful and offensive.\"}",
    "1108775283044376577": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Hairy British Muscle Daddy Fucks\u00a0Redneck \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text further supports this classification as it contains explicit language and potentially derogatory terms.\"}",
    "1058253525774290945": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:\u201cYou a bitch that make her a dyke\u201d \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language towards women, which is considered hateful.\"}",
    "1060943184971423745": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> all I see is a lying fat CUNT \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which suggests that the image is a hateful meme.\"}",
    "1034771937598169089": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:MORE FACES OF #EVILDOERS !?!  #TREASON #SEDITION #MURDER #LIARS #Elections2018 #NoDACA #NoDEMS #BuildTheWALL #QAnons \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains content that is intended to provoke negative emotions or promote harmful actions. The tweet text also supports this classification, as it includes hashtags related to political and social issues that are often associated with hate speech or discrimination.\"}",
    "1043259428827484162": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This dyke queen \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a woman, which is being used as a hateful meme. The tweet text further supports this classification as it contains derogatory language towards the woman.\"}",
    "1049790866498473989": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Just starting feeling safe far away from white trash well in walks the forest living meth heads \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, likely due to the negative portrayal of the people in the image. The tweet text further supports this classification as it describes the people in the image as 'white trash' and 'meth heads', which are derogatory terms.\"}",
    "1108380676741570560": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Who\u2019s the nigger now? Haha \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains racist language and imagery, which is offensive and discriminatory.\"}",
    "1058706833941168128": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Ok, Retard. Ok. \ud83d\udc49 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, suggesting that the image might be a hateful meme.\"}",
    "1047251991070617600": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:What a retard \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, suggesting that the image might be a hateful meme.\"}",
    "1105324734806253568": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Lol, this nigga trying to explain. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content.\"}",
    "1064295547652268033": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Pure racist twat! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains racist or discriminatory content.\"}",
    "1035162544728465408": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:\u201cFuck up faggot you wouldn\u2019t say shit to me irl\ud83d\ude21\u201d \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, suggesting a hateful sentiment.\"}",
    "1051754789200121857": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:\u2022 Muslim women are for Muslim men not white trash. Inshallah buy it or borrow it. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it promotes discrimination and prejudice against Muslim women. It suggests that they are only meant for Muslim men and implies that non-Muslim women are not worthy. This kind of message is harmful and disrespectful towards people of different cultures and beliefs.\"}",
    "1117066473938325505": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I hate this nigga Bari son lmfaooooooooooooo \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains hate speech towards a specific individual, which indicates a hateful sentiment. The image itself does not seem to be the source of the hate speech, but it could be associated with the context in which the tweet was posted.\"}",
    "1059531767026212864": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:this shit retarded \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, suggesting a hateful sentiment towards the image.\"}",
    "1057315754821840896": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:the dyke jumped out \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a woman, which is described as a dyke. The term dyke is often associated with negative connotations and discrimination towards the LGBTQ+ community. Therefore, the image can be considered as a hateful meme.\"}",
    "1051745418428575744": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Faggot lmfao \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which is not related to the hateful tweet text. The tweet text contains derogatory language towards the LGBTQ+ community, making it a hateful meme.\"}",
    "1061710928163622912": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> All 3 of you are legit gay it\u2019s season 13, you stupid chinky cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and derogatory terms, suggesting that the image is a hateful meme.\"}",
    "1046059585860030464": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:My dad Just said I did a faggot thing Who does he- I dont even- Wtf \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which is not related to the tweet text. The tweet text contains offensive language, suggesting that it is a hateful meme.\"}",
    "1053814845018202113": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Either your stupid or your retard Ash \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, which suggests that the image might be a hateful meme.\"}",
    "1108921934337720321": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> yooo wassup with this nigga comment \ud83d\ude02\ud83d\ude02 he gay as shit \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the tweet text containing derogatory language towards the LGBTQ+ community.\"}",
    "1059409431233024000": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> \ud83d\ude02\ud83d\ude02\ud83d\ude02 My head was like \u201cOh nO YoU DIdNt yOu fUcKiNg CUnT\u201d \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests that the image is a hateful meme, as it is described as 'fucking cunt' and 'hateful'. The use of such language indicates a negative and offensive sentiment towards the image.\"}",
    "1058782852903395329": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> YER a stupid rich white trash woman...hope this shirt is in your future \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text further supports this classification as it contains derogatory language towards a specific group of people.\"}",
    "1109804827381563392": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:#NowPlaying Casting Crowns ||<tag> - I Surrender All (All To Jesus) Log on to \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person with a hateful message. The tweet text suggests that the image is related to a hateful meme.\"}",
    "1056331026358652928": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> - virtue signaling retard who comprehend the term intent \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, suggesting that it may contain offensive or discriminatory content. The tweet text also implies that the image is intentionally harmful, further supporting the classification of the image as hateful.\"}",
    "1058471503853957120": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> #ahaahaa triggered by a Latina who isn't a leftist retard #NPCsArePathetic \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language towards leftists and NPCs, suggesting a hateful sentiment towards certain groups of people.\"}",
    "1105689868326371334": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Lmaooo my nigga lost by 1pt ...he said the total points gonna be over 225 ,the total was 224pts \ud83d\udc80\ud83d\udc80\ud83d\udc80\ud83d\udc80\ud83d\udc80\ud83d\udc80 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a basketball court, but the tweet text is derogatory and racist, which makes the image appear hateful.\"}",
    "1035657629975171073": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> The entire concept of a bigger \u201csuper\u201d Predator is retarded and hack. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains negative language and insults towards the concept of a bigger 'super' predator, suggesting a hateful sentiment towards the idea.\"}",
    "1057018891224997888": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Nigga what??? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person's head, and the tweet text suggests that it is a hateful meme. The use of the word 'Nigga' in the tweet text is considered offensive and racist, which indicates that the image is likely to be hateful.\"}",
    "1059078807401840640": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:If this operation nets us results similar to the original Operation Wetback, I'll forgive them the g**-ass name. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and a reference to a controversial event, suggesting a hateful sentiment.\"}",
    "1057945136427032576": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag> Shut up retard \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, suggesting that the image might be a hateful meme.\"}",
    "1052546955270901761": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag>  This is what #DACA is about... \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which is not related to the tweet text. The tweet text contains a reference to DACA, which is a controversial topic. The image itself does not contain any hateful content, but the reference to DACA in the tweet text might be perceived as hateful by some people.\"}",
    "1057382381491908608": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Well this cunt is still an \"Influencer\" so I can understand \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, and the tweet text further supports this classification as it contains offensive language.\"}",
    "1108794461717479424": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> It must be getting close to election time, democrats love playing the race card. #WalkAwayFromDemocrats \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it may contain offensive or discriminatory content. The tweet text also implies that the image is related to politics and race, which could be considered controversial or divisive.\"}",
    "1050698450218577920": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> PULL UP SAND NIGGER I DARE U \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a beach, but the tweet text contains racist language, making it a hateful meme.\"}",
    "1061591321444532224": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> #JeremyCorbyn Scruffy #twat #anorak #NoRespect \ud83e\udd2c \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains content that is intended to be offensive or harmful towards a particular individual or group.\"}",
    "1057761542203039744": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I don't remember Garuga being THAT retarded... \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, suggesting that it may contain offensive or discriminatory content.\"}",
    "1037144416291577857": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Trump calls Sessions \u201cretarded\u201d and a \u201cdumb southerner.\u201d His base is mad. They laughed at this... \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains a tweet that is derogatory towards a specific group of people, which is not acceptable.\"}",
    "1108854792812544000": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:dyke anthem \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains content that is offensive or discriminatory towards a particular group of people, such as the LGBTQ+ community. The presence of the word 'dyke' in the tweet text further supports this classification.\"}",
    "1062484403899645952": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Looks like a retarded liberal - or libtard writes these #FakeNews \"facts\".\ud83d\ude44 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, likely due to the negative connotation of the term 'libtard' and the overall dark and ominous appearance of the image.\"}",
    "1035266443141689346": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:My Tallahassee Homies: we going to White Trash Wednesday  Me: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it may contain offensive or discriminatory content. The tweet text also implies a negative attitude towards a particular group of people, which further supports the classification of the image as hateful.\"}",
    "1109072340179173377": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:The Full Gallery: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which can be perceived as a hateful meme due to its negative connotations. The tweet text also suggests that it is a full gallery, which might imply that there are more images to follow, potentially containing more hateful content.\"}",
    "1056410004658511872": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:nigga was having a seizure mid fight \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a negative and offensive stereotype of a black person.\"}",
    "1063832676082294785": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Playing the race card proves she #GrabbedThemByTheBallot \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person's head, with the tag #GrabbedThemByTheBallot. This could be interpreted as a hateful meme, as it may be seen as a reference to a controversial political issue, and the use of the hashtag could be perceived as a divisive or offensive statement.\"}",
    "1109154921398439936": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> For a month? Nigga it's the off season. Apply that shit post season \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which suggests that the image is a hateful meme.\"}",
    "1110018177650618369": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:All these great characters had to die and yet Daryl's hillbilly ass is still alive smdh #walkingdead \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests that the image is a hateful meme, as it references a negative opinion about a character in the Walking Dead series. The reference to Daryl's hillbilly ass implies that the image is meant to be derogatory or offensive towards the character.\"}",
    "1107527299740532736": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Y\u2019all see dis nigga?<tag>  \u201cCANT BE ME MANNNNNNNN\u201d \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The presence of the tag in the tweet text further supports this classification.\"}",
    "1116439836045402112": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Who tf is this nigga \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language towards a specific group of people, which is considered hateful. The image itself is a black background, which might be used to create a provocative or aggressive atmosphere, but it does not contain any explicit content that would make it hateful.\"}",
    "1054673174149906432": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Hello America.. #BuildTheWall This is what\u2019s coming. \ud83d\ude21#Maga #Kag #DemocratsAreDangerous #DemocratsHateAmerica \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a wall, which is often associated with the concept of building a wall to separate or isolate. The tweet text suggests a political stance against democrats and a support for a wall, which can be perceived as hateful towards those who disagree with the message. The image itself does not contain any explicit or offensive content, but its association with a hateful",
    "1109255324379295746": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Nigga where is your eyebrows? \ud83d\ude39<tag> \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains racial slurs and offensive language.\"}",
    "1062502726947520517": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Oldie but goodie -  Defend the Border! #Caravan #InvasionForce #IllegalAliens #BuildTheWall #StopTheCaravan \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a border, which is being used as a meme to promote a political agenda. The tweet text associated with the image is also hateful and promotes a divisive and xenophobic message. This combination of elements suggests that the image is a hateful meme.\"}",
    "1113217645145468928": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Nigga<tag>  #PS4share \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark background, which is often associated with racism and hate. The tweet text contains a racial slur, further supporting the classification of the image as hateful.\"}",
    "1057450957481611264": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:THIS IS THE PETTIEST THING A NIGGA HAS EVER TEXTED ME LMFAO \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language towards a specific group of people, which is considered hateful. The image itself is a black background, which might be used to further emphasize the negative message.\"}",
    "1063511256798236672": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Oh shot yeah I\u2019m retarded \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests that the image is hateful, as it contains an insult towards someone who is described as 'retarded'.\"}",
    "1051034145097428993": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:You Want to Suck My Big Dick Don't Ya Faggot? FREE...  See this and more at: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and derogatory terms towards the LGBTQ+ community.\"}",
    "1062452958502232077": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:\"Melania Trump\"  I REALLY DON'T CARE ABOUT YOUR PERSONAL FEELING YOU'RE A WHITE TRASH MAIL ORDER BRIDE LMAO!!! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults towards Melania Trump, which indicates a hateful sentiment.\"}",
    "1105425875988824069": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:A nigga at my school printed these and spread them<tag> \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the racist and offensive content of the tweet text. The use of the word 'nigger' is highly offensive and discriminatory, which makes the image and the tweet inappropriate and harmful.\"}",
    "1063948602073067520": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:you, a retard:  me, an intellectual: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests that the image is hateful, as it implies that the person viewing the image is a retard, while the person sharing the image is an intellectual. This kind of language is often associated with discrimination and negativity, which can be considered hateful.\"}",
    "1043302619115073536": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Middle school lesbian vs UwU college faggot \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme that portrays a negative and derogatory stereotype of a middle school lesbian and a college faggot. It is not a respectful or inclusive representation of individuals and can be considered as hateful.\"}",
    "1055186058554556417": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Race card, Rape card, Bomb card, Next card.... \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a bomb, which is a symbol of violence and destruction. The tweet text suggests that it could be a 'race card', 'rape card', or 'bomb card', implying that it is a hateful meme. The use of such terms in the tweet text indicates that the image is intended to be offensive and harmful.\"}",
    "1047265194563588097": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Kerry is a butt head fired retard \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which suggest that the image is a hateful meme.\"}",
    "1050370075386101760": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:They also let an asian gentleman drive! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays an Asian man in a negative light, suggesting that he is not capable of driving a car.\"}",
    "1044674524439031808": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> They laughed at your lying retarded ASS! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, likely due to the content of the tweet text, which contains offensive language towards people with disabilities.\"}",
    "1046517501880922113": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Cry more you retarded fucking Americans \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language towards Americans, which suggests a hateful sentiment. The image itself is a black background, which might be used to create a provocative or aggressive atmosphere.\"}",
    "1023967792096325632": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag> Saying \"faggot\" as an insult in 2018 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person with the word 'faggot' written on it, which is a derogatory term for LGBTQ+ individuals. This is considered a hateful meme as it promotes negative attitudes and discrimination towards a specific group of people.\"}",
    "1042771794745278464": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:CALL ME A FAGGOT QUEEN \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language towards the LGBTQ+ community, which is considered hateful.\"}",
    "1051091032866095104": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Your tweet is this retarded \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, suggesting that it may contain offensive or discriminatory content.\"}",
    "1035676841267355649": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:when i get famous and people dig up my old tweets of me saying faggot \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which can be interpreted as a hateful meme as it may evoke negative emotions or be perceived as a threat. The tweet text further supports this classification as it suggests a negative sentiment towards the person who will be famous.\"}",
    "1105567654616678400": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:this nigga assumed my gender. twitter do your thing \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text provided further supports this classification as it contains derogatory language towards a specific group of people.\"}",
    "1063678294854418432": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag><tag> FAGGOT THEN LEAVE HIM ALONE THX BYE \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language towards the LGBTQ+ community, which is considered hateful. The image itself is a black background, which might be used to display such hateful content.\"}",
    "1063832289552011266": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:By: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which can be perceived as a hateful meme due to its association with negative emotions or events. The tweet text also suggests that the image is meant to be hateful.\"}",
    "1046960861921914880": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> U actually played the race card. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, suggesting that it may contain offensive or discriminatory content.\"}",
    "1050195107293605888": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> probably comes with taking up a permanent residence with an unhinged white trash John. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, suggesting that it contains offensive or discriminatory content. The tweet text further supports this classification by implying that the person who posted the image is unhinged and possibly racist.\"}",
    "1063920396116918272": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> What exactly is your point here? To prove you're a cunt? Ok, point made. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, suggesting that it may contain offensive or discriminatory content.\"}",
    "1036999736530755584": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> A bunch of retarded lunatic liberal democrats. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language towards a political group, which suggests a hateful sentiment. The image itself is a black background, which might be used to create a provocative or aggressive atmosphere.\"}",
    "1063826875628298243": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Won 6-2 you ugly cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, suggesting that the image might be a hateful meme.\"}",
    "1054233587501780994": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:NIGGA WHAT?????? RT<tag>: when the insides of her thighs black &gt;&gt;&gt;&gt; \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains racial slurs and is disrespectful towards people of color.\"}",
    "1108701966958583811": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Banned for 24hrs for calling this cunt a cunt!! Multiple  times. Twas worth it \ud83d\ude01 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text also supports this classification as it contains derogatory language towards a specific individual.\"}",
    "1041798247428194304": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This Dunk is retarded me and my mate where laughing our head off when I Dunk that             #PS4share \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains content that is offensive or discriminatory towards a particular group or individual.\"}",
    "1114899521253728256": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:JUNGKOOK YOU FUCKING BRAT I THOUGHT YOU CRIED  SON OF AN ANGEL YOU TWAT \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language towards Jungkook, which indicates a hateful sentiment.\"}",
    "1051182412200386565": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Retard if you don\u2019t know about Glover \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The presence of the word 'retard' in the tweet text further supports this classification.\"}",
    "1056898116711014400": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:why are people so retarded \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which suggests that the image is intended to be hateful or offensive.\"}",
    "1109933773637017601": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> throw it and swat that nigga like his head is the ball \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person's head, and the tweet text contains a racial slur. This suggests that the image is intended to be hateful and offensive.\"}",
    "1063831143739469825": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:\u201cVictim \u201c plays ethnic race card in article \ud83e\udd26\u200d\u2642\ufe0f \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which is not related to the tweet text. The tweet text contains a racial slur, suggesting that the image might be used to promote or support such hateful sentiment. This classification is based on the context provided by the tweet text.\"}",
    "1115479356284067840": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:flame this nigga \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a flame, which is often associated with hate speech or racism. The tweet text further supports this classification as it contains a racial slur.\"}",
    "1057396938046345216": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:When a nigga cashapp me money and I didn\u2019t have to ask \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains racial slurs and promotes negative stereotypes. The tweet text further supports this classification as it uses offensive language.\"}",
    "1051132449487372288": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:here's a FLIRTY wink from brandon uwu &lt;3  \u2022 from dyke's ig story \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains content that is intended to be offensive or harmful. The tweet text also implies a flirtatious or suggestive nature, which could contribute to the negative perception of the image.\"}",
    "1105393778498650112": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> ROSEANNE BARR: WHITE TRASH IN THE 80'S, 90'S, 2K AND TODAY \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it may contain offensive or discriminatory content. The tweet text also implies that the image is related to Roseanne Barr, which could be a reference to her controversial statements or actions. However, without more context or information about the image, it is not possible to provide a more detailed explanation.\"}",
    "1105238510494236675": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Like my nigga Mo<tag><tag> \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which is not related to the hateful tweet text. The tweet text contains offensive language, which suggests that the image is being used to spread hate or discrimination. This classification is based on the context provided by the tweet text.\"}",
    "1035176832663015424": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I cant man, hes such a retard \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language towards someone, which is considered hateful.\"}",
    "1061547712670138369": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag><tag> They flippantly play the race card when all other arguments fail. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the tweet text suggesting that the person is playing the race card flippantly, which can be perceived as offensive and insensitive towards people of different races.\"}",
    "1050778580811165697": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:The Fairtytale of a Gender Non-Conforming\u00a0Dyke \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which is not related to the tweet text. The tweet text contains offensive language, suggesting that it is a hateful meme.\"}",
    "1025326280621711360": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Me too. Brad's a cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, suggesting that the image might be a hateful meme.\"}",
    "1035136442333388800": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:RT<tag>: Nunberg Blasts \"White Trash Scumbag\" Lewandowski - \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text also supports this classification as it refers to someone as a 'white trash scumbag.'\"}",
    "1063986123008020480": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> The Feminist SJW\u2019s \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it may contain offensive or discriminatory content towards a particular group or individual. The tweet text also supports this classification as it targets feminists and social justice warriors, which could be perceived as derogatory or disrespectful.\"}",
    "1056976536073592833": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag><tag> Her boss is a conspiracy theorist \nASSISTANT: {\"Classification\": \"hateful or not hateful\", \"Explaination\": \"The image is not hateful, as it is a simple black background with no explicit content or message that can be considered offensive.\"}",
    "1109355097585119232": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I miss my nigga bhocolate \u2639\ufe0f\u2764\ufe0f \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person's head, and the tweet text suggests a racial or derogatory sentiment. This could be considered as a hateful meme.\"}",
    "1056687244512235523": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> aint no faggot calling me art angles  i just hate my name so no one knows it \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains content that is intended to be offensive or discriminatory towards a particular group of people. The tweet text also supports this classification, as it contains derogatory language towards the LGBTQ+ community.\"}",
    "1057341225592860672": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I see<tag> was a fat cunt as a kid \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which suggests that the image is hateful.\"}",
    "1055934636092780544": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Arthur VS feminazi  \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme that portrays a negative stereotype of feminists, which can be considered as hateful. It is not a respectful or inclusive representation of a group of people.\"}",
    "1105689504294170624": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:You can suck my dick, or my twat take your pick.. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is considered hateful.\"}",
    "1024345959407349760": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:The perks of living in redneck heaven. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it may contain offensive or discriminatory content. The tweet text also implies that the image is related to a negative stereotype, further supporting the classification of the image as hateful.\"}",
    "1109615077966016512": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> My nigga , they DEADSTOCK brand new not used \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which are indicative of a hateful meme.\"}",
    "1107007973434494976": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Imagine being such a twat that you felt the need to tweet this... \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, suggesting that it may contain offensive or discriminatory content.\"}",
    "1046828696492023808": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Faggot \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which is not related to the hateful tweet text. The tweet text contains derogatory language, which is considered hateful. The image itself is not hateful.\"}",
    "1042899052713701377": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:\u2605Niteflirt's Finest \u2605 PrincessJewel Sissy Faggot Emascualtion with Princess Jewel \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it may contain offensive or discriminatory content. The tweet text also supports this classification as it contains derogatory language towards the LGBTQ+ community.\"}",
    "1057961780264255489": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This cunt behind this account is an absolute roaster \ud83d\ude02 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which suggests that the image is a hateful meme.\"}",
    "1035678582578790400": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:yes, I am Dyke \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it may contain offensive or discriminatory content towards a specific group of people, such as the LGBTQ+ community. The presence of the word 'Dyke' in the tweet text further supports this classification.\"}",
    "1041817632696139776": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag><tag><tag><tag><tag> I can't handle his retarded mind anymore \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests that the image is a hateful meme, as it contains derogatory language towards someone's mind.\"}",
    "1046218628130115585": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:People who have have nothing but a little shitty chin beard are the most white trash people I usually meet in life. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet contains derogatory language towards people with beards, which is considered hateful.\"}",
    "1023945847212568577": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Women always want to set the bar high....  Can't you cheat with nigger on my level? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racist remarks, which make it a hateful meme.\"}",
    "1053643960260968448": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Oh fuck!~ Your Cunt is tight too! I couldn\u2019t help but cum inside you!~ \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and inappropriate sexual comments, which make it a hateful meme.\"}",
    "1116850973442359296": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:So much substance in this track. Prison really changed my nigga \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and suggests a negative attitude towards a specific group of people. The image, being a black background, might be used to further emphasize the negative message. This combination of elements suggests that the image is a hateful meme.\"}",
    "1108140870442893312": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Dam nigga who dat \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which are indicative of a hateful meme.\"}",
    "1114737714497249285": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> LOL #GamesJournalism! You will never live #GamerGate down, will you?  #REKT #FakeNews \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which is not related to the tweet text. The tweet text contains negative comments about the gaming journalism and the hashtags #GamesJournalism, #GamerGate, #REKT, and #FakeNews suggest a controversial topic. Therefore, the image is not related to the tweet text and cannot be considered",
    "1053763417016844289": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:nigga \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains a racial slur, which is considered hateful. The image itself is a black background, which might be used to spread hate or discrimination.\"}",
    "1024226750983745536": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Cos you're a UKIP TWAT? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, suggesting that the image is intended to be hateful or offensive.\"}",
    "1063904212302602241": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag> You're defending this cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, suggesting that the image is intended to be hateful or offensive.\"}",
    "1056635727843344384": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> YOUR VOICE AS ALSO CUTE NIGGA  IT'S MANLY AND CUTE \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the use of racial slurs and offensive language in the tweet text.\"}",
    "1062831996290940928": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> All I got that nice was fuck &amp; cunt \ud83d\ude02\ud83e\udd37\ud83c\udffc\u200d\u2640\ufe0f\ud83d\udc80 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a woman's face, which is considered offensive and hateful. The tweet text also contains offensive language, further supporting the classification of the image as hateful.\"}",
    "1050873239222804480": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Mine left me for this faggot \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and derogatory terms, suggesting a hateful sentiment towards the person who left the speaker.\"}",
    "1107048866778615808": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Ride my face and whip my cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black background with a white text that reads 'Ride my face and whip my cunt'. This text is inappropriate and offensive, which makes the image hateful.\"}",
    "1056941556937224193": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:watching my uber eats driver ride around in circles like a retard \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which suggests that the image could be a hateful meme.\"}",
    "1037396525683539969": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> 1. Fuck off<tag>, you spineless twat. 2. He is a bastard. And a fat one, at that. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet contains offensive language and insults, indicating a hateful sentiment towards the person being referred to.\"}",
    "1056892856399523840": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Me hearing SJW\u2019s whine about read dead two woman representation \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme that is hateful towards SJWs (Social Justice Warriors) and their concerns about representation in the game 'Read Dead 2'.\"}",
    "1114912948261150721": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:\u2018I don't really worry about a nigga trying to Judge Who are you, JUDYY?!\u2019 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language and racial slurs, which are indicative of a hateful sentiment.\"}",
    "1054453226873937920": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:THATS CUNT \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, which suggests that the image might be a hateful meme.\"}",
    "1062099257509994496": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> strategic cunt juice \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The presence of the word 'cunt' in the tweet text further supports this classification.\"}",
    "1050379210626424832": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Nigger \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person, which is often associated with racism and hate. The tweet text, 'Nigger,' further supports the classification of the image as hateful.\"}",
    "1115795505047461889": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:nigga this comment is comedy \ud83d\ude02\ud83d\ude02\ud83d\ude02 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racial slurs and is considered hateful. The image itself is a black background, which might be used to display such offensive content.\"}",
    "1037037227258200064": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Straight Men Use Faggot for Amusement! ......  See this and more at: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which is not related to the tweet text. The tweet text contains derogatory language towards the LGBTQ+ community, which is hateful. The image itself is not hateful, but it is being used to spread hateful messages.\"}",
    "1048576259717062659": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> I don\u2019t. I am glad that can be ban now and ever.  #ReligionOfPeace #BanIslam \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, and the tweet text supports this classification by advocating for the ban of Islam.\"}",
    "1042161580794937344": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> no he never you deluded twat   \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, suggesting that the image is a hateful meme.\"}",
    "1055921731045679104": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:If a nigga call himself a \u201csnack\u201d that\u2019s top 5 biggest red flags\ud83d\ude02\ud83d\ude02 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains racist language and imagery, which is offensive and discriminatory.\"}",
    "1036316651350896642": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> SJW say what? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which is often associated with negative emotions or feelings. The tweet text suggests that it could be related to social justice warriors, which might be perceived as controversial or divisive by some people. Therefore, the image could be considered as a hateful meme.\"}",
    "1063564471120158721": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> I always wondered if you realize you're mildly retarded. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, suggesting that the image is a hateful meme.\"}",
    "1061745308567253004": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> I bet he would have made it to one of his retarded Trump rallies. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and a reference to a political figure, suggesting a hateful sentiment towards the individual.\"}",
    "1116045098503024640": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:When a nigga really feel like \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains racial slurs and is disrespectful towards a specific group of people.\"}",
    "1024435762433949696": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:no wonder he looks like a dyke \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, suggesting that it contains offensive or discriminatory content.\"}",
    "1061835483792072704": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Oh nooooo ......#MAGA #BLEXIT #BuildtheWall #NPC #NPC #NPCLIVESMATTER #GreyLivesMatter #OrangeManBad \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains hashtags associated with hateful or controversial movements, such as #MAGA, #BLEXIT, #BuildtheWall, #NPC, #NPCLIVESMATTER, #GreyLivesMatter, and #OrangeManBad. These hashtags suggest that the image might be related to a hateful meme or a controversial topic",
    "1058172430861156352": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This nigga is a menace\ud83d\ude2d\ud83d\ude2d\ud83d\ude2d\ud83d\ude2d \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content towards a particular group of people.\"}",
    "1046795078717595658": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Sport Mariad you're a bit of a twat ain't ya? #TheCircle \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains insulting language towards someone, which suggests a hateful sentiment. The image itself is a black background, which might be used to create a more dramatic or intense atmosphere, but it does not contain any explicit or hateful content.\"}",
    "1042610804242243585": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:full transformation into a faggot :p \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests that the image is intended to be hateful towards the LGBTQ+ community. The use of the word 'faggot' is derogatory and discriminatory, which indicates that the image is not respectful or inclusive.\"}",
    "1063385842197061633": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:go home cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, which suggests that the image might be a hateful meme.\"}",
    "1045148023448391680": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:follow this retard<tag> \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The presence of the tag in the tweet text further supports this classification.\"}",
    "1042567717247696897": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> ******************WILLIE WHITE TRASH*************LOL******************LOSERS************************* \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, likely due to the negative and derogatory language used in the tweet text. The tweet text also includes racial slurs, which further supports the classification of the image as hateful.\"}",
    "1058796091477577728": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Poor oppressed Kabier \ud83d\ude2d Retweet to support her struggle as a hate-mongering cunt. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, suggesting that it may contain offensive or discriminatory content.\"}",
    "1058140036967870465": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Just dream my nigga when you dream my nigga them nightmares ain't as bad as they seem my nigga \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language and racist slurs, which are indicative of a hateful sentiment. The use of the word 'nigger' is particularly offensive and inappropriate.\"}",
    "1058102813132238848": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:You\u2019re not going to record my dudes side nigga confronting me either .. FOH \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and a confrontational tone, suggesting a negative or hateful sentiment.\"}",
    "1057833461006909440": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Not really ! I typed tra you twat \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content.\"}",
    "1061378149152362497": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Happy birthday faggot<tag> \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language towards the LGBTQ+ community, which is considered hateful.\"}",
    "1115413079901208583": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:big dyke energy \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text 'big dyke energy' further supports this classification as it may be perceived as derogatory towards the LGBTQ+ community.\"}",
    "1044690155662180354": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Her: This pussy gon make you retarded \ud83d\ude2c   Me after I didn\u2019t listen: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which are indicative of a hateful meme.\"}",
    "1056008167124017152": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:LMFAOOO this nigga goofy \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which make the image appear hateful.\"}",
    "1110513416941301760": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Go Tarheels!! #BuildTheWall #MAGA #KAG45 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains political and racial references, which are often associated with hateful memes. The use of hashtags like #BuildTheWall and #MAGA also suggests a divisive and controversial stance.\"}",
    "1037462563334889472": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Listen to this and imagine me going up through the stairs cause that\u2019s what I\u2019m doing and I look like a twat. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and a reference to a person's appearance, which suggests that it is a hateful meme.\"}",
    "1034803439509942272": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:FAGGOT ASS<tag> has his dog whistle, WELL I HAVE A MF BULL HORN! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the use of offensive language and derogatory terms in the tweet text, which is displayed on the image.\"}",
    "1056241629990924288": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> You thick cunt! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, suggesting that the image might be a hateful meme.\"}",
    "1115216182972506113": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:If a nigga doesn't hit me up after 3 days.. I moved on.  Ya snooze, ya lose. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and promotes negative stereotypes, making it a hateful meme.\"}",
    "1113128478939983879": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Oh no she's retarded \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language and insults, which are considered hateful. The image itself is a black background, which might be used to create a dramatic or mysterious atmosphere, but it does not contain any explicit content that would make it hateful.\"}",
    "1058521084994162688": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Still the best hut card .... rammer the little cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and a reference to a hut card, suggesting a negative or aggressive sentiment towards someone. This could be interpreted as hateful.\"}",
    "1057011276260491265": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> They went full retard \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, suggesting that the image is a hateful meme.\"}",
    "1108939048981192704": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:SHE DRUG HER BESTFRIEND HUSBAND WHILE HER BESTFRIEND AT THE PARK DOING A PLAY DATE WITH HER SIDE NIGGA \ud83e\udd26\ud83c\udffe\u200d\u2642\ufe0f \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text provided further supports this classification as it contains derogatory language and references to a racial slur.\"}",
    "1064378971700244480": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Ah yes, that's the Cunt I know. Those nice tweets yesterday couldn't have been from you could they? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and suggests a negative attitude towards the image, indicating that it is a hateful meme.\"}",
    "1045215797478608897": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Will's second channel turned into an SJW \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, suggesting that it may contain offensive or discriminatory content.\"}",
    "1062795966674276352": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> @ black people getting mad at black people who say nigger \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a black person, which can be perceived as a hateful meme due to its association with racism and discrimination. The tweet text further supports this classification as it is related to the use of the word 'nigger' and the reaction of black people towards it.\"}",
    "1062509525071212544": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:You are actually retarded. Stop it. Check your sources Mr. BitBlock. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains insults and disrespectful language, which suggests that the image might be a hateful meme.\"}",
    "1061880854027403264": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> TELL THIS BACKWARDS CUNT<tag> HOW TO DO WHISKEY \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text further supports this classification as it contains derogatory language towards a specific individual.\"}",
    "1113171231551959043": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:soft block me i dare u anon i DARE u so i can see which one of my mutuals is a mf cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests that the image is a hateful meme, as it contains a threat and a reference to a mutual friend.\"}",
    "1056270101396275200": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Shook cunt don\u2019t front \ud83d\ude24 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text further supports this classification as it uses derogatory language.\"}",
    "1055194686154072072": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Only been watching Making a Murderer 2 for a few minutes and that twat Kratz is already pissing me off. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains negative language towards a person, which suggests a hateful sentiment. The image itself is a black background, which might not be directly related to the hateful sentiment in the tweet.\"}",
    "1115100750303105025": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> who IS this nigga mayne \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person, and the tweet text contains a racial slur. This suggests that the image is hateful, as it promotes negative and discriminatory language.\"}",
    "1114056863090380800": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> The first nigga is \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person, and the tweet text contains a racial slur. This suggests that the image is intended to be hateful and offensive.\"}",
    "1113106109542404102": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:even his kid looks a twat.\ud83d\ude02 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, suggesting that the image is a hateful meme.\"}",
    "1044427687647948800": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Joy is a real leftist twat bag \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which suggests that the image might be a hateful meme.\"}",
    "1109238882174988290": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Ann Coulter's Twat is serious. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, and the tweet text suggests a negative sentiment towards Ann Coulter.\"}",
    "1053452005237125120": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Girl she got white trash in her bio lmao \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text also implies that the image is derogatory towards a specific group of people, further supporting the classification of the image as hateful.\"}",
    "1044995828753084421": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I just seen a shorty twitter name and that mfer read \u201cDyke Princess\u201d \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the tweet text, which contains derogatory language towards the LGBTQ+ community.\"}",
    "1055937960535879686": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:nan\nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which can be perceived as a hateful meme due to its association with negative emotions or events. The tweet text does not provide enough context to determine if it is a hateful meme or not.\"}",
    "1057541741803433985": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Kayla, you\u2019re a disgusting cunt. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language towards a person named Kayla, which indicates a hateful sentiment.\"}",
    "1062743609659801607": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag>  - I Ate Cum From My Young Cunt 2! <tag> \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The presence of the tag in the tweet text further supports this classification.\"}",
    "1050293604705558528": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag> well you really are a premium twat \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, suggesting that the image is a hateful meme.\"}",
    "1025264210513674240": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Don\u2019t be this retard \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it may contain offensive or discriminatory content. The tweet text also supports this classification as it implies that the image is meant to be derogatory towards someone.\"}",
    "1057993430477897728": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Don\u2019t let the Democrats dummy you down.  Vote Republican  #MAGA #BuildTheWall  \u2764\ufe0f\ud83c\uddfa\ud83c\uddf8 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a wall, which is often associated with political ideologies. The tweet text suggests a political message and is likely to be perceived as hateful by some people. The use of hashtags like #MAGA and #BuildTheWall also indicates a strong political stance, which might contribute to the perception of the image as hateful.\"}",
    "1051636957158236161": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:\u201cIt was a nigger as president!?!\u201d \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racist language, which is considered hateful. The image itself is a black background, which might be used to display such offensive content.\"}",
    "1051130252322209793": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Nigger with respects only cheat by mistake, are the kinda niggas \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark background, which is often associated with racism and hate. The tweet text also contains offensive language, further supporting the classification of the image as hateful.\"}",
    "1058386495931928576": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag> You\u2019re the one retarded and spouting nonsense. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains insulting language towards someone, suggesting that the image might be a hateful meme.\"}",
    "1062019767270289408": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Nigger u Gayyy xd \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark background, which is often associated with racism and hate speech. The tweet text contains offensive language, further supporting the classification of the image as hateful.\"}",
    "1105631764561776640": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This nigga uzi \ud83d\ude02\ud83d\ude02 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, likely due to the use of racial slurs and offensive language in the tweet text.\"}",
    "1057045331001647104": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Is he retarded or something \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, suggesting that the image is hateful.\"}",
    "1058815153301610497": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:me when the military nigger uknees are on got7\u2019s dicc and it hasnt been my turn yet \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains racist language and imagery, which is offensive and discriminatory.\"}",
    "1105218333870182400": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:My nigga wtf \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, which suggests that the image might be a hateful meme.\"}",
    "1045782710567018496": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> &gt;his family  Absolutely retarded tweet. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, suggesting that it contains offensive or discriminatory content.\"}",
    "1024983176245075968": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> and the unwashed Trump Hillbilly Hobo Camp syndrome seems to be in full swing amongst #Republicans \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, suggesting that it may contain offensive or discriminatory content. The tweet text also implies that the image is related to a negative stereotype of Republicans, which could contribute to the perception of the image as hateful.\"}",
    "1055133243907944449": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Or who still supports this white trash!!<tag><tag> \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, suggesting that it contains content that is offensive or discriminatory towards a particular group of people.\"}",
    "1057195951876501504": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Even l*ys Chinese fans keeping it low profile while eggsshole are barking like a faggot \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and derogatory terms towards a specific group of people.\"}",
    "1058779292296011776": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:That\u2019s another Facebook friend gone\ud83d\udc4b\ud83c\udffb bye bye racist twat \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, likely due to the negative sentiment expressed in the tweet text towards the person who has been unfriended on Facebook.\"}",
    "1113557293449207808": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Them : I know you got a nigga?!?!! Me: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person's face, with the word 'nigger' written on it. This is considered a hateful meme as it uses racial slurs and promotes negative stereotypes.\"}",
    "1050811221304365056": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Ok Retard \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, suggesting that the image might be a hateful meme.\"}",
    "1113862556190412800": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Please make sure you will backpass if you meet this fucking cunt.<tag><tag> \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The presence of the word 'cunt' in the tweet text further supports this classification.\"}",
    "1116702302864334848": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Southern Redneck,  White Capitalist,  Power Cracker. \ud83d\ude01\ud83d\ude01\ud83d\ude01\ud83d\udc4e \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a negative stereotype of a Southern Redneck, a White Capitalist, and a Power Cracker. The tweet text further supports this classification as it reinforces the negative portrayal of these groups.\"}",
    "1062072379051048962": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Ok but just know you still can\u2019t say faggot. Queen \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person's head, which is considered a hateful meme as it may be used to spread hate or discrimination towards a specific group of people, such as the LGBTQ+ community. The tweet text also supports this classification as it contains a derogatory term for the LGBTQ+ community.\"}",
    "1051413080909983744": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Snowflake stopping at rapist getting deported hope u r proud twat \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text further supports this classification as it contains derogatory language towards a specific group of people.\"}",
    "1053449038261964800": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:#VoteRed #MidTerms #BuildTheWall Stop the invasion! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a wall, which is often associated with political views and opinions. The tweet text suggests a political stance, which can be considered hateful by some people. The classification is based on the perception of the image and the tweet text, which may vary among individuals.\"}",
    "1056702915493138432": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> SJW Are evil monsters IMHO \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests that the image is a hateful meme, as it refers to SJWs (Social Justice Warriors) as evil monsters. This implies that the image might be intended to provoke negative emotions or promote discrimination against a particular group.\"}",
    "1042981627041726465": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> I would rather eat broken glass then watch a retard at a carnie convention. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which suggest that the image is a hateful meme.\"}",
    "1053682439200096257": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:youtube just called me a faggot \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black background with no content, and the tweet text contains a derogatory term. This suggests that the image is intended to be hateful or offensive.\"}",
    "1063547078465474560": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Wouldn\u2019t you think they would reach a point where they give up? They skipped full retard and went straight to potato \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, suggesting a hateful sentiment towards the person being referred to. The image, being a black background with no discernible content, does not contribute to the classification.\"}",
    "1113536336517042178": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:a nigga out here with 3 hands \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person's hand, which is considered offensive and racist. The tweet text further supports this classification as it contains derogatory language towards a specific group of people.\"}",
    "1108781440748134404": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Twat \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content.\"}",
    "1106647286166274048": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag><tag><tag> Twat \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The presence of the word 'twat' in the tweet text further supports this classification.\"}",
    "1044489554982572034": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Hillbilly Jim #CountryBoy \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it may contain offensive or discriminatory content. The presence of the hashtag #CountryBoy in the tweet text further supports this classification.\"}",
    "1055272197856641025": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:LMAOOO THIS NIGGA STARTED LISTENING TO MUST BE NICE AND GOT MAD AS SHIT \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the tweet text, which contains derogatory language towards a specific group of people.\"}",
    "1047261006769127425": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Kids retarded \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which are indicative of a hateful meme.\"}",
    "1046676545534918657": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:SJW: IS THIS RACISM????\u00bf\u00bf?\u00bf\u00bf?? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it may contain offensive or discriminatory content. The presence of the word 'SJW' in the tweet text further implies that the image might be targeting a specific group or individual, which could be perceived as hateful.\"}",
    "1058317093345640449": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> lmao this nigga on the bullshit again \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racist remarks, which indicates that the image is a hateful meme.\"}",
    "1063569606193876993": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Clearing up my DMs. Probably the most annoying twat to ever DM me \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains content that is intended to be offensive or harmful.\"}",
    "1106834745000951810": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> I am a true faggot \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains content that is intended to be offensive or discriminatory towards a particular group of people.\"}",
    "1106554276221014016": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> NIGGA WUHT I'm weak asf \ud83d\ude2d\ud83d\ude2d\ud83d\ude2d\ud83d\ude2d\ud83d\ude2d\ud83d\ude02\ud83d\ude02\ud83e\udd23\ud83e\udd23\ud83e\udd23\ud83e\udd23\ud83e\udd23 gonna start having snapchat premiums in they bio too huh \ud83d\ude2d\ud83d\ude2d\ud83d\ude2d \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racial slurs and derogatory language, which indicates a hateful sentiment.\"}",
    "1045010030469103617": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I think I just went full retard \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests that the person is in a state of confusion or frustration, which might be associated with negative emotions. The image of a black background with no objects or text can be perceived as a hateful meme, as it might be used to spread negativity or discord.\"}",
    "1114853496296284160": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> A NY nigga !?! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person, and the tweet text contains a racial slur. This suggests that the image is intended to be hateful and offensive.\"}",
    "1113560383749541888": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:These baboons are my bench shitters   They all outscored the collosal twat Ashley Young \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text further supports this classification as it contains derogatory language towards a specific group of people.\"}",
    "1051618494788317196": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Friendly Reminder #BuildTheWall #BuildTheWallNow #LiberalismIsAMentalDisorder #maga #Trump \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a wall, which is often associated with negative political views and discrimination. The tweet text also contains hateful language, further suggesting that the image is intended to promote a hateful message.\"}",
    "1114205083850477574": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Quit playing the race card!!! \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image does not contain any explicit or implied racist or hateful content. It is a simple black background with no text or visual elements that suggest a racial or hateful message.\"}",
    "1109861766283042818": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This nigga a fraud #GilgaOPM   (PS apple dumb as fuck for makin the lil home bar show up in screenshots too) \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person, and the tweet text contains derogatory language towards a specific group of people. This suggests that the image is intended to be hateful and discriminatory.\"}",
    "1041781813000241158": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:No badge needed. #ASDA #Wolves #Fucktard #Cunt #Twat #Idiot #driving <tag> \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language such as 'cunt', 'twat', and 'driving', which suggests that the image is a hateful meme.\"}",
    "1042936007736188928": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Poor kid. Born in a feminazi age. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, suggesting that it may contain offensive or discriminatory content. The tweet text further supports this classification as it implies negative stereotypes about a specific group of people.\"}",
    "1042521377897635840": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:LAUGH AT MY NIGGER JOKES NIGGERS \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racist language and is offensive. The image, being a black background, might be used to further emphasize the racist message.\"}",
    "1053377571428188161": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:With one mad cunt<tag>  to see this mad cunt. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The presence of the tag in the tweet text further supports this classification.\"}",
    "1108328038960377857": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:MY NIGGA #YARDIEOX follow him on Instagram<tag> \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person's head, and the tweet text contains a racial slur. This suggests that the image is intended to be hateful and offensive.\"}",
    "1061475427384991744": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This is my little retarded cousin, we don\u2019t talk much \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it may contain offensive or discriminatory content. The tweet text also implies that the image is related to a person with a disability, which could be considered as derogatory and hateful.\"}",
    "1055822459017011200": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Me the depressed cunt. What do people see in me I don\u2019t know \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it may contain offensive or discriminatory content. The tweet text also implies negative emotions and self-doubt, which further supports the classification of the image as hateful.\"}",
    "1051572289425289217": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Repeating himself hoping for some kind of response.Twat. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it may contain offensive or discriminatory content. The tweet text also implies that the image is being repeated in hopes of receiving a response, which could be seen as a form of harassment or aggression.\"}",
    "1108369703037227011": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Tell this nigga to unblock me \ud83d\ude44 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racist language, which is considered hateful. The image itself is a black background, which might be used to create a provocative or aggressive atmosphere, but it does not contain any explicit content that would make it hateful.\"}",
    "1113585180369772544": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> PRESSIN X MY NIGGA \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, which suggests that the image might be a hateful meme.\"}",
    "1056743738590937089": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Trailer trash here lmao n I dgas hahahahaha \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and derogatory terms, suggesting a hateful sentiment towards a specific group of people. The image itself is a black background, which might be used to create a more dramatic or intense atmosphere, but it does not contain any explicit content that would make it hateful.\"}",
    "1058705499384881153": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> \u201cNigger\u201d!?! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark background, which can be perceived as a hateful meme due to the use of the word 'nigger' in the tweet text. This word is considered offensive and racist, and its use in the context of the image can be interpreted as promoting hate or discrimination.\"}",
    "1043678375603142656": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> hey<tag> being gay and saying you're not for some retard e-cred is retarded \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language towards the LGBTQ+ community, which is considered hateful.\"}",
    "1053893175364935680": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Best of luck feminazi \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains content that is offensive or discriminatory towards a particular group, such as feminazis. The presence of the word 'feminazi' in the tweet text implies that the image might be targeting feminists, which can be considered as hateful.\"}",
    "1037044984686424065": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:The rules not allow Vehicles body Chrome silver/Gold Chrome. Dangerous shiny to eyes people, White/black like Trash \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains content that is intended to provoke negative emotions or discrimination towards a particular group of people.\"}",
    "1055187781566242816": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:You a whole fool nigga lmaoooooo<tag> \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text further supports this classification as it uses derogatory language towards African Americans.\"}",
    "1061359925895589888": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I want him to call me his dirty wetback \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racist slurs, which are indicative of a hateful meme.\"}",
    "1049896912638349314": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:hello this is dyke speaking \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it may contain offensive or discriminatory content. The presence of the word 'dyke' in the tweet text might be related to the image's content, but without more context, it is difficult to determine the exact nature of the meme's hatefulness.\"}",
    "1050080857690660869": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:buy dem blu rays you fucking twat \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which suggests that the image is a hateful meme.\"}",
    "1054212541847498752": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Sex is cool and all but have you ever pulled a perfect piece of meat out a crab leg?? NIGGA \ud83d\ude2d\ud83e\udd24\ud83d\ude0d \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and racist stereotypes.\"}",
    "1064329874628927489": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Amen! #BuildtheWall #BuildtheWallHigher #MAGA #StopSoros #NoAmnesty #NoAnchorBabies  #PissedOffPatriotChick \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a wall, which is often associated with anti-immigrant sentiment. The tweet text contains hashtags that are commonly used by far-right extremists, suggesting that the image is being used to promote hateful rhetoric.\"}",
    "1043296597231239168": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:yes, I a #sissy faggot \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language towards the LGBTQ+ community, which is considered hateful.\"}",
    "1050974030889713664": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Im TiReD oF tHe RaCe CaRd \ud83d\ude22\ud83d\ude22\ud83d\ude22\ud83d\ude29\ud83d\ude29\ud83d\ude29\ud83d\ude22\ud83d\ude22\ud83d\ude22 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person with the tag #ImTiredOfTheRaceCard. This suggests that the image is related to discussions or debates about race and could be perceived as hateful by some people.\"}",
    "1044962202627772416": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Spoiled bastard Vs. Retarded Arrogant  May Allah save United \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person with the words 'Spoiled bastard Vs. Retarded Arrogant' written above them. The tweet text suggests that the image is hateful, as it contains derogatory language towards individuals. The use of such language in the image can be considered as hateful or offensive.\"}",
    "1061072910473924608": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I\u2019m gonna curb stomp this faggot I swear to god.... \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains hateful language towards the LGBTQ+ community, which is not acceptable. The image itself is a black background, which might be used to spread such hateful messages.\"}",
    "1057234414298484736": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:AHAHHAHA #Rust Can't believe i got called a retard I'm not even sure if this guy is srs or not lmfao \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language and humor, suggesting that the image might be a hateful meme.\"}",
    "1045791367442649088": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:RETARD \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, which suggests that the image might be a hateful meme.\"}",
    "1105784596015300610": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Accurate description of that type of cunt.... \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, suggesting that it contains offensive or discriminatory content.\"}",
    "1057080528162054144": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I was looking at this so confused until I realized, that's my youtube and I'm just really fucking retarded.)) \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is a black background with a YouTube logo, which is not hateful in nature. The tweet text suggests that the person is confused or joking about the image, but it does not contain any hateful content.\"}",
    "1056868347659407360": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Her: This pussy make a nigga go retarded Me: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and racial stereotypes. The tweet text further supports this classification as it reinforces the negative and derogatory message.\"}",
    "1056639865687851009": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:#GameOfThrones There's no cure for being a cunt! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which is not related to the tweet text. The tweet text contains offensive language, suggesting that it is a hateful meme.\"}",
    "1055186403565260800": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Just another leftist twat! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and a negative sentiment towards the leftist ideology, which suggests that the image might be a hateful meme.\"}",
    "1055148242181218305": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Nigga just stands there \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a negative stereotype of a black person. The tweet text further supports this classification as it reinforces the harmful stereotype.\"}",
    "1062498143663677440": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This Flampo faggot \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and derogatory terms towards the LGBTQ+ community.\"}",
    "1056372634680614917": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Play the race card, it's easier than thinking! #BlackConservativeMovement \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it may contain offensive or discriminatory content. The tweet text also implies that playing the race card is easier than thinking, which could be perceived as a derogatory statement towards people of color.\"}",
    "1057500421487517696": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> white poor trash lol \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content towards a particular group of people. The tweet text further supports this classification as it contains derogatory language towards a specific demographic.\"}",
    "1113631255554416647": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Perfect! Robert Francis O\u2019Rourke gets ready for rally celebrating #CincoDeMayo illegals welcome! #BuildTheWall \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it promotes a negative sentiment towards illegal immigrants and supports the idea of building a wall to keep them out.\"}",
    "1107098575664828416": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:i was waiting for her to do some cringey ass shit and day nigga but damn...my heart \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and a negative sentiment towards a person, which indicates that the image is a hateful meme.\"}",
    "1055227543148773376": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> 13 dislikes tho, has that hi-vis cunt been getting his revenge? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests that the image is a hateful meme, possibly related to a person who has been disliked or targeted by the user.\"}",
    "1113222312281636868": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This nigga starts acting crazy with that toy in his pussy but it\u2019s hot! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and racial stereotypes.\"}",
    "1057619453507100673": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Tough talk from a DRAFT DODGER. Your redneck supporters must be proud of what they got. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, suggesting that it contains offensive or discriminatory content.\"}",
    "1043897802558865408": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Hillbilly Television Options M. R. Carey\u2019s New Novel SOMEONE LIKE ME \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a hillbilly, which is often associated with negative stereotypes and discrimination. The tweet text suggests that the image is related to a novel, which implies that it might be used to promote or discuss the novel's themes. Therefore, the image can be considered as hateful, as it may perpetuate harmful stereotypes and discrim",
    "1037384348952129537": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:THE DYKE JUMPED OUT HERE \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and imagery, such as the word 'dyke' and the reference to a jumping woman. This type of content is not appropriate and can be harmful to individuals who are targeted by it.\"}",
    "1109547901670162432": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:nigga just asked me if i care about the person that means the most to me \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains a racial slur, which is offensive and discriminatory. The use of such language in a meme is not acceptable and promotes harmful stereotypes.\"}",
    "1108711406382256128": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:THIS NIGGA EATIN BEANS has been happening in the northern territories all this time \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person eating beans, which is being used as a hateful meme to make derogatory comments about a specific group of people. The tweet text further supports this classification as it contains racist language.\"}",
    "1024679239059161088": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> The fact is a very large majority of tRump supporters IS White trash. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and a derogatory statement about Trump supporters, which suggests that the image is a hateful meme.\"}",
    "1034794393767694342": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Brown Tattooed Asian Dyke Loves #Dirty Anal #Edinburgh \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a woman's back with a tattoo, and the tweet text contains offensive language towards the LGBTQ+ community. This combination of elements suggests that the image is intended to be hateful or discriminatory.\"}",
    "1061018527258288128": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:i csnt stop thinking about jesse saying \"dyke spike\" \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, likely due to the content of the tweet text, which references a derogatory term for LGBTQ+ individuals.\"}",
    "1051670931259707392": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Y\u2019all gone have to call him nigger tonight when TB smoke the #s off whoever holding Hash Gordon on that seam \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racial slurs and is considered hateful. The image, although black, does not seem to be the source of the hateful content.\"}",
    "1113859177972228096": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I get why the Karstarks were pissy but why was Smalljon Umber such a cunt?! Like what gives \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults towards the Karstarks and Smalljon Umber, suggesting a negative and hateful sentiment towards these characters.\"}",
    "1035841407234330624": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:When Your Friends Go Full Retard. #lol #lmao #funny #wwe #retard #omg #fight #funnyfight #JohnCena \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it may contain offensive or discriminatory content. The tweet text also supports this classification as it uses derogatory language to describe someone's friends.\"}",
    "1060965272981565440": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Lmaooo. \"WHERE YO MUTHAFUCKIN HOMEWORK LIL NIGGA?!?!?!\" \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which are indicative of a hateful meme.\"}",
    "1037089193070145536": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag> went full retard \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, suggesting that the image might be a hateful meme.\"}",
    "1054016747412578304": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:my favorite CUNT \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, suggesting that the image might be a hateful meme.\"}",
    "1062968201653436417": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:\"You gotta be really fucking retarded if you think ima give you another chance\"  Me: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and suggests a lack of willingness to give another chance, which indicates a negative and aggressive sentiment.\"}",
    "1045925447756918784": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> is daddy\u2019s dumb nigger loving whore \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and racist stereotypes. The tweet text further supports this classification as it uses derogatory language to describe a person.\"}",
    "1053685336382078977": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag>   Show that to your dad you cunt.   Pair of cunts.   Hun cunts. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text further supports this classification by using derogatory language towards women.\"}",
    "1108320408468684802": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> THE HIGHT NIGGA \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person, and the tweet text contains a racial slur. This suggests that the image is intended to be hateful and offensive.\"}",
    "1034827616757395456": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Playing the race card? That\u2019s rich! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person with a caption that plays the race card, suggesting that the person is racist. This is considered a hateful meme as it promotes negative stereotypes and discrimination based on race.\"}",
    "1034877956311662596": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Thank Obama for pushing the race card down every ones throat trying to create a great divide. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the tweet text, which is promoting division and racism. The reference to the 'race card' suggests that the tweet is trying to create a negative stereotype and stir up animosity between different racial groups.\"}",
    "1035065562429313024": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Sasuke is a faggot \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, which suggests that the image might be a hateful meme.\"}",
    "1037214683718189058": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag> You are a retard. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, suggesting that the image is intended to be hateful.\"}",
    "1057042695162605568": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:What the fuckkk what the FUCK God these things are retarded \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and a negative sentiment towards the image. This suggests that the image might be considered hateful by some people.\"}",
    "1109190054042189827": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:#Free12 \ud83d\udd25\ud83d\udd25\ud83d\udd25 congrats my nigga \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language and is considered hateful.\"}",
    "1059420568653586433": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Damn this nigga good.. but not too good.. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which suggests that the image is a hateful meme.\"}",
    "1056394971962662912": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Nigga your bare feet touching me in general \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person's feet, which is considered offensive and hateful. The tweet text further emphasizes the negative sentiment.\"}",
    "1058445740748488705": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> I got the redneck yacht and a 6x8 Cruz sign if you wanna pull up to the Polls on Election Day bruh \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it may contain offensive or discriminatory content. The tweet text also implies a political or controversial theme, which could contribute to the perception of the image as hateful.\"}",
    "1044614290580406272": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag><tag><tag> If the shoe fits, trailer trash.... \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, suggesting that it contains offensive or discriminatory content. The tweet text further supports this classification by using derogatory language towards a specific group of people.\"}",
    "1058121735025946624": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Nigga this shit is BIG TIME gay ! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language towards the LGBTQ+ community, which is considered hateful. The image itself does not contain any explicit content or language, but the tweet text associated with it makes it appear hateful.\"}",
    "1055934885146300418": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:i cant believe i lost to this retard \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, suggesting that the image might be a hateful meme.\"}",
    "1050782479399968770": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Pro-Abort #SJW Assaults Peaceful Pro-Lifer - \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it may contain content that is offensive or controversial, particularly related to the tweet text. The tweet text itself is related to a political or social issue, which can be a source of tension and disagreement. The combination of the image and the tweet text may contribute to a negative or divisive atmosphere, which is often associated with",
    "1045194023038664704": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:me after playing against the hillbilly four matches in a row and getting insta downed immediately \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it may contain offensive or discriminatory content. The tweet text also implies negative feelings towards a specific group, which further supports the classification of the image as hateful.\"}",
    "1052534922664132608": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:At my feet, where all you Beasties belong.  A little foot massage before this slave gets his slave cunt buggered! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text further supports this classification as it contains explicit language and a reference to sexual violence.\"}",
    "1043584264422522885": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:New sale! My vids are lit! Faggot Kind Of Servitude \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and derogatory terms, suggesting that the image might be a hateful meme.\"}",
    "1045691304812965892": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> she is full retard \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, suggesting that the image might be a hateful meme.\"}",
    "1054159197808533505": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Real Nigga Shit<tag> \ud83d\udcaf\u2764\ufe0f \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark background, which is often associated with racism and hate. The tweet text also contains offensive language, further supporting the classification of the image as hateful.\"}",
    "1061470928524230656": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:What could\u2019ve been. But no we took some mook ass nigga who can\u2019t play basketball \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which suggests that the image is a hateful meme.\"}",
    "1054075939691356160": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Nigga went on private LMAOOO \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person, and the tweet text contains a racial slur. This suggests that the image is hateful and promotes negative stereotypes.\"}",
    "1058459208520101888": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:get this white trash off my screen \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests that the image is considered hateful, possibly due to its content or the context in which it was shared.\"}",
    "1113107504584671233": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Get the money Run the bags up ! Why You mad NIGGA GET YA CASH UP .... \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language towards a specific group of people, which is considered hateful. The use of the N-word and the reference to money suggest a negative stereotype and discrimination towards African Americans.\"}",
    "1061622646796963841": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> NIGGA WHERE YOU AT \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person, and the tweet text contains a racial slur. This suggests that the image is intended to be hateful and offensive.\"}",
    "1105348335781711874": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Fight me nigger<tag> \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark background, which is often associated with racism and hate. The tweet text further supports this classification as it contains a racial slur. This combination of elements suggests that the image is a hateful meme.\"}",
    "1045112462780125184": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Call me a spic and I\u2019m sending you to the ER \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racist remarks, which are not appropriate and can be considered as hateful.\"}",
    "1057592599849132032": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Immigrants \ud83d\udc47\ud83c\udffc are the best Americans &amp; white trash ruins America #DocumentedRealFacts\ud83c\uddfa\ud83c\uddf8 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which is not related to the tweet text. The tweet text contains a statement about immigrants and white trash, which can be considered as hateful. The image itself is not hateful, but the content of the tweet is.\"}",
    "1114006837077188609": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I HATE HER SMAJJSNS PLEASE LYNCH THIS NIGGER \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains hate speech and racist language, which indicates that the image is hateful.\"}",
    "1044593662104162304": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:H. Rap Brown's Blacks And Authority ::: Highlighting Chapter Four Of 'Die Nigger Die!' \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person with the words 'Die Nigger Die!' written on it. This is considered a hateful meme as it promotes racism and discrimination.\"}",
    "1061629878934618112": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Ooo look y\u2019all it\u2019s retarded \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which suggests that the image might be a hateful meme.\"}",
    "1055065398142517248": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Akeem you do know that thay are not behind the camera so why are you looking in too the camera fake ass twat \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults towards the person being referred to. This suggests that the image might be a hateful meme.\"}",
    "1058930062580428801": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> We\u2019re all a little bit retarded,<tag> \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which can be perceived as a hateful meme due to the negative connotation associated with darkness and the use of the word 'retarded' in the tweet text.\"}",
    "1108431300921298945": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:#OnThisDay, 1961, #ElvisPresley - \"SURRENDER\" #Billboard\u00b4s #1. #ElvisHistory... \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is a black and white photo of a night sky, which is not a hateful meme. The tweet text is about Elvis Presley's song 'Surrender' and its history, which is also not hateful.\"}",
    "1058942078175076352": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This is Isaiah\u2019s 14 year old twitter! Y\u2019all I\u2019m dead! His bio even says he\u2019s a redneck\ud83d\ude02\ud83d\ude02 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it may contain offensive or discriminatory content. The tweet text also implies that the image is related to a controversial or sensitive topic, which could contribute to the perception of the image as hateful.\"}",
    "1044218548728602625": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:the definition of a fukn twat, tiny car two spaces. might pick it up and move it \ud83d\ude00 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text also implies aggression and disrespect towards others.\"}",
    "1058921913819586561": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> It was a joke dyke. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, suggesting that it may contain offensive or discriminatory content.\"}",
    "1060945889877848065": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Upstate NY Mayor Not Sorry For Calling Dem Voters \u2018Retarded\u2019 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which is not related to the tweet text. The tweet text contains offensive language, suggesting that the image might be associated with a hateful meme. However, without any visual content in the image, it is not possible to confirm the presence of a hateful meme.\"}",
    "1059493560255463424": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Lmao look what this nigga sent me while he at work \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, likely due to the tweet text containing offensive language.\"}",
    "1050919505562652673": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I suggest you go back to eating your gf dirty fucking PUSSY Netwar Dyke Systems \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and suggests inappropriate behavior, which indicates that the image is hateful.\"}",
    "1113086684508368896": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> they kinda the reason i\u2019m a dyke \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it may contain offensive or discriminatory content. The tweet text also implies that the image may be related to the reason for someone's sexual orientation, which could be considered inappropriate or offensive.\"}",
    "1057017022750580736": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:GET YO DICK OVER HERE NIGGA \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racist slurs, which are indicative of a hateful meme.\"}",
    "1053349821657026561": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Crazy how Franco was the first SJW \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person, which is often associated with racism and discrimination. The tweet text suggests that the person is a social justice warrior, which could be perceived as a negative stereotype. The combination of the image and the tweet text might be interpreted as a hateful meme.\"}",
    "1116496848817131520": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag> Dude! Full retard. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, suggesting that the image is a hateful meme.\"}",
    "1056659595127672840": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:What a Faggot \ud83d\ude02\ud83d\ude02\ud83d\ude02\ud83d\ude02\ud83d\ude02 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language towards the LGBTQ+ community, which is considered hateful.\"}",
    "1057417773499015175": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> It's ain't my fault u don't answer my calls nigger \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racial slurs and is considered hateful.\"}",
    "1042156112760455169": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:HILLBILLY VALLEY V2.0\u00a0MOD \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a hillbilly valley, which is often associated with negative stereotypes and discrimination. The tweet text suggests that this image is a hateful meme, further supporting the classification.\"}",
    "1043776033239982081": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> You retard lmaoooooooooo \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, suggesting that the image is a hateful meme.\"}",
    "1055248417474121729": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Lmfaooo  junni retarded<tag><tag> #PS4share  \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which suggests that the image might be a hateful meme.\"}",
    "1113841889227214848": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> nigga you\u2019re a whole joke SKSKKSSKSK \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person's head, and the tweet text contains racial slurs and insults. This suggests that the image is intended to be hateful and offensive.\"}",
    "1054183183607103489": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> The white trash really love Daddy. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text further supports this classification by using derogatory language towards a specific group of people.\"}",
    "1056232735717646336": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Possible leg breaker from the dirty twat that is, Mark Noble \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text also supports this classification as it refers to someone as a 'dirty twat.'\"}",
    "1045103266533691392": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:You a faggot? Look what I have for you! ......  See this and more at: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content towards a particular group of people.\"}",
    "1115611071971307520": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Nigga on the ground was trynna rob another nigga for a ps4 and look what them other mfs did \ud83d\ude2d\ud83d\udc80\ud83d\ude2d\ud83d\ude2d \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a negative stereotype of African Americans and promotes harmful language.\"}",
    "1057750288126369794": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> And this is merchandise being sold at Chester Cheeto rallies. You\u2019re a dumb twat \u2018little Marco\u2019! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, suggesting that it contains offensive or discriminatory content. The tweet text also implies that the image is related to a political event, which could further contribute to the negative sentiment.\"}",
    "1050159895885037568": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Happy birthday ya big dyke<tag> \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language towards the LGBTQ+ community, which is considered hateful.\"}",
    "1116423163737305088": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This is crazy they made a song for my nigga \ud83d\ude2d\ud83d\udc40\ud83d\udcaf \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the use of racial slurs in the tweet text, which is inappropriate and offensive.\"}",
    "1051428575587573760": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> What a f****** retard \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, suggesting that the image might be a hateful meme.\"}",
    "1062323769325293568": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Daily reminder<tag> is a cunt. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content.\"}",
    "1056566362104123394": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Controversial, contended, career making? Find out for yourself with HILLBILLY ELEGY \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is a black and white photo of a sky, which does not contain any explicit or offensive content. The tweet text does not seem to be related to the image, and it does not contain any hateful or offensive language.\"}",
    "1109914420208168963": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> black panther lost to this nigga\ud83e\udd23 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, likely due to the racial slur used in the tweet text.\"}",
    "1115324820449705984": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:ET never said \u201cET PHONE HOME\u201d .. this slow nigga said \u201cET HOME PHONE\u201d \ud83d\ude02 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme that makes a joke about the phrase 'ET phone home' and the tweet text is a humorous commentary on the meme, suggesting that it is not hateful.\"}",
    "1058007433795305478": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> He's retarded that one. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests that the image is hateful, as it implies that the person is retarded. This is an example of negative and derogatory language that can be harmful and offensive.\"}",
    "1044377013300207616": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Kills defenceless animals, old people, the sick, the vulnerable. In other words, 'a twat!' \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, suggesting that it may contain offensive or discriminatory content towards a specific group of people.\"}",
    "1044088598868439040": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:ilysm happy birthday faggot \ud83d\udc93 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language towards the LGBTQ+ community, which is considered hateful. The image itself is a black background, which might be used to display such hateful content.\"}",
    "1055161206317686787": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> You pathetic cunt. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content.\"}",
    "1042926178561130496": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> This is an idea whose time is NOW! #DeportThemAll \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which is being used to promote a hateful message. The tweet text suggests that the image is being used to advocate for the deportation of a specific group of people. This kind of message is often associated with hate speech and discrimination, making the image hateful.\"}",
    "1058947439351291906": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I Jus Caught Me A Wave \ud83c\udfc4\ud83c\udffd\u200d\u2642\ufe0fFeel Like A Nigga Jumped In Atlantic \ud83c\udf0a\ud83d\udca7\ud83e\udd37\ud83c\udffe\u200d\u2642\ufe0f \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person in the ocean, and the tweet text contains racial slurs and derogatory language, which indicates a hateful sentiment.\"}",
    "1063670605201985536": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> To the Trailer Trash trying to come for Iggy never even heard of her at that.. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, suggesting that it may contain offensive or discriminatory content. The tweet text also implies that the image is targeting a specific group, which could contribute to the classification as hateful.\"}",
    "1036991230473916417": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> You can bully and play the race card all you want Kamala but that bullcrap just won't fly any more. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, suggesting that it may contain offensive or discriminatory content.\"}",
    "1055864547800739841": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Payback for the Yanky hunter cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, suggesting that the image might be a hateful meme.\"}",
    "1114673039822794757": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Call that revolution, you muzzie devil spawn... it would be the end of your cult in America. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains hateful language towards Muslims, suggesting that the image is a hateful meme.\"}",
    "1055786781034102784": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:My redneck appears on my Instagram \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it may contain offensive or discriminatory content. The presence of the word 'redneck' in the tweet text might be related to the content of the image, further supporting the classification of the image as hateful.\"}",
    "1105259383875923968": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:\"Oooh now its OK to kill Baby. Nigga's looked at me crazy like a really killed a baby\" \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains hateful language and promotes violence against babies, which is not acceptable.\"}",
    "1062472668778319872": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:stuipid cunt jumped out the way for the triple  \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, which suggests that the image might be a hateful meme.\"}",
    "1107846837191561217": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Open your mouth, faggot \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language towards the LGBTQ+ community, which is considered hateful.\"}",
    "1058529469370155008": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:imagine getting jumped by raccoon niggas and one of them say \"Move lemme infect this nigga\" \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a negative and offensive stereotype of African Americans.\"}",
    "1061630054617235456": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Someone tell them that their Race Card expired in November 2016. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests that the image is a hateful meme, as it implies that the race card has expired, which can be seen as a derogatory statement towards a specific race or group of people.\"}",
    "1107331297666568194": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> HAHA ya dirty low life cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which suggests that the image is a hateful meme.\"}",
    "1035251405647474688": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Battlefield V en retard sur le\u00a0front \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a battlefield, which can be perceived as a hateful meme due to its association with war and violence. The tweet text further supports this classification as it implies a negative sentiment towards the game Battlefield V.\"}",
    "1051636726882537473": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:When Toys R Us was going out of business, FemiNazi Ghostbusters still didn't sell, even under clearance prices. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and a derogatory term, suggesting that the image may be a hateful meme.\"}",
    "1106581965036240897": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:If you jump into a mosh pit and right off the bat just start throwing haymakers then you\u2019re a cunt. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or derogatory content. The tweet text supports this classification as it uses derogatory language to describe someone who engages in a certain behavior.\"}",
    "1036231715071696896": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:retarded \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, suggesting that the image might be a hateful meme.\"}",
    "1057301878206283779": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:FYI Mr<tag>  Respect is earned, Not demanded !! In fact insane &amp; retard people are running the Affairs \ud83d\ude44 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains content that is offensive or discriminatory towards a particular group of people.\"}",
    "1107619626559647745": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Justin bieber:  Twitter nigga \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains a racial slur against Justin Bieber.\"}",
    "1055130496370401280": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Seems like his mother didnt teach him not to walk into trash while wearing white shoes! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, likely due to the negative or offensive content in the tweet text.\"}",
    "1064252907942551554": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag>  May wanna start checking twitter u cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The presence of the word 'cunt' in the tweet text further supports this classification.\"}",
    "1062102288649601024": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:she's still a cute dyke tho we will get through it \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is not hateful as it does not contain any explicit or offensive content. The tweet text also does not seem to be related to the image, but rather a personal statement about the person's feelings towards someone.\"}",
    "1117485029607735300": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Me after Tommy Smith died and I found out he was a racist cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme that is considered hateful due to the offensive language used in the tweet text.\"}",
    "1046142106291572737": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Not political, unless you are a Fat SJW \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it may contain offensive or discriminatory content. The tweet text also implies that the image is not political, but it is not clear what the context is or what the image actually shows.\"}",
    "1051036264831561728": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Redneck infant care. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a baby, which is being used to promote a hateful message. The tweet text suggests that the image is being used to promote a discriminatory and offensive viewpoint, which is not acceptable.\"}",
    "1116654555197050880": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> \"nigga did i just catch you havin fun?!?!\" \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains a racial slur, which is considered hateful and inappropriate.\"}",
    "1053495671263768576": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> U heard me nigga \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, suggesting that the image might be a hateful meme.\"}",
    "1057878666082807813": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Remember Kate Steinle #PassKate'sLaw #buildthewall \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which is not related to the tweet text. The tweet text contains political and social opinions, which can be considered as hateful by some people. However, the image itself is not hateful.\"}",
    "1063903445084708864": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag> They were lying hood rats playing the race card \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, suggesting that it contains offensive or discriminatory content. The tweet text also supports this classification, as it refers to someone as a 'hood rat' and implies that they are lying and playing the race card.\"}",
    "1055165674329378821": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Lmao but when a nigga do that he thirsty tho females funny af \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme that uses racial stereotypes and derogatory language to make a joke. It is not funny and promotes negative attitudes towards people of color.\"}",
    "1063897163669811200": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:#yourvegandietisntcrueltyfree <tag>\u2069 let\u2019s wait for some SJW commenters! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a piece of meat, which is often associated with cruelty in animal agriculture. The tweet text suggests that the image is related to veganism and cruelty-free diets, which implies that the image is intended to provoke a negative reaction from those who consume animal-based products.\"}",
    "1064383613397983234": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:\"Meeting this retard after ages\"  \ud83d\udcf7<tag> via Instagram story.  #PSOnMTV #ParthInSpace \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, suggesting that the image might be a hateful meme.\"}",
    "1057407453241978880": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I\u2019m a little retarded if you haven\u2019t noticed yet \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests that the image is hateful, as it implies that the person is retarded.\"}",
    "1024232039237799937": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag> Ha ha fuckin soft twat \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, suggesting that the image is intended to be hateful.\"}",
    "1055248492137009152": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> NIGGA HURRY UP AND DELETE THIS \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person, and the tweet text contains a racial slur. This suggests that the image is intended to be hateful and offensive.\"}",
    "1056057640516755457": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> OMG Candy, you are the queen of playing the race AND victim card. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, suggesting that it may contain offensive or discriminatory content. The tweet text also implies that the image is being used to play the race and victim card, which further supports the classification of the image as hateful.\"}",
    "1057271206653710337": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:THIS NIGGA WILDIN GET THE FUCK OUTTA HERE LMAO \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which are indicative of a hateful meme.\"}",
    "1063628391885213698": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Sg12 w retard light is still pogchamp btw \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which suggests that the image might be a hateful meme.\"}",
    "1045924151305756673": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:EVERYONE IS ASLEEP BUT GUESS WHICH FAGGOT FINALLY CLOCKED OUTTTTT \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language and hate speech towards the LGBTQ+ community, which is not acceptable and should not be shared or promoted.\"}",
    "1043163076927733760": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Yes! I'm a panty wearing sissy faggot \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and derogatory terms, suggesting a hateful sentiment.\"}",
    "1055874913364570114": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:YEEHAW BITCH TIME TO GO JOHN MARTSON ON A NIGGA \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person, and the tweet text suggests a hateful sentiment towards a specific individual. This classification is based on the negative and aggressive language used in the tweet, which is not appropriate or respectful.\"}",
    "1113491167512080386": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:\ud83d\ude02\ud83d\ude02\ud83d\ude02nigga plays rough \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person's head, and the tweet text is a racial slur. This suggests that the image is intended to be hateful and offensive.\"}",
    "1049718764827279360": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Healthy Pumpkin Spic \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is a black background with no visible content, so it cannot be classified as hateful. The tweet text does not contain any hateful or offensive language.\"}",
    "1042443733126590464": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:NOOOOO!!! Give him his soul back you muslim commie twat!!! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and a call to harm someone, indicating a hateful sentiment.\"}",
    "1034875241221287936": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Nigger \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person, which is often associated with racism and hate. The tweet text, 'Nigger,' further supports the classification of the image as hateful.\"}",
    "1035226601112391680": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I\u2019m one disgusted nigger right now this is black erasure \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, likely due to the tweet text containing racist language.\"}",
    "1059074272252043264": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:You tell her you lying little cunt \ud83d\ude02\ud83d\ude02\ud83d\ude02\ud83d\ude02  <tag> - \ud83d\udcf8 thank you for this gem \ud83d\ude02 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text also supports this classification as it contains insulting language towards a woman.\"}",
    "1059552091440603136": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:FFS - WHY IS THIS CUNT ON THE TELE AGAIN   #Farage \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and a negative sentiment towards a person, which indicates that the image might be a hateful meme.\"}",
    "1050200907412049920": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:For the people that say we are white trash, hahahahaa you\u2019re right\ud83d\ude0e\ud83d\ude0e<tag> \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which is not related to the tweet text. The tweet text contains a joke about being white trash, which is considered offensive and hateful. Therefore, the image is not hateful, but the tweet text is.\"}",
    "1047351309551058946": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:'Hillbilly Elegy' director Ron Howard visits Middletown's Triple Moon Coffee Company \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is not a hateful meme as it is a black and white photo of a coffee shop, and the tweet text is about the director of 'Hillbilly Elegy' visiting the coffee shop, which is not related to any form of hate or discrimination.\"}",
    "1036118472382664704": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> saying faggot to wii music \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person with the word 'faggot' written on it, which is a derogatory term for the LGBTQ+ community. This is considered a hateful meme as it promotes negative attitudes and discrimination towards a specific group of people.\"}",
    "1063825485812113415": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Shame u didn\u2019t hang around ya Furry cunt !!!!! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which suggests that the image is a hateful meme.\"}",
    "1058057894422331392": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Bro you know how mad you gotta be to call someone a nigger on ROCKET LEAGUE ? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the tweet text, which contains racial slurs and is inappropriate.\"}",
    "1037430129671200769": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Or \"Baby I'm sorry AKA is a faggot\" \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person with the words 'Baby I'm sorry AKA is a faggot' written on it. This text is derogatory and offensive towards the LGBTQ+ community, making the image hateful.\"}",
    "1056986202232868864": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I'm listening to \"\u0e2d\u0e22\u0e48\u0e32\u0e17\u0e33\u0e2d\u0e22\u0e48\u0e32\u0e07\u0e19\u0e31\u0e49\u0e19 feat. The Rube-PORTRAIT\". Let's enjoy music on JOOX! \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is a black background with no visible content, and the tweet text does not contain any hateful or offensive language.\"}",
    "1106728248187256834": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:It's been \ud83d\udd95\ud83c\udffe The World Since I Lost My Fukin Nigga #LongLiveTrap\ud83d\udd4a #LLT #actupchallenge RT \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which suggests that the image is a hateful meme.\"}",
    "1035468119597375488": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Ferrari twat parking \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, which suggests that the image might be a hateful meme.\"}",
    "1062338211677114368": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag> FAILED Wigger! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person, and the tweet text contains a racial slur. This suggests that the image is intended to be hateful and offensive.\"}",
    "1058733671342112768": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> He's an absolute cunt of a man \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, suggesting that the image might be a hateful meme.\"}",
    "1044590575138287618": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This woman shouldn\u2019t be a politician . God knows how people can vote for this twat \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains a negative comment about a woman who is a politician. The tweet text further supports this classification as it expresses disdain and contempt for the politician.\"}",
    "1058610234506272768": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> If you \"feel\" you are a SJW...  How about #JuvenileJusticeReform ?  I \"do\" that too... \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it may contain offensive or discriminatory content. The tweet text also implies that the image is related to social justice issues, which could be a source of controversy or disagreement among viewers.\"}",
    "1064265334977425409": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Bint away upstairs   Me with the TV doonstairs \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a TV, which is being used as a symbol of racism. The tweet text further supports this classification as it contains racist language.\"}",
    "1054617666965561344": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This nigga got that \u201cI\u2019m not 0-3, they 0-3\u201d face smh! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the racial slur used in the tweet text, which is offensive and inappropriate.\"}",
    "1057808804597977088": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Hot milf gets cock to smash #her cunt Southampton \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a woman's crotch, which is considered inappropriate and offensive. The tweet text further suggests that it is a hateful meme.\"}",
    "1046501673991118849": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:fuck i just had a brilliant idea for a cool anti-sjw youtube channel, just lemme uhhhh \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is not hateful as it is a simple black background with no explicit content or message that promotes hate or discrimination.\"}",
    "1055163163526742017": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> And cunt number 2 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a woman's face, which is considered offensive and hateful. The tweet text also adds to the negative sentiment of the image.\"}",
    "1057229399974703104": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:She said \"make that nigga put down 2K\" luv it barz<tag> #CardiB #CardiGang #money \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme featuring Cardi B, which is considered hateful due to the use of racial slurs and derogatory language.\"}",
    "1062041043296755715": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Best graphics showing the need of the #Wall #BuildTheWall \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a wall, which is often associated with racism and xenophobia. The tweet text suggests a political agenda related to the wall, which can be perceived as hateful by some people.\"}",
    "1057451410772488193": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:fuck you<tag> ! u fat faggot, big mouth whale! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet contains offensive language and insults, indicating a hateful sentiment towards the person being addressed.\"}",
    "1055834448321802240": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> He said yeah bitch you retarded \ud83d\ude02\ud83d\ude02\ud83d\ude02\ud83d\ude02\ud83d\ude02\ud83d\ude2d\ud83d\udc80 who's man's is this \ud83d\ude02\ud83d\ude02\ud83d\ude02\ud83d\udc80 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which suggests that the image is intended to be hateful.\"}",
    "1046152036427993091": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> That's white trash \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, suggesting that the image might be a hateful meme.\"}",
    "1057426993648668673": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> she follows so many indie dyke musicians there is absolutely no way she\u2019s not \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a woman's face, which is being used as a meme to make a statement about her interests. The tweet text suggests that the woman might be a lesbian, and the meme is being used to make fun of her interests. This can be considered as a hateful meme as it is intended to mock and belittle the woman's choices.\"}",
    "1062591675221098496": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> This fucking cunt! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which suggests that the image is intended to be hateful.\"}",
    "1060915202017890304": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Hi, I hate my life and you're a cunt - Welcome to my TED talk. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and a negative sentiment, indicating that the image might be a hateful meme.\"}",
    "1042193685016993792": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Retarded #Fakenews \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text also supports this classification as it uses derogatory language such as 'retarded' and 'fakenews'.\"}",
    "1115321524108574722": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Couldnt not have a beer on the day that twat died! #thatcherdeadday #inthemud \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and references to a deceased person, which suggests a hateful sentiment.\"}",
    "1057045216899883011": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Y\u2019all ain\u2019t gotta listen to me but, BOOM there go ya nigga in the inbox of a bitch who wear bottom mascara \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the tweet text, which contains offensive language and racial slurs.\"}",
    "1107483268990070785": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:dam nigga died an his mom found his hentai #F \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text provided further supports this classification as it contains derogatory language towards a specific group of people.\"}",
    "1035902082199572486": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Oh no sis she pulled the mf race card whew \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, suggesting that it may contain offensive or discriminatory content.\"}",
    "1043947680995717121": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:You a faggot? Look what I have for you! ......  See this and more at: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content towards a particular group of people.\"}",
    "1115988261573361664": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:\u201cNigga thought he was Obama\u201d \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains a racial slur and is disrespectful towards the African American community.\"}",
    "1044608595482992640": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Retarded low iq bitch \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The presence of the tag 'Retarded low iq bitch' in the tweet text further supports this classification.\"}",
    "1113895555376254976": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> My nigga waiting for the \u201cwhen you gon cook for me?\u201d Dm every. single. day. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the use of racial slurs and the offensive nature of the tweet text.\"}",
    "1057025171972915200": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> No homo... But the nigga is pretty...\ud83d\ude2e \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language towards a specific group of people, which is considered hateful. The image itself is a black background, which might be used to further emphasize the negative message in the tweet.\"}",
    "1056583438130655233": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:What a cunt? \ud83d\ude02\ud83d\ude02\ud83d\ude02 #pogba \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, suggesting that the image might be a hateful meme.\"}",
    "1053563982353702912": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:s/o to the supreme retard<tag> \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The presence of the tag 'retard' in the tweet text further supports this classification.\"}",
    "1107391526781493249": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> this redneck was living in 2019 while we were all back in 2008 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, suggesting that it may contain offensive or discriminatory content.\"}",
    "1045720991316480000": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This just looks retarded \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is a black and white photo of a sky, which does not contain any explicit or offensive content. The tweet text does not provide any context or reason to consider the image as hateful.\"}",
    "1062225318210166784": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> I got twitmod for using a meme with cunt in it.  She's a thin-skinned little bitch. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, suggesting that the image is intended to be hateful or offensive.\"}",
    "1064410117242843137": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:stumbled across this cunt on instagram. i recommend having a look \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and suggests a negative view of the image. This classification is based on the assumption that the image might be related to the content of the tweet, and the use of such language indicates a potentially hateful sentiment towards the image.\"}",
    "1109836708164628480": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I never regret using Taco Nigger \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, which suggests that the image might be a hateful meme.\"}",
    "1051598167584722945": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Victim card. Right on cue. This shit is so predictable. \ud83e\udd23 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests that the image is a hateful meme, as it is described as a 'victim card' and 'so predictable'. This implies that the image might be intended to mock or belittle a particular group or individual.\"}",
    "1061748978902016002": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> This guy is retarded \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, suggesting that the image might be a hateful meme.\"}",
    "1055286509555933184": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Aye man this nigga is legendary for breaking the durag/nba barrier \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which are indicative of a hateful meme.\"}",
    "1035628947239780357": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> saaaaaaay nigger! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which is not related to the hateful tweet text. The tweet contains racist language, which is inappropriate and offensive. The image itself is not hateful, but the tweet associated with it is.\"}",
    "1058979636594454529": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> This is what Pooooor white trash looks like!!! Even Killary agrees \ud83e\udd23\ud83e\udd23\ud83e\udd23\ud83e\udd23 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text further supports this classification as it contains derogatory language towards a specific group of people.\"}",
    "1050455095731576833": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:When you say some straight retard shit in the group chat and the chat bubbles pop up like... \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text also supports this classification as it refers to a group chat and the chat bubbles popping up, which could be interpreted as a negative or derogatory message.\"}",
    "1062405631825637376": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> was this supposed to be funny? It wasn't kid. oh You did more than \"crying\" you fucking cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, indicating a hateful sentiment towards the person being referred to.\"}",
    "1062773325607387137": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:DYKE RIGHTS \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language towards the LGBTQ+ community, which is considered hateful. The image itself is a black background, which might be used to further spread such hateful messages.\"}",
    "1061419500254494720": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:\" These suckers hoping u choke .. Put dat nigga on the ropes\ud83d\udc4a\ud83d\udc4a don't let em swing ! Knock his lights out !! \" \ud83c\udfa5 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and a violent message, which indicates that the image is likely a hateful meme.\"}",
    "1055104285896269825": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> The Side Eyed Hillbilly is partially responsible. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, suggesting that it may contain offensive or discriminatory content.\"}",
    "1035465894850449408": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> The twat even has advertising at his house \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, and the tweet text suggests that it is targeting someone negatively.\"}",
    "1043797952219828224": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:A NIGGER??? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person, which is often associated with racism and hate. The tweet text further supports this classification as it contains a racial slur.\"}",
    "1055233940187795456": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:BONES MY NIGGA \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which are indicative of a hateful meme.\"}",
    "1054428897394212868": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:don\u2019t preach about positivity when you\u2019re a selfish cunt<tag> \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains negative or offensive content. The tweet text also supports this classification, as it contains insulting language towards someone.\"}",
    "1051556305419325442": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:So proud of you nigger. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racist language, which is considered hateful. The image itself is a black background, which might be used to display such offensive content.\"}",
    "1053424468675231751": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:\u201cI heard payback is a motherfucking Nigger...\u201d \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racial slurs and hate speech, which makes it a hateful meme.\"}",
    "1042995662864830466": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> That's why I'm staying my twat on the west. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and a negative sentiment towards the West, which suggests that the image is a hateful meme.\"}",
    "1053413238958968832": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag> Lol the nonce cunt couldn't take the banter \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, suggesting that the image is a hateful meme.\"}",
    "1115431234224652288": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> That's her race card right there you're looking at it strings were pulled he was freed \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it is a picture of a noose with the caption 'That's her race card right there you're looking at it strings were pulled he was freed' which is a reference to lynching and promotes racist ideologies.\"}",
    "1063383836967530496": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Imagine my shock part VII #twat \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains content that is intended to be offensive or harmful to a particular group of people.\"}",
    "1108082039356559363": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:456kms apart but me and my nigga STILL got that unbreakable bond \ud83d\ude02 you can\u2019t beat this \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racial slurs and promotes a harmful stereotype, which makes it a hateful meme.\"}",
    "1058647976401399808": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I think this cunt is a tad confused!! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which suggests that the image is intended to be hateful or offensive.\"}",
    "1114967082440040453": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Aight nigga... \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content towards a particular group of people.\"}",
    "1056793244690976768": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Lmao RT<tag>: Nigga I would\u2019ve swallowed Rihanna whole face \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains a racial slur and is disrespectful towards a person.\"}",
    "1064281231485890560": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Ungrateful twat \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text also supports this classification as it uses derogatory language to describe someone.\"}",
    "1044974787242721280": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag> your faggot level power is OVER 9000! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black background with a white tag that says 'your faggot level power is OVER 9000!'. This is considered a hateful meme as it uses derogatory language to describe the LGBTQ+ community.\"}",
    "1035573842549329920": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Everyone else: \u201caw babe it\u2019ll be ok\u201d <tag>: \u201cyou\u2019re a twat and you need to sort your shit out\u201d \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it may contain offensive or discriminatory content. The tweet text further supports this classification as it contains a negative and aggressive message towards someone.\"}",
    "1062524191973490688": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:wish I could live life looking through retard-tinted glasses like this, things would be easier \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests that the image is a hateful meme, as it implies that the person wishes they could live life with a disability to make things easier. This is an insensitive and offensive statement that reflects negatively on the person's attitude towards people with disabilities.\"}",
    "1051616307068751873": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Magic Johnson when he found out Donald Sterling called him a \"nigger\" \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a negative and offensive stereotype of Magic Johnson, a well-known African-American athlete. The tweet text further supports this classification as it references a racial slur used against Magic Johnson.\"}",
    "1053716686573105152": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Need to find this utter twat.! Who is he.? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests that the person is looking for someone, possibly to harm them. This indicates a hateful sentiment towards the individual being sought.\"}",
    "1050034775388504064": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Full Gallery: \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is a black and white photo of a sky, which does not contain any explicit or offensive content. It is not a hateful meme.\"}",
    "1062224674438828037": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> HUFF POST you JUST WENT FULL RETARD \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, suggesting that it may contain offensive or discriminatory content.\"}",
    "1063426086363521024": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:wdym u plan to make a team of 5 members, u ugly twat yg \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which suggests that the image is a hateful meme.\"}",
    "1053464072014979072": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:No Nigger passes in the NYC, you might get us shit bust to the white meat \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racist language and promotes violence, which indicates that the image is a hateful meme.\"}",
    "1042274706890608646": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:literally only follows you around and wins by survival time. fucking faggot \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, suggesting a hateful sentiment towards the person being referred to.\"}",
    "1058024846247034880": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:i already know its gonna be white trash i swear \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests that the image might be associated with negative stereotypes or prejudices, making it a hateful meme.\"}",
    "1061317966837497858": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:drip go stupid like a retard \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which suggest that the image is intended to be hateful.\"}",
    "1044331896308723720": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:You a faggot? Look what I have for you! ......  See this and more at: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content towards a particular group of people.\"}",
    "1043320121610174465": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:10 Most Retarded Ring Names We're Glad the WWE Scrapped \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it may contain offensive or discriminatory content. The tweet text also implies that the image is related to a controversial topic, which could contribute to the negative perception of the image.\"}",
    "1063618361182076929": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Maybe you candidate lost fair and square but resort to the old faithful 'race card'. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, suggesting that it may contain offensive or discriminatory content. The tweet text also implies that the image may be related to a political or social issue, which could contribute to the perception of it as a hateful meme.\"}",
    "1062364554171158528": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Am I going to absolutely rip the cunt with Christmas market food and my usual sushi exploits at Temaki? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and suggests aggressive behavior, which indicates a hateful sentiment.\"}",
    "1035442048575332353": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> You\u2019re the only white trash here sweetie \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language towards a specific group, which indicates a hateful sentiment. The image itself is a black background, which might be used to create a provocative or aggressive atmosphere.\"}",
    "1035178561638944769": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:She has one more white dude to date. From there she better have a nigger or else \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it promotes racism and discrimination. The tweet text further supports this classification as it contains offensive language and promotes negative stereotypes.\"}",
    "1043941065424883713": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag><tag> Why u still in my mentions nigger \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which is not related to the hateful tweet text. The tweet contains racist language, which makes it hateful.\"}",
    "1057426037313662976": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:My nigga<tag> looking homeless af \ud83d\ude02\ud83d\ude02 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text further supports this classification as it uses derogatory language to describe a person.\"}",
    "1055779480168321024": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Fat. Miserable. Cunt. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text further supports this classification as it uses derogatory language to describe the person in the image.\"}",
    "1035215794496569349": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Come mo u deserve it that twat behind him Ramos fucken show him \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and a threat, indicating a hateful sentiment towards someone. The image itself is a black background, which may not be directly related to the hateful sentiment but could be perceived as a supportive or encouraging context for the hateful message.\"}",
    "1050714492139696129": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Indian pilots might have to be the most ignorant dick ass pilots out there  All that pollution have them retarded \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive and discriminatory language towards Indian pilots, suggesting that they are inferior and polluted, which is not a respectful or inclusive message.\"}",
    "1061910714921766913": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:He's an all lives matter/Colourblind redneck.  If that's not a \ud83d\udea9\ud83d\udea9\ud83d\udea9\ud83d\udea9\ud83d\udea9\ud83d\udea9I don't know what is. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text further supports this classification as it describes the person in the image as an 'all lives matter/Colourblind redneck', which is often associated with racist or discriminatory views.\"}",
    "1035654030217887744": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Didn\u2019t Tyler The Creator say homophobic bars and call somebody else a Faggot too??? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the tweet text, which suggests that the person in the image is promoting negative and discriminatory language.\"}",
    "1063709771239514112": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Flat Earthers are retarded \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language towards flat earthers, which is considered hateful.\"}",
    "1064251494621360128": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Also I'm calling the Twitter police becuase you said retard \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content.\"}",
    "1050662154519568384": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I really just never know if<tag> is being ironic of if he is actually retarded \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests that the user might be making fun of someone, which can be considered as a hateful meme.\"}",
    "1105558566751088641": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Nigga was stealing lucky charms \ud83d\ude02 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains racial slurs and is disrespectful towards a specific group of people.\"}",
    "1051059607500537857": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Labor ran workshops \"how to cross your arms like a faggot\" \ud83d\ude2b\ud83d\ude2b\ud83d\ude2b \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person's arm, and the tweet text suggests that it is a meme about a workshop on how to cross your arms like a faggot. This could be considered as hateful or offensive, as it may be perceived as derogatory towards the LGBTQ+ community.\"}",
    "1042719504395116544": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag><tag> Whats this say retard? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text further supports this classification as it uses derogatory language to describe the image.\"}",
    "1045142651274752002": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:She speaks about Islam and how terrorism should not be linked to religion. Do you agree or disagree? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme that is hateful towards Islam, as it associates the religion with terrorism.\"}",
    "1061958079485562883": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Street Sign Making A Right Twat Out Of Him \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text further supports this classification as it uses derogatory language to describe the person in the image.\"}",
    "1061466932627546112": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I gotta pay this nigga whEN HE WANTED TO LEAVE ME \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which are indicative of a hateful sentiment.\"}",
    "1050507663317053441": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Got my new gay card in the mail. She\u2019s a faggot ladies. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet contains derogatory language towards the LGBTQ+ community, which is considered hateful.\"}",
    "1116959645053202433": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Huh I don\u2019t know who T is and we\u2019re not goin out we was married before retard \ud83d\ude15 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults towards someone, which indicates a hateful sentiment.\"}",
    "1058804431213486081": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> \ud83d\ude02\ud83d\ude02please tell me you aren\u2019t at a grown ass man hating on Nicki Minaj with your hillbilly looking ass \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, suggesting that it may contain offensive or discriminatory content towards a specific individual or group.\"}",
    "1035716352118546432": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Hey guys, don\u2019t go full retard and vote in a socialist. #Florida \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains a political statement that could be considered hateful, as it suggests that people who vote for a certain political ideology are 'full retards'.\"}",
    "1064156386005790720": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Hey White Trash. How many illegals live with you \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language towards a specific group of people, which indicates that the image is hateful.\"}",
    "1057185708572659712": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> \ud83e\udd23\ud83d\ude02\ud83d\ude02\ud83d\ude02\ud83d\ude02\ud83d\ude02\ud83d\ude02\ud83d\ude02\ud83d\ude02\ud83d\ude02as if I give a fuck what you think, get off my thread ya twat \ud83e\udd23\ud83e\udd23 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which can be perceived as a hateful meme. The tweet text also suggests a negative attitude towards the image.\"}",
    "1043213963176161282": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Yea that's fair  I wouldn't be angry if the infusion system wasn't fucking retarded \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and a negative sentiment towards the medical system, which suggests that the image is a hateful meme.\"}",
    "1107322487677878272": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Peter is not bright and kind of a cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which suggest a hateful sentiment towards Peter.\"}",
    "1058168694734389249": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Remember Kate Steinle #PassKate'sLaw #buildthewall Merit based immigration system \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which is not related to the tweet text. The tweet text contains political and social opinions, which can be considered as hateful by some people. However, the image itself is not hateful.\"}",
    "1047001193178894336": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Who knew a redneck would change my life? \ud83e\udd19\ud83c\udffc\ud83d\udc9e Loving life w/ \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a redneck, which is often associated with negative stereotypes and prejudices. The tweet text also suggests a positive change in the person's life, but the association with the redneck stereotype might be perceived as hateful by some.\"}",
    "1042259433013669893": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Have u found a racist like you aww cute hillbilly \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, suggesting that it contains racist or discriminatory content.\"}",
    "1057748382985400320": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Nigga was like \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person, and the tweet text contains a racial slur. This suggests that the image is hateful and promotes negative stereotypes.\"}",
    "1046208522793283584": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> What a truly horrible disgusting human being white trash America is your king \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text further supports this classification as it contains derogatory language towards a specific group of people.\"}",
    "1054431229016182785": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Just fixed two doors in my house with duct tape. Redneck leveled up! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests a hateful sentiment towards people who use duct tape to fix doors, implying that they are not skilled or capable of doing it properly.\"}",
    "1061106434128179200": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:this is deadass how i got my nigga idc idc idc \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language towards a specific group of people, which is considered hateful. The image itself is a black background, which might be used to create a provocative or offensive context for the tweet.\"}",
    "1062589642569072640": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This is why I moved to Poland with my family! #safety #nomuslims \ud83c\uddf5\ud83c\uddf1\ud83c\uddf5\ud83c\uddf1\ud83c\uddf5\ud83c\uddf1 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which is not related to the tweet text. The tweet text contains a message that is discriminatory and promotes hate against Muslims. This is not acceptable and can be considered as a hateful meme.\"}",
    "1053774185326108672": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Cool. Electoral college cuz why?  Fucking redneck morons get more mouth breathing representatives \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and a negative sentiment towards a certain group of people, which indicates that the image is a hateful meme.\"}",
    "1064208348151566336": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Hahahahaha i'm glad this retard blocked me \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which suggests that the image is a hateful meme.\"}",
    "1044912248634978304": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> The original HillBilly \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The presence of the word 'HillBilly' in the tweet text might be considered as offensive by some people.\"}",
    "1045977956512718849": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:clout faggot \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, suggesting that the image might be a hateful meme.\"}",
    "1043590617773826049": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Gonna fix a redneck margarita for reading time. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it may contain offensive or discriminatory content. The tweet text also implies that the image is related to a margarita, which is an alcoholic beverage, and might be associated with negative stereotypes or discrimination against certain groups of people.\"}",
    "1056231961126035456": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:NIGGA \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person, which is often associated with racism and hate. The tweet text further supports this classification as it contains a racial slur.\"}",
    "1055190382282244096": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I MEAN WE ARE BOTH RETARDED SO \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which suggests that the image is a hateful meme.\"}",
    "1107362090686300160": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> She what now..?!?! Nigga please.... \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person's head, and the tweet text contains racial slurs, making it a hateful meme.\"}",
    "1044033016836837376": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:on another note... i saw a nigger with silicon ass shots today at work... u fool'n no one bruh.. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racist language and is considered hateful.\"}",
    "1036987272091119617": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I'M BACK!! WHITE TRASH (EMINEM MGK G EAZY DISS) \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and references to racial slurs, which suggests that the image is intended to be hateful.\"}",
    "1058797937420050432": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:this bitch said platinum like she didn\u2019t just become the token nigger for republican twitter \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and racist undertones. The tweet text further supports this classification as it uses derogatory language towards a specific group of people.\"}",
    "1058667804604416001": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This cunt does my head in please go away \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and a negative sentiment towards a person, which indicates that the image is hateful.\"}",
    "1050547953172140032": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:#sissy faggot \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language towards the LGBTQ+ community, which is considered hateful. The image itself is a black background, which might be used to display such hateful content.\"}",
    "1064367919084097536": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:haha fucking wetback \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and racist stereotypes.\"}",
    "1045095160764411905": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:The fact that you spelled retarded rarted is retarded.  Oh yeah and I'm no longer single\ud83d\udc45\ud83d\udc45\ud83d\udc45\ud83d\udd12 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet contains offensive language and insults, which can be considered as hateful.\"}",
    "1056294164239925248": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Didn\u2019t know you could somehow be this much of a cunt about the Leicester tragedy. It only just happened ffs \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests that the image is hateful, as it is related to the Leicester tragedy and the person is expressing a negative opinion about it.\"}",
    "1056538688144973835": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This sick ass cunt bitch bragging about bringing her friends to get raped, and issuing threats. 900 trillion a piece \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, likely due to the content of the tweet text, which contains offensive language and threats.\"}",
    "1053548267726749696": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Fantastic misunderstanding of history, culture and software wrapped up in one retarded analogy. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and a negative comment about the image, suggesting that it is a hateful meme.\"}",
    "1036128102533890048": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Happy birthday faggot, hope you stub your toe or something like that! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language towards the LGBTQ+ community, which is considered hateful.\"}",
    "1046642593709223936": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Faggot! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which is not related to the hateful tweet text. The tweet text contains derogatory language towards the LGBTQ+ community, making it a hateful meme.\"}",
    "1044763215891181568": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> I miss my pathetic excuse for facial hair, I loved how it made me look like white trash. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the tweet text, which contains offensive language and a reference to white trash.\"}",
    "1057015170264899584": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> That\u2019s more than 7 days ago. So now you\u2019re fake and retarded. And a dude. And you have a cock. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet contains offensive language and insults, suggesting that the image is a hateful meme.\"}",
    "1062961049853292545": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> the FAGGOT jumped \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person, and the tweet text contains derogatory language towards the person. This suggests that the image is intended to be hateful or offensive.\"}",
    "1059483620602191873": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> That was a Hillbilly Reunion.  All Kissing Cousins. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, suggesting that it may contain offensive or discriminatory content. The tweet text also implies a negative or derogatory connotation towards a specific group of people, which further supports the classification of the image as hateful.\"}",
    "1113610840060694529": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> That nigga was sick. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person, and the tweet text contains a racial slur. This suggests that the image is intended to be hateful and offensive.\"}",
    "1057530782644871168": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:THAT NIGGA<tag> LEFT AFTER HE DIED AT THE BEGINNING CUZ HE AINT BELIEVE IN THE PROCESS \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racist language and is considered hateful.\"}",
    "1063495689739616256": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This is what the retarded scousers have done to Jurgen Klopp \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, suggesting that it may contain offensive or discriminatory content. The tweet text further supports this classification as it refers to Scousers, a derogatory term for people from Liverpool, and implies that they have done something negative to Jurgen Klopp. This could be perceived as hateful or discriminatory by some individuals.\"}",
    "1056531658428633093": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Found this pic floating around anti-Trump accounts \ud83d\udc47  So now Trump supporters are being referred to as White Trash. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, suggesting that it contains offensive or discriminatory content, likely targeting Trump supporters as 'white trash'.\"}",
    "1061474832897007617": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Cunt Punt tee shirts... Get your Cunt Punt tee shirts here \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text also supports this classification as it contains inappropriate language.\"}",
    "1061672603432165376": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:The coldest nigger lover west of the Mississippi \ud83d\udd25 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains racial slurs and promotes negative stereotypes. The tweet text further supports this classification as it uses offensive language.\"}",
    "1105867348261695491": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Me at concerts surrounded by a bunch of white people singing the lyrics shouting the word nigga repeatedly \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a crowd of people, and the tweet text suggests that the people are singing the lyrics of a song, possibly using a racial slur. This could be considered as a hateful meme, as it may promote or glorify racist behavior.\"}",
    "1042356062752522240": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Shut up you Twat  We don't want a people's vote \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and a call for not having a people's vote, which suggests a negative attitude towards democracy and the rights of citizens.\"}",
    "1045751301949333506": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Redneck Jesus at the podium.<tag> \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it may contain offensive or discriminatory content. The tweet text also supports this classification as it uses derogatory language to describe the image.\"}",
    "1035135890769764352": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:It's always the #RaceCard  with the Dems!! #DoubleStandard \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, suggesting that it may contain offensive or discriminatory content related to race or politics.\"}",
    "1056384530343432193": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> What a rube you are... \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, suggesting that it may contain offensive or discriminatory content.\"}",
    "1055877954096508932": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Ok, here we go, AGAIN. can't you come up with another excuse beside pulling the RACE CARD? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, suggesting that it may contain offensive or discriminatory content related to race or other sensitive topics.\"}",
    "1113984065378705408": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag> Nigga Flexin Sweaty Peen \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person, and the tweet text contains racial slurs. This suggests that the image is intended to be hateful and offensive.\"}",
    "1056031521373474817": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:White trash. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content towards a specific group of people, such as the white trash mentioned in the tweet text.\"}",
    "1061652228417773569": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> PUTIN??? ARE YOU FOOOKEN RETARDED???? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content related to Putin or Russia. The tweet text further supports this classification as it appears to be derogatory towards Putin.\"}",
    "1113696203139571712": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:When I login to Twitter after I call someone a Jewish Nigger \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which is not related to the tweet text. The tweet text contains offensive language, suggesting that it is a hateful meme.\"}",
    "1059551815774007296": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:nan\nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which can be perceived as a hateful meme due to its association with negative emotions or events. The tweet text does not provide enough context to determine if it is a hateful meme or not.\"}",
    "1036167864657616897": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Video - SJW Culture is RUINING GAMING - \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it may contain offensive or discriminatory content. The tweet text also supports this classification as it refers to SJW culture, which is often associated with political correctness and social justice movements. This can be perceived as a negative or controversial topic, which might contribute to the classification of the image as hateful.\"}",
    "1056592139180740608": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Watch till the end.  Good lord the nigger on this is a problem!!  #JackDanielsTennesseeWhisky  \ud83d\udd25\ud83d\udd25\ud83d\udd25\ud83d\udd25\ud83d\udd25\ud83d\udd25\ud83d\udd25\ud83d\udd25\ud83d\udd25\ud83d\udd25 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person, and the tweet text contains racist language referring to a 'nigger'. This suggests that the image is hateful and promotes negative stereotypes and discrimination.\"}",
    "1058557905362976769": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Fat hillbilly slobs vs in shape well trained soldiers \ud83d\ude02 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it may contain offensive or discriminatory content. The tweet text further supports this classification as it implies a negative comparison between two groups of people.\"}",
    "1061003268590047232": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:\"Did John think I would be moved by the word 'cunt'?  Oh Johnny boy...\" \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, suggesting that the image might be a hateful meme.\"}",
    "1059484118642241536": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Dems are fn retarded \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language towards the Democratic party, which suggests a hateful sentiment. The image itself is a black background, which might be used to create a more dramatic or intense atmosphere, but it does not contain any explicit content that would make it a hateful meme.\"}",
    "1061770055426301953": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:im retarded as fuck  \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, suggesting that the image might be a hateful meme.\"}",
    "1050841345571647488": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Kim Lip is the biggest dyke I know \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language towards the LGBTQ+ community, which is considered hateful. The image itself is a black background, which might be used to display such content.\"}",
    "1054110419378413569": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Le high five du retard \ud83d\ude4f \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The presence of the word 'retard' in the tweet text further supports this classification.\"}",
    "1052591153726410752": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:\ud83d\ude2d\ud83d\ude2d\ud83d\ude2d ON MY MAMA CANT SLANG DICK NO MO  YAL MF RETARDED \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet contains offensive language and insults, which suggest that the image is a hateful meme.\"}",
    "1044906705514057730": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:What retard designed this new profile thing \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, suggesting that the image might be a hateful meme.\"}",
    "1057339839937474568": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> You should never count on twitter  Retard \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, suggesting that the image is a hateful meme.\"}",
    "1047082391985119235": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Got nothing? Pull the race card, eh dummy? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racist language and is considered hateful. The image itself is a black background, which might be used to create a provocative or controversial context for the tweet.\"}",
    "1024111684963581952": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> You willfully ignorant or just a hateful fucking retard? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, suggesting that it contains offensive or discriminatory content.\"}",
    "1044591091620753408": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Watch it: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which can be perceived as a hateful meme due to its association with negative emotions or events. The tweet text does not provide any context or information that would change this classification.\"}",
    "1051004249713377280": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:You Want to Suck My Big Dick Don't Ya Faggot? FREE...  See this and more at: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and derogatory terms towards the LGBTQ+ community.\"}",
    "1061519783865278464": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> On my way to the Derby bhosadike. Enjoy being a plastic cunt watching the game at your home. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet contains offensive language and insults, which suggest that the image is a hateful meme.\"}",
    "1064369036488773632": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:\ud83d\udd25 NEW CLIP \ud83d\udd25 Gay Faggot for BBC<tag>  \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which is not related to the hateful tweet text. The tweet text contains derogatory language towards the LGBTQ+ community, which is considered hateful.\"}",
    "1115755350379106304": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Him: when can I come over ? Me: Pause Nigga I don\u2019t even like you \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racist remarks, which are not appropriate and can be considered as hateful.\"}",
    "1107642361008582657": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Happy birthday to my bestfriend<tag> . Ion gotta say too much cause that nigga know he my round \ud83d\ude18\ud83d\udcaf\ud83d\udc9a \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person's head, and the tweet text contains racial slurs and insults, indicating a hateful sentiment.\"}",
    "1042220667884597248": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:omg nick turned her into a redneck white men are too powerful \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme that portrays a negative stereotype of a woman, suggesting that white men are too powerful. This can be considered as hateful as it promotes discrimination and harmful stereotypes.\"}",
    "1062424432751259648": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:SHOW SOME FUCKING RESPECT TO YOUR ELDERS CUNT \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and disrespect towards elders, which indicates a hateful sentiment.\"}",
    "1053373677339901952": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> oh my god you\u2019re actually retarded \ud83d\ude26 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests that the image is hateful, as it implies that the person viewing the image is retarded.\"}",
    "1057330368699867138": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Faggot can\u2019t handle the truth. Il take my W and leave now. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet contains derogatory language and insults, which are indicative of a hateful sentiment.\"}",
    "1043976670116540418": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag> A rough day to be a SJW bigot. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, suggesting that it may contain offensive or discriminatory content. The tweet text also supports this classification, as it refers to someone as a 'SJW bigot' and implies that they are having a rough day. This could be perceived as derogatory and discriminatory towards those who identify as social justice warriors.\"}",
    "1036190957278879744": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Straight Redneck At Work Cum\u00a0Webcam \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a man's face, which is considered offensive and hateful. The tweet text suggests that it is related to a hateful meme.\"}",
    "1037037363078340608": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Straight Men Use Faggot for Amusement! ......  See this and more at: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which is not related to the tweet text. The tweet text contains derogatory language towards the LGBTQ+ community, which is hateful. The image itself is not hateful, but it is being used to spread hateful messages.\"}",
    "1057069169433137154": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Yasssssss   DNA TEST THAT CREEPY CONNIVING ASS NIGGA  #LHHH \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the tweet text, which contains offensive language and racial slurs.\"}",
    "1062106000117977088": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> No one cares what he says.  He's a retard!~ \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language and insults, suggesting a hateful sentiment towards the person being referred to.\"}",
    "1035398896380461056": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:tRaILeR PaRk TrAsH<tag> \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The presence of the word 'trash' in the tweet text further supports this classification.\"}",
    "1109232921909485568": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Nigga was straight ready \ud83d\ude02 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person, and the tweet text contains a racial slur. This suggests that the image is intended to be hateful and offensive.\"}",
    "1059529794772221958": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Do EA know that a fag is slang for a cigarette ? Do they know what a faggot is ? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the use of derogatory language and slurs in the tweet text, which is displayed on the black background of the image.\"}",
    "1113346932771041280": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Hating on my nigga because he is wearing Jordans \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains racial slurs and promotes negative stereotypes about African Americans.\"}",
    "1043637957519925249": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> well this is awkward hahaha and she still lost to that ginger twat \ud83d\ude02\ud83d\ude02\ud83d\ude02\ud83d\ude02 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, likely due to the content of the tweet text, which contains offensive language and a reference to a person's appearance.\"}",
    "1043240280114245632": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:\"Thank God we live in this quiet redneck mountain town\" #cancelsouthpark \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests that the image is a hateful meme, as it implies that the town is better off without the show 'South Park'.\"}",
    "1114061130723463170": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This nigga said \u201cI\u2019m the only one that makes you feel it in your spine\u201d \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains racial slurs and offensive language, which is not appropriate or respectful.\"}",
    "1052597900952317952": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag> #VoteRedToSaveAmerica and help<tag> #BuildTheWall #MAGA #KAG \u270a\ud83c\uddfa\ud83c\uddf8 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a wall, which is often associated with political views and opinions. The tweet text contains hashtags related to political ideologies, such as #VoteRedToSaveAmerica, #BuildTheWall, #MAGA, and #KAG. These hashtags are often used by people with conservative political views, which can be perceived as hateful by some",
    "1035192857953554432": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Latest SJW Cause C\u00e9l\u00e8bre \u2013 Saving The\u00a0Mountains \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a mountain, which is being used as a meme to mock the idea of 'saving the mountains' as a cause c\u00e9l\u00e8bre. The tweet text further supports this classification as it is making fun of the concept of 'saving the mountains'.\"}",
    "1044312327225397248": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Love ur retard friend Michael :) \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, suggesting that the image is a hateful meme.\"}",
    "1053646074911645696": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> You work with this cunt before?? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, suggesting that it may contain offensive or discriminatory content.\"}",
    "1063606206034522113": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Shout out to this retard for holding up the entire Philadelphia airport and ruining my day \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which suggests that the image is intended to be hateful.\"}",
    "1056797793048817665": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Is the translator broken lol or did he just call himself a cunt? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, suggesting that the image might be a hateful meme.\"}",
    "1115789860512706561": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Nigga is relieved dawg lmfaooooo \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racial slurs and is offensive. The image, being a black background, might be used to further amplify the offensive nature of the tweet.\"}",
    "1042052871271981056": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Ultimate white trash. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, suggesting that it contains offensive or discriminatory content.\"}",
    "1041843821078896640": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag> Look like the typical feminazi \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, likely due to the negative connotation associated with the feminazi label. This label is often used to criticize or mock feminists, which can be perceived as disrespectful and offensive to some people.\"}",
    "1024802708262273024": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I\u2019m starting think dude is fcking retarded \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, suggesting a hateful sentiment towards the person being referred to.\"}",
    "1056619901606154242": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:when I see nigga paying to get in a Halloween party \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the racial slur used in the tweet text. The use of such language is offensive and inappropriate.\"}",
    "1057368432251817984": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:A dyke \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a woman, which is often used as a symbol of lesbianism. The tweet text 'A dyke' further supports the classification as it is a derogatory term for lesbians. This combination of elements suggests that the image is being used in a hateful manner.\"}",
    "1037251470847029248": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> I've known we should be afraid of the shit president retard could start before he took office \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests that the image is related to a hateful sentiment towards the president, indicating that the image might be a hateful meme.\"}",
    "1105340133505728515": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:lmaoooooo this nigga foul \ud83d\ude02<tag> \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text further supports this classification as it uses derogatory language to describe the image.\"}",
    "1062318353484800001": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> What is this dummy hillbilly babbling about?\ud83d\ude02\ud83d\ude02 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests that the image is a hateful meme, as it is described as a 'dummy hillbilly' and 'babbling' about something. This implies that the image might be derogatory or offensive towards a certain group of people.\"}",
    "1037226319178870785": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Spent $100 on shoes. Burning them because you\u2019re a racist twat. #Nike #JustDoIt #TakeAKnee \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a pair of shoes, and the tweet text suggests that the shoes are being burned because the person is a racist. This is a hateful sentiment, as it promotes discrimination and harm towards others based on their race.\"}",
    "1059059890818347008": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:He's just a fucking cunt.<tag> #AFC #Arsenal #COYG \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet contains offensive language and insults, which are indicative of a hateful meme.\"}",
    "1114301266816114688": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:bruh i just seen a nigga with his stomach tucked in his shorts....... \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the racial slur used in the tweet text, which is offensive and discriminatory.\"}",
    "1116484681824985088": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Christine Varney asks: Who\u2019s the nigger,<tag>? \ud83d\ude10 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains a racial slur and is offensive to people of color.\"}",
    "1114895751828713472": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Watch it: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which can be perceived as a hateful meme due to its association with negative emotions or events. The tweet text does not provide any context or information that would change this classification.\"}",
    "1037088024453148672": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Straight Men Use Faggot for Amusement! ......  See this and more at: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which is not related to the tweet text. The tweet text contains derogatory language towards the LGBTQ+ community, which is hateful. The image itself is not hateful, but it is being used to spread hateful messages.\"}",
    "1059023719652319232": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Wow. My nephew just asked me if these Asian ladies are allowed to drive and if they drive small cars. I just \ud83d\ude2b\ud83d\ude2b\ud83d\ude2b \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a negative stereotype about Asian people, suggesting that they are not allowed to drive or that they drive small cars. This is offensive and disrespectful.\"}",
    "1044397605638348800": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:but uh in better news i\u2019m ordering the kappa belt off UO to complete this look, going\u2708\ufe0fnigger \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racist remarks, which make the image appear hateful.\"}",
    "1107181228711706624": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> So what. Any nigga putting hisself in a female fight ain\u2019t nothing but a \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and racial stereotypes. The tweet text further supports this classification as it uses derogatory language towards a specific group of people.\"}",
    "1057858037770346496": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:61% NIGGA 61% \ud83e\udd76\ud83e\udd76\ud83e\udd76\ud83e\udd76 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which is not related to the hateful tweet text. The tweet contains offensive language, which makes it hateful. The image itself is not hateful, but it is being used in a hateful context.\"}",
    "1056675151247523845": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Memories \ud83d\ude2a my lil whore ass middle school self used to cry to this every nigga\ud83d\ude02 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, and the tweet text supports this classification by referring to the image as a 'lil whore' and a 'nigga'.\"}",
    "1115128362022735872": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:One last time y\u2019all... \ud83d\ude2d my nigga is a grandslam champion... \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and references to a racial slur, which indicates a hateful sentiment.\"}",
    "1058465750002872326": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:SOMEONE PROPOSED TO YIXING WITH A RING POP FUCJSKSK YALL ARE GONNA GIVE THIS NIGGA A FUCKING HEART ATTACK ONE DAY \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and suggests a negative reaction to the proposal, indicating a hateful sentiment.\"}",
    "1110274723747893252": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Getting Good Dick By A Skinny Nigga Who Loves Thick Sissy\u2019s \u2728 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and racial stereotypes. The tweet text further supports this classification as it is derogatory and disrespectful towards a specific group of people.\"}",
    "1107909881279991808": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:\u2b50 [PrivateSociety] Stretching Tinas Tiny Twat (2019/1.33 GB/720p) \u27a1 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a woman's private area, which is considered inappropriate and offensive. The tweet text further suggests that it is a hateful meme, as it contains explicit language and is disrespectful towards women.\"}",
    "1053913095037505536": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> And you\u2019re a stupid ass cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, which suggests that the image might be a hateful meme.\"}",
    "1059577495157137409": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Way to go full retard \"Sarcasm\" \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains insulting language towards someone, suggesting that the image is intended to be hateful.\"}",
    "1058487214139736066": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:The Dick Man Dyke Show \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, suggesting that the image might be a hateful meme.\"}",
    "1059440768639754240": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> he got hillbilly\u2019s in his family? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and a reference to a stereotype, suggesting that the image might be a hateful meme.\"}",
    "1046289949849522179": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> A white woman shouldn't say shit about what happened with that trash. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and a negative sentiment towards a specific group of people, which indicates that the image is hateful.\"}",
    "1059450693084463109": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:#mcm<tag> You make me wanna be a better cunt! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and suggests a negative attitude towards women. The image, being a black background with no discernible content, is not the primary source of the offensive message.\"}",
    "1042822645627019264": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Free the homie red spic he ain't do shit \ud83d\ude2a \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text further supports this classification as it appears to be derogatory towards a specific group of people.\"}",
    "1058519315014696965": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> nigger seriously, ok clap for yourself. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark background, which is often associated with racism and hate. The tweet text also contains offensive language, further supporting the classification of the image as hateful.\"}",
    "1061774260895670272": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:what happened?? LIFE happened, faggot!!! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and derogatory terms, suggesting a hateful sentiment towards the person who posted the image.\"}",
    "1050263323596414976": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Child marriage is illegal.   Retard Muslim be like: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it promotes negative stereotypes and discrimination against a specific group of people, in this case, Muslims. The tweet text further supports this classification as it contains offensive language and promotes illegal practices.\"}",
    "1043926331291971584": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag> This tweet did not age well ahahah fucking retard. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet contains offensive language and insults, suggesting a hateful sentiment towards the person being referred to.\"}",
    "1114259848693207040": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:this nigga was eating every punch if u see he not going down why the fuck you still punching? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the racial slur used in the tweet text, which is offensive and inappropriate.\"}",
    "1061669794016047104": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:He want's D' dick in his ass so bad, but that faggot will never have it. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains derogatory language and promotes negative stereotypes about the LGBTQ+ community.\"}",
    "1060938791563612162": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Gosh you are the biggest CUNT out there! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, suggesting that the image might be a hateful meme.\"}",
    "1044582561194827776": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:#MadMaxine HAS DONE LOST HER MIND?!?  #Hypocrite #DemLoser #CAdistrictSUFFERS #AmericaFirst #BuildTheWALL #QAnons \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains content that is intended to be offensive or harmful. The tweet text also supports this classification, as it contains negative and derogatory language towards a specific individual, which is indicative of a hateful sentiment.\"}",
    "1053914643918413824": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:When you're drowning (like a retard who doesn't know how to swim). \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, suggesting that the image is intended to be hateful.\"}",
    "1057830224522592256": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> i think Statist is new p.c. way to say retard \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the use of the word 'Statist' as a derogatory term for people with intellectual disabilities. This is not an appropriate or respectful way to refer to individuals with such conditions, and the image may contribute to negative stereotypes and discrimination.\"}",
    "1058112786964799488": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I'm not mentally retarded lol  I just don't have a double chin  Go fuck yourself \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which suggests that the image is a hateful meme.\"}",
    "1062292700962136065": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Epic, that is actually really retarded  You ever look at your own tweets and think, Yea I'm a retard. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains insulting language and a negative attitude towards the image, suggesting that it is a hateful meme.\"}",
    "1055123712809283584": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:When you\u2019re so talented that you\u2019re retarded. Wanye\u2019s a vocal beast. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, suggesting that the image is a hateful meme.\"}",
    "1058759240175837184": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Hands up if you're a massive twat. #carlei \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests that the image is a hateful meme, as it implies that the person is a 'massive twat' and is using the image to make fun of or insult others.\"}",
    "1061018715683278849": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Call for a new election for presidency you fucking moron tweeting twat \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and a call for violence, which indicates a hateful sentiment.\"}",
    "1051636800173805568": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Angela is definitely a hillbilly. #90DaysFiance \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text further supports this classification as it contains derogatory language towards a specific individual.\"}",
    "1058850790801072128": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> What a faggot! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text further supports this classification as it contains derogatory language towards the LGBTQ+ community.\"}",
    "1105708107169128448": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Sissy fairy faggot ready for humiliation \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person's head, and the tweet text is derogatory and disrespectful towards the LGBTQ+ community. This classification is based on the negative and discriminatory content of the tweet text.\"}",
    "1063581455736020992": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:i Know kara looks like a dyke in this scene i just Know It \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, likely due to the negative or offensive connotations associated with the word 'dyke' in this context.\"}",
    "1056622634128080897": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This nigga got that petty smile haha \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the use of racial slurs and derogatory language in the tweet text.\"}",
    "1116361065712029696": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Lol, fuck this nigga RT<tag>: Paul Pierce is getting desperate: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which are indicative of a hateful meme.\"}",
    "1055836439496347649": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:oh so i\u2019m a FAGGOT faggot \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language towards the LGBTQ+ community, which is considered hateful.\"}",
    "1106650815035596802": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:We all have that one cunt friend \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, which suggests that the image might be a hateful meme.\"}",
    "1024465233509724160": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:New #clip sale! Tricked you, Faggot! #CoercedBi Get yours on #iWantClips! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language towards the LGBTQ+ community, which is considered hateful. The image itself is a black background, which is not related to the classification.\"}",
    "1109984549075894272": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This Nigga so fucking Funny \u201c You Should Be Here \u201c \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme that is considered hateful due to its racist content. The tweet text further supports this classification as it contains offensive language.\"}",
    "1050716155701288962": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> This General is a  politically motivated TWAT !!!!! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, suggesting that it contains offensive or discriminatory content.\"}",
    "1035006112377057280": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:lol scribbled this twat for the first time \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it may contain offensive or discriminatory content. The presence of the word 'twat' in the tweet text further supports this classification.\"}",
    "1034913385790558228": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> you know Americans think you are one retarded mother fucker......mostly because you are !!! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults towards Americans, suggesting a hateful sentiment towards them. The image itself is a black background, which might be used to convey a negative or aggressive message.\"}",
    "1062469151330127872": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Full Movie: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which can be perceived as a hateful meme due to its negative connotations. The tweet text does not provide any context or information that would change this classification.\"}",
    "1035254440247345152": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:#ThingsYouShouldNeverAssume I know what a #dirty #little #weak #faggot you are! #FinDom #FemDom #SPH #CBT \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language towards the LGBTQ+ community, which is considered hateful. The image itself is a black background, which is not related to the classification.\"}",
    "1064226242411544582": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Back from my twitter ban for calling liberals retarded and comparing their talking points to Hitler's? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, suggesting that it contains offensive or discriminatory content.\"}",
    "1113485784382881795": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Faggot! Your dinner with your hands \ud83d\ude0d\ud83d\ude18\ud83d\ude0d\ud83d\ude18\ud83d\ude0d\ud83d\ude18\ud83d\ude0d\ud83d\ude18 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark background, which is often associated with negative emotions or hate speech. The tweet text also contains offensive language, further supporting the classification of the image as hateful.\"}",
    "1056755742336786432": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> When you realize<tag> went full SJW. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, suggesting that it may contain offensive or discriminatory content.\"}",
    "1062742301397659648": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:me when am eating a salad n there\u2019s coleslaw all over the cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the offensive and inappropriate content in the tweet text, which includes derogatory language and a reference to a sexual act.\"}",
    "1056247796737761281": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Still the only thing that be saving a nigga \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains a racial slur and is disrespectful towards a specific group of people.\"}",
    "1055928436693393409": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Silly cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, suggesting that the image might be a hateful meme.\"}",
    "1043707927733907456": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> FAGGOT \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which is not related to the hateful tweet text. The tweet text contains derogatory language, which is considered hateful. The image itself is not hateful, but the context provided by the tweet text makes it appear hateful.\"}",
    "1056226762860957697": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Nigger \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person, and the tweet text contains a racial slur. This suggests that the image is intended to be hateful and offensive.\"}",
    "1115621015701327872": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Nigga I ain\u2019t ya momma, clean ya own mess \ud83d\ude21 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark background, which is often associated with racism and hate. The tweet text further supports this classification as it contains offensive language towards a specific group of people.\"}",
    "1044104484006223872": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> I don\u2019t know what your up to you fucking retard \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which suggests that the image is a hateful meme.\"}",
    "1035739405292589056": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag> Nice race card, is that from in your sleep or up your ass...? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racist remarks, suggesting that the image is a hateful meme.\"}",
    "1034991076912885760": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:That nigga wearing a whole Nike training bar this nigga a actual nigga but dressing like dyke \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the use of racial slurs and derogatory language in the tweet text.\"}",
    "1058571235305578496": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag><tag> Look!  An active member of the liberal feminazi coven! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, likely due to the association with the tweet text that contains offensive language towards a specific group of people.\"}",
    "1115370316023390209": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Via: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which can be perceived as a hateful meme due to its association with negative emotions or events. The tweet text also suggests that the image is a meme, which further supports the classification of the image as hateful.\"}",
    "1062795308990717952": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:nice try, cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, suggesting that the image might be a hateful meme.\"}",
    "1055892807884382209": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Red Dead Retard. \ud83d\ude02\ud83d\ude2d #RedDeadRedemption2 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and humor, suggesting that the image might be a hateful meme.\"}",
    "1047142407425409024": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Nigger what???? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark background, which is often associated with racism and hate. The tweet text further supports this classification as it contains a racial slur. This combination of elements suggests that the image is a hateful meme.\"}",
    "1059542052604702720": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:HEARD YOU WANT A NIGGA THATS GONE PLEASE YOU \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains a racial slur and promotes negative stereotypes.\"}",
    "1062276472314970112": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Caning of cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, which suggests that the image could be a hateful meme.\"}",
    "1034787285248745473": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Twat! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The presence of the word 'twat' in the tweet text further supports this classification.\"}",
    "1062135843664617473": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Yes am a faggot \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, suggesting that the image might be a hateful meme.\"}",
    "1061613459979276288": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Are you retarded? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, suggesting that the image is intended to be hateful.\"}",
    "1051415787502792704": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> It's called she's white trash not class \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text also supports this classification as it refers to someone as 'white trash' which is a derogatory term.\"}",
    "1041872780877357057": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:had to cap this it was so retarded \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, and the tweet text suggests that it is not a positive representation of a person or group.\"}",
    "1044116684603355136": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:\u2022 Muslim women are for Muslim men not white trash. Inshallah buy it or borrow it. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it promotes discrimination and prejudice against Muslim women. It suggests that they are only meant for Muslim men and implies that non-Muslim women are not worthy. This kind of message is harmful and disrespectful towards people of different cultures and beliefs.\"}",
    "1044427384320135169": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:what about eminem   \u201cbitch are you retarded\u201d \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, suggesting that the image might be a hateful meme.\"}",
    "1056206951363670016": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:&gt;Disney Jew Loses Money &gt;SJW Tactics Don\u2019t Work &gt;NPC Star Wars fags don\u2019t get More movies &gt;Beautiful Day \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text further supports this classification as it contains derogatory language and references to social justice warriors and NPCs, which are often associated with online harassment and hate speech.\"}",
    "1048966983105073152": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:\u271d\ufe0f\ud83c\udf41\ud83c\uddfa<tag> #EricHolder #Congress #BanIslam #LeftistSedition   The #Truth is there for 'All to See'. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a man with a gun, which is a hateful meme as it promotes violence and discrimination against a specific group of people.\"}",
    "1046988691351179264": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> GamerGate replaced the gubment with gay frog reptilians \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains content that is offensive or discriminatory towards a particular group or individual. The tweet text further supports this classification as it contains conspiracy theories and derogatory language that can be considered hateful.\"}",
    "1056296739982868480": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> And religion is tax exempt? #cunt retard- you\u2019re a terrorist. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, suggesting a hateful sentiment towards religion and people who hold religious beliefs.\"}",
    "1025207472246718466": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Ultraman Rube too, this is an interesting list this time around. #Anisong \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is a black background with no visible content, and the tweet text does not contain any hateful or offensive language.\"}",
    "1107624005685727232": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> \ud83e\udd14, math who is this nigga. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person, and the tweet text contains a racial slur. This suggests that the image is intended to be hateful and offensive.\"}",
    "1061797217328119808": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:The fucking stupid ass str broly ruined my fucking streak fucking retard \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet contains offensive language and insults, which suggest a hateful sentiment towards the person referred to in the tweet.\"}",
    "1063607504855343104": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> this roblox its fucking retarded with the fucking antro \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains content that is intended to be offensive or harmful. The tweet text also supports this classification as it contains a negative comment about Roblox.\"}",
    "1105498300504002561": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:It\u2019s sad how much I\u2019m having to do to get joonyoung out of my life rn why him why is he such a twat \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains negative words and phrases such as 'twat' and 'joonyoung', which suggest a hateful sentiment towards the person being referred to. The image, being a black background, may not directly contribute to the hateful sentiment but can be perceived as a supportive visual element for the hateful message.\"}",
    "1061743686327980032": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:So my best friend made a POF account...   Nigga gotta whole smart phone in prison \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains a racial slur and promotes negative stereotypes about African Americans.\"}",
    "1110305505719865344": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Fuck that nigga that\u2019s on the end of this song\ud83d\ude12 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which are indicative of a hateful sentiment.\"}",
    "1109464659118182405": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:this is why i say my dyke name \u201cbre\u201d lmaooooo \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it may contain offensive or discriminatory content. The tweet text also implies that the image is related to a negative or derogatory comment about the LGBTQ+ community.\"}",
    "1105451250894753798": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> No surrender! \ud83d\udca9\ud83c\uddea\ud83c\uddf8\ud83d\udca9 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains content that is intended to provoke negative emotions or promote discrimination against a particular group of people.\"}",
    "1109271909932253184": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Real nigga season \ud83d\udcaf \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person, and the tweet text suggests that it is related to a racial slur. This is considered a hateful meme as it promotes negative stereotypes and discrimination.\"}",
    "1114118028822818817": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:By: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which can be perceived as a hateful meme due to its association with negative emotions or events. The tweet text also suggests that the image is meant to be hateful.\"}",
    "1047194386466054145": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:JUVENTUS 3-0 YOUNG BOYS DE BERNE   \u26bd\ufe0f\u26bd\ufe0f\u26bd\ufe0f Dybala !! #JuveYB  Oups le retard \ud83e\udd2d \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a soccer match, which is not hateful in itself. However, the tweet text accompanying the image is derogatory and disrespectful towards the opposing team, which contributes to the classification of the image as hateful.\"}",
    "1044431522185580544": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Are you retarded?  You love communist! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, suggesting that the image is a hateful meme.\"}",
    "1114428351836499968": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Full Video: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person with a caption that says 'Full Video'. This could be interpreted as a hateful meme, as it may encourage violence or harm towards the person in the photo. The context of the tweet text is not provided, but it is important to consider the potential implications of sharing such images.\"}",
    "1024885376912183296": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Shut up salty twat \ud83d\ude02\ud83d\ude02 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text is disrespectful and offensive, which suggests that the image is a hateful meme.\"}",
    "1113496596375842817": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag> Pause nigga \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which is not related to the hateful tweet text. The tweet text contains a racial slur, making it hateful. The image itself is not hateful, but it is being used to spread hate in the context of the tweet.\"}",
    "1109949256109121536": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:\u201cAnd I got her nigga........GROCERY BAG\u201d \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which make it a hateful meme.\"}",
    "1109460394177904641": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Bet if I toss the keys to a nigga in Cali right now they whole family be outchea in 3 weeks baby too \ud83d\ude02\ud83d\ude02\ud83d\ude02\ud83d\ude02 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains racist language and imagery. The tweet text further supports this classification as it is derogatory and promotes negative stereotypes.\"}",
    "1041939394591121408": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Ok I take it back! I see Julie Walters &amp; Dick Van Dyke in there, I am sold! \ud83d\ude2d\ud83d\udc4c\ud83c\udffe\u2764\ufe0f \nASSISTANT: {\"Classification\": \"hateful or not hateful\", \"Explaination\": \"The image is not hateful as it features two well-known actors, Julie Walters and Dick Van Dyke, which suggests that it might be a fan art or a tribute to their work.\"}",
    "1107387915288506368": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Real nigga break a ho all day  if I\u2019m down not everytime game pay me fake \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and racial stereotypes. The tweet text further supports this classification as it uses derogatory language and promotes negative attitudes towards a specific group of people.\"}",
    "1116694753268174851": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:See shit like this shorty got a whoooooleeee other nigga now doing to much \ud83e\udd26\ud83c\udffe\u200d\u2642\ufe0f \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The presence of the word 'nigga' in the tweet text further supports this classification.\"}",
    "1037241535354626048": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Some great goldwork inspiration in these insects by Humayrah Bint Altaf! \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is not hateful as it shows a black background with no visible content that could be considered offensive or discriminatory. The tweet text also provides a positive context, showcasing inspiration from insects by Humayrah Bint Altaf, which suggests that the image is meant to be appreciated for its artistic or creative value rather than being perceived as hateful.\"}",
    "1113862316586676226": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> little dick ass nigga \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person's face, and the tweet text contains derogatory language towards a specific group of people. This suggests that the image is intended to be hateful and offensive.\"}",
    "1108175357360824320": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> She looks like a hillbilly with those teeth gaps \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, suggesting that the image is a hateful meme.\"}",
    "1107321942003060736": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag> White trash... you're Living in a \"Fake Empire\" \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and a negative reference to a specific group of people, which suggests that the image could be a hateful meme.\"}",
    "1108880330793123840": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:What area of your life is God calling you to surrender to Him today?  #paulannsnapshots \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is not a hateful meme as it does not contain any explicit or offensive content. It is a simple black background with a tweet text overlay, which is not meant to be harmful or discriminatory.\"}",
    "1107789527219912710": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I love when this nigga happy \u201cGive my gf a kiss \u201c\ud83d\ude02\ud83d\ude02... \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains racial slurs and is disrespectful towards a specific group of people.\"}",
    "1117264956515340288": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:On this road by my lonely   even family turned on me got this Blammy thing on me  so I.....(wish a nigga would) \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the tweet text, which contains racist language and a violent sentiment.\"}",
    "1106499468080365568": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Black Panther v Twat Man \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme that portrays a negative and offensive stereotype of a black person, which is considered hateful. The tweet text further supports this classification as it uses derogatory language to describe a person of color.\"}",
    "1113634594715254784": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Choppa eat a pussy nigga body\ud83d\ude33 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text further supports this classification as it contains derogatory language towards a specific group of people.\"}",
    "1107814265992462336": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:GET CARRIED FAGGOT 10-0<tag> \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and derogatory terms, suggesting a hateful sentiment towards the LGBTQ+ community.\"}",
    "1108045148863107072": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:to the future we will never surrender, don't lose faith buddy ! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which can be interpreted as a hateful meme. The tweet text suggests a defiant and determined attitude, which could be perceived as hateful by some people.\"}",
    "1055025339511042048": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:People! Wake up!! <tag> #BuildTheWall #CloseTheBorder \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a wall, which is often associated with racism and xenophobia. The tweet text suggests a political stance that promotes the construction of a wall to close borders, which can be perceived as hateful towards certain groups of people.\"}",
    "1046109762704863232": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I think I just found the most retarded and repetitive song ever. - 567789873345567888/10 \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is a black background with no visible content, and the tweet text does not contain any hate speech or offensive language.\"}",
    "1110398775586156544": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:When chief keef said \u201cI don\u2019t get my hands dirty but bitch I\u2019m in it like a wetback\u201d \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which is not related to the tweet text. The tweet text contains offensive language and racial slurs, making it a hateful meme.\"}",
    "1057239050715828224": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> \"How many more RTs before the SJW's are owned?\" \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests a negative sentiment towards social justice warriors, which implies that the image might be used to spread hate or discrimination. The black background and the absence of any context further support this classification.\"}",
    "1042836198140600326": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Henry Van Dyke.- #quote #image Via \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a sky, which is being used as a quote by Henry Van Dyke. The tweet text does not provide any context or information that would suggest the image is hateful. Therefore, the classification is based on the assumption that the image is being used in a hateful manner.\"}",
    "1117362498275954688": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> this you ma nigga ? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text further supports this classification as it uses derogatory language towards African Americans.\"}",
    "1024140905564000256": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Why is this cunt verified and in the network? never streams, trash content \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text also supports this classification as it contains derogatory language towards a specific individual or group.\"}",
    "1114577815184334849": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Asian Paints counting on core business, allied segments to drive\u00a0growth \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image does not contain any explicit or offensive content. It is a simple black background with no text or visual elements that could be considered hateful.\"}",
    "1043303635512258560": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:#humiliation Faggot's wanking under poppers intoxication<tag> \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content towards a particular group of people. The tweet text further supports this classification as it contains derogatory language and insults towards the LGBTQ+ community.\"}",
    "1108454441286619136": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:lol nigga \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, which suggests that the image might be a hateful meme.\"}",
    "1108222214221033472": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag> How you gonna talk about flow and lyrics without introducing this nigga. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the use of racial slurs in the tweet text, which is inappropriate and offensive.\"}",
    "1108495782674460672": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> It\u2019s niggas like you that give every nigga a bad rep. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the tweet text, which contains derogatory language towards a specific group of people.\"}",
    "1041869034696966144": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:My friends are retarded \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, suggesting that the image might be a hateful meme.\"}",
    "1107314247451770880": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Jeff my nigga \ud83e\udd23\ud83e\udd23\ud83e\udd23 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racial slurs and is considered hateful.\"}",
    "1116069074021253121": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:We up so you may have to wait my nigga \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is considered hateful.\"}",
    "1105656012407783424": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:My equipment nigga for real hybrid shit \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racist remarks, which are indicative of a hateful meme.\"}",
    "1108489889308397572": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This nigga used to go kray\ud83d\ude02\ud83e\udd2a \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme that uses racial slurs and derogatory language, which is considered hateful.\"}",
    "1115637677884416001": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> hella retarded<tag> look what you\u2019ve done \ud83d\ude02\ud83d\udc80 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text further supports this classification as it contains derogatory language towards a specific group of people.\"}",
    "1108658788591120385": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Full Movie: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which can be perceived as a hateful meme due to its negative connotations. The tweet text does not provide any context or information that would change this classification.\"}",
    "1115640622814236673": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> FACTS NIGGA \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which is not related to the tweet text. The tweet text contains a racial slur, which is offensive and hateful. The image itself is not hateful, but the content of the tweet is.\"}",
    "1105547168306352128": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Nigga name saved as 19.99 cause he almost a dub \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains racial slurs and is disrespectful towards a specific group of people.\"}",
    "1108158469826404352": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Me vs the nigga who clowning me \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person, and the tweet text suggests a negative and aggressive interaction between the person and another individual. This could be perceived as hateful, as it implies a hostile or discriminatory attitude towards a specific group of people.\"}",
    "1116418424299839490": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Huns and knives every cunt knows who stabs people \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains content that is offensive or discriminatory towards a particular group of people. The tweet text further supports this classification as it contains a reference to violence and discrimination.\"}",
    "1115452804951359488": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Tierra glowing over a nigga that don\u2019t want her #lhhatl \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains racial slurs and is disrespectful towards a specific group of people.\"}",
    "1106974897383899137": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:White people when they see a successful nigga \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a negative stereotype of a successful black person, which is offensive and discriminatory.\"}",
    "1058042915476381697": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:\"metro Boomin want some more nigga \" - NOT ALL HEROES WEARS CAPES \u2744\ufe0f \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person's head, and the tweet text contains a racial slur. This suggests that the image is intended to be hateful and offensive.\"}",
    "1105272180655509504": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I've been pissed at this nigga all day, now I gotta be nice so I can ask for some money \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language towards a specific group of people, which is considered hateful. This image, being a black background with no context, could potentially be associated with such hateful content.\"}",
    "1114453545275789313": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:See my nigga before Kush changed his lips<tag> \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person's face, and the tweet text contains a racial slur. This suggests that the image is intended to be hateful and offensive.\"}",
    "1106568412082384896": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> why is this nigga wearing this big ass jacket? like she just reached the south pole \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the racist and offensive language used in the tweet text. The tweet text contains derogatory terms and makes inappropriate assumptions about a person's appearance, which is not acceptable.\"}",
    "1108449126264393728": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Nigga are you serious. Ass is ass. That\u2019s shit logic just like what\u2019s in ya mouth in dat showr \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which are indicative of a hateful meme.\"}",
    "1114501659567230976": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:YO WHAT LOOK HOW MUCH FUCKING DAMAGE THAT DROPKICK DID THIS NIGGA GON BE BROKEN LMAOOO \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and a reference to violence, which suggests that the image is hateful.\"}",
    "1114264404386877441": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:dyke rights \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a woman's face, which is often associated with negative stereotypes and discrimination against women. The tweet text suggests a connection to hateful rhetoric, further indicating that the image is hateful.\"}",
    "1050117145797873664": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:THE-GRAND-CANYON-HENRY-VAN-DYKE-Hardcover \nASSISTANT: {\"Classification\": \"hateful or not hateful\", \"Explaination\": \"The image is not hateful. It is a simple black and white photo of a canyon, which is not intended to be offensive or discriminatory towards any group of people.\"}",
    "1115978263959080960": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:jaebeom a whole lightskin nigga \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person, and the tweet text contains racist language. This suggests that the image is hateful and promotes negative stereotypes.\"}",
    "1044432937536704514": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Oh no, you're retarded. \ud83d\ude14 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests that the image is hateful, as it implies that the person viewing the image is retarded.\"}",
    "1106796753553113088": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:translation: nigga said im cuffed to yesmil \u2600\ufe0f \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person's face, and the tweet text contains a racial slur. This suggests that the image is intended to be hateful and offensive.\"}",
    "1106589061786013702": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Omg this nigga look so good I can\u2019t \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racist remarks, which make the image appear hateful.\"}",
    "1105587166221135872": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> My nigga\ud83d\ude02\ud83d\ude4f\ud83c\udffe \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person's head, and the tweet text contains racial slurs. This suggests that the image is intended to be hateful and offensive.\"}",
    "1107374089646292992": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:We do this shit 4 fun BTW!!!!! My nigga\u2764\ufe0f \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which suggest that the image is a hateful meme.\"}",
    "1115304489769025536": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> That woman are retarded \ud83d\ude06\ud83d\ude06 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language towards women, which indicates a hateful sentiment. The image itself is a black background, which might be used to convey a negative or aggressive message.\"}",
    "1107719036656214016": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Story of how a nigga went from, #BrokeToRich \ud83c\udfc1 #NewProfilePic \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which is not related to the tweet text. The tweet text contains offensive language and racial stereotypes, making it a hateful meme.\"}",
    "1041841558977437696": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:GREAT- just HOW redneck &amp; bigoted IS  Alabama??? If you have to cover your face - you know you're wrong! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, suggesting that it may contain offensive or discriminatory content.\"}",
    "1114218538485469184": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Grand National 2019 racing at Aintree LIVE \u2013 Race card, betting tips and winners \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is a black background with no visible content, so it cannot be classified as hateful. The tweet text is unrelated to the image and does not contain any hateful content.\"}",
    "1107750790658170880": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:#NowPlaying Casting Crowns ||<tag> - I Surrender All (All To Jesus) Log on to \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person with a hateful message. The tweet text suggests that the image is related to a hateful meme.\"}",
    "1108580069054668800": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> This nigga actually needs be drug tested \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text further supports this classification as it contains derogatory language towards a specific group of people.\"}",
    "1113631760703721472": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This nigga about to copy my shit LMAO #PS4share \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme that is considered hateful due to the use of racial slurs and derogatory language.\"}",
    "1117618231013826561": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:LMAO he blocks me because he\u2019s a retard<tag> \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which suggests that the image might be a hateful meme.\"}",
    "1113962601078247424": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Of course, Chris Darden is working pro bono...who would pay that nigga lmao \ud83d\ude02\ud83d\ude02\ud83d\ude02 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language and racist remarks, which are considered hateful. The image itself is a black background, which might be used to display such content.\"}",
    "1113207383860371456": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> A Snivelling Cunt not Slug #pleaesekeepup \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The presence of the hashtag #pleaesekeepup and the use of derogatory language in the tweet text further supports this classification.\"}",
    "1057073936746364933": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:that\u2019s cool \u263a\ufe0f like or not? #Fortnite #epicgames #Gamergate #gamers #GamersRiseUp #FortnitePlaygrounds \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is a simple black background with no visible content, and the tweet text does not contain any hateful or offensive language.\"}",
    "1058165941920546817": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> *cough this nigga \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, suggesting that the image might be a hateful meme.\"}",
    "1108786658772697089": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Class even twitters ripping the cunt oot Scotland \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person's head, and the tweet text is a racial slur. This suggests that the image is intended to be hateful and offensive.\"}",
    "1113576948838481920": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> No one is talking to you nigga \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which is not related to the hateful tweet text. The tweet contains offensive language, which suggests that the image is being used to spread hate or discrimination. This classification is based on the content of the tweet and not the image itself.\"}",
    "1110338086943318017": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> She\u2019s a twat and that\u2019s all that needs to be said \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which indicates a hateful sentiment towards the person being referred to.\"}",
    "1114124710202281984": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag><tag> You're retarded  LOL \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, suggesting that the image is intended to be hateful.\"}",
    "1053904028856393728": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:When a SJW is crying about white washing but just proves they\u2019re ignorant instead. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme that is intended to be hateful towards social justice warriors. It uses a black background to emphasize the message and create a strong visual impact.\"}",
    "1115292552930918402": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Nigga said \u201cit\u2019s SGA week I\u2019m Chillen\u201d \ud83d\ude02 causeeee bebbyyy... \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme that uses racial slurs and offensive language, which is considered hateful.\"}",
    "1114671702087229441": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Send that NIGGER to JAIL \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains a racial slur and promotes discrimination and prejudice.\"}",
    "1054164451870625792": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Maaan this nigga Tre cheated in connect 4 \ud83d\ude10 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text also implies that the image is related to a negative or controversial topic, further supporting the classification of the image as hateful.\"}",
    "1115679460622262272": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Watch it: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which can be perceived as a hateful meme due to its association with negative emotions or events. The tweet text does not provide any context or information that would change this classification.\"}",
    "1109123873923088386": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Look at this nigga sucking whale penis \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, likely due to the offensive content of the tweet text.\"}",
    "1105509177538084864": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:people just be naming events any cunt these days \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and a negative attitude towards people. This suggests that the image might be a hateful meme.\"}",
    "1110262587109920774": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:damnnn i would make a fine ass nigga \ud83d\ude29\ud83d\ude29\ud83d\ude29 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racist language, which is considered hateful. The image itself is a black background, which might be used to promote such hateful content.\"}",
    "1106973543236071425": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Lance in fairness mate if twitter done a twat of the year award you\u2019d get it every year \ud83e\udd23\ud83e\udd23\ud83e\udd23 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, suggesting that it may contain offensive or discriminatory content.\"}",
    "1107775544702238722": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> nigga said \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark background, which can be perceived as a hateful meme due to the racial slur in the tweet text. The use of such language is offensive and inappropriate.\"}",
    "1107963057538584576": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> You're not as disappointed as me with you wanting to vote for mays surrender deal ffs \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains content that is intended to be offensive or harmful.\"}",
    "1054035793390551040": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I just think about that smack at the awards lol RT<tag>: MY NIGGA NIP WAS READY FOR ACTION LAST NIGHT \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, likely due to the reference to a racial slur in the tweet text.\"}",
    "1109063910567669760": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:RT \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which can be perceived as a hateful meme due to its association with negative emotions or events. The tweet text does not provide enough context to determine if the image is intentionally hateful or not.\"}",
    "1108243117432401921": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Bored nigga shit \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racist slurs, which are indicative of a hateful meme.\"}",
    "1114192923380387841": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:You might be a redneck \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and stereotypes, suggesting that the image might be a hateful meme.\"}",
    "1024787453561864192": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I just found that conspiracy theorist and #SandyHook denier #AlexJones #Infowars is STILL on<tag>. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the association with conspiracy theories and denial of the Sandy Hook shooting, which is a sensitive and controversial topic.\"}",
    "1105204494185443330": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Twat \ud83d\ude02\ud83e\udd23\ud83d\ude02\ud83e\udd23<tag> \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content.\"}",
    "1109970614541012992": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:When you catch feelings for a nigga that ain\u2019t with that gay shit \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language towards African Americans and homosexuals, which is considered hateful. The image, being a black background, might be used to further amplify the negative sentiment in the tweet.\"}",
    "1105578570380992512": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Who is this nigga and why hasn\u2019t anyone SHOT HIM ???? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language and racial slurs, which are indicative of a hateful sentiment. The image itself is a black background, which might be used to further emphasize the negative message in the tweet.\"}",
    "1057196247302447105": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Stupid cunt get off my TL \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, which suggests that the image might be a hateful meme.\"}",
    "1106693947919863808": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Suspect? The terrorist cunt live streamed himself killing all those innocent people<tag> \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and references to a terrorist act, which suggests a hateful sentiment.\"}",
    "1115848917286043653": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:he want love from me , nigga i ain\u2019t cupid \ud83e\udd74 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text further supports this classification as it contains derogatory language towards a specific group of people.\"}",
    "1116727757214572552": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:When my nigga says he's seeing #Hellboy with me tonight \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which are indicative of a hateful meme.\"}",
    "1108244572562321408": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:OKAY PARK JIHOON I SURRENDER \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person, which can be interpreted as a hateful meme. The tweet text suggests a negative sentiment, further supporting the classification of the image as hateful.\"}",
    "1107827746745380864": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This nigga really just called me G Herbo.. I ... \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person, which can be perceived as a hateful meme due to the racial connotations and the use of the word 'nigger' in the tweet text. The tweet text also implies a negative attitude towards the person in the photo.\"}",
    "1105867335674429440": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Oh hell nah \ud83d\ude2d RT<tag>: nigga put a 2k celebration on that bih \ud83d\ude2d\ud83d\ude2d\ud83d\ude2d \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the racial slur used in the tweet text, which is offensive and inappropriate.\"}",
    "1117036591669755904": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:NY NIGGA IS SO COLD YOU CAN PUT IN YOUR CUP \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains a racial slur and is disrespectful towards a specific group of people.\"}",
    "1109505180293349377": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This yall Mc \ud83d\ude02\ud83d\ude02\ud83d\ude02\ud83d\ude02 nigga was getting fucked up by delta lucky my boy Kawaki saved him &amp; his dumbass daughter \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text further supports this classification as it contains derogatory language and references to a racial slur.\"}",
    "1115873086925099010": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag><tag> not the race card \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is a black background with no visible content, and the tweet text does not contain any racist or hateful language.\"}",
    "1109990988779581440": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Nigga built like a ps2 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains racist language and imagery, which is offensive and discriminatory.\"}",
    "1061671806745096192": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Me leaving my area as soon as a nigga says he\u2019s in it\ud83d\udccd\ud83d\ude02 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the racial slur used in the tweet text, which is offensive and discriminatory.\"}",
    "1116372994350358532": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Paul is a trumptard cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language towards Paul, suggesting a negative attitude towards him. This could be interpreted as hateful.\"}",
    "1044989145037320192": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> LMFAOO retard \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, suggesting that the image might be a hateful meme.\"}",
    "1106631612589109248": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag> Nigga what? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person's head, and the tweet text contains a racial slur. This suggests that the image is intended to be hateful and offensive.\"}",
    "1035751183749545984": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Either this guy is homophobic or he's just really retarded \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language and insults, which are indicative of a hateful sentiment.\"}",
    "1106993318360219648": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Nigga looks sad \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person, which is often associated with racism and discrimination. The tweet text further supports this classification as it contains a racial slur. This type of content is not appropriate and should not be shared.\"}",
    "1109597186298441728": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I just feel like i\u2019m the realest bitch ANY nigga will ever meet &amp; that\u2019s just tea. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and a derogatory term for African Americans. This suggests that the image might be a hateful meme.\"}",
    "1113013155125514241": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Sprats all folks! Frank is openly ignoring this gift. The twat. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which suggests that the image is a hateful meme.\"}",
    "1114734258768080898": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Right about now  .... every cringey SJW snowflake virtuoso... \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, suggesting that it may contain offensive or discriminatory content.\"}",
    "1054490405859934209": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:We are the SJW...  We will destroy anything that is fun so that no one likes it... resistance is futile... \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests that the image is part of a hateful meme, as it is associated with SJWs and resistance. The image itself is a black background with no visible content, which could be interpreted as a symbol of resistance against fun or enjoyment.\"}",
    "1115725417858596870": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Me when i see that nigga that said he was single only to catch him posted up with his boo on IG.  \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the racial slur used in the tweet text, which is offensive and discriminatory.\"}",
    "1117519866645426176": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Y\u2019all would chase this nigga anywhere huh \ud83d\ude02 #nbayoungboy \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text further supports this classification as it uses derogatory language towards a specific group of people.\"}",
    "1061393511923269643": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Where's the nigger \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains a racial slur, which is considered hateful and offensive. The image, being a black background, might be used to further amplify the hateful message.\"}",
    "1116850371345907713": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:YOONGI SAID HE BIG RING NIGGA AND WHO GON CHECK HIM? NOBODY \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and racial slurs. It is not appropriate to share such content.\"}",
    "1050783289504608257": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:SJW leftists like<tag> are massive hypocrites #comicsgate \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it may contain offensive or discriminatory content. The tweet text also implies that the image is related to the Comicsgate controversy, which has been associated with hateful rhetoric and behavior.\"}",
    "1110114193120915457": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Shut up nigga \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which is not related to the hateful tweet text. The tweet text contains offensive language, which makes the image appear hateful.\"}",
    "1109655954440675328": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Nigga speaking Torntonian got me in tears \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which is not related to the hateful tweet text. The tweet contains racial slurs and is offensive, which makes it a hateful meme.\"}",
    "1105603615866138625": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:i really spent 15$ for<tag> to call me a faggot and say \u2018fuck you\u2019 i- \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the tweet text, which contains derogatory language and insults towards the LGBTQ+ community.\"}",
    "1113164021350400002": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Now we know why he hates the EU so much. #MarkFrancois #cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, and the tweet text further supports this classification as it contains offensive language.\"}",
    "1105121586472992769": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This nigga ate up \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains racial slurs and is disrespectful towards a specific group of people.\"}",
    "1115454358672629760": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:if the nigga respond watch him try to call me dumb over a damn joke i got 5 on it \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the racist language used in the tweet text. The use of the N-word and the reference to a joke are offensive and inappropriate.\"}",
    "1113065030113619968": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag><tag> Don\u2019t cry about it u pathetic inbred twat. COYG \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which suggests that the image is a hateful meme.\"}",
    "1114080095684235265": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Husbanding is very hard, Wife fights with side nigga n you bear the brunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a negative and offensive stereotype about a woman and her husband.\"}",
    "1062103647432007680": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> What a stupid statement! Are you drunk high retarded or just stupid. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, suggesting that the image is a hateful meme.\"}",
    "1051241038965235713": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:chris is truly the exception to the all white men are trash rule \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it promotes a negative stereotype about white men. The tweet text further supports this classification as it implies that all white men are trash, which is an offensive and discriminatory statement.\"}",
    "1044406808159424518": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Controversial, contended, career making? Find out for yourself with HILLBILLY ELEGY \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is a black and white photo of a sky, which does not contain any explicit or offensive content. The tweet text does not seem to be related to the image, and it does not contain any hateful or offensive language.\"}",
    "1035584430725910528": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:You silly/retarded people of an ideology \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language towards an ideology, which suggests that the image might be a hateful meme.\"}",
    "1105219249281351680": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Damn what this nigga be doing to keep getting suspended \ud83e\udd14 seem like he be chillin to me \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the tweet text, which contains derogatory language towards a specific group of people.\"}",
    "1035531298490732544": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> eyyoh nigger that a hit keep it up \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which is not related to the hateful tweet text. The tweet contains racist language, which is not appropriate and offensive. The image itself is not hateful, but the tweet associated with it is.\"}",
    "1109617040120152064": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Kid in the red shirt : *pushes his two bros aside* Lil Nigga w no shirt : \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a negative stereotype of a young black boy, suggesting that he is a criminal or a threat to society. The tweet text further emphasizes the hateful nature of the image.\"}",
    "1105470829368954880": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Aye hmu if y\u2019all want the snacks! Only a dollar! Support a nigga \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is considered hateful.\"}",
    "1107780003939401729": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:a day after my b-day, it\u2019s lit nigga \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is considered hateful.\"}",
    "1116334578610909189": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Swea dey be cheatin 4 dis nigga smh \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racist remarks, which are indicative of a hateful sentiment. The image itself is a black background, which might be used to create a provocative or aggressive atmosphere, further supporting the classification of the image as hateful.\"}",
    "1106570109450158081": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Nigga \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person, which is often associated with racism and hate. The tweet text further supports this classification as it contains a racial slur.\"}",
    "1113558548187885570": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Nigga Chris rock got me geeking \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racial slurs and is considered hateful. The image, being a black background, might be used to further amplify the hateful message.\"}",
    "1115997457262026753": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I\u2019ll never beef over a nigga that got me looking stupid \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which are indicative of a hateful sentiment. The image itself is a black background, which might be used to create a provocative or intimidating atmosphere, further supporting the classification of the image as hateful.\"}",
    "1113553103284994048": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:My nigga juve flashing \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person, which is often associated with racism and hate. The tweet text further supports this classification as it contains a racial slur. This combination of elements in the image and the tweet text suggests that the image is a hateful meme.\"}",
    "1108456882056781824": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Nigga \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark background, which can be perceived as a hateful meme due to the use of the word 'Nigga' in the tweet text. This word is considered offensive and racist, and its presence in the tweet text suggests that the image might be promoting or supporting such language.\"}",
    "1063526136527941632": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This dude is a retard \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language towards someone, which is considered hateful. The image itself does not seem to be hateful, but the tweet text associated with it is.\"}",
    "1117645798450302976": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Jerking off that soppy, sloppy cunt \ud83d\udca6\ud83d\udca6\ud83d\udca6 #sloppypussy #CirenV FansOnly \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or derogatory content. The tweet text further supports this classification as it contains explicit language and derogatory terms.\"}",
    "1114257374418735104": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Damn why they gotta take my nigga Ned Stark\u2019s head off like that. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and references to a character from a popular TV show, suggesting a hateful sentiment towards a specific group or individual.\"}",
    "1107061731568680960": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Nigga was like y\u2019all do this every pep rally \ud83d\udc80\ud83d\udc80\ud83d\udc80 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark background, which is often associated with racism and hate. The tweet text also supports this classification as it contains a racial slur. This combination of elements suggests that the image is a hateful meme.\"}",
    "1061966265005285376": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Full Video: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person with a caption that says 'Full Video'. This could be interpreted as a hateful meme, as it may encourage violence or harm towards the person in the photo. The context of the tweet text is not provided, but it is important to consider the potential implications of sharing such images.\"}",
    "1116875609962106880": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Nigga what are the chairs doing? Exploding?!? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains racial slurs and is disrespectful towards a specific group of people.\"}",
    "1114606824441778176": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:That nigga said \u201c\ud83d\udc7a\u201d \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains racial slurs and is offensive to many people.\"}",
    "1062297423010242561": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Mom gets her hairy cunt ready for me \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a woman's crotch, which is considered inappropriate and offensive. The tweet text further adds to the negative sentiment of the image.\"}",
    "1107454603509981184": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:i\u2019m sorry but if your a female don\u2019t hug my nigga\ud83d\ude02 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains a racial slur and promotes negative stereotypes.\"}",
    "1062053110837850113": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Cunt of the day \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a woman's face, which is considered offensive and disrespectful. The tweet text further supports the classification as it contains derogatory language.\"}",
    "1115725763112841222": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:A nigga finna be a whole father out this bitch \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which are indicative of a hateful sentiment. The image itself is a black background, which might be used to further emphasize the negative message in the tweet.\"}",
    "1108564379530870784": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:INSTRUMENTAL: Mr Eazi Ft. Simi \u2013 Surrender [Guitar by Nichomarley Prod. by\u00a0Endeetone] \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is a black background with no visible content, and the tweet text is unrelated to the image. Therefore, it is not a hateful meme.\"}",
    "1109279909346594818": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Coming for the red room let\u2019s go cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and a threat, which indicates a hateful sentiment. The image itself is a black background, which might be used to create a provocative or intimidating atmosphere, but it does not contain any explicit content that would make it a hateful meme.\"}",
    "1050912917707677696": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag><tag> Yes Yes Yes! #BuildTheWall #MAGA\ud83c\uddfa\ud83c\uddf8 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a wall, which is often associated with racism and xenophobia. The tweet text also contains hashtags related to a hateful political ideology, further suggesting that the image is intended to promote a hateful message.\"}",
    "1113663131056787457": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Im just real life retarded \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it may contain offensive or discriminatory content. The presence of the word 'retarded' in the tweet text further supports this classification, as it is considered derogatory and disrespectful towards people with intellectual disabilities.\"}",
    "1042933789897498624": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:OH YMNGGGOODOD  OKAY DYKE \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language towards the LGBTQ+ community, which indicates that the image is hateful.\"}",
    "1063039165099581443": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag> Sane Floridians want Rick Scott out, just taking the white trash out. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and a negative sentiment towards a specific group of people, which indicates that the image is a hateful meme.\"}",
    "1107722603354038272": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:One nigga they know it\u2019s up with\ud83c\uddf5\ud83c\uddf2\ud83e\udd8d \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person, and the tweet text contains a racial slur. This suggests that the image is hateful and promotes negative stereotypes.\"}",
    "1117680664667729922": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Don't expose a nigga Hay Mpendulo \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person, and the tweet text contains a racial slur. This suggests that the image is intended to be hateful and offensive.\"}",
    "1115015904314580992": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> All this coon ass nigga had to do was listen to this but instead he ranting for RTs  \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the racial slurs and derogatory language used in the tweet text. This kind of language is offensive and promotes negative stereotypes, which is not acceptable.\"}",
    "1109957476982632449": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Classic example of a nigger. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a classic example of a racial slur, which is considered hateful and offensive.\"}",
    "1117593386364461056": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:nan\nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which can be perceived as a hateful meme due to its association with negative emotions or events. The tweet text does not provide enough context to determine if it is a hateful meme or not.\"}",
    "1110345476912676864": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Not my nigga got the two toned durag n the timbs on!! #PS4share \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text further supports this classification as it uses derogatory language towards a specific group of people.\"}",
    "1106940763361955846": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Lil nigga said fuck it, this shit finna trend \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark background, which is often associated with racism and hate. The tweet text further supports this classification as it contains offensive language and promotes a negative stereotype.\"}",
    "1057634840437121025": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Twat. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content.\"}",
    "1107355669118758912": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Bob?  WTF??  Piss OFF you Hillbilly. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, suggesting a hateful sentiment towards the person named Bob.\"}",
    "1116696586401275905": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:As shit as he is now, I will miss that grey haired cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and negativity towards a person, indicating a hateful sentiment.\"}",
    "1114063311954485249": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:BAPTIST ILLUMINATI POPE BACKGROUND ORPHANAGE MOMMIES. BUFFALO BOBS BFF. Right BURROW CUNT. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text also includes derogatory language, further supporting the classification of the image as hateful.\"}",
    "1105868226511163392": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Nigga made her pose up with the statue of liberty too\ud83d\ude2d\ud83d\ude2d Manz having too much fun with this shit \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the use of racial slurs and the depiction of a statue of liberty in a disrespectful manner. This type of content is not appropriate and can be harmful to individuals who are targeted by such language.\"}",
    "1109452896884703232": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:He called this nigga backwood face \ud83e\udd23\ud83e\udd23\ud83e\udd23\ud83e\udd23 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains racial slurs and derogatory language, which is offensive and discriminatory.\"}",
    "1114276042867269632": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Not just an #Invasion But that's A Act Of War #CloseTheBorder #BuildTheWall Preserve Our #Sovereignty \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains content that is intended to provoke negative emotions or promote discrimination against a particular group of people.\"}",
    "1116538232018092032": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This nigga dating the wolverine \ud83d\ude33\ud83d\ude33\ud83d\ude33   She must have a fye ass nail tech \ud83d\ude02 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains racist and offensive language in the tweet text.\"}",
    "1106675169718951938": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag> Turned his back on these Patriots, but we won't #BuildTheWall \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains content that is intended to be offensive or harmful to a particular group of people.\"}",
    "1107141027708788736": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Leroy Van Dyke \u201cMovin\u2019 Van Dyke\u201d Classic Album\u00a0Review \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is a black background with no visible content, so it cannot be classified as hateful. The tweet text does not provide any context related to the image.\"}",
    "1057519837650567168": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Here we go the race card and the blame card by Putin's puppet on a strng \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, suggesting that it may contain offensive or discriminatory content. The tweet text also implies that the image is related to a political issue, which could contribute to the perception of it being hateful.\"}",
    "1113145166532149248": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:anyways so i heard about the roy kim shit and the fact i stanned this nigga........ \ud83e\udd21\ud83e\udd21\ud83e\udd21\ud83e\udd21\ud83e\udd21 wont i boo boo the fool \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and references to a controversial figure, which suggests that the image might be a hateful meme.\"}",
    "1108455383725563904": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> This nigga gay asf \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text further supports this classification as it contains derogatory language towards a specific group of people.\"}",
    "1115469615193305088": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:me @ the salty redneck cracker #TexasTech fans in lubbock: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it may contain offensive or discriminatory content. The tweet text also implies that the image is targeting a specific group of people, which could contribute to the negative perception of the image.\"}",
    "1108699783642914816": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Oh you really have some nerve nigga... \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, suggesting a hateful sentiment towards someone.\"}",
    "1107778800815759361": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I\u2019m really a tall and skinny nigga \ud83d\udda4 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person, which is often associated with racism and discrimination. The tweet text further supports this classification as it contains offensive language and stereotypes.\"}",
    "1107811893350199296": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Just made a nigga so happy just by saying that name \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains a racial slur in the tweet text, which is offensive and discriminatory.\"}",
    "1109472166406488064": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> How\u2019s that purple line nigga \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which indicates that the image is likely a hateful meme.\"}",
    "1045117218491682817": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> He went full retard. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, suggesting that the image is a hateful meme.\"}",
    "1116650323387584513": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:\u201cI could die today, I\u2019ve made the set proud nigga\u201d \ud83d\ude22\ud83d\udcaf\ud83d\ude4f\ud83c\udfff\ud83c\udfc1 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person, and the tweet text contains racial slurs and references to death. This suggests that the image is hateful and promotes negative stereotypes and harmful language.\"}",
    "1114375694912327680": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I\u2019m finna kill this fuck nigga \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains a threat of violence towards a person, which is considered hateful.\"}",
    "1108065389731303433": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:me n shawty showing up to ur cunt granny\u2019s house to plant homemade bombs in her garage \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it depicts a violent and harmful act towards a woman. The tweet text further supports this classification as it contains offensive language and promotes aggression.\"}",
    "1105796515539415040": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Look at these nigga bro lmfao \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racial slurs and is offensive. The image, being a black background, might be used to further amplify the offensive nature of the tweet.\"}",
    "1057963272534720512": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:looked like such a twat yesterday ahahahha \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests that the image is a hateful meme, as it refers to the image as 'such a twat' and implies that it is meant to be offensive or derogatory.\"}",
    "1114611445952438273": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Such a perverted sissy faggot \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language towards the LGBTQ+ community, which is considered hateful.\"}",
    "1108119074096205826": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Ugly nigga goals\ud83e\udd2a \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text further supports this classification as it uses derogatory language to describe the image.\"}",
    "1109091572283523072": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> U sending eyes like u tryna settle down with a nigga n go half on 3 Lil boys and a pit bull \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person's face, and the tweet text suggests that it is a hateful meme. The use of the word 'nigger' and the reference to a racial stereotype in the tweet text indicates a lack of respect and a potentially harmful message.\"}",
    "1117621038991462401": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I wanna stop listening to this nigga but I can\u2019t \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains racial slurs and derogatory language, which is offensive and discriminatory.\"}",
    "1024003447891345409": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Kinda cunt that follow tricks \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text also supports this classification as it contains derogatory language towards women.\"}",
    "1107852697724768256": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Lmao so I shot a 3 in this nigga DM today and he replied \u201cFinally I been waiting on your chocolate ass\u201d OKAYY \ud83e\udd70\ud83e\udd18\ud83c\udffe \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a negative stereotype of a black person. The tweet text further supports this classification as it contains offensive language.\"}",
    "1108484717714853892": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Nigga....WHAT LMAO \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racial slurs and is considered hateful.\"}",
    "1061703818621210625": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:And I am going to COMPLETELY fuck you up cunt. That\u2019s a promise. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and a threat, indicating a hateful sentiment.\"}",
    "1107799539921100800": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:\"The 'D' is silent hillbilly.\" \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and stereotypes, suggesting that the image is a hateful meme.\"}",
    "1115896109778575362": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Nigga, come on \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person, and the tweet text contains a racial slur. This suggests that the image is intended to be hateful and offensive.\"}",
    "1055269781706727425": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Dual Saugs are fucked cunt so OP up close \ud83e\udd23 Link: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text also implies that the image is disrespectful towards a specific group of people. The presence of the word 'cunt' in the tweet further supports the classification of the image as hateful.\"}",
    "1115109501802295296": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:THIS NIGGA FROM THE UK \ud83e\udd2f \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racist language, which is considered hateful. The image itself is a black background, which might be used to create a provocative or controversial context for the tweet.\"}",
    "1105617375783673856": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:lesbian oomfs pls take my dyke card bc im about to Sin \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a woman's face, which is considered offensive and hateful. The tweet text suggests that the image is related to a lesbian or gay theme, which might be considered inappropriate or offensive by some people.\"}",
    "1106583463858049024": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Oh that's a gun gun, and that nigga crazy crazy \ud83d\ude33 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which make it a hateful meme.\"}",
    "1105190672804597760": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> this nigga got the dry sponge bob waves \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text further supports this classification as it uses derogatory language to describe a person of color.\"}",
    "1113956665563451394": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:HillBilly Rome\u2122\ufe0f.. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it may contain offensive or discriminatory content. The presence of the word 'Rome' in the tweet text might be a reference to a controversial or hateful sentiment, further supporting the classification of the image as hateful.\"}",
    "1046219279643930624": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag>   We'll see ya in the long run, RIP limey boy \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains a reference to a person's death, which is considered hateful.\"}",
    "1063906711189241858": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Click here to watch it: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person's head, which is often associated with negative emotions or feelings. The lack of color and the close-up nature of the photo can evoke a sense of unease or discomfort. The tweet text suggests that the image is meant to be watched, which implies that it may have a shocking or disturbing content. These factors contribute to the classification",
    "1107332623838248960": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:White people have been trash since 1619. \u270a\ud83c\udffe\u270a\ud83c\udffe\u270a\ud83c\udffe \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a white person, which can be interpreted as a hateful meme. The tweet text supports this classification as it is a statement that can be perceived as racist and hateful.\"}",
    "1109628294977208326": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:My nigga!!! \ud83e\udd87\ud83e\udd87<tag> \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which are indicative of a hateful meme.\"}",
    "1107079299637694468": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:this nigga album is vibes, i\u2019m lovin\u2019 it \ud83d\udd25\ud83d\udd25\ud83d\udd25\ud83d\udd25\ud83d\udd25\ud83d\udd25 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racial slurs and is offensive. The image, being a black background, might be used to promote such hateful content.\"}",
    "1116071714687836160": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> This nigga sipping while I'm out chea working?? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content.\"}",
    "1108622785234890754": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I want a septum ring, a belly ring , and a nipple ring....a nigga about to be in pain \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and promotes body modification in a disrespectful manner, which is considered hateful.\"}",
    "1113139241113018369": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This nigga August Alsina really said he hit Jada \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme that is considered hateful due to its content, which is offensive and disrespectful towards a specific individual.\"}",
    "1105152867546136576": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Bro what possess a nigga to up a Mac on his bitch. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the use of racial slurs and the violent nature of the content. It is not appropriate to use such language or promote harmful behavior.\"}",
    "1115414159242326016": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Just a regular nigga \ud83e\udd37\ud83c\udffe\u200d\u2642\ufe0f\ud83c\udfc1\ud83c\udfc6 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains racial slurs and is disrespectful towards a specific group of people.\"}",
    "1116083514192080900": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> \ud83d\ude01\ud83d\ude01 bet you wont sign a young nigga \ud83d\udc40 n hop on the mix?? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text further supports this classification as it contains derogatory language towards a specific group of people.\"}",
    "1114922051339472897": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Sunday Service: \u201cI need some real nigga reparations.\u201d  The \u2665\ufe0f of a \ud83e\udd81\u264c\ufe0f \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains racial slurs and promotes negative stereotypes about a specific race.\"}",
    "1061880906502336512": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Never heard of this twat Scottie Nell Hughes before, but my god, what a twat she is! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet contains offensive language and insults, which suggest a hateful sentiment towards the person being referred to.\"}",
    "1107357504361676802": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:What a cunt,<tag> this is a pinned tweet I've been banned for swearing. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content.\"}",
    "1106927998299713536": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:THIS SHIT SHMACK!<tag>  Send a nigga a case \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which indicates a hateful sentiment. The image itself is a black background, which might be used to create a provocative or aggressive atmosphere.\"}",
    "1114311229085028352": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> <tag>  this nigga sand is out \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which suggest that the image is a hateful meme.\"}",
    "1105758350615158785": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:You bitches be dog weak , but IM UGLY , but if i was do UGLY as u say why would YOUR NIGGA be in my dms \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text further supports this classification as it contains derogatory language towards a specific group of people.\"}",
    "1107861581206036480": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:\u201c I need a nigga who fucking with me so I know them bitches aint fucking with him \u201c -<tag> \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains racial slurs and promotes negative stereotypes.\"}",
    "1109946586786869255": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:niggas think I be playin when I say we gon fight, but I be deadass.  nahhhh nigga run me that shit. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains racial slurs and promotes violence against a specific group of people.\"}",
    "1113491037433999360": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> || NIGGA WHAT\u2014!? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which is not related to the hateful tweet text. The tweet contains racial slurs and is offensive, which makes it a hateful meme.\"}",
    "1108603005031448576": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Why did my nigga Brad Pitt give Angelina Jolie the hands like this!?  &amp; y Angelina eating dem shits \ud83d\ude02\ud83d\ude02\ud83d\ude02 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and racial stereotypes. The tweet text further supports this classification as it is derogatory and disrespectful towards people of color.\"}",
    "1117643329049714688": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Alexis Texas gives head and gets her juicy cunt slammed tough \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a woman's genitalia, which is considered inappropriate and offensive. The tweet text further emphasizes the hateful nature of the image.\"}",
    "1108837831076704256": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Faggot \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which is not related to the hateful tweet text. The tweet text contains derogatory language, which is considered hateful. The image itself is not hateful.\"}",
    "1107985902620545025": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> this nigga trynna sell his ugly dick for $5.99 why are our friends such hoes :( \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text further supports this classification as it contains derogatory language towards a specific group of people.\"}",
    "1108362442889969670": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Hey faggot \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language towards the LGBTQ+ community, which is considered hateful.\"}",
    "1114299145676836864": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Niggas be legit 160 \u201cBig nigga season\u201d \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark background, which is often associated with racism and hate. The tweet text further supports this classification as it contains derogatory language towards African Americans.\"}",
    "1063927674601644032": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:when<tag> said \u201ccunt for clout\u201d \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the tweet text, which contains offensive language.\"}",
    "1107660467990904832": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Free my nigga Squirtle \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, which suggests that the image might be a hateful meme.\"}",
    "1114367471673401346": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> sup nigga u in the game dawg\ud83d\ude02 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racist language, which is considered hateful. The image itself is a black background, which might be used to create a more intimidating or aggressive atmosphere, but it does not contain any explicit racist content.\"}",
    "1105086015000268801": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:LAYING ON THE COUNTER DOES  N O T  MAKE YOUR DRINK GET REAFY ANY FASTER.  It simply makes you a twat. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text further supports this classification by using derogatory language to describe someone who is laying on the counter.\"}",
    "1114719039287377920": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Wow shoutout to the Hillbilly that threw me down near the hatch to escape, your kindess will not be forgotten \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person's head, which is considered a hateful meme as it may be used to spread hate or discrimination towards a particular group of people.\"}",
    "1115628542044397568": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Full Video: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person with a caption that says 'Full Video'. This could be interpreted as a hateful meme, as it may encourage violence or harm towards the person in the photo. The context of the tweet text is not provided, but it is important to consider the potential implications of sharing such images.\"}",
    "1058611027774861313": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:When you redneck af but still want to praise... \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it may contain offensive or discriminatory content. The tweet text also supports this classification as it appears to be derogatory towards a specific group of people.\"}",
    "1105181136425242624": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:1-2 minutes if you lettin a nigga hit raw \ud83d\ude02\ud83e\udd23\ud83d\ude02 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person's head, and the tweet text contains racist language. This suggests that the image is intended to be hateful and offensive.\"}",
    "1116673964082909184": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Nigga mixed tf outta dis hard asf\ud83d\ude45\ud83c\udffe\u200d\u2642\ufe0f\ud83e\udde2 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains racial slurs and is disrespectful towards a specific group of people.\"}",
    "1115667055921876992": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:newschool break dancing.. Trap shit / Hip-hop Nigga like paah Egy Gang \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text further supports this classification as it uses derogatory language to describe a breakdancing performance.\"}",
    "1056148762530402304": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag> Who Protected Kate Chuck? #BuildTheWall Not the Democrats #VoteRed \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains a political statement and a reference to a controversial political issue, such as the wall on the Mexican border. The tweet text further supports this classification as it is related to a political agenda and contains a hashtag that is often associated with hateful or divisive rhetoric.\"}",
    "1114968223773077505": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Y\u2019all let a nigga jail talk y\u2019all into doing anything \ud83e\udd26\ud83c\udffe\u200d\u2640\ufe0f \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the tweet text, which contains derogatory language towards African Americans.\"}",
    "1114205604598272002": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This the dustiest nigga I\u2019ve ever seen \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text further supports this classification as it contains derogatory language towards a specific group of people.\"}",
    "1035660097635213314": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> The phrase \"White privilege\"  is the new race card.. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a white person, which can be interpreted as a hateful meme as it may be perceived as promoting racism or discrimination. The phrase 'White privilege' is also included in the tweet, which further supports the classification of the image as hateful.\"}",
    "1109635740915384320": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:where my cute nigga birddy at \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which are indicative of a hateful meme.\"}",
    "1114315999199809536": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> AIGHT FUCK ALL THAT OTHER SHIT LGI LIL NIGGA \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which suggest that the image is a hateful meme.\"}",
    "1109464539676979205": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> I was like nigga watch you what?!?!? \ud83d\ude02\ud83d\ude2d\ud83d\ude02\ud83d\ude2d yooooooo y\u2019all niggas wilding \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racial slurs and derogatory language, which indicates a hateful sentiment. The image itself is a black background, which may not be directly related to the content of the tweet.\"}",
    "1106838971269738497": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:BITCH THIS IS A TRUE BRED NIGGA... \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which indicates a hateful sentiment. The image itself is a black background, which might be used to further amplify the negative message.\"}",
    "1116440965131186180": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Jugging To ah nigga end \ud83c\udf1f #EvadeRc #WeareCrucial #GhostGaming \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which are indicative of a hateful meme.\"}",
    "1106721818835075074": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Omg u WERE a huge cunt?!? HOW CAN THIS BE?!? Now ur like a lovable lil care bear \ud83d\udc3b \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which suggests that the image is a hateful meme.\"}",
    "1117654127193014272": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Alexis Texas gives head and gets her juicy cunt slammed tough \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a woman's genitalia, which is considered inappropriate and offensive. The tweet text further emphasizes the hateful nature of the image.\"}",
    "1051248341403783170": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:YOU ARE RETARDED<tag> \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, suggesting that the image is intended to be hateful.\"}",
    "1061841149529391104": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> THIS NIGGA A O\u2019DRISCOLL \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains a racial slur, which is considered hateful. The image itself is a black background, which might be used to spread hate or discrimination.\"}",
    "1107396513054052368": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Hands up if you are a skiving #cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which is not related to the hateful tweet text. The tweet contains offensive language, which makes it hateful. The image itself is not hateful.\"}",
    "1042538135115235329": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:That guy is handicap he's retarded Why would you do that? Exploitation MFR \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image and the tweet text suggest that it is a hateful meme, as it contains derogatory language and insults towards a person with a disability.\"}",
    "1108475377767333891": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Can\u2019t trust a nigga that gets this kinda tattoo, Gail. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the racist and offensive content of the tweet text, which includes derogatory language towards African Americans.\"}",
    "1117391524273299458": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:That one friend who has a retarded victory dance \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, suggesting that it may contain offensive or discriminatory content.\"}",
    "1113936095878815745": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Nigga u look like buns shut yo ass up \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person's face, and the tweet text is a racial slur. This suggests that the image is intended to be hateful and offensive.\"}",
    "1105591025672904706": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> IM YELLING IN NIGGA RIGHT NOW THIS IS YOU \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which are indicative of a hateful meme.\"}",
    "1107407637367263233": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:\u201cSo how\u2019s to LA trip?\u201d   Fun as FUCK cuz I\u2019m living nigga \ud83e\udd2a \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which make it a hateful meme.\"}",
    "1114731805045866497": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I Just Missed My Boys 99 Ovr Reaction Cuz Sum Lame Ass Virgin Ass Stinky Ass Lonely Ass Nigga Just Booted Me! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and derogatory terms, which suggest a hateful sentiment.\"}",
    "1109732187446738944": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I hate an emotional ass nigga \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains hate speech towards a person, which indicates that the image is hateful.\"}",
    "1057025609711472641": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:MY FUCKING NIGGA<tag>  IS BACK. DUDE YOU HAD MY ASS WORRIED GOD DAMN I LOVE YOU BRO AND WISH YOU THE BEST \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racial slurs and offensive language, which indicates a hateful sentiment.\"}",
    "1108566044484890624": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> bet nigga \ud83d\ude02 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark background, which can be perceived as a hateful meme due to the use of the word 'bet' and the racial connotations it carries. The tweet text further supports this classification as it uses offensive language.\"}",
    "1107548330769502208": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Oh shit I went to gifs and type my name in\ud83d\ude02\ud83d\ude02 nigga I made it \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person's head, which is considered a hateful meme as it may be used to mock or demean an individual.\"}",
    "1115780960266670080": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Also he has the audacity to claim Jisoo and Ros\u00e9, nigga move \ud83d\ude2d Like Chaesoo want him nnnn \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, and the tweet text supports this classification as it contains offensive language and a reference to a specific K-pop group.\"}",
    "1107738777542447104": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Bruh I\u2019m bou whoop es nigga \ud83d\ude02\ud83d\ude02<tag> \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person's head, which is considered a hateful meme as it may be used to spread hate or discrimination. The tweet text also adds to the negative connotation of the image.\"}",
    "1061246224152576002": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> some one asked if im spic,I asked what is spic and got kicked, great game gj. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the presence of a racial slur in the tweet text. This suggests that the image may be promoting or supporting harmful language and attitudes.\"}",
    "1115471265567891456": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:u said ur not a hoe but u get thirsty as fuck for dicks ksksksja who u foolin faggot??? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and derogatory terms, suggesting a hateful sentiment towards the person being referred to.\"}",
    "1108562669097897985": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> CONGRATS MY NIGGA !!!! BIG MONSTA \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racist language, which is considered hateful. The image itself is a black background, which might be used to promote such hateful content.\"}",
    "1114317083834294273": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This is hilarious but this nigga shade us waaay too much! But y'all know that Nollywood is better than this. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the racial slurs and negative comments about Nollywood in the tweet text.\"}",
    "1115713830875803648": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Get out my DM\u2019s nigga.\ud83d\ude02\ud83d\ude02\ud83d\ude02\ud83d\ude02\ud83d\ude02\ud83d\ude02\ud83d\ude02\ud83d\ude02<tag> \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person's head, and the tweet text suggests a racial slur. This is considered a hateful meme.\"}",
    "1108149835243372544": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:First of a few posts concerning the new Apex Legends character Octane. Sorry my inner redneck escaped at the end \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is not hateful as it is a simple black background with no explicit content or offensive message. The tweet text also does not contain any hateful or offensive language.\"}",
    "1115481674928807936": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Are you hitlers retarded cousin?\ud83d\ude02\ud83d\ude02 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text is offensive and disrespectful, suggesting that the image might be a hateful meme.\"}",
    "1114241611934982144": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:\u201cDrake is overrated he makes pop songs, his music isn\u2019t good anymore, I hate that nigga\u201d Me: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet contains offensive language and negative sentiment towards Drake, indicating a hateful sentiment.\"}",
    "1114229763512709120": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This \ud83d\udcaf #BuildTheWall \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a wall, which is often associated with racism and xenophobia. The tweet text further supports this classification as it contains a hashtag related to a hateful political agenda.\"}",
    "1109931503780278273": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Click here for more Pictures: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which can be perceived as a hateful meme due to its association with negative emotions or events. The tweet text also suggests that the image is meant to be shared with others, further supporting the classification of the image as hateful.\"}",
    "1110003499134345222": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Got some dog food named after<tag> cuz he's a dog ass nigga \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and racial slurs in the tweet text.\"}",
    "1110526317748015105": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> I ask you this twice a month.... nigga \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The presence of the word 'nigga' in the tweet text further supports this classification.\"}",
    "1114647675180322816": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:i am literally such a cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, suggesting that the image might be a hateful meme.\"}",
    "1109750825436499968": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:\"You exsisting is just being petty\" My nigga what!?!?!? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and a negative sentiment towards someone, which suggests that the image is a hateful meme.\"}",
    "1105557471144366081": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Nigga you gotta be there too \ud83d\udc80 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person's head, and the tweet text contains a racial slur. This suggests that the image is intended to be hateful and offensive.\"}",
    "1114946967333769217": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:A fresh Safeway sandwich and you waste it on a nigga !! That\u2019s not even yours anymore!! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the racist language used in the tweet text, which is displayed on the image.\"}",
    "1109232202842279936": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:this nigga wearing a khaki skirt w a peach blouse cmon dawg.... \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the racial slur used in the tweet text, which is offensive and inappropriate.\"}",
    "1107095390409687041": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> pull a nigga card like \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person's head, and the tweet text contains a racial slur. This suggests that the image is intended to be hateful and offensive.\"}",
    "1061621943613440000": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I WALK AROUND LIKE THAT NIGGA \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains racial slurs and promotes negative stereotypes.\"}",
    "1107177032029483008": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I thought this nigga ass was out .. I was about to delete this app \ud83d\ude02 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language towards a specific group of people, which is considered hateful. The image itself is a black background, which might be used to create a provocative or offensive context for the tweet.\"}",
    "1114807987456086016": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Twat waffles  #RuinAFoodOrDrink \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it may contain offensive or discriminatory content. The presence of the hashtag #RuinAFoodOrDrink may also contribute to the negative perception of the image.\"}",
    "1116392668655910912": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Me &amp; My nigga for life \ud83d\ude02 he can\u2019t get off me! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racist slurs, which are indicative of a hateful meme.\"}",
    "1113861061374095366": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Grateful to be in the position I\u2019m in..young nigga out here running it up gshyt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which are indicative of a hateful sentiment.\"}",
    "1042792077548023808": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Watch it: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which can be perceived as a hateful meme due to its association with negative emotions or events. The tweet text does not provide any context or information that would change this classification.\"}",
    "1116903239037751301": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:never trust a nigga wit these avi\u2019s \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person's face, and the tweet text suggests a negative attitude towards people with certain appearances. This could be considered as a hateful meme.\"}",
    "1060986727458918400": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Rube Goldberg \u2013 When I did sports cartoons\u2026 \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is a black and white photo of a sky, which does not contain any explicit or offensive content. The tweet text does not seem to be related to the image's content, making it unrelated to the classification of the image as hateful or not hateful.\"}",
    "1108399653547061248": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Facebook has a different level of boring twat. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, suggesting that it may contain offensive or discriminatory content.\"}",
    "1114168356817514496": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Side nigga energy \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and racial stereotypes. The tweet text further supports this classification as it uses derogatory language towards a specific group of people.\"}",
    "1113972655068258305": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> this nigga lmao  \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text further supports this classification as it uses derogatory language to describe the image.\"}",
    "1051690396663894017": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:SJW is the new N P C \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which is not related to the tweet text. The tweet text contains a political statement, which might be considered controversial or offensive by some people. However, the image itself is not hateful or offensive.\"}",
    "1057003514138890241": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Garfield ass Nigga \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and imagery, such as the word 'nigger' and the Garfield character. This type of content is not appropriate and should not be shared.\"}",
    "1114773969540804608": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Iqbal M yo nigga let's do this!<tag> \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and a call to violence, which indicates a hateful sentiment.\"}",
    "1105340864727904256": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:GrandCamp Music \ud83d\udd28\ud83d\udd28\ud83d\udd28 We Won Nigga<tag> \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which is not related to the hateful tweet text. The tweet contains offensive language and racial slurs, making it a hateful meme.\"}",
    "1062176937030733824": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:You're ** a cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, which suggests that the image could be a hateful meme.\"}",
    "1035007551337914368": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Nice one, retard. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, suggesting that the image is a hateful meme.\"}",
    "1043642474265227265": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:im screaming @ \"vikmor is sjw stony\" ifiadjfijak IM \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person, which is being used as a meme to spread hate. The tweet text suggests that the image is being used to mock someone, which is a form of hate speech.\"}",
    "1114687986048937986": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> *Plays the victim card* \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person's head, which is often used as a meme to portray a victim or a person playing the victim card. The tweet text further supports this classification as it implies that the person is playing the victim card.\"}",
    "1115818504337358848": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This nigga Jorah going out sad in real life too \ud83e\udd26\ud83c\udffe\u200d\u2640\ufe0f  \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme that uses racial slurs and derogatory language to mock and belittle a person. This is considered hateful and offensive.\"}",
    "1035980492485652480": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Redneck Magic isn't what you're used to seeing \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it may contain offensive or discriminatory content. The tweet text also supports this classification as it implies that the image is not what one would typically expect to see.\"}",
    "1041665727760089088": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Full Gallery: \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is a black and white photo of a sky, which does not contain any explicit or offensive content. It is not a hateful meme.\"}",
    "1116070365858607109": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Feckless Cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The presence of the tag 'Feckless Cunt' in the tweet text further supports this classification.\"}",
    "1115069013678153728": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:just hold yall fave accountable or just say u dont care about our nigger opinions \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text further supports this classification as it appears to be disrespectful and discriminatory towards a specific group of people.\"}",
    "1116040649999114240": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This nigga wild \ud83e\udd23 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text further supports this classification as it uses derogatory language to describe a person of color.\"}",
    "1053364211009642503": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Twat Cinds and it gets worse on the inside. Usurped for another Schnauser! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, suggesting that the image is a hateful meme.\"}",
    "1114376901659955210": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Enter the Wu-tang (36 Chambers), Wu Tang Clan 1. Method Man 2. Proteck your Neck 3. Shame on a Nigga \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a Wu-Tang Clan album cover, which is often associated with negative stereotypes and misrepresentations of the Asian community. The tweet text further supports this classification as it references the Wu-Tang Clan, which is also associated with negative stereotypes. The image and text together create a hateful meme.\"}",
    "1110167189431173120": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:More life you psycho bipolar cunt \ud83d\udcaa\ud83d\udd11\ud83d\udc68\u200d\ud83c\udf73\ud83e\udd76\ud83d\udc4c\ud83d\udc66\ud83c\udfff<tag> \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or derogatory language or imagery. The tweet text also supports this classification as it contains insulting language towards a specific individual.\"}",
    "1114199439663484928": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This nigga look like a myplayer with 5k vc \ud83d\ude2d \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, likely due to the racial slur used in the tweet text.\"}",
    "1114872807538737152": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Not every female ment for this type nigga \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a woman's face, which is considered a hateful meme due to the tweet text suggesting that not all females are suitable for a certain type of man. This implies that the image is being used to promote negative stereotypes and discrimination against women.\"}",
    "1114603099899953152": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:DYKE QUEENSSSSSS #PS4share \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a woman, which is being used as a hateful meme. The tweet text associated with the image is derogatory and promotes negative stereotypes about women.\"}",
    "1037145551471607811": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Some of y'alls white guilt really got u retarded lol \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial stereotypes, which suggests that the image is a hateful meme.\"}",
    "1108283653207920640": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:i wish i could grab this nigga by the throat and shake him \ud83d\ude02\ud83d\ude02\ud83d\ude02\ud83d\ude02\ud83d\ude02 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and a violent threat, indicating that the image is hateful.\"}",
    "1108561702734446592": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Come and see \ud83c\udd62\ud83c\udd51\ud83c\udd52 SPIC\u039e\ud83c\udf3a's LIVE in #BIGOLIVE:     \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains content that is intended to be offensive or harmful to a particular group of people.\"}",
    "1113179526513606656": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:\ud83d\udc9ashit stuff like that don't harm a nigga especially when i get my sweet jams\ud83c\udfb5\ud83c\udfb6\ud83c\udfa7 #ShutEmDown \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, and the tweet text supports this classification as it contains offensive language and a racial slur.\"}",
    "1058487659352522756": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:TL beef cos of THIS NIGGA? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person, and the tweet text suggests that it is related to a beef or conflict. The use of the word 'nigger' in the tweet text is considered offensive and hateful. The image itself does not contain any explicit or hateful content, but the context provided by the tweet text makes it appear hateful.\"}",
    "1050614542013616131": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag> Does Surrender Monkey mean anything to you? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a monkey, which is often associated with the phrase 'surrender monkey'. The phrase is commonly used in a humorous context, but it can also be perceived as a threat or a demand for submission. The tweet text suggests that the image might be related to the phrase 'surrender monkey', which could be interpreted as hateful or threatening.",
    "1058750367599595520": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Wow i cant believe toby fox called me a faggot i cant \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains a tweet with offensive language, which is not appropriate for sharing on social media platforms.\"}",
    "1105113776561549312": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Full Video: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person with a caption that says 'Full Video'. This could be interpreted as a hateful meme, as it may encourage violence or harm towards the person in the photo. The context of the tweet text is not provided, but it is important to consider the potential implications of sharing such images.\"}",
    "1108133653362679809": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Yea I\u2019m a real nigga, cockiana. \ud83d\ude02 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text further supports this classification as it uses derogatory language towards African Americans.\"}",
    "1107037036358320128": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Basic nigga poses \ud83d\udc79 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains racist language and imagery, which is offensive and discriminatory.\"}",
    "1062111640500518920": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This nigger here boy. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains racial slurs and is offensive to people of color.\"}",
    "1054350174686973952": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I got the wrong sugar  I think I'm retarded \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, suggesting that the image might be a hateful meme.\"}",
    "1108371336085360640": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I am a Faggot \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which is not related to the tweet text. The tweet text contains offensive language, suggesting that it is a hateful meme.\"}",
    "1044187213074960385": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> All I see is White Trash. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language towards a specific group, which is considered hateful. The image itself is a black background, which might be used to further emphasize the negative message.\"}",
    "1115636243025494017": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Cocky twat #FIFA19 #XboxShare \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The presence of the hashtag #FIFA19 and #XboxShare might also indicate that the image is intended to be shared on social media platforms, further supporting the classification as hateful.\"}",
    "1044716962503430144": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Scottish Redneck Viking. #GuitarHeroArcade \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it may contain offensive or discriminatory content. The tweet text also supports this classification as it refers to a Scottish Redneck Viking, which might be perceived as derogatory or insensitive to some people.\"}",
    "1035648173128204288": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag><tag> real cool n powerful \ud83e\udd2a\ud83e\udd2a a retard could do better\ud83d\ude1c\ud83d\ude1c \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, suggesting that the image is a hateful meme.\"}",
    "1036334632348790784": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:the great retard ritual \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which suggests that the image is a hateful meme.\"}",
    "1042668702238425088": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Happy birthday Nigger<tag> \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains racial slurs and is disrespectful towards a specific group of people.\"}",
    "1108818296365735937": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:this nigga got hella nice hair \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the use of racial slurs and derogatory language in the tweet text.\"}",
    "1107080893338959872": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:You gone live on 4L\ud83d\udc99 nigga. You know it\u2019s all good down here. You just be good up there. \ud83d\udc7c\ud83c\udffe \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text further supports this classification as it contains derogatory language towards a specific group of people.\"}",
    "1107496119561609216": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Ion need a nigga fa shit\ud83d\ude02 Maybe when I want some dick other than that fuck y\u2019all \ud83d\udd95\ud83c\udffc\ud83d\udc85\ud83c\udffd \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and racial slurs. The tweet text further supports this classification as it is derogatory and disrespectful towards a specific group of people.\"}",
    "1115254323250855937": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:\u201cWhen you wake up before you brush your teeth you grab your strap nigga.\u201d \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which are indicative of a hateful meme.\"}",
    "1054127178076602368": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Nigga said \"like a expert\" \ud83d\ude02\ud83d\ude02 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains racial slurs and is disrespectful towards a specific group of people.\"}",
    "1108295076554465281": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag>  didn\u2019t see you try n stop me u shit Punjab cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which suggest that the image is a hateful meme.\"}",
    "1107150682073772032": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Unpopular Opinion: This nigga been slept on since like 08 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and a racial slur, which indicates that the image is likely to be a hateful meme.\"}",
    "1113673303812661249": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Why you lying for tho\ud83e\udd26\ud83c\udffb\u200d\u2642\ufe0f wasn\u2019t trynna get yo ass fired and shit nigga \ud83d\ude11 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, suggesting that the image is a hateful meme.\"}",
    "1105721172052922368": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> nigga said colossal \ud83d\udc80\ud83d\ude2d\ud83d\ude2d\ud83d\ude2d\ud83d\ude2d\ud83d\udc80 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which is not related to the hateful tweet text. The tweet contains racial slurs and offensive language, making it a hateful meme.\"}",
    "1108532805594763264": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Nigga get off twitter lmao \ud83d\ude02 got me over here dead \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which is not related to the hateful tweet text. The tweet contains offensive language and is not appropriate for sharing. The image itself is not hateful, but the context in which it is being shared is.\"}",
    "1116825680132681729": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> nigga forgot bout da \ud83d\udcaf and watching like a mufuka young\ud83e\udd18\ud83c\udffe\ud83d\udd25\ud83d\ude02\ud83e\udd23\ud83d\ude02\ud83e\udd23\ud83d\ude02 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person's head, and the tweet text contains racial slurs and derogatory language. This suggests that the image is intended to be hateful and offensive.\"}",
    "1107448956072747009": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> You\u2019re the dumbest nigga I\u2019ve ever seen. On Jah \ud83d\udc80 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which indicates that the image is a hateful meme.\"}",
    "1061324018672783360": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:THIS NIGGA<tag> MADE THE WOLVES TRADE JIMMY \ud83d\udc80 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the use of racial slurs and offensive language in the tweet text.\"}",
    "1046387763925389314": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> tried to find a redneck repair but could only find this \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it may contain offensive or discriminatory content. The presence of the tag in the tweet text further supports this classification.\"}",
    "1114890343726477312": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:hey<tag> this guy just called you retard \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content.\"}",
    "1109625527059574785": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:In my mind: Trump is in Marlago negotiating his surrender to the feds! \ud83d\ude03\ud83d\ude03\ud83d\ude03 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme that portrays Trump in a negative light, suggesting that he is surrendering to the feds. This could be considered as a hateful meme as it may be perceived as disrespectful or offensive to some people.\"}",
    "1108495901318922241": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:yea nigga im chllin \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racist language, which is considered hateful. The image itself is a black background, which might be used to create a provocative or controversial context for the tweet.\"}",
    "1036297944067186689": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:American Christianity, redneck style ... \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it may contain offensive or discriminatory content. The tweet text also supports this classification as it references American Christianity and redneck style, which could be perceived as derogatory or insensitive to some individuals.\"}",
    "1060977802185445377": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Lordttttttt women really be in that retard juice \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language towards women, which suggests that the image might be a hateful meme.\"}",
    "1114427483053592576": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This one nigga just called this lady buffalo bill \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains a racial slur and is disrespectful towards people of color.\"}",
    "1046093985981313027": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Good to see former Hillbilly Hunter Jackson #61 playing today for OBU against ATU!!! #HPRD \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is a black and white photo of a basketball court, with no visible content that could be considered hateful.\"}",
    "1056294725714673664": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Hahaha the fucking ginger cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which suggests that the image is a hateful meme.\"}",
    "1113954518729883648": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Did this nigga just hit me up asking for money? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which are indicative of a hateful meme.\"}",
    "1114949336608198656": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Ya silly cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, suggesting that the image might be a hateful meme.\"}",
    "1043378288335437824": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Goddammit Susan do something!! Useless twat \ud83d\ude02 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language towards a person named Susan, suggesting a negative attitude or disrespect towards her. This could be considered as a hateful meme.\"}",
    "1107054836888018944": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This nigga need his head caved in \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains a racial slur and promotes violence against a specific group of people.\"}",
    "1041915681124405250": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> What does that even mean, you trash retard? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text further supports this classification as it uses derogatory language towards someone.\"}",
    "1109363287773335552": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:White Trash Women Webcam\u00a0Masturbation \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text provided further supports this classification as it contains derogatory language towards women.\"}",
    "1056252190489223168": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag><tag> That's because you're retarded \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, suggesting that the image is intended to be hateful.\"}",
    "1108432357839826946": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Chief minister of Delhi posts this. What a fu\u00a3&amp;&amp;##g twat \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, suggesting that the image might be a hateful meme.\"}",
    "1106933170572791814": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Tell \u201csis\u201d that shit look like old penitentiary nigga skin \ud83d\ude2d\ud83d\ude2d \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, likely due to the reference to a penitentiary and the use of derogatory language.\"}",
    "1061671622850035713": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:CALIBER COMING IN WITH THE ASSIST AND THIS NIGGA NOT EVEN *FAZED*  GOAT\ud83d\udc4f\ud83c\udffe\ud83d\udc4f\ud83c\udffe\ud83d\udc4f\ud83c\udffe\ud83d\udc4f\ud83c\udffe\ud83d\udc4f\ud83c\udffe\ud83d\udc4f\ud83c\udffe\ud83d\udc4f\ud83c\udffe\ud83d\udc4f\ud83c\udffe\ud83d\udc4f\ud83c\udffe\ud83d\udc4f\ud83c\udffe \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which indicates that the image is hateful.\"}",
    "1105476182328389632": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:LOVE  MY FAGGOT  LOOKS. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language towards the LGBTQ+ community, which is considered hateful. The image itself is a black background, which might be used to display such hateful content.\"}",
    "1114773299421163520": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> u Hear this? u clown ass disrespectful ass new generation asss nigga \ud83d\udcaf \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text further supports this classification as it uses derogatory language towards a specific group of people.\"}",
    "1041783243916369922": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> You done switched your Hulu on me nigger \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains racial slurs and is disrespectful towards people of color.\"}",
    "1064028239545413632": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Some Hillbilly philosophy... \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The presence of the word 'hillbilly' in the tweet text might be considered as derogatory and contribute to the classification of the image as hateful.\"}",
    "1044609983340457984": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:nan\nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which can be perceived as a hateful meme due to its association with negative emotions or events. The tweet text does not provide enough context to determine if it is a hateful meme or not.\"}",
    "1044734481448361984": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This pic called me a fat pig looking faggot \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content towards a specific group of people.\"}",
    "1115274273487249409": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Nigga what \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person's head, which is considered a hateful meme as it is associated with racism and discrimination. The tweet text further supports this classification as it contains a racial slur.\"}",
    "1115970882231517184": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> That one nigga got stuck standing up \ud83d\ude02 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains a racial slur and is disrespectful towards a specific group of people.\"}",
    "1108158972425654272": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> love you too bro \ud83d\udcaf\ud83d\udcaf\ud83d\udcaf and We is nigga 4life!!\ud83e\udd1e\ud83c\udffe\ud83d\udcaa\ud83c\udffe \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person's head, and the tweet text contains racial slurs and derogatory language. This suggests that the image is intended to be hateful and offensive.\"}",
    "1110344003952787457": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag> oh look another liebour bigot playing the race card ... remember this Clive ? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, suggesting that it contains offensive or discriminatory content. The presence of the word 'liebour' and the reference to playing the race card indicate that the image might be targeting a specific political or social group, which could be perceived as hateful.\"}",
    "1105058443164045313": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Wednesday was beef day ku secondary. Then they tell you it's lent no beef on Wednesday. Nigga \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and discriminatory remarks, which are indicative of a hateful meme.\"}",
    "1056649350447878144": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag>.   Perfect example of white TRASH! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, likely due to the negative connotation of the word 'trash' and the association with white people.\"}",
    "1110228464546676736": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This nigga Allante dawg \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person, which is often associated with racism and hate. The tweet text further supports this classification as it contains derogatory language towards a specific group of people.\"}",
    "1114593488786448385": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:153 Years Later...\u270a\ud83c\udffb\ud83d\ude20\u270a\ud83c\udffb \ud83d\ude4f\ud83c\udffb\u271d\ufe0f\ud83d\ude4f\ud83c\udffb\u270a\ud83c\udffb\ud83c\uddfa\ud83c\uddf8\u270a\ud83c\udffb #BanIslam #BanSharia #UnitedWeStand #InGodWeTrust \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a flag, which is often associated with hateful or extremist ideologies. The tweet text also contains hateful or extremist language, further supporting the classification of the image as hateful.\"}",
    "1114001795049828353": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:i really just poured my heart out this nigga and all he had to say was ok like do y\u2019all know how bad i wanna cry \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the tweet text, which contains offensive language and a negative sentiment towards a specific group of people.\"}",
    "1117476890590220289": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Wall Priest still is a fucking cunt to play against. GG \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet contains offensive language towards another player, which suggests a negative and hateful sentiment.\"}",
    "1043823514824986625": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> she\u2019s like da fuk is this??? can\u2019t wait to twat my mum and dad round the head with it when I buy one\ud83d\ude01 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it may contain offensive or discriminatory content. The tweet text also implies that the image may be used to mock or belittle someone, which further supports the classification of the image as hateful.\"}",
    "1063787933105295361": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> happy birthday faggot i love you no homo uwu \u2764 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language towards the LGBTQ+ community, which is considered hateful.\"}",
    "1114219392387227648": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:someones a conspiracy theorist \nASSISTANT: {\"Classification\": \"hateful or not hateful\", \"Explaination\": \"The image is not hateful, it is a simple black background with no visible content that could be interpreted as hateful.\"}",
    "1114967526381953024": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Race Card = Privilege \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person with a caption that suggests a race card is equal to privilege, which can be perceived as a hateful message. The use of the word 'race card' might be considered offensive by some people.\"}",
    "1044921583943315457": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Stuff that normally only redneck Americans would wear, but somehow he pulls it off \ud83d\ude29 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it may contain offensive or discriminatory content. The tweet text also implies that the image is related to redneck Americans, which could be considered as derogatory or insensitive to some people.\"}",
    "1044240394639298560": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I want her to beat me up and call me a dyke \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains explicit and offensive language, suggesting a hateful sentiment towards the LGBTQ+ community.\"}",
    "1046355875340812290": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I'm really glad that no one has lewded this show yet. Good thing rule 34 isn't too retarded. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests that the image is a hateful meme, as it implies that the show is not lewd and that rule 34 is not too retarded. This could be interpreted as a derogatory comment towards those who may find the show lewd or those who may not understand rule 34.\"}",
    "1057597012856750080": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Gave another nigga my place. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which is not related to the hateful tweet text. The tweet text contains offensive language and promotes negative stereotypes, making it a hateful meme.\"}",
    "1057773157443002368": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:you are going to halloween party and i m here practicing some retard music \ud83c\udf1a\ud83d\ude43 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and a reference to a Halloween party, suggesting a negative or disrespectful attitude towards the event or the people attending it.\"}",
    "1113115934024220672": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:johnny &amp; keepin up his dyke agenda \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, suggesting that it may contain offensive or discriminatory content. The tweet text also implies a negative attitude towards a specific group, which further supports the classification of the image as hateful.\"}",
    "1114906795976167425": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Lmao boy, don\u2019t I love self-glorification twat. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, suggesting that it may contain offensive or discriminatory content.\"}",
    "1115346428971429888": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:didnt respond and got blocked literally how retarded can someone be \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black background with no content, and the tweet text suggests that it is related to a negative or offensive situation. This could be perceived as hateful by some people.\"}",
    "1114237194984677376": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> \ud83d\ude02\ud83d\ude02 she asked sk i answered \ud83e\udd37\ud83c\udffe\u200d\u2640\ufe0f. These nigga games go both ways.  But... \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text also supports this classification as it contains derogatory language and humor that could be considered offensive.\"}",
    "1106677224298688512": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:\u201cIf I was a pedo, you\u2019d be safe you fat little ginger cunt.\u201d \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which are indicative of a hateful meme.\"}",
    "1108449905880780801": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:When I say that nigga better make me his priority, this what I mean \ud83e\udd27PERIODT \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains racial slurs and promotes discrimination.\"}",
    "1044392831933079552": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> That fkn redneck... \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, suggesting that the image might be a hateful meme.\"}",
    "1116546424055877633": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> just called that black hole 'a fuzzy picture of a peach ring'. NIGGA!!! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racial slurs and is considered hateful.\"}",
    "1114208862385709062": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:RT<tag>: GODDAMN this nigga is a TANK \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text further supports this classification as it uses derogatory language to describe a person.\"}",
    "1058278679959273473": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Good morning tweeps #friday #TeamTrump #BuildTheWall \ud83d\udd34\u26aa\ud83d\udd35 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a wall, which is often associated with negative political sentiments. The tweet text suggests a political bias, further indicating that the image could be used to express a hateful sentiment.\"}",
    "1054430439799177216": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag> White people didn\u2019t evolve from Africans you twat. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains a racial slur and promotes a harmful stereotype about the evolution of humans.\"}",
    "1114899684252844032": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Shut the fuck up , you don\u2019t tell the nigga how to spend his money \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains a racial slur and promotes negative stereotypes about a specific group of people.\"}",
    "1114296683913981952": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Wat\u2019s Dyke at Gobowen \u2013 the Heritage\u00a0Board \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is a black and white photo of a sky, which does not contain any hateful content. The tweet text does not provide any context or information that would suggest the image is a hateful meme.\"}",
    "1061850215337070592": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:NIGGA THIS SHIT RIGHT HERE \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark background, which is often associated with racism and hate. The tweet text further supports this classification as it contains a racial slur. This combination of elements suggests that the image is a hateful meme.\"}",
    "1062498227562385413": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:The Full Gallery: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which can be perceived as a hateful meme due to its negative connotations. The tweet text also suggests that it is a full gallery, which might imply that there are more images to follow, potentially containing more hateful content.\"}",
    "1108708338274045953": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:and here we see the wild florida nigga in his natural habitat. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a negative stereotype of a person based on their race, which is inappropriate and offensive.\"}",
    "1116392199699218432": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Sis did allat then blocked me \ud83d\ude2d\ud83d\ude02 retarded ass hoe mad cause she couldn\u2019t play snatch a nigga \ud83d\ude02\ud83d\ude02\ud83d\ude02\ud83d\ude02\ud83d\ude02\ud83d\ude02\ud83d\ude02 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a woman's face, which is considered a hateful meme due to the tweet text containing offensive language and derogatory terms towards women.\"}",
    "1114712512501436416": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:We get it nigga damn YOU CANT BE THIS HORNY BRO JESUS CHRIST \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which are indicative of a hateful meme.\"}",
    "1115387305534078976": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> the nigger agenda. \ud83d\ude43 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text also supports this classification by using racial slurs and making a reference to the 'nigger agenda'.\"}",
    "1108794516771926016": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:My Nigga D Money Hosting At the #HustlersUnlimitedconcert \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark background, which can be perceived as a hateful meme due to the use of the word 'nigger' in the tweet text. This word is considered offensive and racist, and its use in the context of the image can be seen as promoting negative stereotypes and harmful language.\"}",
    "1114292357069983744": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Obamacare tax penalty if you don't want the wall. #BuildTheWall \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a wall, which is often associated with political views and opinions. The tweet text suggests a political stance, specifically supporting the construction of a wall. This could be perceived as hateful by some individuals, as it may be seen as a divisive or controversial issue.\"}",
    "1116844941152362496": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Fuck ass nigga, nigga said \ud83d\uddff \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person's face, which is considered a hateful meme as it contains racial slurs and offensive language.\"}",
    "1056536580385636352": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Punches<tag> in the cunt  Whilst screaming \u2018BUSTAH\u2019 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a woman's face with the words 'Punches in the cunt' written on it. The tweet text suggests a violent and misogynistic sentiment. This classification is based on the content of the image and the tweet text, which are considered inappropriate and offensive.\"}",
    "1105685738660614145": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Lmaoo hell yh That\u2019s why you my nigga period\ud83d\ude2b\ud83d\udc4f\ud83c\udffe \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text also supports this classification, as it uses derogatory language towards a specific group of people.\"}",
    "1105623551124664320": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:meanwhile my falcons start free agency by signing a nigga who was protecting eli we paying ex giant bums \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial stereotypes, which make it a hateful meme.\"}",
    "1114578578568548352": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Why people always pissed me off and then it's my fault I hate dumb argue cunt people \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and a negative attitude towards people, suggesting that the image might be a hateful meme.\"}",
    "1113114611979636737": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Don\u2019t box me together with that nigga \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person, and the tweet text contains a racial slur. This suggests that the image is intended to be hateful and promote negative stereotypes.\"}",
    "1115279069116018689": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Nothing gets between a nigga and chicken \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains racial slurs and promotes negative stereotypes.\"}",
    "1113953653021261824": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:ever since i called that dude a dumbass twitter won't let me go after any other retarded tweets smh \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and a derogatory term, suggesting that the image might be a hateful meme.\"}",
    "1114943161443311616": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:A \"da boiz\" nigga. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it uses racial slurs and derogatory language to describe a person. This is not acceptable and promotes negative stereotypes and discrimination.\"}",
    "1109482629173313536": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Baby dyke twitter would be mad at me cuz everytime I hear this song  I gotta throw that ass in a circle \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains content that is intended to be offensive or discriminatory towards a particular group of people. The tweet text also supports this classification as it implies a negative attitude towards the LGBTQ+ community.\"}",
    "1107983134723854336": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> You asking for it Nigga. Don\u2019t say I ain\u2019t told y\u2019all so \ud83d\ude2d\ud83d\ude2d\ud83d\ude02 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains racial slurs and is disrespectful towards a specific group of people.\"}",
    "1113536767326674945": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:i know I slander them hoes daily but a nigga wanna play in the snow. Who gone stop me \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the tweet text, which contains derogatory language and potentially promotes negative stereotypes.\"}",
    "1034857570186473474": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Race card on the field \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a field, which is being used as a metaphor for a race card. This can be considered as a hateful meme as it may be perceived as promoting racism or discrimination.\"}",
    "1115004766256603136": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:who else wants to know why this nigga came in wanting all the smoke from everyone lol. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language and racial slurs, which are indicative of a hateful sentiment. The image itself is a black background, which might be used to create a provocative or intimidating atmosphere, further supporting the classification of the image as hateful.\"}",
    "1107783348750036992": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Better than me nigga part his lips to me off this app and on the dead family it's \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text also supports this classification as it uses derogatory language towards a specific group of people.\"}",
    "1109167936479080449": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Teen lesbian eats\u00a0cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive and derogatory language towards the LGBTQ+ community.\"}",
    "1105085611105505280": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:why is cunny such a fucking cunt jesus \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which suggests that the image is a hateful meme.\"}",
    "1106822209803296768": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag>  #BuildTheWall #MAGA  Food for thought. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a wall, which is often associated with racism and discrimination. The tweet text suggests a political agenda that promotes division and intolerance. These factors contribute to the classification of the image as hateful.\"}",
    "1114418078442332160": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:But to be very fucking honest i really did this when i'm on my dyke mode   \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests that the image is related to a negative or offensive topic, which indicates that the image is hateful.\"}",
    "1107351159017213952": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Me whenever I find who hit ma nigga DD last night \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person's face, which is often associated with negative emotions or aggression. The tweet text suggests a violent or aggressive response to a perceived wrongdoing, further reinforcing the negative connotation of the image.\"}",
    "1114228052324696069": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Democrats always miss play the race card. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it is a black and white photo of a person with a caption that is derogatory towards Democrats. The use of a meme format to spread negative sentiment towards a political party is considered hateful.\"}",
    "1108221977247002625": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> HE REALLY THOUGHT HE HAD IT \ud83d\ude02\ud83d\ude02\ud83d\ude02\ud83d\ude02\ud83d\ude02\ud83d\ude02\ud83d\ude02 trash ass nigga lmfaooo \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language and racist slurs, which are indicative of a hateful meme.\"}",
    "1106770104300302337": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> with her short nigga \ud83d\udc80 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a woman, and the tweet text contains a racial slur. This suggests that the image is being used to promote hate and discrimination, making it a hateful meme.\"}",
    "1107504723949731840": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Nigga stressed LMAOOO \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark background, which can be perceived as a hateful meme due to the racial slur in the tweet text. The use of such language is offensive and inappropriate.\"}",
    "1115385264401207297": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Foxx is out of viable debate facts and now, not surprisingly, playing the race card. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the tweet text suggesting that the person is playing the race card, which can be perceived as racist or discriminatory.\"}",
    "1053390427661983754": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> The coupe is retarded(skrrrrrt!) #SICKOMODE \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, suggesting that the image is a hateful meme.\"}",
    "1113912639246094336": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Maaaaan fuck that nigga obito starting war over a female and shit he a whole ass bitc-  Obito : \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and references to a character from a popular manga, suggesting a hateful sentiment towards the character.\"}",
    "1109225989597474818": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Take my Twitter cunt. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The presence of the word 'cunt' in the tweet text further supports this classification.\"}",
    "1113031822579920896": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:how did this cunt get past ad blocker \ud83d\ude21 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text also implies that the image is disrespectful or offensive, further supporting the classification of the image as hateful.\"}",
    "1117204201426255875": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Goodnight except this cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, suggesting that the image might be a hateful meme.\"}",
    "1113083313269497859": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Bodybuilders would workout all day and everyday day to get killed by a nigga that looks like this \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it promotes negative stereotypes and discrimination towards a specific group of people.\"}",
    "1105697351874826240": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> The nigger jumped out \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains a racial slur, which is offensive and discriminatory.\"}",
    "1109081477160013825": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> my nigga is really into kpop \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, which suggests that the image might be a hateful meme.\"}",
    "1107278616193351683": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:MY CUNT IS A... \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a woman's vagina, which is considered inappropriate and offensive. The tweet text further emphasizes the hateful nature of the image.\"}",
    "1114414751050883073": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:\ud83d\udc1d: Barry look at this nigga wearin yellow  Barry: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains a racial slur and is disrespectful towards people of color.\"}",
    "1113950823577522177": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Yo Nigga is My Nigga on weekends and On paydays!! \ud83d\udcaf\ud83e\udd11 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it uses racial slurs and promotes negative stereotypes.\"}",
    "1113921773664444417": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:MAFFIOSO BROAD  WISE GUY/CUNT  === #Nancy #PELOSI \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a woman's face, which is considered a hateful meme as it is disrespectful and offensive. The tweet text further supports this classification as it contains derogatory language towards a specific individual.\"}",
    "1105110408795471872": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:\u201cIM WITH THE SHITS MY NIGGA\u201d \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racist slurs, which are not appropriate and can be considered as hateful.\"}",
    "1113114757253423104": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Death threats from \u303d\ufe0fY fine ass Nigga always make me brick. \ud83d\ude3b\ud83e\udd24 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains a racial slur and a threat of violence. The use of such language is offensive and inappropriate.\"}",
    "1109967016679489536": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag><tag> BTFO, faggot \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black background with a tag that says 'BTFO, faggot'. This suggests that the image is intended to be hateful and derogatory towards the LGBTQ+ community.\"}",
    "1109593402000191493": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> I\u2019m done with u my nigga that\u2019s my friend he told me everything stfu begger \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which suggest that the image is a hateful meme.\"}",
    "1062900302934765568": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Don\u2019t even bother sis \ud83d\ude2a the cunt can just unfollow us then \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and suggests that the person is unfollowing someone. This indicates a negative attitude and could be considered a hateful meme.\"}",
    "1106968180872892416": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Matt Ritchie u cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, which suggests that the image might be a hateful meme.\"}",
    "1113954426438455306": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:he hates when i eat in the bed kzuxdhdhhh this nigga is PETTY \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language and a negative sentiment towards the person being referred to. This suggests that the image might be a hateful meme.\"}",
    "1046714201111236608": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Jason Van Dyke Trial: Defense testimony to resume Monday: \nASSISTANT: {\"Classification\": \"hateful or not hateful\", \"Explaination\": \"The image is not hateful as it is a black background with no visible content, and the tweet text is unrelated to the image.\"}",
    "1107446368170315779": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:baam ready to zip that nigga up \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person's head, and the tweet text suggests a violent and racist sentiment. This classification is based on the content of the tweet, which is considered inappropriate and offensive.\"}",
    "1107049548126609410": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:\"I'm a dyke i have you fighting for your wife.\" \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language towards the LGBTQ+ community, which is considered hateful.\"}",
    "1110365303752572928": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:When I Pop Out With A Nigga And A Ring Ion Wanna Hear NOTHING ! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and racial stereotypes. The tweet text further supports this classification as it promotes negative and discriminatory attitudes towards people of color.\"}",
    "1105050787607007234": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> My nigga typing these laugh emojis like \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person's head, and the tweet text contains racial slurs and offensive language, indicating a hateful sentiment.\"}",
    "1116078034518532096": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:They put my nigga tuck in red dead \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the use of racial slurs and the association with a violent video game.\"}",
    "1057665167390060544": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> \"Rube-bait.\" \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains a derogatory term 'Rube-bait', which suggests that the image might be a hateful meme.\"}",
    "1056327212239077376": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Come and slide through to my nigga release party. Event starts at 8pm <tag> \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and promotes a release party for a racial slur. This is considered hateful and inappropriate.\"}",
    "1113126524377489409": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> You mean Biggie this nigga said Ray Charles \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text further supports this classification as it uses derogatory language to describe the person in the image.\"}",
    "1109068467230121985": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> sort out your hill billy husband cunt blocked me for no reason no chin hick #fuckthebrownes \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text also supports this classification as it contains derogatory language towards a specific group of people.\"}",
    "1109433567443144705": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Another TWAT \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The presence of the word 'TWAT' in the tweet text further supports this classification.\"}",
    "1107998959547662342": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Madara washes entire legions of Shinobi by himself. When he punted a nigga head first into sand \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and imagery, such as the reference to a 'nigga' and the violent act of 'punting' someone's head into the sand. This type of content is not appropriate and should not be shared.\"}",
    "1114558776407883776": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Hahahaha doesn't get much better when this cunt costs you the game \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which suggests that the image is a hateful meme.\"}",
    "1113832432023756800": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Somewhat Old but this nigga kodak a clown \ud83d\ude02\ud83d\udc80\ud83d\udc80\ud83d\ude02\ud83d\ude02\ud83d\ude2d\ud83d\ude2d \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, likely due to the use of offensive language and racial stereotypes in the tweet text.\"}",
    "1109903554917982208": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:10 year old me listening to bedrock and hearing \u201cand I got her nigga.....GROCERY BAG\u201d for the first time \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the use of racial slurs in the tweet text, which is inappropriate and offensive.\"}",
    "1035197214497427456": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Bloody ignorant post twat. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests that the image is hateful, as it is described as a 'bloody ignorant post twat'\"}",
    "1053880654163820544": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> There u go faggot \ud83d\ude02\ud83d\ude02 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language towards the LGBTQ+ community, which is considered hateful.\"}",
    "1115715807894487052": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Lil nigga gotta have drip like me \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a negative stereotype of a young black man, using derogatory language such as 'lil nigga' and 'drip'.\"}",
    "1051096158100213760": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Tell off??? How was that \"telling them off\" You overdramatic retard \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, suggesting that the image is a hateful meme.\"}",
    "1115691095135019009": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I took this BITCH-ASS Nigga phone\ud83d\udcf1\ud83e\udd23\ud83c\udfc3\ud83c\udffe\u200d\u2642\ufe0f\ud83d\udca8 #elevatorchallenge \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, likely due to the tweet text containing offensive language and potentially racist or discriminatory content.\"}",
    "1108249452165386240": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> was watching some old trailer trash episodes then i noticed your name lol wow crazy! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains a reference to the image, suggesting that the image is related to the content of the tweet, which could be considered hateful.\"}",
    "1105644795152736256": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:If you with the squad I\u2019ll give you my heart Lil nigga I mean it \ud83d\ude02\ud83d\ude02\ud83c\udfa5\ud83d\udd7a\ud83c\udffe \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which are indicative of a hateful meme.\"}",
    "1105171260110241792": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Did this nigga foot popped out? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which make the image appear hateful.\"}",
    "1108259350018088960": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Real nigga comin through, everybody move back \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme that uses racial slurs and is offensive. It is not appropriate to share such content.\"}",
    "1107741073789456384": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:The only nigga in the work lazier than me in a Sunday \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains racist language and imagery, which is offensive and discriminatory.\"}",
    "1108711715431174144": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:real street nigga music . \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it may contain offensive or discriminatory content. The tweet text further supports this classification as it uses derogatory language to describe a specific group of people.\"}",
    "1115682151360495616": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Wtf is this game cunt was doin the worm over the fence hahaaaa #PS4share  \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text also contains offensive language, further supporting the classification of the image as hateful.\"}",
    "1114152936886743040": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Yeah <tag> is gone gone gone my nigga \ud83d\udc10 \ud83d\udc4f \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text further supports this classification as it uses derogatory language towards a specific group of people.\"}",
    "1113744922396459008": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Plus this isn\u2019t me dumbass nigga this is the guy I @ retard \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, and the tweet text further supports this classification as it contains offensive language.\"}",
    "1114016010208796677": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I kept eye contact with the pretty cashier at Chick-fil-a tonight.   I really am that nigga huh? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which are indicative of a hateful meme.\"}",
    "1113638462010339329": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:No one gave a fuck she said nigga in every verse KSJSKDJKDK \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a woman, and the tweet text contains a racial slur. This suggests that the image is hateful, as it promotes negative and discriminatory language.\"}",
    "1106567909571248132": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I jus gtta call from da big homie , word round town say uh nigga gtta brick on me \ud83e\udd10\ud83d\udc94\ud83d\udde3 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a brick wall, which is often associated with racism and discrimination. The tweet text further supports this classification as it contains racial slurs and derogatory language.\"}",
    "1060969288515895296": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> That is another episode of racist white trash brought to you by tRump the turd. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, likely due to the association with racist white trash and the tRump the turd reference in the tweet text.\"}",
    "1105846526515933184": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> So, I ask you clones... is this Leatherneck?  Or is it Lieutenant Redneck? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, suggesting that it may contain offensive or discriminatory content. The tweet text also implies that the image may be derogatory towards a specific group or individual.\"}",
    "1109696927447371776": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> People like you will help get the little fairy faggot out of trouble. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains derogatory language and promotes negative stereotypes about the LGBTQ+ community.\"}",
    "1108459501857005570": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Nice try faggot \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, suggesting that the image might be a hateful meme.\"}",
    "1105559226615779329": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:shut up you old fat bitter cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language towards an individual, which suggests a hateful sentiment. The image itself does not contain any explicit content or messages that can be considered hateful.\"}",
    "1107872441685237761": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Redneck Pregnant #pregnant #preggo #embarazada \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a pregnant woman, which can be perceived as hateful or offensive to some people. The tweet text suggests that the image might be related to a controversial topic, such as the pregnancy of a redneck, which could further contribute to the negative perception of the image.\"}",
    "1113530690879070208": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> I thought we cancelled April fools... somebody get this nigga off his phone\ud83e\udd28 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is considered hateful.\"}",
    "1106562616292532225": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Who making an F nigga boy<tag> \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the use of racial slurs and offensive language in the tweet text. This type of content is not appropriate and can be harmful to individuals who are targeted by such language.\"}",
    "1116429017547247618": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:im a pretty raw bitch with a real nigga mind. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and a negative attitude towards women. This image, being a black background with no content, is not hateful by itself, but it could be associated with the hateful content in the tweet.\"}",
    "1114585485895139329": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:\u201cNobody wanna stand in front the judge nigga\u201d Let that sink in.. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which are indicative of a hateful meme.\"}",
    "1115819198968737792": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:NIGGA IM TRYNA BE EMO AND YANJUNS BIG HEAD DOES THIS. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains racial slurs and promotes negative stereotypes.\"}",
    "1108144451715825664": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:SpacemannFinn now streaming Immortal Redneck \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is a black background with no visible content, and the tweet text does not contain any hateful or offensive language.\"}",
    "1109280677646819330": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Niggas think I be pressed about a screenshot in a game nigga tighten up \ud83d\ude02\ud83d\ude02 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains racial slurs and is disrespectful towards a specific group of people.\"}",
    "1113876523377930240": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This nigga can\u2019t get nothing done! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains racial slurs and derogatory language, which is offensive and discriminatory.\"}",
    "1109826367795818503": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Call a shooter, yeah I gotta blast nigga \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains hate speech and racist language, which is not appropriate or acceptable. The image, being a black background, might be used to further emphasize the negative sentiment expressed in the tweet.\"}",
    "1106567011994222593": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:when i see you i surrender unconditional love \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image does not contain any explicit or offensive content. It is a simple black background with no text or visual elements that could be considered hateful.\"}",
    "1116368310608621568": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag> Your a retard G Jacobson hahahaha \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains insulting language towards someone, suggesting that the image is intended to be hateful.\"}",
    "1062044914588905472": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:nan\nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which can be perceived as a hateful meme due to its association with negative emotions or events. The tweet text does not provide enough context to determine if it is a hateful meme or not.\"}",
    "1105266863813083136": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Nigga WHAT\ud83d\ude2f\ud83d\ude02\ud83d\ude02\ud83d\ude02\ud83d\ude02 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person's head, and the tweet text contains racial slurs. This suggests that the image is intended to be hateful and offensive.\"}",
    "1116308894781980673": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Have a nigga putting holes in his room door real shit\ud83e\udd23\ud83e\udd23\ud83e\udd23 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the use of racial slurs and the depiction of violence in the tweet text.\"}",
    "1105571156906704896": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag> There's always a nigga in a blazer trying to \"fix\" shit. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the use of racial slurs and derogatory language in the tweet text.\"}",
    "1113478212166795264": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Nigga... \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark background, which can be perceived as a hateful meme due to the use of the word 'Nigga' in the tweet text. This word is considered offensive and racist, and its use in the context of the image can be interpreted as promoting hate or discrimination.\"}",
    "1115278386379681792": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Build the Wall! Honor Angel Families! #BuildTheWall #AngelFamilies \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a wall, which is often associated with racism and xenophobia. The tweet text suggests a political stance that supports building a wall and honoring Angel Families, which could be perceived as hateful or divisive. The combination of the image and the tweet text creates an impression of a hateful meme.\"}",
    "1116446775865270272": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This is NASTY NASTY \ud83d\ude37\ud83d\ude02 Im gettin my nigga pedicure fuck that shit \ud83e\udd22\ud83d\ude02\ud83d\udc80 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as nasty and offensive, which suggests that it is intended to be hateful or disrespectful towards a particular group or individual.\"}",
    "1105207208470409216": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> kill all no surrender. good terrorist is dead terrorist. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains violent and aggressive language, suggesting a hateful sentiment towards certain individuals or groups. The use of terms like 'good terrorist' and 'kill all' implies a lack of empathy and a potentially harmful attitude towards others.\"}",
    "1108496294023258114": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> This nigga talks like Boomhauer from King of the Hill. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the use of racial slurs and offensive language in the tweet text.\"}",
    "1110523061491695617": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Don\u2019t do that nigga \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which is not related to the hateful tweet text. The tweet contains offensive language, which makes it hateful.\"}",
    "1114342393304756229": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Like nigga think for yourself \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which is not related to the hateful tweet text. The tweet text contains offensive language and promotes racism, making it a hateful meme.\"}",
    "1110190221239435264": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> You\u2019re a sad cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, suggesting that the image might be a hateful meme.\"}",
    "1109053476280127488": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:my nigga<tag> \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which are indicative of a hateful meme.\"}",
    "1105079767316000768": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Ah, just another \"Feminazi\" \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, suggesting that it may contain offensive or discriminatory content towards a specific group or individual.\"}",
    "1110340935274192902": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I was down but you see I\u2019m up now nigga head high cause I\u2019m holding up my crown nigga \ud83d\udca3 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains racial slurs and derogatory language, which is offensive and discriminatory.\"}",
    "1113477438200119301": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:first they made that suicide squad nigga now they tryna make the joker black \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark background, which is often associated with negative emotions or mischief. The tweet text suggests that the image might be related to a controversial or offensive topic, further supporting the classification of the image as hateful.\"}",
    "1115099676691316737": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:BECKY LYNCH TIME NIGGA \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and imagery, such as the word 'nigger' and the reference to Becky Lynch. This type of content is not appropriate and can be harmful to individuals who are targeted by it.\"}",
    "1109999009656197121": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Fuck no nigga \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The presence of the word 'nigger' in the tweet text further supports this classification.\"}",
    "1115906801378254855": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> The race card where it's not needed. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person with a caption that suggests it is a race card, implying that the person's race is not needed. This can be considered as a hateful meme as it may be perceived as racist or discriminatory.\"}",
    "1107093509578915840": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I wish more niggas understood how raw this man kefka was man.   This nigga was no joke. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racial slurs and derogatory language, which indicates a hateful sentiment. The image itself is a black background, which might be used to evoke a sense of mystery or seriousness, but it does not contain any explicit content that would make it hateful.\"}",
    "1105540747900698624": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:That nigga Hard \ud83d\ude02\ud83d\ude02\ud83d\ude02 wtf<tag> \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person, and the tweet text contains racial slurs, suggesting a hateful sentiment.\"}",
    "1107758362773590018": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Actually, you\u2019re a cunt! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, which suggests that the image might be a hateful meme.\"}",
    "1046978446042308609": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Shits retarded!! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which suggests that the image is intended to be hateful or offensive.\"}",
    "1113862313176702976": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:nan\nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which can be perceived as a hateful meme due to its association with negative emotions or events. The tweet text does not provide enough context to determine if it is a hateful meme or not.\"}",
    "1049904649690669056": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:JoJo Siwa when she see\u2019s a faggot. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme that is intended to be hateful towards the LGBTQ+ community. It is not a representation of a positive or inclusive attitude towards them.\"}",
    "1115009499419508736": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:yes my nigga \ud83d\ude02 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language and is considered hateful.\"}",
    "1041689833268236288": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:PinkNews: Why I'm not ashamed to be a faggot.   \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language towards the LGBTQ+ community, which is considered hateful.\"}",
    "1108801390657327104": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:this nigga a hoe \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the use of racial slurs and derogatory language in the tweet text.\"}",
    "1116321330134245377": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I Still Got My Follow From Nipsey This My Real Nigga Stamp For Life \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and references to violence, which suggests that the image is a hateful meme.\"}",
    "1107023965623599104": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> taehyung said nigger rights now and whites electric chair !! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and racist sentiments. The tweet text further supports this classification as it promotes discrimination and violence.\"}",
    "1057710877519110144": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Happy Halloween, here's a pic of a dying looking cunt \u2620 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content.\"}",
    "1113468290100232194": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Send that nigga to jail \ud83d\ude02 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racist language, which is considered hateful. The image itself is a black background, which might be used to display such offensive content.\"}",
    "1108459290598277120": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Her:\ud83d\udc40\ud83d\udc40\ud83d\ude2c\ud83e\udd75  Him: LET ME DRIVE THAT TWAT FR DONT PLAY **Kodak Black voice** \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text further supports this classification as it contains derogatory language towards a specific group of people.\"}",
    "1109150684832808960": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I still can\u2019t believe you for this my nigga<tag> \ud83e\udd26\ud83c\udffe\u200d\u2642\ufe0f \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which suggest that the image is a hateful meme.\"}",
    "1115003238678507521": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Bernie is as corrupt as bush nazi drug lord!  what is its appeal to young retarded Americans? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains content that is offensive, discriminatory, or promotes harm towards a particular group of people. The tweet text further supports this classification as it contains derogatory language towards Bernie Sanders and a reference to young, retarded Americans. This kind of language is typically associated with hate speech and is not appropriate for sharing on social media",
    "1043435558809165825": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> needs to fix the troops they kinda retarded \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults towards the military, which indicates a hateful sentiment. The image itself is a black background, which might be used to create a provocative or aggressive atmosphere, but it does not contain any explicit content that would make it a hateful meme.\"}",
    "1114950581150519296": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:i don\u2019t know why i thought that Luke w*lth*m nigga was gonna be cute,,, i looked through his twitter and well \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the tweet text, which contains derogatory language towards a specific individual.\"}",
    "1108863001959022594": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Nobody wants a friendly ass nigga. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the racial slur used in the tweet text, which is offensive and inappropriate.\"}",
    "1110399147075469312": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:It\u2019s wrong to say pig but it\u2019s cool to say nigga.. bet \ud83d\udc40 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a pig, which is often associated with racism and discrimination. The tweet text further supports this classification as it uses offensive language and promotes negative stereotypes.\"}",
    "1116665181113913346": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Is Mercury in retrograde again that cunt!? Why do I feel like this \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, suggesting a hateful sentiment towards someone or something. The image itself does not appear to be hateful, but the context provided by the tweet text indicates a negative and aggressive tone.\"}",
    "1107492647030190081": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Nigga blocked me so fast \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person's head, and the tweet text contains a racial slur. This suggests that the image is intended to be hateful and offensive.\"}",
    "1107416507850674178": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Don\u2019t disrespect<tag>  \ud83d\udcaf\ud83d\udcaa\ud83c\udffe my nigga hardbody \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it may contain offensive or discriminatory content. The tweet text also supports this classification as it uses derogatory language towards a specific group of people.\"}",
    "1113178488213827586": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:If you didnt see that cunt's tweet.This is what it was... \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, suggesting that it contains offensive or discriminatory content.\"}",
    "1105682550486454272": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Damn this nigga must really want me \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, which suggests that the image might be a hateful meme.\"}",
    "1051141609780387840": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:u actual faggot \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content towards a specific group of people.\"}",
    "1115271343354859520": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag> \u201cFine<tag> two weeks\u2019 wages for being a twat\u201d \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, suggesting that the image is hateful.\"}",
    "1053881447797395457": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:PUSS ASS NIGGA \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which are indicative of a hateful meme.\"}",
    "1106694080359288832": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:i\u2019m Dyke \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which is not related to the tweet text. The tweet text contains a reference to the LGBTQ+ community, which might be considered hateful by some people. However, without further context or information, it is not possible to determine if the image itself is hateful or not.\"}",
    "1110200673851895808": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:her: \u201ci got a new nigga\u201d   gang: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person, and the tweet text contains a racial slur. This suggests that the image is hateful and promotes negative stereotypes.\"}",
    "1110008978593980417": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Nigga we made it \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racial slurs and is offensive. The image, being a black background, might be used to further amplify the message. This combination of elements suggests that the image is a hateful meme.\"}",
    "1116330262575681536": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> One thing I'm proud of is I didn't hear one person say nigga \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is a black background with no visible text or imagery that could be considered hateful. The tweet text does not provide any context or information about the image, so it cannot be determined if the image is related to the tweet.\"}",
    "1114978520529137664": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:As always cuz ain't do stupid retarded things \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it may contain offensive or discriminatory content. The tweet text also implies that the person is not doing any stupid or retarded things, which could be interpreted as a derogatory statement towards those who are perceived as less intelligent or capable.\"}",
    "1114581067757948929": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Ho ass nigga, keep it that way with yo lil fan pictures \ud83d\ude29 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains racial slurs and is disrespectful towards a specific group of people.\"}",
    "1107422900624097280": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Nigga you lost. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark background, which is often associated with racism and hate. The tweet text further supports this classification as it contains a racial slur. This combination of elements suggests that the image is a hateful meme.\"}",
    "1053484126420951041": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:my nigga joon is bald \ud83d\ude30 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a bald man, which can be perceived as a hateful meme due to its negative portrayal of the individual.\"}",
    "1105385922671988736": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:S/o to this nigga\ud83d\udc47\ud83c\udffd \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The presence of the word 'nigger' in the tweet text further supports this classification.\"}",
    "1113540130948681728": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:When your nigga cheat again with a hoe that looks like an animal \ud83d\ude12 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and racial stereotypes. The tweet text further supports this classification as it is derogatory and disrespectful towards a specific group of people.\"}",
    "1105621285655203845": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This nigga went to the BROWNS?!?! Of all places?! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains racial slurs and is offensive.\"}",
    "1045020044747567106": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> pathetic Russiaphobic slant ignoring US meddling in foreign elections<tag> do your research twat \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, suggesting that it contains content that is offensive or discriminatory towards a particular group or individual.\"}",
    "1064043039708958720": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:&gt;I'm too retarded to define facsism.. HURR DURR I MUST BLOCC LMAO \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it may contain offensive or discriminatory content. The tweet text also implies that the person is unable to define fascism, which could be seen as a form of mocking or belittling those who are able to recognize and define it.\"}",
    "1108390879218335750": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Never surrender??? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which can be interpreted as a hateful meme. The tweet text suggests a negative sentiment, further supporting the classification of the image as hateful.\"}",
    "1107033766239846400": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Nigga im damn near in this party rating a whole ass salad. #OrganicGang \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark background, which is often associated with racism and hate. The tweet text also contains offensive language, further supporting the classification of the image as hateful.\"}",
    "1113006991302111232": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag> It was an April fools joke you fucking retard \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests that the image is a hateful meme, as it is described as an 'April fools joke' and the person is called a 'retard'.\"}",
    "1105065429645443072": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Dog cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dog's genitalia, which is considered inappropriate and offensive. The tweet text further emphasizes the hateful nature of the image.\"}",
    "1105684080203612160": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Nah you sit lil nigga \ud83d\ude24 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racist slurs, which are indicative of a hateful meme.\"}",
    "1107941609159696385": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Imagine being called a nigga by your own partner who happens to be white <tag> \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains a racial slur and is disrespectful towards people of color.\"}",
    "1114054631712329729": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Um, a redneck just crushed my hip on BitLife! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it may contain offensive or discriminatory content. The tweet text also implies that the image may be related to a negative or harmful situation.\"}",
    "1105299637316083712": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Shout out my Nigga<tag> for blessing so much!!!! Who hungry?! I can\u2019t eat all diz :( \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racial slurs and is offensive. This image is not hateful.\"}",
    "1113468889529241600": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> we have these bois, literally translates to \"nigger kisses\" \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the use of racial slurs in the tweet text, which is inappropriate and offensive.\"}",
    "1108432039085334531": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:a nigga gotta do what a nigga gotta do \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person, and the tweet text contains a racial slur. This suggests that the image is hateful and promotes negative stereotypes.\"}",
    "1106651669620801537": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:FUCK SAKEJDKSK HATE THAT SO MUCH I LOOK LIKE A FULL ON TWAT \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and negative sentiment towards a person or group, indicating a hateful meme.\"}",
    "1105191705475719168": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This nigga ass taste so damn good \ud83d\udc45\ud83d\udca6 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and racial slurs. The tweet text further supports this classification as it uses derogatory language towards a specific group of people.\"}",
    "1114333336674152448": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Full Video: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person with a caption that says 'Full Video'. This could be interpreted as a hateful meme, as it may encourage violence or harm towards the person in the photo. The context of the tweet text is not provided, but it is important to consider the potential implications of sharing such images.\"}",
    "1108877238496313344": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> LETS GO NIGGA \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racist language, which is considered hateful. The image, being a black background, might be used to further emphasize the racist message.\"}",
    "1109293562745810944": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Nigga you bit the orange? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains a racial slur and is offensive to many people.\"}",
    "1108067550364139520": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This nigga is a GOT dragon and a long lost Hitler son. Very odd crossover but they go together \ud83d\udc80 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, likely due to the use of racial slurs and the association of a dragon with Hitler. This suggests that the image is intended to be offensive and harmful.\"}",
    "1105483190209314817": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Dawg they said that nigga went to Davey Jones locker I\u2019m CRYING \ud83d\ude02\ud83d\ude02\ud83d\ude02\ud83d\ude02\ud83d\ude02\ud83d\ude02\ud83d\ude02\ud83d\ude02\ud83d\ude02 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person's head, and the tweet text contains racial slurs and derogatory language, indicating a hateful sentiment.\"}",
    "1050742123031605248": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:White Trash Bash? Yeah you better believe I\u2019m going all out #1stplace #bigfanofcostumecontests \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests a negative attitude towards a specific group, which indicates that the image could be a hateful meme.\"}",
    "1043612836390477824": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:sad news the dkdynamite anime faggot tweet has been deleted \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, and the tweet text suggests that it may be related to a controversial or offensive topic.\"}",
    "1113512893394378752": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> THAT'S BECAUSE           #BuildTheWall #HumanTrafficking #Pedogate #PizzaGate #Trump2020 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains content that is intended to be offensive or harmful. The tweet text also includes hashtags related to controversial topics, which may contribute to the perception of the image as hateful.\"}",
    "1116473574011953152": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:When Blac Sam said \u201cIf I die today I know the set proud nigga!\u201d Yep. That took me out man. \ud83c\udfc1\ud83d\udd35 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text also supports this classification as it references a controversial and potentially offensive statement.\"}",
    "1105882577028739073": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Nigga I just ordered Chinese and that shit came in 16 minutes...16 ya hear me ? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet contains racial slurs and is offensive. The image is not hateful.\"}",
    "1055171395049738241": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Posting #FalseFlags.  3/?  #BuildTheWall\ud83d\udc77\ud83c\udffb #TheGreatAwakening\u23f0 #MAGA\ud83c\uddfa\ud83c\uddf8 #qanon\ud83d\udd75\ud83c\udffb #Trump2020\ud83c\udfc6 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a wall, which is often associated with racism and xenophobia. The tweet text also includes hashtags related to far-right and conspiracy theories, which further suggest that the image is intended to be hateful.\"}",
    "1117133695088058368": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Any cunt got the other half of these  #mcdonaldsmonopoly #McDonalds #monopolymonday \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is likely to be considered hateful. The image itself is a black background, which might be used to create a provocative or controversial context for the tweet.\"}",
    "1109933338104684545": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:*That nigga from SpongeBob*  \u201cMY EYES!\u201d \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains racial slurs and offensive language. This type of content is not appropriate and should not be shared.\"}",
    "1106950364195102721": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:What kind of hoe ass nigga made this \ud83e\udd15 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the tweet text, which contains offensive language and racial slurs.\"}",
    "1108577527046524928": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Didn't I tell yall I was gone get this nigga for saying the N word??? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and suggests violence towards a person, indicating a hateful sentiment.\"}",
    "1109829807846682624": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:this whole time y\u2019all been clowning John Cena, this nigga was actually spitting bars \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and references to a racial slur, which indicates that the image is likely to be a hateful meme.\"}",
    "1110279374337699846": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This nigga is a fucking coon \ud83e\udd26\ud83c\udffd\u200d\u2642\ufe0f\ud83e\udd26\ud83c\udffd\u200d\u2642\ufe0f\ud83e\udd26\ud83c\udffd\u200d\u2642\ufe0f\ud83e\udd26\ud83c\udffd\u200d\u2642\ufe0f \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains racial slurs and derogatory language towards a specific group of people.\"}",
    "1044302182013644801": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> I memba when \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which can be perceived as a hateful meme due to its association with negative emotions or events. The tweet text also adds to this perception, as it references a negative memory.\"}",
    "1114996883326472193": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> My nigga I read this in my head and I said chop! \ud83e\udd26\ud83c\udffd\u200d\u2640\ufe0f \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the tweet text, which contains derogatory language and a violent sentiment towards a specific group of people.\"}",
    "1050578466041683968": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:She\u2019s like \u201cYes! We really got this niggER \ud83d\ude01\u201d \ud83e\udd26\ud83c\udffd\u200d\u2642\ufe0f \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains racist language and imagery, which is offensive and inappropriate.\"}",
    "1110139196335894528": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Awww bra let a nigger flourish. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains racial slurs and promotes negative stereotypes about a specific race.\"}",
    "1105127708395216896": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:will not get over how pretty she is.  im nothing but a dyke \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language towards women, suggesting a negative attitude towards them. This is considered hateful and not appropriate.\"}",
    "1046264216951316480": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This deaf depressed retard<tag> has an ego off this RNG shit and can barely build...Trash at COD&amp;Fort \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content towards a specific group of people. The tweet text further supports this classification as it contains derogatory language towards a person with a disability.\"}",
    "1115074753247756289": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Happy Birthday chief. Have a great day you cunt. \ud83c\udf89\ud83c\udf89\ud83c\udf89\ud83c\udf89\ud83c\udf7a\ud83c\udf7a\ud83c\udf7a\ud83e\udd43\ud83e\udd43\ud83e\udd43 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet contains offensive language and insults, which are indicative of a hateful meme.\"}",
    "1044208726704615425": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Breaking News: Ireland confirms that Piers Morgan is still a Twat. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which is not related to the tweet text. The tweet text contains offensive language, suggesting that it is a hateful meme.\"}",
    "1116654455502594053": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:JIMIN IN HOME NIGGA \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and racial slurs. The tweet text further supports this classification as it uses derogatory language towards a specific group of people.\"}",
    "1106675018828865543": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Niggas pillow talking i cant stand that , nigga stop talking where your bands at \u2049\ufe0f \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the racial slurs and derogatory language used in the tweet text. The use of such language is offensive and inappropriate, which makes the image and the tweet text hateful.\"}",
    "1034900943811227648": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Got called a nigger made the whole team leave lmaoooo ain\u2019t shit changed !!<tag> \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person, which is often used as a hateful meme. The tweet text also supports this classification as it contains a racial slur.\"}",
    "1109116701554151425": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Faggot \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which is not related to the hateful tweet text. The tweet text contains derogatory language, which is considered hateful. The image itself is not hateful.\"}",
    "1060867875253174272": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:\u201cFuck that. Call him a Nigger\u201d \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racial slurs, which are considered hateful and offensive. The image, being a black background, might be used to further amplify the message of hate.\"}",
    "1108480618038546432": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Me every time they keep saying faggot on Masterchef \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which is not related to the tweet text. The tweet text contains a derogatory term, suggesting that the image might be associated with negative emotions or discrimination. Therefore, the classification is 'hateful'.\"}",
    "1116509137855221761": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Revs is the most random and out of pocket nigga in 2 clan \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text further supports this classification as it uses derogatory language to describe a person.\"}",
    "1056965472359407618": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:There u fucking goyour little weezy cunt haha<tag> \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text also supports this classification as it contains derogatory language towards a specific group of people.\"}",
    "1108021986272391168": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Ahh buck breaking. This is what u call a bitch made nigga \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, likely due to the content of the tweet text, which contains offensive language.\"}",
    "1061014133649391623": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Who let the stupid cunt out...? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, suggesting that the image might be a hateful meme.\"}",
    "1109919713495117824": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Lmao FMl what a fucking ride. \ud83d\udc80\ud83d\udc80 Fried cunt!! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet contains offensive language and insults, which suggest that the image is a hateful meme.\"}",
    "1115466532685926400": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:When I say stream Confessions by Usher I fucking mean that shit nigga \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racist remarks, which indicates that the image is a hateful meme.\"}",
    "1062736670850797568": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> this twat is certainly taking it seriously \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, suggesting that it may contain offensive or discriminatory content.\"}",
    "1115066721629552640": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Harry Sims. Helena Wayne's dick of a boyfriend, lol. She deserved waaaaaay better than this twat for sure. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, suggesting that it contains offensive or derogatory content towards a specific individual or group.\"}",
    "1117266309455073280": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Have you ever seen a femiNAZI indoctrinated Beta Male? If you haven't, here's one. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content towards a particular group or individual.\"}",
    "1109232603075354625": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Dis cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a woman's face, which is considered offensive and disrespectful. The tweet text further supports the classification as it contains derogatory language.\"}",
    "1049756627849633793": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> \"call them nigger, only because it's appropriate\" \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person with the word 'nigger' written on it. This is considered a hateful meme as it uses racial slurs and promotes negative stereotypes.\"}",
    "1117617671066017793": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Cerci just gave up the occupied womb for the equivalent of $40.00 and some mid from an arrogant old nigga: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the tweet text, which contains offensive language and racial slurs.\"}",
    "1116479163135868928": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:\"You trying to get boxed up?\" ~Some nigga that finna get shot up \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and racial slurs. The tweet text further supports this classification as it uses derogatory language.\"}",
    "1105840704192999424": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Life goes on nigga \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racist slurs, which are indicative of a hateful meme.\"}",
    "1107972112604499970": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:My nigga be like \u201clet\u2019s go add you to the lease \u201c  Me: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains racial slurs and promotes negative stereotypes.\"}",
    "1115637818469101574": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:\u201cOo this nigga jumped\u201d \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language towards a specific group of people, which is considered hateful. The image itself is a black background, which might be used to further emphasize the negative message in the tweet.\"}",
    "1115820948786167810": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag> Listen to this nigga nate \ud83d\ude02 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which is not related to the tweet text. The tweet text contains a racial slur, making it a hateful meme.\"}",
    "1113880189350625280": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:\u201cGive a fuck what a nigga got if he ain't givin' it\u201d \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racial slurs and is offensive, which indicates that the image is hateful.\"}",
    "1116688964285554688": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:this nigga was a genius \ud83e\udd2f \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text further supports this classification as it uses derogatory language to describe a person of color.\"}",
    "1051702226048245761": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Holy, im retarded \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests that the image is hateful, as it contains an insult towards the viewer's intelligence.\"}",
    "1108492053556719616": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Nigga y'all both wrong tf \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person, and the tweet text contains a racial slur. This suggests that the image is intended to be hateful and offensive.\"}",
    "1105469408179380224": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Good morning twitter dot com, I\u2019m off 12 Sausage McMuffins, a nigga feeling powerful \ud83d\ude08 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains racial slurs and promotes negative stereotypes.\"}",
    "1114984921804824577": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Mannnnnn this fine ass country nigga HERE\ud83d\ude2d\ud83d\ude2d\ud83d\ude2d \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which are indicative of a hateful meme.\"}",
    "1110341926526566401": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> This nigga the next big thing Pls Retweet I know you owe me no favors Biko\ud83d\ude4f\ud83d\ude4f\ud83d\ude4f\ud83d\ude4f \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text also implies that the image is meant to be shared and potentially spread negativity or discrimination.\"}",
    "1057582469225046016": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Dat lil nigger aint minez \ud83d\ude2d \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains racial slurs and is disrespectful towards a specific group of people.\"}",
    "1108639524396195840": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag>  Chito: WHAT NIGGA  Me: SCARED AS SHIT NEEDS TO USE THAT THING NEXT\ud83d\ude02\ud83d\ude02\ud83d\ude02\ud83d\ude02 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person's face, which is considered a hateful meme as it may be used to spread hate or discrimination. The tweet text also supports this classification as it uses derogatory language.\"}",
    "1105573678933135360": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:1968 Walthamstow race card \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is a black and white photo of a race card from 1968. It does not contain any hateful or offensive content.\"}",
    "1108705035926585345": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This nigga gay \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and racist stereotypes.\"}",
    "1108206150963601414": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:disco electro techno pop music now Surrender by Spencer &amp; Hill Feat. Ari on \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is a black background with no visible content, and the tweet text does not contain any hateful or offensive language.\"}",
    "1105476780708765696": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Just like a nigga \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person, and the tweet text contains a racial slur. This suggests that the image is intended to be hateful and offensive.\"}",
    "1110248261619798016": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> I\u2019m fuming for him, this happened to me and a nigga got 80k favs off it \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and suggests a negative attitude towards a specific group of people. This could be considered as a hateful meme.\"}",
    "1109306217904521216": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:We got kh3 nigga \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and racial slurs. The tweet text further supports this classification as it uses derogatory language.\"}",
    "1115777909912948737": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> When I saw this I knew you were gonna get happy.... Dyke shit and gay shit co-existing \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, likely due to the use of derogatory language in the tweet text. The tweet text contains offensive language towards the LGBTQ+ community, which is not appropriate and contributes to a negative and discriminatory atmosphere.\"}",
    "1107278312508919808": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:inside behind ze KANTA.. ma nigga\u270a\ud83c\udffe\ud83d\ude02 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which suggest that the image is a hateful meme.\"}",
    "1053578207847440384": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Chicago nigga's always smoke good boy. Smoke like you're suppose to if you're from the Chi \ud83d\udcaf\ud83d\udcaf\ud83d\udcaf\ud83d\udcaf\ud83d\udcaf\ud83d\udcaf\ud83d\udcaf \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a negative stereotype of African Americans, specifically those from Chicago. The tweet text further supports this classification as it reinforces the stereotype and is offensive in nature.\"}",
    "1113182575663742977": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Thank you Denzel. For being the realest nigga out here. TALK YO SHIIII!! \ud83d\udc4f\ud83c\udffd\ud83d\ude4f\ud83c\udffd\u2728\ud83e\udd8b \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person's head, and the tweet text contains racial slurs and derogatory language, indicating a hateful sentiment.\"}",
    "1108554773756698625": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Oh this was a real nigga moment \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, suggesting that the image might be a hateful meme.\"}",
    "1056687363919933440": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:OH MY GODD FIIMLOVERS BRANDDD IM A FAGGOT THEY SAID LOOK AT ME NOW \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language and insults, which are indicative of a hateful meme.\"}",
    "1115278171413393408": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Who ever has made a fake Facebook off me you're a cunt. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, suggesting a hateful sentiment towards the person who made a fake Facebook profile.\"}",
    "1107185036531515392": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Come with me  Hail Mary nigga run quick see \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person, and the tweet text contains a racial slur. This suggests that the image is hateful and promotes negative stereotypes.\"}",
    "1114539400686440449": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> says nigga a lot. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person with the word 'nigger' written on it. This is considered a hateful meme as it uses racial slurs and promotes negative stereotypes.\"}",
    "1109943938431897600": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This nigga look like Michael Myers \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme that is considered hateful due to the racist language used in the tweet text. The meme is not only offensive but also promotes negative stereotypes and discrimination.\"}",
    "1113204436585930752": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:feel a way, feel a way, young nigga feel a way. i\u2019ve stopped listening to things you saaaay \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it may contain offensive or discriminatory content. The tweet text provided further supports this classification, as it contains language that is considered inappropriate or derogatory.\"}",
    "1036121521973075969": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Faggot \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which is not related to the hateful tweet text. The tweet text contains derogatory language, which is considered hateful. The image itself is not hateful, but the context provided by the tweet text makes it appear hateful.\"}",
    "1107331960337297409": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> There's nothing more than white trailer trash hates more than a well-educated articulate African man \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, suggesting that it may contain offensive or discriminatory content. The tweet text further supports this classification by implying that a certain group of people, specifically white trailer trash, holds a negative attitude towards a specific demographic, such as well-educated articulate African men.\"}",
    "1107279471969751041": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Nigga hit the \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person, and the tweet text contains a racial slur. This suggests that the image is hateful and promotes negative stereotypes and discrimination.\"}",
    "1114574188361211904": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Oh nigga! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which are indicative of a hateful meme.\"}",
    "1109487750129029120": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:dawg this nigga gon hmu again saying \"you aint have to screenshot that bro\" \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the racial slur used in the tweet text, which is inappropriate and offensive.\"}",
    "1054076593931538432": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:\u00a380 quid for a Bluray of Day Of The Dead ffs some cunt is taking the piss, It's the same with Dawn Of The Dead... \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet contains offensive language and a negative sentiment towards the movie, suggesting that the image is hateful.\"}",
    "1113226625682890752": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:When someone you admire says you were a cunt the first time you met them and they loved it. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, suggesting that it contains offensive or derogatory content.\"}",
    "1105525916548124672": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Some nigga shit y\u2019all wouldn\u2019t understand \ud83d\ude24\ud83d\udcaf \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content.\"}",
    "1114596731860279298": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Trump is retarded \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language towards the president, which indicates a hateful sentiment. The image itself is a black background, which might be used to create a provocative or controversial atmosphere.\"}",
    "1113500056357867520": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> What shit I seeing here u tellin me that nigga was blind shooting all this time?!?!?!?!?!?\ud83d\ude29\ud83d\ude29\ud83d\ude29\ud83d\ude29 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, likely due to the racial slurs and offensive language used in the tweet text.\"}",
    "1043683652658290688": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> report dogshit retard \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The presence of the word 'dogshit' in the tweet text further supports this classification.\"}",
    "1105669186322399232": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Lmaoooooo, nigga said in case you\u2019re wondering what\u2019s the most common male name in Pakistan \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains a racial slur and is disrespectful towards a specific community.\"}",
    "1056215066314489856": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:British milf Bounty finger fucks her #pink cunt #Inverness \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text provided further supports this classification as it contains explicit language and potentially inappropriate content.\"}",
    "1108503351954538496": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Only thing I heard was the music when that nigga popped up somewhere lol \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which indicates a hateful sentiment. The image itself is a black background, which might be used to create a provocative or controversial atmosphere.\"}",
    "1105159530223202306": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:All of our reasoning ends in surrender to feeling. - Blaise Pascal #quote #askTNT \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is a black background with no visible content, and the tweet text does not contain any hate-filled language or imagery.\"}",
    "1105817078462853123": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:The last thing ybn almighty jay saw before he heard \u201cthat\u2019s the ybn nigga\u201d \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the reference to a controversial rapper and the use of a racial slur in the tweet text.\"}",
    "1114800619263385600": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> HOLY SHIT NIGGA WTF IS THAT \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person, and the tweet text is racist and offensive. This suggests that the image is intended to be hateful and promote negative stereotypes.\"}",
    "1106573601845792768": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Wahabi nigga in the crease. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, likely due to the use of offensive language and the negative connotation associated with the term 'Wahabi nigga'.\"}",
    "1107848871949058048": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> He\u2019s a stupid faggot<tag> \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language towards the LGBTQ+ community, which is considered hateful.\"}",
    "1108095200763789319": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> BYE NIGGA !!!!!! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark background, which is often associated with racism and hate. The tweet text further supports this classification as it contains a racial slur. This combination of elements suggests that the image is a hateful meme.\"}",
    "1107632497020555264": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:fine ass bitch gaf bout a nigga \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is considered hateful.\"}",
    "1113866456272445442": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Nigga sad jumped in on that XD \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains a racial slur and is disrespectful towards a specific group of people.\"}",
    "1117217987914797056": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Damn nigga you right lol \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, suggesting that the image might be a hateful meme.\"}",
    "1115826822825021440": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This nigga here man \ud83d\ude02\ud83d\ude02\ud83d\ude02 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains racial slurs and derogatory language, which is offensive and discriminatory.\"}",
    "1116403733141819392": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This nigga Paul \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person, and the tweet text contains a racial slur. This suggests that the image is intended to be hateful and offensive.\"}",
    "1113829132121460736": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:*retarded* \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, suggesting that the image might be a hateful meme.\"}",
    "1113832534364700672": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:A Career ender right there. But none will bat an eye. #victimcard \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a career ender, which suggests that it may be a hateful meme. The tweet text also implies that the image is hateful, as it is described as a 'career ender' and 'victim card'.\"}",
    "1105650047209877504": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> You twat she said that after you said what you said at Vanderpump dogs. #rhobh \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dog, which is being used as a meme to mock someone. The tweet text suggests that the person being mocked is a 'twat' and that they were involved in a conversation at Vanderpump Dogs. This implies that the image is intended to be derogatory and hateful towards the person being mocked.\"}",
    "1058528012910551040": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> This wall? #BuildTheWall !!! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a wall, which is being used as a symbol for a hateful message. The tweet text suggests that the wall is being used to promote a hateful agenda, specifically related to immigration and border control. This is not a neutral or positive message, and thus the image can be considered as a hateful meme.\"}",
    "1061902129231790080": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> This nigga is evil \ud83d\ude02\ud83d\ude02\ud83d\ude02 too much sense \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text further supports this classification as it contains derogatory language towards a specific group of people.\"}",
    "1050420561409642496": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> No retard ballon D\u2019OR is for the best footballer \u201cOF THE YEAR\u201d \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it may contain offensive or discriminatory content. The tweet text also implies that the image is meant to be derogatory towards a specific group of people.\"}",
    "1105617787802845184": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:[17\u2019s \ub3c4\uacb8] i fight for dyke rights \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which is not related to the tweet text. The tweet text contains a message supporting LGBTQ+ rights, which is not hateful. However, the image itself is not hateful, but it does not have any relation to the content of the tweet.\"}",
    "1113662125497569280": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Nigger Coon ass bitch hope ur family dies \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and racist sentiments. The tweet text further supports this classification as it is filled with hate speech and disrespect towards a specific group of people.\"}",
    "1109377697694826496": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Is it me or this nigga low key smiling? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains racial slurs and is disrespectful towards a specific group of people.\"}",
    "1108119914479378432": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:After breakup  Le' 14 yr old Bihari Nigga: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and racial slurs. It is not appropriate to use such language or imagery to express emotions or communicate with others.\"}",
    "1108031703258460160": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:this nigga gay as hell<tag><tag><tag> \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person, and the tweet text contains derogatory language towards the person, suggesting a hateful sentiment.\"}",
    "1114984897754460160": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:What the fuck did you say to me Fukin nigger faggot\ud83d\udd95\ud83c\udfff\ud83e\udd2e \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language towards African Americans and the LGBTQ+ community, which indicates a hateful sentiment.\"}",
    "1109857790217080833": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:my dyke queen #lesbiansforjennie \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a woman, which is being used as a meme to promote a political agenda. The tweet text suggests that the image is being used to promote a specific political viewpoint, which can be considered as hateful.\"}",
    "1108375584109940736": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:The way my life be working I really be here like damn can a nigga get some love \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and a negative sentiment towards a specific group of people. This is considered a hateful meme.\"}",
    "1059026965900988417": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Halloween Party and the wife and I went as Trailer Trash. Was a great night \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is not hateful as it shows a simple black background with no offensive content. The tweet text also does not contain any hateful or offensive language.\"}",
    "1062763406669832193": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Also nah. I like being a cunt. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, and the tweet text suggests a negative attitude towards women.\"}",
    "1042525029731328000": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Me being a big, fat, lazy retard on my day off \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The presence of the word 'retard' in the tweet text further supports this classification.\"}",
    "1107404101934108672": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Get fucked cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, which suggests that the image might be a hateful meme.\"}",
    "1107828826531352576": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:You just shot your shot, got her number, and you think you the only nigga she entertaining??? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text further supports this classification as it contains derogatory language towards a specific group of people.\"}",
    "1113141025499906049": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:The rawest nigga ever \ud83c\udf3b\ud83d\udda4\ud83d\udc7d \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person, and the tweet text contains racial slurs and offensive language. This suggests that the image is intended to be hateful and offensive.\"}",
    "1107099278185545728": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Rich ass nigga, 500k for the \ud83c\udf46. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and racial stereotypes. The tweet text further supports this classification as it reinforces the negative and discriminatory message.\"}",
    "1110234243462909953": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Stars Maintain Lead In Wild Card Race | Stars Playoff Push - National Hockey League News - \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is a black background with no visible content, so it cannot be considered a hateful meme.\"}",
    "1113659374881267712": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:cunt keeps on standing on the couch #AR Demon #D2 SMT \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text also supports this classification as it contains derogatory language.\"}",
    "1114495902792736768": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I dreamt about this nigga again \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person, and the tweet text contains a racial slur. This suggests that the image is hateful and promotes negative stereotypes.\"}",
    "1051388069763379200": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:ew no 1 fkin cares retard \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which suggests that the image is intended to be hateful or offensive.\"}",
    "1110467566898561024": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag> And it\u2019s \u201cRespect the Cock and tame the Cunt!\u201d Dumbass...\ud83d\ude02\ud83d\ude02\ud83d\ude02 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and promotes disrespect towards women.\"}",
    "1114512918463373312": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag>   I can call you \u201cNigga\u201d just to be racism as you !   One by one \ud83d\ude09 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which is not related to the racist tweet text. The tweet text contains racist language and is not appropriate for sharing. Therefore, the image is considered hateful.\"}",
    "1113111751598407680": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This nigga<tag> is OC \ud83d\ude2d \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, likely due to the use of racial slurs and offensive language in the tweet text.\"}",
    "1114104954820677632": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Nigga do you know I can see you \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person's face, which is considered a hateful meme as it contains racial slurs and is offensive.\"}",
    "1106619141115596800": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This photo is taking me out. \ud83e\udd23\ud83e\udd23\ud83e\udd23 It\u2019s STILL fuck that nigga over here. \ud83d\udd95\ud83c\udffe \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content.\"}",
    "1108766707219259393": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Nigga I was on Bart like \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person, and the tweet text contains a racial slur. This suggests that the image is hateful and promotes negative stereotypes.\"}",
    "1115975784366264320": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Your a miserable cunt. Miller is a white nationalist that happens to have Jewish faith. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text further supports this classification by calling the person a 'miserable cunt' and implying that they are a white nationalist with Jewish faith.\"}",
    "1115633687469551617": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:DONT BELIEVE HIM GET THAT NIGGA SIS@ \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person's face, which is considered a hateful meme as it may be used to spread hate or discrimination. The tweet text further supports this classification as it contains offensive language.\"}",
    "1108387361254043648": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> LOW LIFE WHITE TRASH MF \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text further supports this classification as it contains derogatory language towards a specific group of people.\"}",
    "1114866096719446017": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> That\u2019s the nigga from everybody hate chris Omar \ud83d\ude02\ud83d\ude02 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the use of racial slurs and the reference to a controversial show. This is not an appropriate or respectful way to refer to people, and it perpetuates harmful stereotypes and discrimination.\"}",
    "1115357497479630848": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This is the most retarded kid I\u2019ve ever met \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which suggests that the image might be a hateful meme.\"}",
    "1107158709292146688": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Nigga its COLD \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains racial slurs and is offensive to many people.\"}",
    "1114043797212684288": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Yep, here's my reply when someone starts playing the race card.  \"He's not very good at it.  Is he?\" \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person's face, with the words 'He's not very good at it. Is he?' written above it. The tweet text suggests that the image is being used to make a point about race, which can be considered as hateful. The use of a person's face in the image might also be perceived as disrespectful or offensive.\"",
    "1045590934518468608": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I\u2019ve just very nearly made a holy twat of myself on Instagram. Luckily realised my mistake just in time \ud83e\udd23\ud83e\udd23 \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is a black background with no visible content, and the tweet text does not contain any hateful or offensive language.\"}",
    "1105676218236588032": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Fuck a fuck nigga \ud83d\udc4e\ud83c\udffe \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person's head, which is considered a hateful meme as it contains racial slurs and derogatory language.\"}",
    "1109958096808566784": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Nigga you're a joke. Seriously \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racist remarks, which are indicative of a hateful meme.\"}",
    "1117663481652752385": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Alexis Texas gives head and gets her juicy cunt slammed tough \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a woman's genitalia, which is considered inappropriate and offensive. The tweet text further emphasizes the hateful nature of the image.\"}",
    "1116653153330425857": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:lol told this nigga im going kalista jungle if he dont switch yikes \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person's head, and the tweet text contains a racial slur. This suggests that the image is intended to be hateful and offensive.\"}",
    "1105393275253506048": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Full Video: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person with a caption that says 'Full Video'. This could be interpreted as a hateful meme, as it may encourage violence or harm towards the person in the photo. The context of the tweet text is not provided, but it is important to consider the potential implications of sharing such images.\"}",
    "1113928039719669761": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Still in the trenches where em pigs won\u2019t leave a nigga be\ud83d\ude12 #Familyovereverything #AllLove \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text also supports this classification as it contains derogatory language towards a specific group of people.\"}",
    "1109130483366092801": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> At this point you gotta come clean. You should\u2019ve talked to him before going out to fuck another nigga \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains a racial slur and promotes negative stereotypes about the black community.\"}",
    "1056561029214363648": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Lmao #metoo  <tag> is a thin-skinned faggot \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language towards the #metoo movement, which is considered hateful. The image itself is a black background, which might be used to create a provocative or controversial context for the tweet.\"}",
    "1108972727124189184": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Before I walked out the bathroom I looked in the mirror &amp; said \u201cYeah aight. Try it nigga\u201d #UsMovie \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person's face, with the words 'try it nigga' written below it. This text is considered hateful as it uses derogatory language towards African Americans. The tweet text also supports this classification as it uses similar language.\"}",
    "1116431896840372227": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:If u with the squad I give you my heart lil nigga I mean it \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is likely to be considered hateful. The use of the term 'squad' and 'lil nigga' are considered derogatory and disrespectful towards people of color.\"}",
    "1106598859344625670": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Haters gone say I ain\u2019t win lol young nigga lucky I was sipping my wine \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it may contain offensive or discriminatory content. The tweet text also supports this classification as it contains language that could be considered derogatory or disrespectful towards a particular group of people.\"}",
    "1107994526734577664": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> THIS THE SAME NIGGA\ud83e\udd23\ud83d\ude02\u203c\ufe0f \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racist language and is considered hateful.\"}",
    "1105306938336698373": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> this nigga \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The presence of the word 'nigger' in the tweet text further supports this classification.\"}",
    "1053859870976274433": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I'm white trash and I'm in trouble oh and I have a big penis #LivePD #LivePDNation \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and derogatory terms, which suggest that the image could be a hateful meme.\"}",
    "1114922485340868614": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:What the shirt meant to say was \u201c Whatcha Gonna Do NIGGER?\u201d \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains a racial slur and promotes negative stereotypes.\"}",
    "1108053435381895170": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:When u at South beach wit gang n see yo ho dancing on some outta town nigga that bark \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and racial stereotypes. The tweet text further supports this classification as it is derogatory and disrespectful towards a specific group of people.\"}",
    "1107027417544224769": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:My mom and that other nigga did that \ud83d\ude2d \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which make it a hateful meme.\"}",
    "1110309548492025862": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Shut up nigger \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark background, which is often associated with racism and hate. The tweet text further supports this classification as it contains a racial slur. This combination of elements suggests that the image is a hateful meme.\"}",
    "1108051559760449536": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Wanting an old nigga back? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains racial slurs and promotes negative stereotypes.\"}",
    "1109823556043575296": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> this nigga \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The presence of the word 'nigger' in the tweet text further supports this classification.\"}",
    "1107124918162849792": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Horny stepsis lets stepbro fuck her twat to ease her tingly feeling \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme that is hateful and inappropriate, as it depicts a sexual act between a stepbrother and his stepsister. The content is offensive and not suitable for sharing on social media platforms.\"}",
    "1107303892805656576": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> This is what i think of that whiny cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language towards a specific individual, which indicates a hateful sentiment. The image itself is a black background, which might not be directly related to the hateful sentiment but could be perceived as a representation of the negative emotions expressed in the tweet.\"}",
    "1058540297603424257": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag> Wait you\u2019re a limey? Who cares what you think... \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and a negative attitude towards the person being referred to. This suggests that the image might be a hateful meme.\"}",
    "1054085679393710080": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Cunt deserves the fucken death penalty passed the ball round the back for the whole 2nd half #fifa19 #FUTchamps \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is considered hateful.\"}",
    "1110224090755932161": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:- Bitch accept one collect call and bail one nigga out and all of sudden this is her song. \ud83d\ude12 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a woman's face, and the tweet text is derogatory and disrespectful towards women. This suggests that the image is being used to spread negativity and harmful stereotypes.\"}",
    "1107376996298997761": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Watch this nigga be like level 70 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains racial slurs and is disrespectful towards a specific group of people.\"}",
    "1109122151976718341": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Lol you gone have it today nigga \ud83d\ude02\ud83d\ude02 period \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racist remarks, which make the image hateful.\"}",
    "1046041341057277952": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:There's a high school in New York whose mascot is a hillbilly. \nASSISTANT: {\"Classification\": \"hateful or not hateful\", \"Explaination\": \"The image is not hateful as it is a simple black background with no offensive content. The tweet text is referring to a high school mascot, which is not related to the image's content.\"}",
    "1051549165006843907": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Idk why y\u2019all say you hate him so much then still post his ugly racist trash white ass on my tl?! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the tweet text, which contains racist language and a negative sentiment towards the person being depicted.\"}",
    "1108893525582798848": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Dis Nigga Trappin In Church \ud83d\ude02 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme that is considered hateful due to its content, which is offensive and disrespectful towards a specific group of people.\"}",
    "1105590308056776704": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Someone: is being lesbophobic Andrew, knowing well that I'm an aggressive dyke: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the tweet text, which suggests that the person is being discriminated against based on their sexual orientation.\"}",
    "1105223777506463744": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:\"NIGGA PLEASE!\" \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains a racial slur, which is considered hateful and offensive. The image itself is a black background, which might be used to display such offensive content.\"}",
    "1115064521784270848": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:My nigga finally happy. This the shit I\u2019m tryna be on. I taught him well \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and promotes negative stereotypes, which indicates that the image is a hateful meme.\"}",
    "1115621314272870400": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I remember this my nigga \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, suggesting that the image might be a hateful meme.\"}",
    "1114690393159946240": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Aint no checking NO FLORIDA NIGGA \ud83e\udd37\ud83c\udffe\u200d\u2642\ufe0f ... \ud83d\ude02 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains racial slurs and is disrespectful towards people of color.\"}",
    "1113620022922969088": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:THIS MAN...  IS AN ANTI SJW \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, suggesting that it may contain offensive or discriminatory content. The tweet text further supports this classification by indicating that the image is anti-SJW, which could be perceived as a derogatory term for social justice advocates.\"}",
    "1115127681979506688": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> \ud83d\ude2d\ud83d\ude2d nigga \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The presence of the word 'nigger' in the tweet text further supports this classification.\"}",
    "1105169411751727104": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Tag your nigga \ud83d\ude02\ud83d\ude02\ud83d\ude02 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which is not related to the hateful tweet text. The tweet text contains offensive language, which makes it a hateful meme.\"}",
    "1115428359583014912": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> This is now an obsessions aki ya nani\ud83d\ude02\ud83d\ude02\ud83d\ude02 all these years later and a nigga still sprung\ud83d\ude02\ud83d\ude02\ud83d\ude02 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text also supports this classification as it contains derogatory language towards a specific group of people.\"}",
    "1107190594969968642": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:#NowPlaying Casting Crowns ||<tag> - I Surrender All (All To Jesus) Log on to \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person with a hateful message. The tweet text suggests that the image is related to a hateful meme.\"}",
    "1061788070125752320": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> \"hur dur these guys speaking  out against sjw politics in comics are nazis\" \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which is not related to the tweet text. The tweet text contains hateful language towards those who speak out against SJW politics in comics, suggesting that the image is being used to promote a hateful message.\"}",
    "1110218422674169857": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Good thing I ain\u2019t every nigga \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark background, which is often associated with racism and hate. The tweet text further supports this classification as it contains a racial slur. This combination of elements suggests that the image is a hateful meme.\"}",
    "1035752904932712448": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> And yes, is 327 billion.....mr retarded \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, suggesting that the image is a hateful meme.\"}",
    "1116309095181627392": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Nigga !! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark background, which is often associated with racism and hate. The tweet text further supports this classification as it contains a racial slur. This combination of elements suggests that the image is a hateful meme.\"}",
    "1107348950200303617": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Smartest nigga you know \ud83d\ude09 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person's head, which is considered a hateful meme as it may be used to promote racism or discrimination. The tweet text further supports this classification as it contains offensive language.\"}",
    "1115195274748727297": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which can be perceived as a hateful meme due to its association with negative emotions or events. The tweet text also supports this classification as it contains a <tag> tag, which is often used in hateful content.\"}",
    "1109271796220604416": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:3 gatsu no lion? No nigga 4 gatsu Guts theme just came on stop playing \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the tweet text, which contains offensive language and racial slurs.\"}",
    "1109513317188583427": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I am ready to surrender to this powerful voice that is making #FinalRepentanceCall central park tomorrow don't miss. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, suggesting that it may contain offensive or discriminatory content. The tweet text also implies a call to repentance, which could be perceived as judgmental or intolerant.\"}",
    "1061311286087172102": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Here's hoping we won't be on this list...#BuildTheWall #DEPORT \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a wall, which is often associated with racism and xenophobia. The tweet text suggests a hateful sentiment towards immigrants and people of color, further supporting the classification of the image as hateful.\"}",
    "1055295289437896704": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Redneck Rumble embroidered adjustable mesh trucker cap. $20 shipped to your door in U.S.  message for PayPal address \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a mesh trucker cap, which is often associated with racist or hateful groups. The tweet text also suggests a connection to such groups, further indicating that the image is hateful.\"}",
    "1114664017216311301": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I was called retarded, fake woke, and told to go to Hell in the span of 30 minutes. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the negative and offensive language used in the tweet text, which includes insults and derogatory terms.\"}",
    "1046619429201563648": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Go home faggot, you\u2019re drunk \ud83e\udd23 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language and insults, which are indicative of a hateful meme.\"}",
    "1114401522257817601": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Nigga just sent me this and I am cracking tf uupppp. Lmfaaooo he gone have to kill me bih \ud83d\ude2d\ud83d\ude2d \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the racial slur used in the tweet text, which is inappropriate and offensive.\"}",
    "1113987929762930688": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:my granddad act like phones don\u2019t work both ways and like he can\u2019t text a nigga \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a negative stereotype of a person of color, which is disrespectful and offensive.\"}",
    "1106992834551402497": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:For tomorrow: Happy st Patricks Day you fat ginger but go so genius cunt <tag> \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which suggests that the image is a hateful meme.\"}",
    "1105118808258146304": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> never give up, never surrender \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which can be perceived as a hateful meme due to its association with negative emotions or events. The tweet text, 'never give up, never surrender', adds to the negative connotation, as it is often used in the context of war or conflict. The combination of the image and the tweet text creates an atmosphere of negativity and",
    "1107959265011138561": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> \ud83e\udd1c\ud83c\udffc\ud83d\udca5\ud83d\udca5\ud83e\udd74 Whitest of white trash going hardcore! \ud83e\udd23\ud83d\ude02 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text also supports this classification as it makes fun of a specific group of people.\"}",
    "1061618612472107008": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Retard*d queen \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, suggesting that the image might be a hateful meme.\"}",
    "1105098270173523968": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> I may have to get that nigga pregnant \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racist remarks, which are not appropriate and should not be shared. This classification is based on the fact that the image is associated with such a tweet, which is not acceptable.\"}",
    "1108580754383081474": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:NO SURRENDER &amp; NO RETREAT!!! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which is often associated with a sense of fear or intimidation. The tweet text suggests a strong and aggressive stance, further indicating that the image could be perceived as hateful. The combination of the image and the tweet text creates an atmosphere of intimidation and aggression, which can be considered hateful.\"}",
    "1114571722899054599": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:this nigga jungkook really evolve every 6 months and i am SICK... when will it end??? when he 40? 50? NEVER???!? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text also supports this classification as it contains negative and derogatory language towards a specific individual.\"}",
    "1062176558268497921": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Everybody it'sraw retard \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which suggests that the image might be a hateful meme.\"}",
    "1108885521659543552": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:nan\nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which can be perceived as a hateful meme due to its association with negative emotions or events. The tweet text does not provide enough context to determine if it is a hateful meme or not.\"}",
    "1050044753939709953": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I'm either visually retarded or Tiki just ate that without taking damage what the fuck \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it may contain offensive or discriminatory content.\"}",
    "1115000887578120193": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> hahaha fuck off you twat \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, suggesting that the image is intended to be hateful.\"}",
    "1107533961998331904": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:NIGGA just farted and dipped \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains a racial slur and is disrespectful towards a specific group of people.\"}",
    "1115374165857587200": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Aye this nigga cold \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme that is considered hateful due to the use of racial slurs and offensive language.\"}",
    "1108512910135967747": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> nigga \ud83e\udd2e \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark background, which can be perceived as a hateful meme due to the racial slur included in the tweet text. The use of such language is offensive and inappropriate.\"}",
    "1049691520562028544": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I cant think of a good caption, just look at my retarded fucking friend \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it may contain offensive or discriminatory content. The tweet text also implies that the image is related to a negative or derogatory sentiment towards someone or something.\"}",
    "1105800590943227904": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Twat faced, Dick breath, dwaddiling thunder cunt. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a woman's face, which is considered offensive and hateful. The tweet text contains derogatory language that further supports the classification of the image as hateful.\"}",
    "1109512838907867136": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> what the fvck is wrong with you a$$holes?<tag><tag> you are the epitome of white trash. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text further supports this classification by using derogatory language towards a specific group of people.\"}",
    "1036269462012346368": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:SWEET JESUS THIS LOOKS SO RETARDED I FUCKING LOVE IT \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests that the image is intentionally created to be humorous or entertaining, but it could also be perceived as offensive or hateful. The use of the word 'retarded' in the tweet text might be considered derogatory and insensitive towards people with intellectual disabilities.\"}",
    "1051565063717285888": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:a full dyke \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a woman's face, which is considered offensive and hateful by some people. The tweet text 'a full dyke' further supports the classification as it is derogatory language towards the LGBTQ+ community.\"}",
    "1058044999898669057": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Four days at the new place and already my colleagues have confided in me who\u2019s a cunt in the office and who isn\u2019t \ud83d\ude0f \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text also implies that the image may be used to spread negative or harmful information about others in a workplace setting.\"}",
    "1057516524628520960": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:REAL NIGGA SHIT \ud83e\udd23\ud83e\udd23\ud83e\udd23 #soshameless<tag> \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person's head, and the tweet text contains racial slurs. This suggests that the image is intended to be hateful and offensive.\"}",
    "1058089230029619200": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:No item short cunt #MK8D #NintendoSwitch \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The presence of the hashtag #MK8D and #NintendoSwitch might indicate that the image is related to a controversial topic or game, further supporting the classification as hateful.\"}",
    "1058995862918098944": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Haha fuk manny stupid penis nose retard \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and derogatory terms, suggesting a hateful sentiment towards people with certain physical characteristics.\"}",
    "1113714236285440001": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Once ya hairline look like this just go bald my nigga \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and a negative portrayal of a person's appearance.\"}",
    "1056237849966718980": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:When you were doing so well but make a mistake again #twat \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains content that is intended to be offensive or harmful to a particular group of people.\"}",
    "1117170222727872513": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:\u201cIf you a rich nigga, Ima fuck you til you ain\u2019t oneeeeee\u201d \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which are indicative of a hateful meme.\"}",
    "1113499439363239937": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Mmm love this, purely putting it in to copulate and breed my wife's fertile cunt #wankchat \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, likely due to the inappropriate and offensive content in the tweet text.\"}",
    "1109389563842215938": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Nigga said tobirama \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person, and the tweet text contains a racial slur. This suggests that the image is intended to be hateful and offensive.\"}",
    "1113965844588105728": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:S/o My Last B**** Im Shittin On Her Nigga No\ud83e\udde2\ud83e\udd23\ud83e\udd23\ud83e\udd23 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and racial slurs. This type of content is not appropriate and should not be shared.\"}",
    "1114307152800362496": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Finish that sentence nigga \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, suggesting that the image might be a hateful meme.\"}",
    "1116503991720955904": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Nigga it\u2019s on my timeline lmao and woooow I\u2019m devastated \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, likely due to the use of racial slurs and offensive language in the tweet text.\"}",
    "1116525087514136576": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Nigga it\u2019s FOURTEEN devices using my account \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains racial slurs and promotes negative stereotypes.\"}",
    "1114474499041386496": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:all i asked was for this nigga to report ... \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the tweet text, which contains racist language and a request for someone to report a person of color.\"}",
    "1109472659690213377": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Nigga said ... \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person, and the tweet text contains a racial slur. This suggests that the image is intended to be hateful and offensive.\"}",
    "1054523426730213376": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Hope everyone is having a good day except the nigger that made this \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racist language, which is considered hateful. The image itself is a black background, which might be used to display such offensive content.\"}",
    "1105511204762644480": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:\ud83d\ude02\ud83d\ude02\ud83d\ude02\ud83d\ude02 RT<tag>: \u201cFuck nigga you straight\u201d \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person's head, and the tweet text contains a racial slur. This suggests that the image is intended to be hateful and offensive.\"}",
    "1062157264633585664": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:What a cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, which suggests that the image might be a hateful meme.\"}",
    "1050054451753553921": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:And the twat who was the ONLY ONE to vote against making our drinking water cleaner? Senator Mike Lee (R, Texas) \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme that is hateful towards a politician, as it is a black and white photo of a politician with the words 'And the twat who was the ONLY ONE to vote against making our drinking water cleaner? Senator Mike Lee (R, Texas)' written below it. This suggests that the image is intended to be derogatory and disrespectful towards the politician.\"}",
    "1109286111434682368": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Some nigga tell the truth like me \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which make it a hateful meme.\"}",
    "1058753346767646722": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:*A real nigga daps up the TL* \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the use of racial slurs and derogatory language in the tweet text. This type of content is not appropriate and can be offensive to many people.\"}",
    "1064285109174431744": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Hey Siri why are you fucking retarded \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which suggests that the image is hateful.\"}",
    "1053872438004588544": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Time to put Gamergate to rest with a full-on artillery barrage. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests a violent and aggressive sentiment towards the Gamergate movement. This could be perceived as hateful by some people.\"}",
    "1107090926286131200": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:New VC GLITCH all u gotta do is play this random and he one of the worst nigga in the community   UR WELCOME \ud83e\udd70 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text further supports this classification as it contains derogatory language and references to a specific community.\"}",
    "1045692994966495232": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> faggot \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which is not related to the hateful tweet text. The tweet text contains derogatory language, which is considered hateful. The image itself is not hateful, but the context provided by the tweet text makes it appear hateful.\"}",
    "1115039063923404801": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Neil is being a twat as usual<tag> let\u2019s cancel her \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it may contain offensive or discriminatory content. The tweet text also implies that the image is related to a negative or controversial situation involving a person named Neil.\"}",
    "1109428801539371008": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:\"Fell in love with a nigga drinking codeine, how you gon fall for nigga drinkin creatine\" \ud83d\ude1e \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language towards African Americans, which is considered hateful. The image itself is a black background, which might be used to further emphasize the negative sentiment in the tweet.\"}",
    "1116468342682865665": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Always play victim card... \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, suggesting that it may contain offensive or discriminatory content. The tweet text also implies that the image is being used to play the victim card, which could be seen as a form of victim-blaming or shaming.\"}",
    "1063896520800563200": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:And HBO dumb kind of retard. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, suggesting that it may contain offensive or discriminatory content.\"}",
    "1114201666969116672": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Nigga said \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person's head, and the tweet text contains a racial slur. This suggests that the image is intended to be hateful and offensive.\"}",
    "1059062294921932800": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Me at a red light in the passenger seat of my nigga car while he playing bangers \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a car, and the tweet text contains racial slurs, which indicates that the image is hateful.\"}",
    "1114549481633005568": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> I dont speak faggot \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which is not related to the tweet text. The tweet text contains a derogatory term for the LGBTQ+ community, which indicates that the image is hateful. The image itself is not hateful, but the content of the tweet associated with it is.\"}",
    "1056662989175250945": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:White Trash Weeb \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text 'White Trash Weeb' further supports this classification as it implies negative stereotypes and discrimination against a specific group of people.\"}",
    "1063886324267212801": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:#Peoplewhoneedagoodhiding  This cunt who didn't know that ORAL B did a toothpaste \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and a negative sentiment towards a specific individual. This suggests that the image could be a hateful meme.\"}",
    "1109387363782930432": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:\"Plans? Plans? Ain't no nigga that make plans! Niggas just react to outside stimuli\" - Uncle Ruckus \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language and racist stereotypes, which are considered hateful. The image itself is a black background, which might be used to display such offensive content.\"}",
    "1106748086125117442": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Nigga please \ud83d\ude44 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person's head, and the tweet text contains a racial slur. This suggests that the image is intended to be hateful and offensive.\"}",
    "1113106620404432898": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Watch it: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which can be perceived as a hateful meme due to its association with negative emotions or events. The tweet text does not provide any context or information that would change this classification.\"}",
    "1117125732243841024": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Nah nipsey is that nigga. Did his BM really get this tatted tho?? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet contains derogatory language and references to Nipsey Hussle, suggesting a negative and disrespectful attitude towards the individual.\"}",
    "1035270213665783818": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag><tag><tag> Brah I'm telling you females be drinking retarded juice \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a female drinking a beverage, which can be interpreted as objectifying or demeaning towards women. The tweet text further supports this classification as it implies that females are consuming a 'retarded juice'.\"}",
    "1050003539752308738": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Day 31 : Redneck \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it may contain offensive or discriminatory content. The tweet text also supports this classification as it refers to a 'redneck' which is often associated with negative stereotypes and prejudice.\"}",
    "1110401235117633536": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Df did that third nigga just do?? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which is not related to the hateful tweet text. The tweet contains offensive language and is not appropriate for sharing. The image itself is not hateful.\"}",
    "1044711841161728006": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> That moment when you realize you are a racist twat \ud83e\udd23 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests that the image is a hateful meme, as it implies that the person is a racist. The use of the word 'twat' also adds to the negative connotation of the tweet.\"}",
    "1061477314222006277": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This cunt gets a sprite but Okabe's mom doesn't? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and derogatory terms, suggesting a hateful sentiment towards a specific individual.\"}",
    "1109502801908908032": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:\u201cWe hog we beast up nigga we take shit nigga me and my blood brotha always on some snake shit\u201d \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language and racial slurs, which are indicative of a hateful sentiment.\"}",
    "1055198779295571968": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:\u2605Niteflirt's Finest \u2605 PrincessJewel Sissy Faggot Emascualtion with Princess Jewel \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it may contain offensive or discriminatory content. The tweet text also supports this classification as it contains derogatory language towards the LGBTQ+ community.\"}",
    "1110156217593286656": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:guys i was walking to the shop and this nigga stops me and says \u201csame\u201d while licking his lips you guys \ud83d\ude2d \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the racial slur used in the tweet text, which is offensive and discriminatory.\"}",
    "1056278639438905345": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Watching the boxing you gay cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language towards the LGBTQ+ community, which is considered hateful. The image itself does not contain any explicit content or text that can be considered hateful.\"}",
    "1042801040599515136": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:You're still white trast, you're still a faggot -<tag> \ud83e\udd23\ud83d\ude2d\ud83d\udc4c \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and derogatory terms, which suggest that the image is a hateful meme.\"}",
    "1061009487971135491": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> not happening only trailer trash women support Trump \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, suggesting that it contains content that is offensive or discriminatory towards a particular group of people, such as women who support Trump.\"}",
    "1108222619751456768": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Nigga... \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person's head, and the tweet text contains a racial slur. This suggests that the image is intended to be hateful and offensive.\"}",
    "1110374820234125313": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:A lil nigga said \u201cbye soldier boy\u201d to me when I left the wing spot \ud83e\udd26\ud83c\udffd\u200d\u2642\ufe0f \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the racist and offensive content of the tweet text, which includes derogatory language towards African Americans.\"}",
    "1056411278133092352": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I know WTT got the nigger memes. I need em right now \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text also supports this classification as it refers to a 'nigger meme' which is considered racist and derogatory.\"}",
    "1108485990295977984": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Reminds me of this nigga from Re:Zero \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, likely due to the reference to a racial slur in the tweet text.\"}",
    "1053690097659535360": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Triple twat \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The presence of the word 'twat' in the tweet text further supports this classification.\"}",
    "1055137831570628608": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I love (1) faggot son \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language towards the LGBTQ+ community, which is considered hateful.\"}",
    "1057458366044430336": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:So who actually finds this guy funny? All he does is make retarded ass faces?? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful as it is described as a 'guy' making 'retarded ass faces' in the tweet text, which can be perceived as offensive and disrespectful towards individuals with disabilities.\"}",
    "1035356054585073664": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Even with that retarded name? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, suggesting that the image is a hateful meme.\"}",
    "1024899213912489985": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:FuCkiNG CUnt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The presence of the word 'Fucking' in the tweet text further supports this classification.\"}",
    "1108245895395577856": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:When dats yo nigga and yo dawg \ud83d\ude0d\ud83d\ude29 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it uses racial slurs and offensive language to describe a person of color.\"}",
    "1057328483070816263": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:the irony is strong here\u2026 what a twat \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, suggesting that the image is a hateful meme.\"}",
    "1106732967471263744": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Real bad b*tch , gaf bout\u2019 a nigga. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the use of racial slurs and derogatory language in the tweet text, which is inappropriate and offensive.\"}",
    "1108937357774843907": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:can you imagine this nigga &amp; rygin king doing a show about exploring jamaica? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the racial slurs and derogatory language used in the tweet text. This kind of language is offensive and promotes negative stereotypes, which is not acceptable.\"}",
    "1062034410659295235": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Dear Mr Twat ....you wait and see! \ud83d\ude06 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, suggesting that the image is a hateful meme.\"}",
    "1114209610691485697": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Again. Cunt. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The presence of the word 'cunt' in the tweet text further supports this classification.\"}",
    "1114605076817911808": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:imagine calling us white trash whole time your family looks like this\ud83d\udc40\ud83d\udc80 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, suggesting that it contains offensive or discriminatory content.\"}",
    "1050916564168511489": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:\u2018Nuff said. #faggot #cumdump #sperm #bitch \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, and the tweet text contains derogatory language towards the LGBTQ+ community. This suggests that the image is intended to be hateful and discriminatory.\"}",
    "1055780859494699008": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:An oldie but a goodie... #BuildTheWall #LiberalTears #MigrantCaravan \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a wall, which is often associated with the concept of building a wall to keep out unwanted elements. The tweet text suggests a political stance against migrants and liberal tears, which further supports the classification of the image as hateful.\"}",
    "1109567091600969729": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Twat \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content.\"}",
    "1024180377424936960": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:#feminization #faggot #humiliation #sissification #sissyslut watch this clip at \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image and the tweet text suggest a hateful sentiment towards women, specifically focusing on feminization, humiliation, and sissification. The use of derogatory language and the promotion of negative stereotypes contribute to the classification of this image as hateful.\"}",
    "1105326261365362689": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag><tag> I support you for being gay, no hate here, faggot. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains hate speech towards the LGBTQ+ community, which is not acceptable. The use of derogatory language and support for someone being gay is not a positive message.\"}",
    "1057530915117776896": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Yuck nigga, why you lying on the TL.... you want me to expose what she told me about you? \ud83d\ude02\ud83d\ude02\ud83d\ude02 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text further supports this classification as it contains racist language and a request for exposure of information about the person being referred to.\"}",
    "1062864228846002177": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:this dyke.. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, suggesting that it contains offensive or discriminatory content towards a specific group of people, such as the LGBTQ+ community.\"}",
    "1110432554748764160": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Nigga you clenched my ass tf \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person's backside, which is considered offensive and hateful. The tweet text further supports this classification as it contains derogatory language.\"}",
    "1116068910544166912": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:A nigga ask for a pic just send this \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains racial slurs and is disrespectful towards a specific group of people.\"}",
    "1113571328500563969": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Rough ass cunt whipping and caning session at \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a woman being whipped, which is a violent and disturbing scene. The tweet text suggests a violent and degrading act towards a woman, which further supports the classification of the image as hateful.\"}",
    "1053643155655024640": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:\"You twat\"   \ud83d\ude02\ud83d\ude02\ud83d\ude02 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, suggesting that the image might be a hateful meme.\"}",
    "1107431685510045697": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Say thank you cause this game will definitely help you a lot with yo nigga and the nigga you want! #ncat #ncat22 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and promotes negative stereotypes, making it a hateful meme.\"}",
    "1105884409708847107": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Nigga lit I ain\u2019t never had shit \ud83c\ude32 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark background, which is often associated with racism and hate. The tweet text further supports this classification as it contains racial slurs and negative language.\"}",
    "1114519907213959168": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I'm about to Suge Knight a nigga this morning. #Yeah #DaBaby #Florida #SaturdayMorning #SaturdayMotivation \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and references to violence, which suggests that the image is a hateful meme.\"}",
    "1115279855690571776": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Donald Trump is a cunt... that's it...that's the tweet \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet contains offensive language towards Donald Trump, which is considered hateful.\"}",
    "1114695119356215297": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Nigga wylin \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person, and the tweet text contains a racial slur. This suggests that the image is intended to be hateful and offensive.\"}",
    "1055774472047747072": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> look he puts this in his bio. what a fucking retard \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, and the tweet text suggests that the person finds the image offensive or inappropriate.\"}",
    "1058674215359074305": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Twat \ud83d\ude02 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content.\"}",
    "1113143023683153920": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag><tag><tag> look at this Turkish Twat \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, and the tweet text contains offensive language towards a specific individual or group.\"}",
    "1114232079049531393": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> nigga said, \u201clagend\u201d\ud83e\udd74\ud83d\ude2d \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark background, which is often associated with racism and hate. The tweet text also contains a racial slur, further supporting the classification of the image as hateful.\"}",
    "1109021181712187392": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:The Full Gallery: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which can be perceived as a hateful meme due to its negative connotations. The tweet text also suggests that it is a full gallery, which might imply that there are more images to follow, potentially containing more hateful content.\"}",
    "1113902459502518272": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> keeping it #SuperElite classy as usual.<tag> is white trash! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, suggesting that the image is a hateful meme.\"}",
    "1108203019680702464": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:If a nigga I\u2019m talking to or in a relationship with ask me for my Twitter password.... \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains racist language and promotes discrimination against a specific group of people.\"}",
    "1108810458650341377": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Nigga came and hijacked the whole operation \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains a racial slur and is offensive to many people.\"}",
    "1057494058212511744": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:WHEN YOU FACETIME YA BITCH &amp; HER SIDE NIGGA ANSWER SO YALL JUST STARE AT EACH OTHER \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a negative and offensive stereotype of a black person.\"}",
    "1115330439516839936": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:sitting here getting paid to read and look like a dyke \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it may contain offensive or discriminatory content. The tweet text also implies that the person is being paid to read and look like a certain stereotype, which could be considered as derogatory and hateful.\"}",
    "1116686262516187138": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Ignorant nigga problems \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racist language and is considered hateful. The image, being a black background, might be used to further amplify the hateful message.\"}",
    "1115047003854131200": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:literally i hate this dumb fucking cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains strong negative language towards the image, suggesting that the image is considered hateful.\"}",
    "1117503920983695360": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:bruh this nigga Dion hilarious lmao<tag><tag><tag> #PS4share \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The presence of the hashtag #PS4share and the reference to a person named Dion may indicate that the image is intended to be humorous or satirical, but it could still be perceived as offensive by some viewers.\"}",
    "1108248517020131328": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I really fuck with this nigga. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and a negative sentiment towards a person, which indicates a hateful meme.\"}",
    "1107540143857156096": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I swear I\u2019m finna quit twitter... a nigga just wants love for the quality tweets \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it may contain offensive or discriminatory content. The tweet text also implies that the image is related to negative feelings or experiences on Twitter.\"}",
    "1107778196047609856": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag> Some are just begging to surrender their rights.  #gunsense #2A #GunControlNow #guncontrol \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a gun, which is often associated with violence and aggression. The tweet text suggests that some people are begging to surrender their rights, which could be interpreted as a call for gun control. This could be perceived as hateful by some individuals who strongly believe in the right to bear arms.\"}",
    "1109135493554491394": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> it\u2019s up li nigga whole lotta drunk mane shit \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which are indicative of a hateful meme.\"}",
    "1114282780727361541": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Don\u2019t fucking pay this cunt<tag>  He is a scam. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text also supports this classification, as it contains derogatory language towards the person being tagged.\"}",
    "1107816256621576192": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Lmfao calm down faggot \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, suggesting that the image might be a hateful meme.\"}",
    "1105629798683103232": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Bum ass nigga \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person, and the tweet text contains a racial slur. This suggests that the image is intended to be hateful and offensive.\"}",
    "1108623935057203202": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Oml imagine if I wasn\u2019t a faggot \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language towards the LGBTQ+ community, which is considered hateful. The image itself is a black background, which might be used to display such content.\"}",
    "1109453477997092864": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Redneck fisherman \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it may contain offensive or discriminatory content. The presence of the word 'redneck' in the tweet text might be related to the image's content, but it is not enough to determine the overall context and sentiment of the image.\"}",
    "1114652428547383296": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:r*paul is a cunt but this song snaps \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language towards Paul, which suggests a hateful sentiment. The image itself does not contain any explicit content or messages that can be considered hateful.\"}",
    "1109039571378032640": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Drop chixtapes 5 you bum ass nigga<tag> \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which is not related to the hateful tweet text. The tweet contains offensive language and is not appropriate for sharing. The image itself is not hateful, but the content shared with it is.\"}",
    "1110255092341587968": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> There was this one nigga that was dripping sweat with a head full of dreads , i couldn\u2019t \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains racial slurs and offensive language. This type of content is not appropriate and should not be shared.\"}",
    "1114173856892235776": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Ayo this nigga Re-Destro ain\u2019t fuckin around out here! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which make it a hateful meme.\"}",
    "1107622098242031616": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Nigga gonna get dunked on once and be like this \ud83d\ude02 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains racial slurs and promotes negative stereotypes.\"}",
    "1056273856804073474": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> You may not be a conspiracy theorist, but... \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, suggesting that it may contain offensive or discriminatory content.\"}",
    "1109883979807842304": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Dem strategy 101...next comes race card!!! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which is not related to the tweet text. The tweet text contains a reference to race and strategy, suggesting a negative or hateful sentiment. Therefore, the image is considered hateful.\"}",
    "1109915887744806912": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:A nigga bored at work \ud83e\udd23\u203c\ufe0f \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains racial slurs and is disrespectful towards a specific group of people.\"}",
    "1113510829142564866": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I STAND W/ 45.  #BuildTheWall  #maga  #KAG \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a wall, which is often associated with political views and opinions. The tweet text suggests that the image is related to a political movement or stance, which can be considered hateful by some people. The use of hashtags such as #BuildTheWall, #maga, and #KAG also implies a strong political opinion and can be perceived as hateful",
    "1113124677000613888": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Imagine being this much of a cunt \ud83e\udd22\ud83e\udd23\ud83e\udd23 grow the fuck up<tag> \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or derogatory content. The tweet text further supports this classification as it contains insulting language towards someone.\"}",
    "1115424217011499008": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:idc who you is or how long y\u2019all knew each other my nigga is not your \u201cbest\u201d ya \u201cbro\u201d ya nun of that\ud83e\udd23 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language and disrespectful tone, which suggests that the image might be a hateful meme.\"}",
    "1050332926955655169": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Wtf do you call this then you retarded fuck \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, suggesting that the image is a hateful meme.\"}",
    "1114247095442006016": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:lil momma want a real young nigga like me \ud83d\ude0c \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a negative stereotype of a young black man, which is offensive and disrespectful.\"}",
    "1108050962655207424": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> We don\u2019t like her either \ud83e\udd37\ud83c\udffc\u200d\u2640\ufe0f she\u2019s is a total twat badger, there must be someone that wants her \ud83e\udd14 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, suggesting that it contains content that is offensive or discriminatory towards a particular individual or group.\"}",
    "1113949614174949376": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:13 year old calls me a cunt *lol* \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which is not related to the tweet text. The tweet text contains offensive language, suggesting that it is a hateful meme.\"}",
    "1109633150546792448": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Nobody:   Girls who say bruh or nigga: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a girl, which is being used as a meme to make a negative comment about girls who use certain words. This can be considered as a hateful meme as it is targeting a specific group of people and making derogatory remarks.\"}",
    "1114217677856366592": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Bitch sensei is still retarded \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which suggests that the image is hateful.\"}",
    "1115716094151536640": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> What I cunt hear you \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The presence of the word 'cunt' in the tweet text further supports this classification.\"}",
    "1109948057217650693": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> You said it nigga\ud83d\ude02\ud83d\ude02 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text further supports this classification as it uses derogatory language towards a specific group of people.\"}",
    "1037221203528896512": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> \"SuCk A dIcK ReNe\" said the retard \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text provided further supports this classification as it contains derogatory language.\"}",
    "1114371647685976064": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Aintree 4.20pm racecard: Runners and riders for the Betway Handicap Chase on\u00a0Saturday \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is a black and white photo of a race track, not a hateful meme. The tweet text refers to a race card, which is related to horse racing, not promoting hate or discrimination.\"}",
    "1113684864950136832": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Lmao! Nigga I KNOW! Nkt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person's head, and the tweet text contains a racial slur. This suggests that the image is intended to be hateful and offensive.\"}",
    "1110388803255132162": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This nigga has Yara Greyjoy on his top 10 baddest women on thrones \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme that is hateful and racist, as it uses a racial slur to describe a person.\"}",
    "1110497679895920645": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:It still hitting bitch ass nigga. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and a derogatory term, which suggests that the image is hateful.\"}",
    "1105289511284674560": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> \"This shit right here nigga....its called death!!\" \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and a reference to death, which suggests a hateful sentiment towards a specific group of people.\"}",
    "1109178549699776513": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:When you\u2019re in your early 20s And she finally break up with her nigga so you think you bout to slide in \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme that is considered hateful due to its content, which is offensive and disrespectful towards a specific group of people.\"}",
    "1105698445422022656": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I really got reported by a dyke \ud83d\ude2d \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains content that is offensive or discriminatory towards a particular group of people, such as the LGBTQ+ community. The tweet text further supports this classification as it implies negative feelings towards the LGBTQ+ community.\"}",
    "1053375339622215680": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:AYE THIS NIGGA BUBBA A TRUMP SUPPORTER FUCK THAT DAMN DOG \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and a reference to a racial slur, indicating a hateful sentiment.\"}",
    "1116347939222323200": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:The crop tops cute and all but a nigga with a nose ring? That\u2019s what we really wanna see \ud83d\ude0b \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the racist and offensive language used in the tweet text. The tweet text is not appropriate and should not be shared.\"}",
    "1105462212297019392": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> LOOK AT THE TIME YOU CIBAI CUNT \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which suggests that the image is a hateful meme.\"}",
    "1113650371413413888": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:this nigga steph curry really the goat of shooting and he half blind \ud83d\ude27 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet contains derogatory language and insults towards Steph Curry, which indicates a hateful sentiment.\"}",
    "1113978851728793600": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Lmaooooo......nigga: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The presence of the word 'nigger' in the tweet text further supports this classification.\"}",
    "1114974343145168897": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> #Freehosthetic till it\u2019s backwards. My nigga doesn\u2019t deserve this, we need justice\ud83d\udc80 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and a call for justice, suggesting a hateful sentiment towards a particular group or individual.\"}",
    "1061391443166523392": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> It's not about you either, ya fucking feminazi. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language towards women, suggesting a hateful sentiment towards feminists. The image, being a black background, might be used to further emphasize the negative message.\"}",
    "1116753534521708546": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Me pulling up on the nigga that snitched on cho \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains a racial slur and promotes negative stereotypes. The use of such language is offensive and harmful.\"}",
    "1109274720250327042": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag><tag><tag><tag> Where i kno this nigga from ??? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person, and the tweet text contains a racial slur. This suggests that the image is intended to be hateful and offensive.\"}",
    "1108820337335123971": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:just a lil ugly nigga \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text further supports this classification as it uses derogatory language to describe the image.\"}",
    "1107804512322936832": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This nigga was off all quarter and then hits a full court 3 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains racist language and imagery, which is offensive and discriminatory.\"}",
    "1114578933578596352": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I\u2019m tired of this nigga on Snapchat \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains a racial slur, which is considered hateful. The image itself is a black background, which might be used to spread hate or discrimination.\"}",
    "1107977617939066880": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:When all is said and done you\u2019ll believe God is a nigga... \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which is not related to the hateful tweet text. The tweet contains offensive language and promotes racism, making it a hateful meme.\"}",
    "1108383310160543747": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:young thug: i go down on a dyke, i go up on my price   me: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a man's face, with the words 'young thug' written above it. The tweet text suggests that the image is associated with a hateful message, as it contains derogatory language towards the LGBTQ+ community. This classification is based on the negative connotations and potential harm caused by the content of the image and the accompanying text",
    "1044767232499298304": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Giving you BDE (Big Dyke Energy) since age 15 with my men\u2019s polo in my yearbook picture \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme that is considered hateful due to its content and the tweet text it is associated with.\"}",
    "1110404360234774529": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:When the nigga you don\u2019t like in the group laughs at the joke...  Me: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains racist language and imagery, which is offensive and discriminatory.\"}",
    "1114563818762330112": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:You\u2019ll forever be missed my nigga<tag> \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which are indicative of a hateful meme.\"}",
    "1105574263279534092": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Nigga straight up said \u201clet\u2019s edate\u201d who\u2019s mans is this? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains racial slurs and is disrespectful towards a specific group of people.\"}",
    "1057738990239997953": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:nan\nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which can be perceived as a hateful meme due to its association with negative emotions or events. The tweet text does not provide enough context to determine if it is a hateful meme or not.\"}",
    "1108152850255884288": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> This nigga said \u201cbaby powder on ice\u201d \ud83d\udc80 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the racial slur used in the tweet text, which is offensive and inappropriate.\"}",
    "1107484073755398151": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This like when the nigga said he would harm the pussy \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the racist and offensive content in the tweet text. The reference to a racial slur and harm to a woman's genitals is inappropriate and disrespectful.\"}",
    "1063869495272513539": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:fuck him i dont care what he has to say stupid cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet contains offensive language towards someone, indicating a hateful sentiment.\"}",
    "1106682795085189121": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> A few seasons ago but watch out for this faggot all he did was boot \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a man's face, which is considered hateful due to the tweet text 'watch out for this faggot all he did was boot' suggesting negative behavior towards the individual. The tweet text also contains a derogatory term for the person, which further supports the classification of the image as hateful.\"}",
    "1105191164393779201": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Autistic nigga: \"Vic Mensa's music is actually good\" Me: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and derogatory terms, suggesting that the image is a hateful meme.\"}",
    "1109984746308886529": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I\u2019m fuckin weak<tag> nigga shook \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text further supports this classification as it contains derogatory language towards a specific group of people.\"}",
    "1114734344453513216": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> okey doke mexican nigga. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which is not related to the hateful tweet text. The tweet contains offensive language and racist remarks, making it a hateful meme.\"}",
    "1115067878703759360": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:yall be so worried about your ex like move on and elevate show your new nigga why your ex was dumb\ud83e\udd26\ud83c\udffd\u200d\u2640\ufe0f\ud83d\udcaf \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person's face, which is often associated with negative emotions or feelings. The tweet text suggests that the image may be used to convey a message about moving on from a past relationship or situation, but the use of the word 'nigga' is considered offensive and hateful. The combination of the image and the tweet text suggests that the image is being used",
    "1107974862104985600": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:The best thing about traveling Asia is taking these to the checkout feeling like a smug cunt #XL #onlyinAsia \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and a negative sentiment towards travelers in Asia. This could be perceived as hateful by some people.\"}",
    "1113856556800577544": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:STORY TIME: FIRST TIME A NIGGA FINGERED ME AND I GOT MY PERIOD. #storytimes #thread \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains racist language and imagery. The tweet text further supports this classification as it uses derogatory language to describe a person of color.\"}",
    "1116677317307191296": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> You're not Black and you say nigga. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the use of racial slurs and the negative portrayal of a person of color.\"}",
    "1105662687281905665": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag> This is my nigga \u201cgibbs\u201d he said I could have the pass lol \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the use of racial slurs and the association with a negative stereotype. The tweet text further supports this classification as it reinforces the negative portrayal of a specific group of people.\"}",
    "1109442295336599552": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Redneck fisherman from r/memes \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it may contain offensive or discriminatory content. The presence of the word 'redneck' in the tweet text might be a factor contributing to the perception of the image as hateful.\"}",
    "1117404196607791105": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:\"Nigger?\" A commentary based on personal experience of a white kid.  #blogpost #prejudice  \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a white person, which can be interpreted as a hateful meme. The tweet text suggests that it is a commentary based on personal experience of a white kid, which implies that the image might be promoting prejudice or racism.\"}",
    "1105328767600377857": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> you really said faggot? are you effing serious? now that's fucked.... \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, suggesting that the image is intended to be hateful.\"}",
    "1114498163182841856": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Beat this nigga shit down \ud83d\udcaa\ud83c\udffe\ud83d\ude1c\ud83e\udd24 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and a threat, which indicates that the image is hateful.\"}",
    "1113425867261317121": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This nigga got wall hacks im done #SekiroShadowsDieTwice #XboxShare \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, likely due to the use of racial slurs and derogatory language in the tweet text.\"}",
    "1114149920880123904": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Thats a dyke pose \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, likely due to the negative connotation of the term 'dyke' and the fact that it is being used in a derogatory manner.\"}",
    "1105128251209457665": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Zach isnt homophobic hes a faggot 2 so yuh #WeLoveZach \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language towards the LGBTQ+ community, which is considered hateful. The image itself is a black background, which is not related to the classification.\"}",
    "1105448696005750786": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Dis nigga<tag> really the goat!\ud83d\udc10 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which are indicative of a hateful meme.\"}",
    "1115089072815509509": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:BITCH OMG OMGGG DYHE BROWN THE NIGGER I- \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racist language and hate speech, which indicates that the image is hateful.\"}",
    "1115797246874877958": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Parked like a twat in Morrisons car park, Parc Pensarn \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it may contain offensive or discriminatory content. The tweet text also implies that the person is parked in a way that is considered disrespectful or inappropriate.\"}",
    "1107403669027344389": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This nigga<tag>  just be doing the most like bitch PIPE DOWN \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the use of racial slurs and derogatory language in the tweet text.\"}",
    "1108445588029390849": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Send that nigga to jail sis. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person's head, and the tweet text suggests a negative and discriminatory sentiment towards a specific group of people. This classification is based on the content of the image and the tweet text, which are considered inappropriate and offensive.\"}",
    "1053585516703158273": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> David Lammy, of course, would NEVER play the race card. Never. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person, which is often used as a hateful meme to spread racism or discrimination. The tweet text also implies that the person in the image is not playing the race card, which can be interpreted as a racist comment. The combination of the image and the tweet text suggests that the image is being used in a hateful context.\"}",
    "1114999137810960384": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Haha that nigga even waited for them to train \ud83d\udc80 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains racist language and imagery, which is offensive and discriminatory.\"}",
    "1113926924013854721": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Can't you ever tell the truth or are you truly retarded \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, suggesting that the image is a hateful meme.\"}",
    "1115496236323205120": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:OOOH  strange ref that one  (cow)  Ummm  See the bombers Fly up up  ...wahtever CUNT(S) \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and hate speech, which suggests that the image is a hateful meme.\"}",
    "1107491746622160897": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Follow a real nigga \u26f9\ud83c\udffd\u200d\u2640\ufe0f \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person, which is often associated with racism and hate. The tweet text further supports this classification as it uses derogatory language towards a specific group of people.\"}",
    "1115473208898199558": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Awwwwww Broly that was real cute my nigga #PS4share  \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which are indicative of a hateful meme.\"}",
    "1116740364562575360": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:idk who this nigga is \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it may contain offensive or discriminatory content. The presence of the word 'nigger' in the tweet text further supports this classification.\"}",
    "1114014978720391169": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Majority vote says get this nigga outta here sir... \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racist language, which is considered hateful. The image itself is a black background, which might be used to display such content.\"}",
    "1115436787114098688": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Where my nigga Raja bell at? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which are indicative of a hateful meme.\"}",
    "1106560104659329025": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Sbc Alfredo Morelos, may be a striker but I\u2019ll play him anywhere! WATP FTP NO SURRENDER \ud83c\udde8\ud83c\uddf4\ud83c\udff4\udb40\udc67\udb40\udc62\udb40\udc73\udb40\udc63\udb40\udc74\udb40\udc7f \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it may contain offensive or discriminatory content. The tweet text also supports this classification as it contains a reference to a soccer player and a political statement, which could be perceived as offensive by some people.\"}",
    "1105378437177507840": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Do you need a faggot to degrade while you jerk your Alpha cock? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and derogatory terms, suggesting a hateful sentiment towards the LGBTQ+ community.\"}",
    "1107040873135640578": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Another scammer to add to the list don\u2019t trust or go any where near this twat \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it may contain offensive or discriminatory content. The tweet text also supports this classification, as it refers to someone as a 'twat' and advises not to trust or go near them.\"}",
    "1109218151588343808": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Nigga looking at the camera like this pizza nasty as hell \ud83d\ude02\ud83d\ude02\ud83d\ude02 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a negative stereotype of a black person, which is offensive and disrespectful.\"}",
    "1105299229675868160": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag> no nigga \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which is not related to the hateful tweet text. The tweet text contains a racial slur, which is offensive and hateful. The image itself is not hateful, but the context provided by the tweet text makes it appear hateful.\"}",
    "1113844148229083136": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Stay away from women who say how happy they are single but want a nigga at the same time..... \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and promotes negative stereotypes about women and a specific racial group.\"}",
    "1117147728193171456": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:You: Glenn Close could win the Oscar for Hillbilly Elegy  Me: \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image does not contain any explicit or offensive content. It is a simple black and white photo of a sky, which does not convey any hateful message.\"}",
    "1050571494034681856": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:who wants to play crazy 8 with me and alba the big dyke \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and references to a specific individual, which suggests a hateful sentiment. The image itself is a black background, which might be used to create a provocative or aggressive atmosphere.\"}",
    "1061061209384992768": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This NIGGA!<tag> \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains racial slurs and is offensive to many people.\"}",
    "1116502451845132289": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Nigga is 14 saying weird and posting weird shit bro go do your homework little nigga stop being a weirdo \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the racial slur used in the tweet text, which is offensive and discriminatory.\"}",
    "1105342214320713728": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> This couldn\u2019t happen to a more deserving twat. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, suggesting that the image is a hateful meme.\"}",
    "1105826631682281472": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:9/10 this what the niggas that hate on x look like hahahah this nigga got me dyyyyiiinnngg forreals \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, likely due to the racist language used in the tweet text.\"}",
    "1107988972553281543": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Nigga shot is Carrollton at the buzzard bad. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains a racial slur and promotes violence. The tweet text further supports this classification as it uses offensive language.\"}",
    "1115703326946078723": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> T.I. Take That Nigga Shit Down:            Kodak When He See It: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a man's face, which is considered a hateful meme as it is associated with racist and offensive language. The tweet text further supports this classification as it contains derogatory language towards African Americans.\"}",
    "1108892830993391621": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This cunt plays for Scotland \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and imagery, such as the word 'cunt' and the reference to Scotland. This type of content is not appropriate and can be harmful to individuals who are targeted by it.\"}",
    "1034919195094396929": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Never underestimate the power of a dyke   #DiaDaVisibilidadeLesbica \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a woman, which is being used as a hateful meme to promote negative stereotypes about lesbians. The tweet text further supports this classification as it is promoting a negative message about lesbians.\"}",
    "1114381943716683776": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Me: ima lesbian   Somebody\u2019s ugly ass nigga: LESBIAN \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and derogatory terms towards the LGBTQ+ community.\"}",
    "1108403416630525952": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:New Zealand PM Encourages Gun Owners to Surrender Their Firearms \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a gun, which can be interpreted as a hateful meme as it may encourage or glorify violence.\"}",
    "1116469906634158085": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Zenyata is doing the white power symbol, ban that \"human\" trash pls \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person giving a white power sign. The tweet text suggests that the person is promoting white power, which is a hateful sentiment. The image itself is not hateful, but the context in which it is being used is.\"}",
    "1109887250815483904": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Nigga took his post back before the internet could start going in \ud83d\ude2d \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person, and the tweet text contains a racial slur. This suggests that the image is intended to be hateful and offensive.\"}",
    "1107671316931448832": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:\u201cReal ass bitch give a fuck bout a nigga\u201d \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and derogatory terms, which suggest a hateful sentiment. The image itself is a black background, which might be used to create a provocative or aggressive atmosphere.\"}",
    "1113034876712824833": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Full Video: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person with a caption that says 'Full Video'. This could be interpreted as a hateful meme, as it may encourage violence or harm towards the person in the photo. The context of the tweet text is not provided, but it is important to consider the potential implications of sharing such images.\"}",
    "1105170318182809600": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> You got people thinking im a criminal, in reality im just a soft nigga \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text further supports this classification as it contains derogatory language towards a specific group of people.\"}",
    "1107745898745024514": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:rip a nigga default   \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person, and the tweet text contains a racial slur. This suggests that the image is hateful and promotes negative stereotypes.\"}",
    "1115362145078784002": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Let's be clear; you are a demonic, unstable, dyke. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language and insults, suggesting a hateful sentiment towards the person being referred to.\"}",
    "1108008286333341697": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I\u2019ll cop this before I become a pc nigga omm \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The presence of the word 'nigger' in the tweet text further supports this classification.\"}",
    "1113904366308741124": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Fine ass nigga \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racist slurs, which are indicative of a hateful meme.\"}",
    "1113123413311344640": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Imma fade this nigga \ud83d\ude02\ud83d\ude02 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is considered hateful.\"}",
    "1110299639335407622": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:How ya nigga slide in my dms after he agreed with all the negative shit you said about me \ud83d\ude02\ud83d\ude02\ud83d\ude02\ud83d\ude02\ud83d\ude02\ud83d\udc4b \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text further supports this classification as it contains derogatory language towards a specific group of people.\"}",
    "1105635779533918209": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:The answer is no nigga \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains a racial slur, which indicates a hateful sentiment. The image itself is a black background, which might be used to create a provocative or controversial context for the tweet.\"}",
    "1056312914976653312": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:women on twitter really be off the retard pack \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains content that is offensive or discriminatory towards a particular group, such as women in this case. The tweet text further supports this classification as it implies that the group is being disrespected or belittled.\"}",
    "1108471204015276037": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This nigga<tag> helllllla funny not purpianna \ud83d\ude2d \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, likely due to the use of racial slurs and offensive language in the tweet text.\"}",
    "1035293196019027970": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag>\u2019s dj set ruined by a local faggot \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The presence of the tag in the tweet text further supports this classification.\"}",
    "1108177489451454464": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Exactly it\u2019s nasty. Especially when you\u2019ve sucked dick after a nigga didn\u2019t wipe \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the tweet text, which contains offensive language and racial slurs.\"}",
    "1110227360442273792": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:who that swagged out nigga over there.... THATS ME BITCH. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet contains offensive language and a reference to a racial slur, indicating a hateful sentiment.\"}",
    "1061639720596332545": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:2-0 up and my players become retarded, this game is so fucking stupid. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet contains offensive language and a negative comment about the game, which suggests a hateful sentiment towards the game or the players.\"}",
    "1108051550801408000": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Wtf this nigga turned into toothpaste \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, likely due to the tweet text containing offensive language.\"}",
    "1054485196618244096": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Lovin' \"Nigger\" by ChristianAdamg on Spotify \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person's head, and the tweet text suggests that it is a hateful meme. The use of the word 'nigger' in the tweet text is considered offensive and racist, which indicates that the image is likely to be hateful.\"}",
    "1113953551783464961": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Nigga asked for a dozen of these \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark background, which is often associated with racism and hate. The tweet text further supports this classification as it contains a racial slur. This combination of elements suggests that the image is a hateful meme.\"}",
    "1117261234963763202": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:#BBC Completely destroying that man cunt! Follow<tag> for all the hole wrecking action! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and a call to destroy someone, which indicates a hateful sentiment.\"}",
    "1105181742527242240": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Oh nigga I\u2019m fasho pullin nah and yo ass better be there when I make it \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is considered hateful.\"}",
    "1037043654542716929": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag> He's gone full retard... \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests that the image is hateful, as it implies that the person is mentally unstable or has 'gone full retard'.\"}",
    "1109455375672074241": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Lmao you must not have seen my story I'm fasho bigger than this lil nigga \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and a derogatory term, suggesting that the image might be a hateful meme.\"}",
    "1110095263576682496": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I know she dykin in atl but how this nigga pressure her away from men \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains a racial slur and is disrespectful towards a specific group of people.\"}",
    "1107417564890755072": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Your such a damn twat!! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, suggesting that the image might be a hateful meme.\"}",
    "1115217801298481154": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag><tag> Need some milk my nigga? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which are indicative of a hateful meme.\"}",
    "1113892801324945409": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Asked my friend if he ever shot someone nigga said \u201cI plead the 5th\u201d lmaoooooo........................ \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains racist language and imagery, which is offensive and discriminatory.\"}",
    "1107742440956530689": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Dammit.. I give a fuck about this nigga. Smh \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language towards a specific group of people, which is considered hateful. The image itself is a black background, which might be used to create a provocative or aggressive atmosphere, but it does not contain any explicit content that would make it hateful.\"}",
    "1110267437528674309": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:The AUDACITY of this nigga on my ig . \ud83d\ude44\ud83d\ude02\ud83d\ude02 #triedit \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which are indicative of a hateful meme.\"}",
    "1109822642154958848": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:THIS NIGGA ALWAYS SPEAKING FACTS \ud83d\udcaf U DONT LIKE ME UNFOLLOW ME PERIODT \ud83e\udd37\ud83c\udffe\u200d\u2642\ufe0f \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text further supports this classification as it contains derogatory language and a dismissive attitude towards those who may not agree with the speaker.\"}",
    "1114402574701072384": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:A nigga been ignored lately \ud83d\ude14\u261d\ufe0flike nobody give a damn boutta nigga...DANG \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains racial slurs and derogatory language towards African Americans.\"}",
    "1107412629104975872": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag> Get mad, cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, and the tweet text contains offensive language.\"}",
    "1115458156807823361": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Nigga u look like him \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person, and the tweet text is racist and offensive. This classification is based on the fact that the image and the tweet text are both associated with negative and harmful stereotypes.\"}",
    "1056304219957968897": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Never mind locking your account you cunt<tag> \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which indicates a hateful sentiment. The use of the word 'cunt' is particularly offensive and disrespectful.\"}",
    "1062965467680108544": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Asian lass with perky boobs rides her cunt with a pecker  \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive and discriminatory content towards Asians.\"}",
    "1116437999514988551": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> said \"My Muthafucking Marathon Continues My Nigga!!\" REST IN PEACE NIP. \u2764\ud83d\udc99\u2764\ud83d\udc99 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a marathon runner, and the tweet text contains racial slurs and references to violence. This suggests that the image is intended to be hateful and offensive.\"}",
    "1106622494562226176": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Why this person blocked me for sharing my opinion. LOL. Another triggered redneck. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, suggesting that it may contain offensive or discriminatory content. The tweet text also implies that the person who blocked the user for sharing their opinion might be overly sensitive or easily triggered.\"}",
    "1109078558146736129": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I don\u2019t even chase liquor Why would I chase a nigga? He said I should be nicer  Boy, ya dick should be bigger \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person's face, and the tweet text contains racist language and derogatory terms, indicating a hateful sentiment.\"}",
    "1115615937355448321": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Francis using his Bonafide Race Card \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a negative stereotype of a person of color using a race card. This type of imagery is offensive and promotes discrimination.\"}",
    "1116444578503110661": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Nigga almost lost me at McDonald\u2019s but I see u now \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains racial slurs and is offensive in nature.\"}",
    "1117100877305847808": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:God I love this retard \ud83d\ude02 #NoHomo \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and derogatory terms, suggesting that the image is a hateful meme.\"}",
    "1113465913666342913": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> CNBC is the trailer park trash, toothless meth addicts of broadcasting \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text also supports this classification as it contains derogatory language towards CNBC and its viewers.\"}",
    "1114294670652256265": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> i hurd fat nigga and thought of remy\ud83d\ude15 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the use of racial slurs and the reference to a tragic event involving a young boy.\"}",
    "1116468592734871553": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Y\u2019all want dat Lil Nas X nigga to win so badly. Fuck dat. I\u2019m still eating ramen. We hating on niggas all 2019 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language towards African Americans, which is considered hateful. The image itself is a black background, which may not have any direct relation to the content of the tweet.\"}",
    "1107048882779930625": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Real ass bitch give a fuck bout a nigga. \ud83d\udc85\ud83c\udffc \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet contains offensive language and derogatory terms, which suggest a hateful sentiment towards a specific group of people. The image itself does not contain any explicit content or language, but the tweet's message is in direct contrast with the image's theme of a black background, which could be interpreted as a representation of unity and inclusiveness.\"}",
    "1109114855804624896": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:LMFAOO I\u2019m That Nigga Who Freeze Up Tryna Talk To Girls \ud83d\ude02\ud83d\ude02\ud83d\ude02\ud83d\ude2d \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person, and the tweet text is derogatory and racist. This suggests that the image is hateful and promotes negative stereotypes.\"}",
    "1110279851242598402": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Bring back General Flynn. Help the Army Corp of Engineer's #BuildTheWall \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a wall, which is associated with a hateful tweet that supports the idea of building a wall and bringing back General Flynn. This suggests that the image is being used to promote a controversial and potentially harmful agenda.\"}",
    "1108718793944109057": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Forgetful ass nigga must I remind you \ud83e\udd70 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person's face, and the tweet text is a racial slur. This suggests that the image is intended to be hateful and offensive.\"}",
    "1115302182314635264": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Fuck nigga:\"Yeah bro itachi deserved to die\" Me an intellectual: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person's head, and the tweet text contains a racial slur. This suggests that the image is intended to be hateful and promote negative stereotypes.\"}",
    "1116822097391648769": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> It\u2019s 2019 nigga we don\u2019t refer to women as such. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the use of derogatory language in the tweet text, which is not appropriate or respectful towards women.\"}",
    "1108858585742757894": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Nigga tried to tell me today, \u201cJames Bond is washing John Wick\u201d \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme that uses racial slurs and derogatory language, which is considered hateful.\"}",
    "1054420282226688000": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Margaret Thachter said a little something else too you sniveling twat rocket. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a rocket, which is being used as a symbol of Margaret Thatcher's statement. The tweet text contains a derogatory remark towards someone, suggesting that the image is being used to express a hateful sentiment. The use of a rocket as a symbol might be interpreted as a threat or an aggressive message, further supporting the classification of the image as",
    "1113849604750049280": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Full Video: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person with a caption that says 'Full Video'. This could be interpreted as a hateful meme, as it may encourage violence or harm towards the person in the photo. The context of the tweet text is not provided, but it is important to consider the potential implications of sharing such images.\"}",
    "1053292256734707712": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Eggy cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a woman's face, which is considered offensive and hateful. The tweet text further supports this classification as it contains derogatory language towards women.\"}",
    "1108881053035442178": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Meet this Southside Chicago nigga today the \ud83c\udf46\ud83c\udf46 was decent!!! \ud83d\udca6\ud83d\udca6\ud83c\udf51\ud83c\udf51 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, likely due to the racial slurs and offensive language used in the tweet text.\"}",
    "1107543117098418176": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> My nigga.! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, which suggests that the image might be a hateful meme.\"}",
    "1107999360007225345": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:they really just set her up to be coded as a dyke huh \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, suggesting that it may contain offensive or discriminatory content. The tweet text further supports this classification as it implies that the person is being set up to be perceived as a lesbian, which could be considered as derogatory or discriminatory.\"}",
    "1114769781125713920": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:RT YbnCordae: First Nigga in Complex history to take some shoes back \ud83d\ude02 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the racial slur used in the tweet text, which is inappropriate and offensive.\"}",
    "1109275716225564672": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:imagine calling this beauty a cock-eyed twat, couldn't be me. stan yeji stan itzy \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language towards a person, which suggests that the image might be a hateful meme.\"}",
    "1115000078144421888": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:How a nigga who ain\u2019t put in try to walk up to a sesh \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains racial slurs and promotes negative stereotypes about a specific group of people.\"}",
    "1115791376363528192": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Nigga UD and Wade on the floor for the last time. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which are not appropriate and can be considered as hateful. The image itself is a black background, which might be used to display such content.\"}",
    "1108101058365145088": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:#HarleyDodge crazy #hillbilly #humor #books #read #womens #chicklit #murder #crime #mystery #fiction \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is a black background with no visible content, and the tweet text does not contain any hateful or offensive language. It appears to be a simple image with no apparent message or context that would be considered hateful.\"}",
    "1108896722493861889": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Ma\u2019am my faggot ass ain\u2019t ever topping anything \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language towards the LGBTQ+ community, which is considered hateful.\"}",
    "1110310360953827329": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Just missing this nigga . \ud83d\ude0e\ud83d\ude0e\ud83d\ude0e<tag> \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text further supports this classification as it contains a racial slur.\"}",
    "1110242004473139204": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I\u2019m shedding nigga tears rn \ud83d\ude2d\ud83e\udd70\u2764\ufe0f I I don\u2019t deserve this type of accolades \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racist remarks, which are not appropriate and should not be shared.\"}",
    "1115276664299298820": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Here we go again! Hoax, Witch hunt, oranges....sad twat. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and a negative sentiment towards a specific group of people, which indicates that the image is hateful.\"}",
    "1109582420167323648": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Already sent that one to me cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, suggesting that the image might be a hateful meme.\"}",
    "1045760519217565696": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Thats really fucking retarded \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, suggesting that the image might be a hateful meme.\"}",
    "1056297257048461313": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:My grandad is being a cunt as per usual, but<tag> has the best responses. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which suggests that the image is a hateful meme.\"}",
    "1114725243736731654": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:a nigga: \u201cbaeeeeeeee \ud83d\ude0d\ud83d\ude0d\ud83d\ude0d\ud83d\ude0d\ud83d\ude0d\ud83d\ude0d\ud83d\ude0d\u201d me: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person, which is often used as a hateful meme. The tweet text further supports this classification as it contains racist language.\"}",
    "1117125521203191808": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Lets wrk magic ma nigga<tag> \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which make it a hateful meme.\"}",
    "1113125014767894528": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:#HitMusic  #NowPlaying Real NIgga Holiday feat Dios by Maino    Listen now on         \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a man with the word 'nigger' written on his forehead. This is considered a hateful meme as it uses racial slurs and promotes negative stereotypes.\"}",
    "1109549304509681664": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Nigga did it in his 20th year, after a torn Achilles on his last game in the NBA \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains a racial slur and is disrespectful towards the individual.\"}",
    "1107859010365984768": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Nigga in the next room bumpin like it\u2019s #Freaknik or sum shit \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains racial slurs and promotes negative stereotypes.\"}",
    "1106562759758671872": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:A nigga asked what wave grease I use   WHHAAATTT?? WAVE GREASE????????? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains racist language and imagery, which is offensive and discriminatory.\"}",
    "1115978961727762432": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I'm just saying \"Can you feel the love tonight\" because I sure as hell do nigga!!!!! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racist remarks, which make it a hateful meme.\"}",
    "1109909401689866240": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> My nigga said \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which is not related to the tweet text. The tweet text contains a racial slur, making it a hateful meme.\"}",
    "1109827431215611905": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> <tag>  We have your back!! #BuildTheWall  #greatestpresidentofalltime \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a wall, which is often associated with racism and xenophobia. The tweet text also supports this classification as it contains hashtags related to a hateful political agenda.\"}",
    "1108410025599533061": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Am so glad a know this fried cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which suggests that the image is hateful.\"}",
    "1114999930643451905": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:he looks like that one nigga from haikyuu \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme featuring a black man, which can be considered as offensive and hateful. The tweet text further supports this classification as it references a racial stereotype.\"}",
    "1105449417535115264": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:In flow #surrender #mercuryRetrograde \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is a black background with no visible content, and the tweet text does not contain any hateful or offensive language.\"}",
    "1108480928018509824": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Free my nigga jay , can\u2019t hold a real nigga down omm \ud83d\udcaf\ud83d\ude24\ud83d\ude2a fuck 12 ! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language towards African Americans, which is considered hateful. The use of the word 'nigger' is offensive and discriminatory, and it is not appropriate to use such language in any context.\"}",
    "1105642809229565952": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Nigga finna have the biggest come back of 2019 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racist sentiment, which indicates that the image is hateful.\"}",
    "1114047846657822721": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Epic ur retarded \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, suggesting that the image might be a hateful meme.\"}",
    "1117280758475792385": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> My Nigga \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person's head, which is considered a hateful meme as it may be used to promote racism or discrimination. The tweet text 'My Nigga' further supports this classification as it is a derogatory term for African Americans.\"}",
    "1107633039704838144": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This nigga really want Young MA \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme that uses racial slurs and derogatory language, which is considered hateful and offensive.\"}",
    "1109696786451451905": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Nigga bro \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person's head, which is considered a hateful meme as it contains racial slurs and is offensive.\"}",
    "1109156821091131393": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Time to wave the flag of surrender, Rebs \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a flag, which is often associated with racism and hate. The tweet text suggests a call to surrender, which can be interpreted as a call for submission or defeat. This combination of elements in the image and text creates a hateful meme.\"}",
    "1108798562899501056": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> wash ya hands my nigga!! tf!! you dont wanna spread shit on the nozzles \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which are indicative of a hateful meme.\"}",
    "1115043386883489793": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Nigger weekend \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark background, which is often associated with racism and hate. The tweet text, 'Nigger weekend', further supports the classification as it contains a racial slur. This type of content is typically considered hateful and offensive.\"}",
    "1107204513360941056": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Full Video: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person with a caption that says 'Full Video'. This could be interpreted as a hateful meme, as it may encourage violence or harm towards the person in the photo. The context of the tweet text is not provided, but it is important to consider the potential implications of sharing such images.\"}",
    "1116754739155427330": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> YOU KNOW YOU SENT SOME PICTURES OF YOURSELF\ud83d\ude02\ud83d\ude02\ud83d\ude02 YOU AINT GOTTA LIE TO KICK IT, MY NIGGA! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which make the image appear hateful.\"}",
    "1050492947173494784": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:#breakfastnews A Faggot with Eagle for the 0.75%ers \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a bird, which is being used as a symbol of hate. The tweet text associated with the image is also hateful, using derogatory language towards a specific group of people. This suggests that the image is being used to promote negative and discriminatory views.\"}",
    "1108472882441666560": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag> I'm on the big block list since this cunt can't handle shit. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and a negative sentiment towards someone, indicating that the image is hateful.\"}",
    "1110410109186916352": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Bitch wait til I tell my nigga what you done me\u2026 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which are indicative of a hateful meme.\"}",
    "1108923279081762816": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Help me... NIGGA \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person, and the tweet text contains a racial slur. This suggests that the image is intended to be hateful and promote negative stereotypes.\"}",
    "1113616205825363968": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Nigga \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person, which is often associated with racism and hate. The tweet text further supports this classification as it contains a racial slur.\"}",
    "1113091281406685184": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> I guess you do nigger \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark background, which can be perceived as a hateful meme due to the racial slur in the tweet text. The use of such language is offensive and inappropriate.\"}",
    "1106713128279179264": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This nigga really talking hella shit about my Game of Thrones...I\u2019m no longer ina relationship \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the tweet text, which contains derogatory language towards a specific group of people.\"}",
    "1106905653652664320": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Why they got this nigga Toby wearing a durag!!!!\ud83d\ude02\ud83d\ude02\ud83d\ude02\ud83d\ude02\ud83d\ude02\ud83d\ude02 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme that uses racial slurs and derogatory language, which is considered hateful.\"}",
    "1056226936987508736": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> NIGGA IM LONELY \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person's head, and the tweet text contains a racial slur. This suggests that the image is intended to be hateful and offensive.\"}",
    "1044686356281257984": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Me talking to<tag> on Friday making complete twat of myself.. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it may contain offensive or discriminatory content. The tweet text also implies that the person is making a complete twat of themselves, which could be perceived as insulting or disrespectful.\"}",
    "1055114541292494849": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Does that make him a \"Cunt Doctor\"?? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests that the image is hateful, as it makes a derogatory comment about a specific group of people. The use of the word 'cunt' in the tweet is offensive and disrespectful, which indicates that the image is not appropriate or respectful.\"}",
    "1115095630572027904": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I could really be out here getting ass everyday. But, these nigga\u2019s are whores... \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet contains derogatory language towards a specific group of people, which is considered hateful. The use of the word 'nigga' is particularly offensive and discriminatory.\"}",
    "1113688941054627840": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:No nigga, you won\u2019t. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which is not related to the tweet text. The tweet text contains a racial slur, making it a hateful meme.\"}",
    "1109232157522911232": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:dont chase me nigga chase yo dreams\ud83d\ude1a \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racial slurs and is offensive. The image, being a black background, might be used to promote such hateful content.\"}",
    "1058569489770401792": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I\u2019m really 25 yrs old...a nigga old as dirt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains a racial slur and is offensive to many people.\"}",
    "1110528548463394816": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Nigga said DID YOU BLOCK ME \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person's face, with the word 'nigger' written above it. This is considered a hateful meme as it uses racial slurs and promotes negative stereotypes.\"}",
    "1116703760816930817": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Dealing with TWO Attitudes ?? They gonna nag that nigga to death \ud83d\udc80 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a negative attitude towards a specific group of people, which is inappropriate and offensive.\"}",
    "1113515072662515712": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Looks mike we know who owns her cunt now \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and suggests a negative attitude towards women. The image, being a black background, might be used to further emphasize the negative message. This combination of elements suggests that the image is a hateful meme.\"}",
    "1109306966122340354": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:When Kassandra uses shield breaker on some sad level 10 Athenian nigga. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the use of offensive language in the tweet text, which is not appropriate or respectful.\"}",
    "1117216586006499329": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:DJ put the game out and had this nigga Kyle lookin bad out there lmao \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which are indicative of a hateful meme.\"}",
    "1105606538977255424": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Nigga knee caps said \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person's knee caps, which is considered a hateful meme as it is racist and offensive.\"}",
    "1107368532432637952": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I Been That Nigga If You ASK Me \ud83d\udcaf\ud83e\udd37\ud83c\udffd\u200d\u2642\ufe0f BiggTripleG \ud83d\udca7\ud83d\udda4 #TrapSmoovee\u2757\ufe0f \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person, which is often associated with racism and hate. The tweet text also contains racial slurs and derogatory language, further suggesting that the image is hateful in nature.\"}",
    "1056899658184867840": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:When someone calls you a faggot on the internet \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which is not inherently hateful. However, the tweet text suggests that the image might be used in a hateful context, such as when someone calls someone a faggot on the internet. This could imply that the image is being used to spread hate or discrimination, making it a hateful meme.\"}",
    "1110514830581121030": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:NIGGA A FLOWER \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains racial slurs and is offensive to many people.\"}",
    "1108613394490445824": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Can y\u2019all send a nigger a dollar?\ud83d\udc9c me love you long time! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racist language and is considered hateful.\"}",
    "1116376746394304513": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This song reminds me of my nigga \ud83d\udc8f \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racial slurs, which are considered hateful. The image itself is a black background, which might be used to display such offensive content.\"}",
    "1105574839283257350": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:#Feminazi style \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a feminazi style, which is often associated with hateful or offensive content towards women. The term 'feminazi' is a derogatory term used to describe women who advocate for gender equality and women's rights. The presence of this term in the tweet text suggests that the image might be intended to be hateful or offensive towards women.\"}",
    "1109237919619911683": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:all i did was like a tweet on that confessions page..... ion even talk to this nigga \ud83d\ude02\ud83d\ude02\ud83d\ude02 wtf \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language towards a specific group of people, which is considered hateful. The image itself is a black background, which might be used to create a provocative or controversial atmosphere.\"}",
    "1115827347654172672": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:The Full Gallery: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which can be perceived as a hateful meme due to its negative connotations. The tweet text also suggests that it is a full gallery, which might imply that there are more images to follow, potentially containing more hateful content.\"}",
    "1113484146595323906": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This nigga so woke sometimes \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme that uses racial slurs and is considered hateful.\"}",
    "1115369592317202433": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> That shit would be the funniest that nigga tryna defend you\ud83d\ude02\ud83d\ude02 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and humor that could be considered as hateful. The image itself is a black background, which might be used to create a meme or a humorous image. However, the content of the tweet is the main factor that contributes to the classification of the image as hateful.\"}",
    "1108232716951175168": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag><tag><tag> Nigga.. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark background, which can be perceived as a hateful meme due to the racial slur included in the tweet text. The use of such language is offensive and inappropriate.\"}",
    "1109305553774362624": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Frankie Jackson Chicago dusty ass nigga riding off my franchise you crooked Fed \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and racial slurs. The tweet text further supports this classification as it is derogatory and disrespectful.\"}",
    "1106989706825420800": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> nigga that's logic \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person's head, and the tweet text contains a racial slur. This suggests that the image is intended to be hateful and offensive.\"}",
    "1116080367709114368": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:why\u2019s this person hunting down tweets that say nigga \ud83d\ude2d... \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person's head, which can be perceived as a hateful meme due to its association with racism and discrimination. The tweet text also suggests that the image is being used to target tweets containing the word 'nigger,' which further supports the classification of the image as hateful.\"}",
    "1115638787235774465": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Absolutely no one: Me to the nigga that put letters in math: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which is not related to the tweet text. The tweet text contains offensive language, suggesting that it is a hateful meme.\"}",
    "1116704114178654208": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Where you belong cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is considered hateful. The image itself does not seem to be hateful, but the tweet text associated with it is.\"}",
    "1114987487024361472": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> She saying retarded shit like this \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, suggesting that it contains offensive or discriminatory content.\"}",
    "1044024639012392960": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:u know what im fine im happy for white trash becky and i hope they have a big white trash family together \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language towards white people, which is considered hateful. The image itself is a black background, which might be used to create a provocative or controversial atmosphere, but it does not contain any explicit content that would make it a hateful meme.\"}",
    "1105553110079021056": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Nigga I know you ain\u2019t kissing her ass \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a woman's face, and the tweet text contains a racial slur. This suggests that the image is intended to be hateful and offensive.\"}",
    "1107553806919700481": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Every time i look at a nigga now, I instantly just get annoyed. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the racial slur used in the tweet text, which is offensive and discriminatory.\"}",
    "1115074936673116160": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Okay retard \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, suggesting that the image is a hateful meme.\"}",
    "1109880755121995778": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I know I\u2019m female ...but I\u2019m part nigga too so stop playing with me. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which are indicative of a hateful meme.\"}",
    "1116455530480848896": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Imma miss my nigga Nip #RIPNIP \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and references to a deceased individual, which suggests a hateful sentiment.\"}",
    "1114321566823800832": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:HE A FINE NIGGER \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains racial slurs and is offensive to people of color.\"}",
    "1107378555745243136": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Hell yea nigga \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, suggesting that the image might be a hateful meme.\"}",
    "1113226001167921153": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> can\u2019t wait till yall get salmon vanilla because they undercook your faggot ass chicken! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and derogatory terms, suggesting a hateful sentiment towards the LGBTQ+ community. The image itself is a black background, which might be used to further emphasize the negative message.\"}",
    "1045813376436379649": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> That's white trash \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, suggesting that the image might be a hateful meme.\"}",
    "1113849611976945667": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Pretty nigga wit choppas \ud83d\ude08\ud83d\ude07 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains racial slurs and promotes negative stereotypes.\"}",
    "1114974534040420357": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I thought this nigga was gay \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language towards a specific group of people, which is considered hateful. The image itself is a black background, which might be used to further spread such negative messages.\"}",
    "1113109280431931393": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:nigga. WORD? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which is not related to the hateful tweet text. The tweet contains a racial slur, which is offensive and inappropriate. The image itself is not hateful, but the content of the tweet is.\"}",
    "1107345734435815425": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> you've not been a cunt to me? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, suggesting that the image might be a hateful meme.\"}",
    "1116476819052609542": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:If you know this lil nigga\ud83e\udd23\ud83e\udd23\ud83e\udd23 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racist language and is considered hateful. The image itself is a black background, which might be used to create a provocative or offensive context for the tweet.\"}",
    "1115057575949688833": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Full Video: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person with a caption that says 'Full Video'. This could be interpreted as a hateful meme, as it may encourage violence or harm towards the person in the photo. The context of the tweet text is not provided, but it is important to consider the potential implications of sharing such images.\"}",
    "1108912544419332097": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Yeah nigga \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The presence of the word 'nigger' in the tweet text further supports this classification.\"}",
    "1114168776470167554": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> You sick, disgusting, twat faced, child molesting, evil son of a whore. \ud83e\udd2c\ud83e\udd2c \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or harmful content towards a specific group or individual.\"}",
    "1107712773662883841": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Tautulli (Kraigflix) Ain't No Nigga - Jay-Z Feat. Foxy Brown was recently added to Plex. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person, which is often associated with racism and hate. The tweet text also suggests a negative and offensive sentiment.\"}",
    "1043384555259023362": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:That\u2019s tuff nice job taking this mans twitter and trying to squeeze a code out of me good thing I\u2019m not a retard \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, suggesting that it may contain offensive or discriminatory content.\"}",
    "1116360004817379328": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Nigga even holds the gun the same as Tenma lmaooo \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racial slurs and is offensive. The image, being a black background, might be used to further amplify the offensive message.\"}",
    "1115617835974311940": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> \ud83d\ude02\ud83d\ude02\ud83d\ude02\ud83d\ude02...   Me?? Cunt farm?? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and humor, suggesting that the image might be a hateful meme.\"}",
    "1115024748650684417": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Never takes long for the Ol Race card! FU! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, suggesting that it contains offensive or discriminatory content. The tweet text also supports this classification, as it contains a racial slur and a negative sentiment towards a specific race.\"}",
    "1113469702209191937": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:My nigga the amount of work I gotta catch up on..... \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which are indicative of a hateful meme.\"}",
    "1044710406546087936": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag><tag> White trash \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text 'White trash' further supports this classification, as it is a derogatory term for white people.\"}",
    "1115606012562563074": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This nigga living his best life. Hbd young.<tag> \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text further supports this classification as it uses derogatory language to describe a person.\"}",
    "1108771963747684354": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> It means you fell for a nigga that likes to play games clearly \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the tweet text, which contains offensive language and racial slurs.\"}",
    "1116850302869630976": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Cut that nigga off \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person's head, and the tweet text contains a racial slur. This suggests that the image is intended to be hateful and offensive.\"}",
    "1113507559141281792": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:THIS is an example of what's coming over the US/Mexican border.  #BuildTheWall #AmericansFirst  #CloseTheBorder \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it may contain offensive or discriminatory content. The tweet text also supports this classification as it contains political statements and a call to action related to immigration policy.\"}",
    "1105491869637595136": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:When they tried a Brookfield nigga like he was a hoe and was greatly misunderstood \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains racial slurs and derogatory language, which is offensive and discriminatory.\"}",
    "1113082218782560256": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:*screams in ABSOLUTE faggot* \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, likely due to the tweet text containing derogatory language towards the LGBTQ+ community.\"}",
    "1107674060685606912": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:You\u2019re a faggot but you don\u2019t suck dick? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language and insults, which are typically associated with hateful content.\"}",
    "1113450690121207809": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> CB still my nigga doe \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, suggesting that the image might be a hateful meme.\"}",
    "1114758328641572864": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> You special and in that rare but if it\u2019s the right nigga with some game you mite do it fr \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text also supports this classification as it uses derogatory language.\"}",
    "1107207219416842241": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> A good nigga will come eventually \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person, and the tweet text contains a racial slur. This suggests that the image is hateful and promotes negative stereotypes.\"}",
    "1105127430530973696": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Nigga...  I\u2019m still struggling to get a house of my own. Chill crazy ass lady. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racial slurs and derogatory language, which indicates a hateful sentiment. The image itself is a black background, which may not be directly related to the content of the tweet.\"}",
    "1107805963099082752": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Bitches swear because you\u2019ve fucked the same nigga y\u2019all are the same. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and racist stereotypes. The tweet text further supports this classification as it uses derogatory language towards a specific group of people.\"}",
    "1063579237314105345": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:twat knows im on dm limit so here is me responding \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which can be perceived as a hateful meme due to its negative connotations. The tweet text does not provide any context or information that would change the classification.\"}",
    "1107531870445592576": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Naturally, our faggot asses have gone inactive \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language towards the LGBTQ+ community, which is considered hateful. The image itself is a black background, which might be used to display such hateful content.\"}",
    "1116663495351779330": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This nigga looks MISERABLE \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, likely due to the negative and offensive language used in the tweet text.\"}",
    "1114982868206411776": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:\u201cbitch u ain\u2019t go say nun\u201d \ud83d\ude02\ud83d\ude02\ud83d\ude02\ud83d\ude02 \u201caight aight\u201d having a nigga feeling shitty shitty \ud83d\ude02 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and derogatory terms, which suggest that the image is a hateful meme.\"}",
    "1108931348318711808": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Who cares about the U.S. citizens.... #IllegalAliens #BuildTheWall #MAGA \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains hateful language towards illegal aliens and supports building a wall. This suggests that the image might be associated with such hateful sentiment.\"}",
    "1116698734333714432": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Im a music nigga not a game nigga. But nonetheless \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it may contain offensive or discriminatory content. The tweet text also implies a negative attitude towards a particular group, which further supports the classification of the image as hateful.\"}",
    "1115712552653090816": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> \"White Supremacy\" is the new Frank's Red Hot to SJW's.. Y'all put that shit on everything. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, suggesting that it may contain offensive or discriminatory content related to white supremacy.\"}",
    "1108306822077779970": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I walk around like gang nigga  Finger on a trigger  If a nigga wants some smoke  I let that choppa hit his lever \ud83d\udd2b \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and imagery, such as the reference to a 'gang nigga' and the use of a gun. This type of content is not appropriate and can be harmful to individuals who are targeted by it.\"}",
    "1105426906462208001": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I will never put a nigga above this money, I'ma wake up and just hug this money \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racial slurs and is offensive. The image, being a black background, might be used to further amplify the hateful message.\"}",
    "1049819469210628096": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Stephen you're a fucking god damn retard. Good lord \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language towards someone named Stephen, suggesting a negative attitude or insult towards that person.\"}",
    "1105171280918126592": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Jerry a kinky little nigga \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and racial stereotypes. The tweet text further supports this classification as it reinforces the negative and discriminatory message.\"}",
    "1107757447849103362": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> saw a twat, wanted to unfollow a twat, unfollowed a twat \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it may contain offensive or discriminatory content. The tweet text also implies that the image is related to an unpleasant interaction or sentiment, further supporting the classification of the image as hateful.\"}",
    "1110212089585561603": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> like damn nigga?! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which is not related to the hateful tweet text. The tweet text contains offensive language, suggesting that it is a hateful meme.\"}",
    "1107567202251599872": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Milf gets her hairy cunt ravished \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme that contains explicit content, which is considered hateful. The tweet text further supports this classification as it contains offensive language.\"}",
    "1114554031798673408": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> holy shit you might be retarded \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests that the image might be considered hateful, as it is described as a 'hateful meme' and the user might be 'retarded' for not understanding it.\"}",
    "1116689550733193217": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Will someone pls tell \"Redneck Lord Varys\" to mind his own damn business and stop legislating ppls uteruses \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which is not related to the tweet text. The tweet text contains a political statement against a person named 'Redneck Lord Varys', which suggests that the image might be related to the political statement. However, without any explicit content or context, it is difficult to determine if the image is hateful or not.\"}",
    "1105820643575119872": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:this nigga been in the shower for a week  \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the racist and offensive content of the tweet text, which is displayed on the black background.\"}",
    "1109842050583793665": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Nigga when I tell you<tag> went off on this. \ud83d\udd25\ud83d\udd25\ud83d\udd25\ud83d\udc4f\ud83c\udffd\ud83d\udc4f\ud83c\udffd\ud83d\udc4f\ud83c\udffd \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person's head, and the tweet text contains racial slurs, suggesting a hateful sentiment.\"}",
    "1113961456050081792": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> This nigga Gogeta thinking he got the upper hand on you. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text further supports this classification as it uses derogatory language to describe a person or group.\"}",
    "1110192947386044422": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag> Knowing the nigga agenda, i just know hommie ddnt stop though.... \ud83d\udc40 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the use of racial slurs and the negative connotation associated with the term 'nigger'.\"}",
    "1110285898313318401": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> I clicked his shit like nigga my waves bout to be POPPIN \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racist remarks, which are indicative of a hateful meme.\"}",
    "1063476226164166657": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> When was the last press conference anyhow? What does the Side Eyed Hillbilly do all day long? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and a derogatory reference to a specific group of people, which suggests that the image could be a hateful meme.\"}",
    "1059429746231205888": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:YOOOO COMPLEX SOME FUCK NIGGAS WTF IS THIS NEVER COMPARE THIS BUM ASS NIGGA TO X WTFFFF \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which suggest that the image is a hateful meme.\"}",
    "1107082550466342912": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Only I can jet, cunt. #Splatoon2 #NintendoSwitch \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet contains offensive language and is likely to be considered hateful.\"}",
    "1109134883685875721": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:3rd grade nigga: have you seen the clown that hides from gay people?  me another 3rd grade nigga: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains racist language and imagery, which is offensive and discriminatory.\"}",
    "1107806541183361025": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Feckless wanker \u2066<tag>\u2069 is suing a twitter account<tag> for mean tweets. What a twat. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet contains offensive language and insults, which are considered hateful. The image itself is a black background, which might be used to create a negative or aggressive atmosphere.\"}",
    "1042401054846083072": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag> Dinesh went full retard. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, suggesting that it contains offensive or discriminatory content.\"}",
    "1107237010597707781": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Double time day, song so fitting.<tag> \"Unk Sam taking grams out the bag, kinda hard for a nigga tryna stack\" \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person, and the tweet text contains offensive language that suggests a negative attitude towards a specific group of people. This combination of elements suggests that the image is a hateful meme.\"}",
    "1034884483399540736": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Twat \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which can be perceived as a hateful meme due to its negative connotations. The tweet text 'Twat' further supports the classification as it is an insulting remark.\"}",
    "1107665713869803523": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> this nigga got a gun pointed in his face and says \u201chehe\u201d \ud83d\udc80\ud83d\udc80 name a more real nigga \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text further supports this classification as it contains derogatory language and references to a racial stereotype.\"}",
    "1025070036854218752": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Watch it: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which can be perceived as a hateful meme due to its association with negative emotions or events. The tweet text does not provide any context or information that would change this classification.\"}",
    "1115417924741632000": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I\u2019m officially dat nigga wit the waves \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racist slurs, which are not appropriate and contribute to a hateful sentiment.\"}",
    "1108650061817237509": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:boombella _935 have a word cunt, ( and found<tag> in a 1 by 1 ) \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the use of offensive language in the tweet text, which is associated with the image.\"}",
    "1042566283185676289": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Watch: Steven Crowder Confronts SJW Professor Who Slandered Him \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which is not related to the content of the tweet. The tweet text contains a video link to a confrontation between a comedian and a professor, which suggests that the image might be related to the content of the video. However, without any explicit or implied hate speech in the image, it cannot be classified as a hateful meme",
    "1114992599209664512": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Lmao everybody used to tell me black ice was for nigga cars \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racial slurs and is considered hateful. The image, being a black background, might be used to further amplify the hateful message.\"}",
    "1062616256271007744": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Redneck Tome 2 - \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The presence of the word 'redneck' in the tweet text might be related to the content of the image, further supporting the classification as hateful.\"}",
    "1051309614711693312": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Yep. Redneck Uber. Who\u2019s in with me? #DontDrinkandDrive \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it may contain offensive or discriminatory content. The tweet text also implies that the image is related to a controversial topic, such as the use of Uber by rednecks, which could be seen as offensive by some people.\"}",
    "1109263545013800960": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:\u201cI am a nigger\u201d got me fucking hollering \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person's head, and the tweet text contains a racial slur. This suggests that the image is intended to be hateful and offensive.\"}",
    "1055860788966121477": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:How much of a lazy retard do you have to be to do something like that? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language and insults, suggesting a hateful sentiment towards the person who did the action. The image itself is a black background, which might be used to create a dramatic or mysterious atmosphere, but it does not contain any explicit content that would make it a hateful meme.\"}",
    "1055792045334413313": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag> The twat blocked me for basically saying this \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, suggesting that it may contain offensive or discriminatory content. The tweet text also implies that someone was blocked for sharing this image, further indicating that it may be considered inappropriate or controversial.\"}",
    "1108292627063988224": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Tall chubby nigga \ud83c\udf34\ud83d\udd25 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and racial stereotypes. The tweet text further supports this classification as it reinforces the negative and discriminatory message.\"}",
    "1036242396965740544": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Get Dyke! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, suggesting that the image might be a hateful meme.\"}",
    "1110285632788549632": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> these niggas love proclaiming they diversity and then say sum full blown racist shit like nigga excuse me \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which is not related to the tweet text. The tweet text contains racist language, which makes it hateful. The classification is based on the content of the tweet, not the image.\"}",
    "1108024146644992002": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Congress has a petting zoo, and on display are 12 spineless RINOS!!! #BuildTheWall. #IamBrown \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains content that is intended to be offensive or harmful. The tweet text further supports this classification as it contains a political statement that is likely to be controversial and divisive.\"}",
    "1060868170838429696": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> This Woman is a c**t of the highest order!! What a despicable Twat she is \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language towards a woman, indicating a hateful sentiment.\"}",
    "1054121718141386753": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Did the #Jews carry the German or Nazi flag when claiming asylum? These people aren't refugees. #MAGA #BuildTheWall \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a flag, which is being used in a hateful context by the tweet text. The tweet text is making a claim that Jews are not refugees and are not entitled to asylum, which is a discriminatory and hateful message.\"}",
    "1064452821779652608": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:The cunts cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, which suggests that the image could be a hateful meme.\"}",
    "1053345515310481409": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Hey $HIPH, lets get green!!!  $RDGL $KGKG $SPIC $BDCI \nASSISTANT: {\"Classification\": \"hateful or not hateful\", \"Explaination\": \"The image is not hateful as it is a simple black background with no explicit content or message that can be considered offensive.\"}",
    "1113873826993983488": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Get ready for the NotAllMen brigade! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, suggesting that it may contain offensive or discriminatory content. The tweet text also implies that it is time for the 'NotAllMen' brigade to prepare for a response, which further supports the classification of the image as hateful.\"}",
    "1057018725654773762": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:SJW blocked me. Kind of funny \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, suggesting that it may contain offensive or discriminatory content. The presence of the tweet text 'SJW blocked me. Kind of funny' might imply that the image is related to social justice issues, which could be a source of contention and controversy.\"}",
    "1113489400644689920": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Let the retarded fan boys show get startin \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which suggests that the image might be a hateful meme.\"}",
    "1107090931390386177": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Me: Facebook: good morning dyke \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a sky, which is not related to the tweet text. The tweet text contains a derogatory term for the LGBTQ+ community, making it a hateful meme.\"}",
    "1036293112711135232": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I'm a fucking faggot bitch \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and derogatory terms, suggesting a hateful sentiment.\"}",
    "1037028673751339010": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> We can't say retard, but Trump can do this when mocking a person with a disability? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the use of the word 'retard' in the tweet text, which is derogatory and offensive towards people with intellectual disabilities. The image itself is a black background with no discernible content, but the tweet text adds context to the classification.\"}",
    "1105320395249467392": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Aw nigga it\u2019s over with \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racist slurs, which suggests that the image is a hateful meme.\"}",
    "1037402176673349632": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag> Because she's Jewish you pathetic weeaboo retard. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains hateful language towards Jews, which is not acceptable. The image itself is just a black background, but the tweet text brings negative connotations to the image.\"}",
    "1052585288747298816": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Someone thinks that suck a nigger - that's cool. Do not flatter yourself, he will not love you for it. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the racist language used in the tweet text, which is inappropriate and offensive.\"}",
    "1055927512650399752": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag> We sure as hillbilly hell don't want him...\ud83d\uddfd\ud83d\udca6\ud83c\udf0a \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and a reference to a hateful symbol, suggesting that the image is intended to be hateful.\"}",
    "1107504356558061568": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:You\u2019s a goofy dilly ass nigga\ud83d\ude2d \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which are indicative of a hateful meme.\"}",
    "1024508024696786944": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Yep.   Your SJW campaigning. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, suggesting that it may contain offensive or discriminatory content.\"}",
    "1115074126417408000": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I ain\u2019t ya EX nigga \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person's face, which is considered a hateful meme as it may be used to spread hate or discrimination towards a specific group of people.\"}",
    "1107717163664707585": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag><tag><tag><tag> Faggot blocked me lmao \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which is not related to the tweet text. The tweet text contains derogatory language towards the LGBTQ+ community, making it a hateful meme.\"}",
    "1045852204035428352": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:You a faggot? Look what I have for you! ......  See this and more at: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content towards a particular group of people.\"}",
    "1109710484624850944": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:biiitch omg she is cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, suggesting that the image might be a hateful meme.\"}",
    "1109588706820792321": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Fucking traitor stick the twat in the tower \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and a call for violence, indicating a hateful sentiment towards the person being referred to.\"}",
    "1034782297944412161": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> retard even when u spell it correctly it's still wrong \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text further supports this classification as it uses derogatory language to describe someone.\"}",
    "1058237765463068672": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> No it\u2019s ok they\u2019re all retarded they just dont know any better #justaprankbro \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, suggesting that the image is a hateful meme.\"}",
    "1054373398246174720": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This cunt just bumped me  #PS4share  \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, suggesting that the image might be a hateful meme.\"}",
    "1115755269395570689": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:a dyke fighting for her little gay boy i think \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains content that is intended to be offensive or discriminatory towards a particular group of people, such as the LGBTQ+ community. The presence of a person fighting for their child implies a negative attitude towards the LGBTQ+ community, which aligns with the classification of the image as hateful.\"}",
    "1116698898968432640": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:How about you guys do yourself a favor and block this guy. He's one annoying cunt btw \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, and the tweet text supports this classification as it contains offensive language.\"}",
    "1106666875491106818": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I asked for a salad...NIGGA THIS AINT NO SALAD THIS IS JUST LETTUCE. IM BIG MAD \ud83d\ude21 BCHDHEIWOFJC SKWKE \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains racial slurs and is disrespectful towards a specific group of people.\"}",
    "1108170431159140352": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Hold da fuck up\ud83d\ude02\ud83d\ude02this nigga disrespecting my name by being garbage \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the disrespectful and offensive language used in the tweet text. The tweet text is disrespectful and offensive, which is not appropriate for a meme.\"}",
    "1116511894054084608": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> This nigga said this like a supervillain revealing his origin \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text further supports this classification as it uses derogatory language to describe the image.\"}",
    "1046343356165558272": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I just died to a retard...<tag>, was on couse for a decent win tbh #PS4share \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains content that is offensive or discriminatory towards a particular group of people.\"}",
    "1114970813592145920": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:nigga has a phone pa na. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racial slurs and is offensive. This image is not suitable for sharing or discussing.\"}",
    "1056608755578740736": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:What a special cunt. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, suggesting that the image might be a hateful meme.\"}",
    "1107545400980848641": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Nigga so mad, I love you lil bro \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racial slurs and hate speech, which makes the image hateful.\"}",
    "1113904844794937345": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> This nigga Dontai said... \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The presence of the word 'nigger' in the tweet text further supports this classification.\"}",
    "1050092269649448962": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Round up, reimburse, then remember your manners faggot.  $MasterBatesOwnsYou #cashmaster #cashfag #findom \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a man's face, which is considered hateful due to the tweet text suggesting disrespect and aggression towards a specific individual.\"}",
    "1058212502134317057": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> \u201cwEll lET mE sEE yOu gEt OUt thErE And PlAY\u201d.... NIGGA SHUT THAT SHIT UP \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which indicates a hateful sentiment. The image itself is a black background, which might be used to further emphasize the negative message.\"}",
    "1109639181247148032": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This dyke just told me she loves that I don\u2019t give a fuck about what she has to say \ud83d\udc80 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains content that is intended to be offensive or discriminatory towards a particular group of people, such as the LGBTQ+ community. The tweet text further supports this classification as it contains derogatory language towards the LGBTQ+ community.\"}",
    "1054442042284273664": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:RefugeesNOTwelcome \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which is often associated with negative emotions or events. The tweet text suggests a negative sentiment towards refugees, which further supports the classification of the image as hateful.\"}",
    "1106995349120520193": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I\u2019M SUCH A DYKE OMG \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and derogatory terms, suggesting a hateful sentiment towards the LGBTQ+ community.\"}",
    "1115263432792641538": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:My nigger Cartman.\ud83d\ude04\ud83d\ude04\ud83d\ude2e\ud83d\ude2e \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme featuring a racial slur, which is considered hateful and offensive.\"}",
    "1041841022798585857": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> This guy is actually retarded... \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, suggesting that it contains offensive or discriminatory content.\"}",
    "1063440345231486979": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Controversial, contended, career making? Find out for yourself with HILLBILLY ELEGY \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is a black and white photo of a sky, which does not contain any explicit or offensive content. The tweet text does not seem to be related to the image, and it does not contain any hateful or offensive language.\"}",
    "1115097933333127168": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Lmfao someone's gonna call me a cunt I just know it. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, suggesting that the image might be a hateful meme.\"}",
    "1105574284523724800": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:What a twat! \ud83d\ude02\ud83e\udd26\ud83c\udffd\u200d\u2640\ufe0f \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, suggesting that the image might be a hateful meme.\"}",
    "1049687834179833856": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> I'll Fuck you retard \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is considered hateful.\"}",
    "1105858092397260810": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> This nigga dont know shit about sports. Yankees good as shit fuck you talking about and suk my dick \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the racist and offensive language used in the tweet text, which is displayed on the image.\"}",
    "1055879041838804992": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:If I ever see this faggot he\u2019s getting his ass beat \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains hate speech towards the LGBTQ+ community, which is not acceptable. The image itself is a black background, which might be used to spread such hateful messages.\"}",
    "1058558039131934720": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> open your doors for them or #BuildTheWall \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a wall, which can be interpreted as a symbol for a border or a barrier. The tweet text suggests that the image is related to a political or social issue, possibly related to immigration or border control. The use of the hashtag #BuildTheWall implies a stance against immigration or support for stricter border control measures. This can be considered",
    "1063596913629569024": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:faggot tingz \ud83d\ude14 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content towards a particular group of people.\"}",
    "1108969462521364480": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Immediate question in mind ......    \u201cIs this nigga taking a hoe bath?\u201d \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text further supports this classification as it contains a racial slur.\"}",
    "1042620668133732354": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:what a faggot \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language towards the LGBTQ+ community, which is considered hateful. The image itself is a black background, which might be used to spread such hateful messages.\"}",
    "1025046859109289985": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Retard \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The presence of the word 'Retard' in the tweet text further supports this classification.\"}",
    "1113528943867568128": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I be tellin my dad \u201cI love you\u201d and that nigga just be like \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains racial slurs and is disrespectful towards a specific group of people.\"}",
    "1061744804051197953": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:What\u2019s this faggot man gave a birthday shoutout saying he wanted to buy him a watch real smart man \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains derogatory language and promotes negative stereotypes about the LGBTQ+ community.\"}",
    "1061478626665881600": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:VIDEO: Tublack \u2013 Song For The\u00a0Nigger \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person, and the tweet text contains a song title that is considered offensive and racist. This suggests that the image is intended to be hateful or promote negative stereotypes.\"}",
    "1037386997260738560": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:THIS EXUDES BIG DYKE ENERGY WOW \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is likely to be considered hateful. The image itself is a black background, which might be used to create a provocative or aggressive atmosphere.\"}",
    "1106704383268605952": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:A nigga know I ain't perfect I hope to accept discipline and grow cause I know I ain't right lolol \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racial slurs and derogatory language, which is considered hateful.\"}",
    "1053504712362717184": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> let\u2019s dyke out \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a woman's face, which is considered a hateful meme as it may be used to promote negative stereotypes or discrimination against women. The tweet text further supports this classification as it contains a derogatory term for women.\"}",
    "1105861674496679941": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:we at the play and this nigga Hamlet actin mad weird and not himself rn, I wonder why \ud83e\udd14 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text also implies that the image is related to a negative portrayal of a person or group, further supporting the classification of the image as hateful.\"}",
    "1116374602333270019": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:White people don\u2019t like the race card because it\u2019s stronger than white privilege. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it promotes racism and discrimination against white people. The tweet text further supports this classification as it implies that white people are not entitled to the same privileges as people of color.\"}",
    "1045715727553114113": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag> Retard reality check \ud83d\udc47 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a 'hateful meme,' suggesting that it contains offensive or discriminatory content. The presence of the word 'retard' in the tweet text further supports this classification.\"}",
    "1058116381193986048": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Suck a nigga dick or something \ud83c\udf4c \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person's face, which is considered a hateful meme due to the offensive language used in the tweet text.\"}",
    "1061438540071006208": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:\"WASHED ASS NIGGA WHAT YOU FINNA DO?\" \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains racial slurs and is disrespectful towards a specific group of people.\"}",
    "1034957405547913216": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:guess who's bad  mad and bad  faggot's bad  tell your dad \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language and negative words towards the LGBTQ+ community, which indicates a hateful sentiment.\"}",
    "1109308166678802432": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:bruh look at ma nigga<tag> \ud83d\ude2d\ud83d\ude2d\ud83d\ude2dwhy he gotta look like ma boi gerald from hey arnold \ud83d\ude02\ud83d\ude02 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme that is considered hateful due to the use of racial stereotypes and offensive language.\"}",
    "1054544080510898176": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag> This nigga was traumatized \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person, and the tweet text suggests that the person is being referred to in a derogatory manner. This could be considered as a hateful meme.\"}",
    "1108156455729930241": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> nigga you supposed to be dead \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person, and the tweet text contains a racial slur. This suggests that the image is intended to be hateful and offensive.\"}",
    "1105827990162890752": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Via: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which can be perceived as a hateful meme due to its association with negative emotions or events. The tweet text also suggests that the image is a meme, which further supports the classification of the image as hateful.\"}",
    "1116691687412305920": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:When a nigga you ain\u2019t do shit to got an unspoken issue with you ?????? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains racist language and promotes negative stereotypes.\"}",
    "1110240099890094085": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Is it aye ye must be fucking gasping for one now daft cunt \ud83e\udd2a\ud83e\udd2a \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which suggests that the image is a hateful meme.\"}",
    "1107389988545675266": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Sooo a nigga finally getting his weight back up \ud83d\ude0c been feeling myself no flex.... next 200lbs \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language towards a specific group of people, which is considered hateful. The image itself is a black background, which might be used to evoke a certain emotion or message, but it does not contain any explicit content that would make it hateful.\"}",
    "1105506676801708032": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Lollll. This nigga think I\u2019m his woman. Sir, no! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains a racial slur and is disrespectful towards a specific group of people.\"}",
    "1106637346483720194": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag>. Bless you. Bumblebee tuna. I'm a Real NIGGA. AX<tag><tag> ODB \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark background, which is often associated with racism and hate. The tweet text contains offensive language and racial slurs, further supporting the classification of the image as hateful.\"}",
    "1047187923651706880": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Retarded as fuck \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, suggesting that the image might be a hateful meme.\"}",
    "1045077356593975296": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:#TrumpPressConference got all you sjw libtards losing your minds.  #qanon #maga \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains political and social commentary that may be considered hateful by some people. The use of hashtags like #qanon and #maga may also be perceived as offensive by certain individuals.\"}",
    "1110391903378259969": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> You really are a twat aren't you? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains insulting language towards the image, suggesting that it is a hateful meme.\"}",
    "1114933831566540800": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Get the fuck off my TL  ya sad pervo cunt or I'll get back in my submarine on my day off... \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and a threat, indicating a hateful sentiment.\"}",
    "1055176502210387969": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Dyke be gone \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a woman's face, which is considered hateful due to the negative connotation of the word 'dyke' and the fact that it is a meme. The tweet text further supports this classification as it uses the word 'be gone' which implies a negative sentiment towards the image.\"}",
    "1055907509838340096": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Awwww! Poor racist white trash. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains racist or discriminatory content. The tweet text also supports this classification by using derogatory language towards a specific group of people.\"}",
    "1062302842906652672": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:If you\u2019re not following then you should be !! Proper funniest old cunt on twitter<tag> \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is considered hateful. The image itself is a black background, which might be used to display such content.\"}",
    "1046249339180408832": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Faggot? Wbk \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which is not related to the hateful tweet text. The tweet text contains derogatory language towards the LGBTQ+ community, making it a hateful meme.\"}",
    "1117282656130146311": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Fuckboy faggot reporting for duty. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black background with no content, and the tweet text is derogatory and offensive, suggesting that it is a hateful meme.\"}",
    "1108611613140103168": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Send that nigga to jail \ud83d\ude02\ud83d\ude43 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racist remarks, which are not appropriate and can be considered as hateful.\"}",
    "1108690010360950784": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Now Playing: I Surrender (Featuring Onaje Jefferson) by Brooklyn Tabernacle Choir on \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person with a caption that says 'Now Playing: I Surrender (Featuring Onaje Jefferson) by Brooklyn Tabernacle Choir on ' which suggests that it is a meme related to music or entertainment. However, the content of the meme is not hateful, but it might be perceived as such by some people due to the",
    "1053728016365428737": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> You're full of it, Princess. Quit playing the victim card. Get a job &amp; pay those taxes you owe. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is disrespectful towards women. It is not a hateful meme.\"}",
    "1054643105297784832": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:GUYS I FOUND PEOPLE TO DO REDNECK SHIT WITH HERE \ud83d\ude02\ud83d\ude02 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests that the image is associated with a hateful meme, as it is described as 'redneck shit' and implies that it is meant to be offensive or derogatory.\"}",
    "1114204568454336512": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Meet faggot Jim. Exposed to the world \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains derogatory language and is intended to insult or discriminate against a specific group of people.\"}",
    "1061732492288385024": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:cunt sent me another emoji when i warned her \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a woman's face, which can be perceived as offensive or disrespectful. The tweet text further supports the classification as it contains offensive language.\"}",
    "1056609789721989120": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:today can CHOKE i can already feel it in my dyke bones that it\u2019s just not it \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains hateful language towards the LGBTQ+ community, which is reflected in the image's content.\"}",
    "1110020697349390337": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Nigga Your ugly \ud83d\ude2d\ud83d\ude2d\ud83d\ude2d<tag> got some big ass lips \ud83d\ude2d\ud83d\ude2d\ud83d\ude02 LMFAOOOO \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and racial slurs. The tweet text further supports this classification as it uses derogatory language towards a specific group of people.\"}",
    "1034780448675823616": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:*Gets called a faggot* \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person with the words 'Gets called a faggot' written below it. This suggests that the image is meant to be derogatory and offensive towards the person depicted, which is considered hateful.\"}",
    "1055124846202576896": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Don\u2019t even tweet too much but<tag> never fails to be the smartest retard ever \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which suggests that the image might be a hateful meme.\"}",
    "1109227935146434561": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Yea aight nigga \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racist slurs, which are indicative of a hateful meme.\"}",
    "1114152409406877697": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This nigga just said his card got declined because someone stole it... \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the racial slur used in the tweet text, which is offensive and discriminatory.\"}",
    "1113499159745781761": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:*Phone rings* \u201cHi son u alright\u201d   Your low levelled brain dead cunt of a mate: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text provided further supports this classification as it contains derogatory language towards someone's friend.\"}",
    "1113185650193334272": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:brie larson is a dyke \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and derogatory terms towards a specific individual, Brie Larson.\"}",
    "1109276852714008578": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Annoyed stepsis lets stepbro rock her tight twat \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme that is considered hateful due to its offensive content, which includes a reference to sexual activity and a derogatory term. The tweet text further supports this classification as it contains explicit language and is inappropriate.\"}",
    "1107835761578205188": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Nigga look like meatball from aqua team hunger force  RT<tag>: Lol \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it uses racial slurs and offensive language to make a joke. This is not appropriate and should not be shared.\"}",
    "1062356385655070720": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I Ate Cum From My Young Cunt 2<tag><tag> \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black background with no content, and the tweet text is inappropriate and offensive. This combination suggests that the image is intended to be hateful or offensive.\"}",
    "1105273235850039296": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I am now the voice of reason friend. I used to be the fuck that nigga/whoop ha ass friend. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, suggesting that it may contain offensive or discriminatory content. The tweet text further supports this classification as it uses derogatory language towards a specific group of people.\"}",
    "1114921043146301442": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Pussy ass nigga u seen me txt u \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person's face, which is considered a hateful meme as it may be used to spread hate or discrimination. The tweet text further supports this classification as it contains offensive language.\"}",
    "1107838864662646786": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This might be the worse case of Cultural Appropriation I've seen since \"Jesus Christ is My Nigga\" \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, likely due to the use of racial slurs and offensive language in the tweet text.\"}",
    "1105621061171924993": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:That shit mad foul RT<tag>: She done gave this nigga somem LMFAOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOO \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text further supports this classification as it contains derogatory language towards a specific group of people.\"}",
    "1115480185229336576": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> That nigga\u2019s joke are the same every time \ud83d\ude2d \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text further supports this classification as it contains a racial slur.\"}",
    "1113871176185667589": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:walking into the session to see which nigga got the 808 out of key  \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language towards African Americans, which is considered hateful. The image itself is a black background, which might be used to display such offensive content.\"}",
    "1107036335192313856": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Sneaky Twat! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content.\"}",
    "1049691239912808450": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Are you retarded ??? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests that the image is hateful, as it contains an insult towards the viewer.\"}",
    "1105823801445634050": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> iLl TwAt ThE bOtH oF yOu \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which can be interpreted as a hateful meme. The tweet text also supports this classification as it contains a negative message towards the viewer.\"}",
    "1042248404917805061": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> U either Stupid , or retarded or even both \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, suggesting that the image might be a hateful meme.\"}",
    "1109670835453755392": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:realest white nigga ever  \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a white person, which can be perceived as a hateful meme due to the racial connotations and the use of the term 'white nigger' in the tweet text.\"}",
    "1106632668169625600": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> \u201cNigga\u201d...\ud83d\ude05 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark background, which can be perceived as a hateful meme due to the use of the word 'Nigga' in the tweet text. This word is considered offensive and racist, and its use in the context of the image can be interpreted as promoting hate or discrimination.\"}",
    "1110015164793933824": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Let's start with this epidemic  #Buildthewall \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a wall, which is often associated with racism and xenophobia. The tweet text suggests a political agenda that promotes a hateful message. Therefore, the image can be considered as a hateful meme.\"}",
    "1109972577882173442": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:SHE LOOKS CUNT!!!!!! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is considered hateful.\"}",
    "1062125442608611333": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:MIA UNBLOCK ME U FAT CUNT \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which suggest that the image is a hateful meme.\"}",
    "1116064739606634497": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:soon as a nigga get a couple years down the road they wanna tat they face like they ain\u2019t never getting out \ud83e\udd26\ud83c\udffe\u200d\u2640\ufe0f \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a negative stereotype about African Americans. The tweet text further supports this classification as it reinforces the stereotype.\"}",
    "1107416087476486150": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:The Full Gallery: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which can be perceived as a hateful meme due to its negative connotations. The tweet text also suggests that it is a full gallery, which might imply that there are more images to follow, potentially containing more hateful content.\"}",
    "1105258790595805184": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Fuck off Juncker you drunken nonce looking twat \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which suggest that the image is a hateful meme.\"}",
    "1113703403039928320": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Nigga this shit funny as hell \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racist slurs, which are not appropriate and can be considered as hateful.\"}",
    "1110398836613230593": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Hipsters are trailer trash via /\nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, suggesting that it contains negative or offensive content towards a specific group or individual.\"}",
    "1113825736362688513": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Like on me this nigga Jaymes needs to shut up and take his L bro \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is considered hateful.\"}",
    "1114015288293507073": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Just a nigga with a rocket launcher #Fortnite #XboxShare \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a rocket launcher, which is often associated with violence and aggression. The tweet text suggests a racist and offensive context, further indicating that the image is hateful.\"}",
    "1108804609881956352": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag><tag><tag> Nigga \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person, and the tweet text contains a racial slur. This suggests that the image is intended to be hateful and offensive.\"}",
    "1106962428535828480": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:yo my nigga is in distraught \ud83d\ude02\ud83d\ude02\ud83d\ude02\ud83d\ude02\ud83d\ude2d\ud83d\ude2d \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text also implies that the image is causing distress to someone, further supporting the classification of the image as hateful.\"}",
    "1060918656777912320": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:literally every neo-liberal/feminazi/unemployed communist in the history of 2015 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains content that is offensive or discriminatory towards a particular group of people. The tweet text further supports this classification as it targets specific groups, such as neoliberals, feminazis, and unemployed communists, which can be perceived as hateful or discriminatory.\"}",
    "1107787491669471232": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:She got ash up on her knees cus I stand up when she blow me \ud83d\udd25\ud83d\udd25\ud83d\udd25 comethazine growing on a nigga \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme that is considered hateful due to its content, which includes offensive language and potentially derogatory references.\"}",
    "1055882725121495041": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag> Yea #Fake you retard!!\ud83d\udd95 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, suggesting that the image is a hateful meme.\"}",
    "1109356050547912704": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Future know how to make a nigga cry \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains a racial slur, which is offensive and discriminatory. The tweet text further supports this classification as it reinforces the negative and derogatory sentiment towards a specific group of people.\"}",
    "1107284584314650624": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Nah this nigga be eating crayons idc \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which make it a hateful meme.\"}",
    "1115268912290107393": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Nigga white people crazy \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains a racial slur, which is offensive and discriminatory towards a particular group of people.\"}",
    "1105724642625490944": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Nigga what \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person's head, and the tweet text contains a racial slur. This suggests that the image is intended to be hateful and offensive.\"}",
    "1109694603806937089": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Stfu fucking cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, which suggests that the image might be a hateful meme.\"}",
    "1113479764227047425": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Top 3 favorite Nipsey tracks . Nigga went CRAZY \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which is not related to the tweet text. The tweet text contains offensive language, suggesting that it is a hateful meme.\"}",
    "1055872326754025473": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:LET NIGGA BEAT UP ON THEM BOOTY CHEEKS.... BRUISE UP THEM BOOTY CHEEKS \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it promotes violence against a specific group of people, which is not acceptable.\"}",
    "1107823822797836289": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:We slangin Rocnation , yea bitch you jigga who, I\u2019m plugged at the boarder nigga send em through\ud83d\udd25\ud83d\udd25\ud83d\udd25\ud83d\udd25\ud83d\udd25\ud83d\udd25\ud83d\udd25\ud83d\udd25\ud83d\udd25\ud83d\udd25\ud83d\udd25\ud83d\udd25\ud83d\udd25 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and slang, which suggests a hateful sentiment towards Rocnation.\"}",
    "1108843242240520193": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag> Nigga what pther word? Dogs!? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dog, and the tweet text contains a racial slur. This combination of elements suggests that the image is being used to promote hate or discrimination, making it a hateful meme.\"}",
    "1106936656278548480": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Tell me this nigga<tag> Don\u2019t look like elephant man\ud83d\ude02\ud83d\ude2d \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme that is considered hateful due to the use of racial slurs and offensive language.\"}",
    "1113103781070286848": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I be worried bout a check \u2705\ud83d\udcb8 fuck a bitch or a nigga \ud83e\udd37\ud83c\udffe\u200d\u2640\ufe0f\ud83d\ude02\ud83d\ude0b\ud83d\udcaf. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a check, which is often associated with money and wealth. The tweet text contains offensive language, which suggests that the image might be used to promote negative stereotypes or discrimination. This could be considered a hateful meme.\"}",
    "1114130742143926272": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:nigga got Mr Wilson as his Avi \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains a racial slur and is disrespectful towards the African-American community.\"}",
    "1105288986434699264": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:this nigga retarded your honor \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text further supports this classification as it contains derogatory language towards a specific group of people.\"}",
    "1105671895087833088": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:THE DARK CURLY HAIR THE FRECKLES THE ARMOR LEE SEOKMIN IS OUT FOR BLOOD AND IM WILLING TO SURRENDER \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests a violent and aggressive sentiment towards someone, which is considered hateful. The image of a black background with no other context or visual cues does not provide enough information to determine if it is hateful or not.\"}",
    "1115297578697015297": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:When a nigga who aint put in on a match session hit da blunt \ud83d\ude02\ud83d\ude02 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains racial slurs and derogatory language. This type of content is not appropriate and should not be shared.\"}",
    "1106959827023130626": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Sluts Love Flashing\u00a0Cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a woman's crotch, which is considered inappropriate and offensive. The tweet text further emphasizes the hateful nature of the image.\"}",
    "1109578502045663233": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Oiled for the eventual whipping.  From the \"Impaled cunt\" series at \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, suggesting that it contains offensive or discriminatory content. The tweet text also supports this classification as it refers to a series of images with potentially derogatory titles.\"}",
    "1109665453880852480": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:anycunt tell me where this cunt stays? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and a request for personal information, which indicates a hateful sentiment.\"}",
    "1113476311555682304": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Lock this nigga up! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and a call to lock someone up, which indicates a hateful sentiment.\"}",
    "1117147330006921217": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:If a nigga wearing this call next I'm going home \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains racist language and imagery, which is offensive and discriminatory.\"}",
    "1109521538984878082": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:They say my nigga a menace I say fuck them free my nigga \u203c\ufe0f\ud83d\udde3 #freeliljacob \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a man's face, and the tweet text contains racial slurs and aggressive language, which suggests a hateful sentiment.\"}",
    "1108941147349499905": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> ultimate fat nigga song Gunna and Nav \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person, and the tweet text contains a racial slur. This suggests that the image is intended to be hateful and offensive.\"}",
    "1042786363903561729": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:It's because he's a fucking retard hth \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, suggesting that the image is intended to be hateful.\"}",
    "1117198749040828416": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> CONGRATS NIGGA \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark background, which is often associated with racism and hate. The tweet text, 'CONGRATS NIGGA', further supports the classification as hateful, as it is a derogatory term for African Americans.\"}",
    "1114796586452889600": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> So sad smh this nigga still on that fuck shit!! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and negative sentiment towards a specific group of people, which indicates that the image is hateful.\"}",
    "1110059848136359936": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> cheeky wee cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The presence of the word 'cunt' in the tweet text further supports this classification.\"}",
    "1109105669582540801": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> THIS NIGGA USIN A WEB CLIENT!!! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person, and the tweet text suggests that it is a hateful meme. The use of the word 'nigger' in the tweet text is considered offensive and racist, which indicates that the image is likely to be hateful.\"}",
    "1115044688757710848": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:is with god, nigga Nipsey Hussle \ud83d\ude4f\ud83c\udffe\ud83d\udc94 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person, and the tweet text contains a racial slur. This suggests that the image is hateful and promotes negative stereotypes.\"}",
    "1114014799376068608": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:if youre white and religiously say the \"n\" word, youre trash. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the tweet text, which contains derogatory language towards a specific group of people.\"}",
    "1110316348066942976": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Its gonna be a great week.. shout out to my ex nigga for the wine.. \ud83d\udc9c \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is likely to be considered hateful. The use of the word 'nigger' is considered racist and derogatory.\"}",
    "1057776749646352384": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:yeah because theyre completely different months you fucking stupid dumbass idiot cunt bitch fuck you \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, suggesting a hateful sentiment towards the person being addressed.\"}",
    "1107814943481573378": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> I\u2019ll get in. But you gone have to save a nigga once my feet don\u2019t touch the ground no more. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racist language and promotes violence, which indicates that the image is a hateful meme.\"}",
    "1109605445860319233": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Nigga Top 3 ever from Tally. I know what I saw lol \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the use of racial slurs in the tweet text, which is inappropriate and offensive.\"}",
    "1113133027482308608": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Pleeeease don\u2019t let me be worst than this cunt afresh spending all the dough.... \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and a negative sentiment towards a person. This suggests that the image could be a hateful meme.\"}",
    "1024845732308705280": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Ps my dad is a sick cunt #420 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which suggests that the image might be a hateful meme.\"}",
    "1114238866700087297": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:nigga just got his ear bit off\ud83d\ude33  -welcome to Birmingham \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains a racial slur and is offensive to people of color.\"}",
    "1114940594877554688": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I don\u2019t wanna no sloppy drunk ass nigga . So I felt this \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person's head, and the tweet text contains offensive language towards African Americans. This suggests that the image is intended to be hateful and racist.\"}",
    "1114205259835105280": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:If I was a conspiracy theorist this would be the kind of thing that fueled my conspiracy theorism. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, suggesting that it may contain offensive or controversial content that could be perceived as harmful or discriminatory.\"}",
    "1114004119868411904": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Who\u2019s this mf being a cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, suggesting that the image might be a hateful meme.\"}",
    "1108069158607036416": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This nigga going to hell with gasoline  drawers on... \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and imagery, such as the word 'nigger' and the reference to 'gasoline drawers on'. This kind of content is not appropriate and should not be shared.\"}",
    "1107630916036452357": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This nigga hit me every morning cappin \ud83d\ude2d<tag> \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text further supports this classification as it contains derogatory language towards a specific group of people.\"}",
    "1113836778018836480": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> The feds waiste more than that on congressional salaries....#BuildTheWall \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a wall, which is often associated with racism and discrimination. The tweet text also contains a political statement related to the wall, which could be perceived as hateful by some people.\"}",
    "1056414922379223040": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> THEOCRATIC TAX FRAUDING cunt Ag ignorant sadistic cult TERRORISTS! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, suggesting a hateful sentiment towards a specific group of people. The use of derogatory terms and aggressive language indicates a negative and hostile attitude.\"}",
    "1109841530364284934": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:SOME DAYS YOU JUST CRAVE REDNECK DICK!\ud83d\ude32\ud83d\udc45\ud83d\ude0b\ud83d\udc4d\ud83d\ude0d \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text also supports this classification as it contains inappropriate language and potentially derogatory references.\"}",
    "1058472639092715520": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:BUT IT'S OK WE GONE KEEP SECRETS NIGGA \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racist language and is considered hateful.\"}",
    "1105708880523333632": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Henry Van Dyke.- #quote #image Via \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a sky, which is being used as a quote by Henry Van Dyke. The tweet text does not provide any context or information that would suggest the image is hateful. Therefore, the classification is based on the assumption that the image is being used in a hateful manner.\"}",
    "1107698952747606016": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This nigga a pedo call for help \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains a racial slur and a call for help, which is offensive and discriminatory.\"}",
    "1049650284668973057": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Shows you weren't watching. But now that you mention it. #BuildTheWall \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a wall, which is often associated with racism and xenophobia. The tweet text suggests a hateful sentiment towards immigrants, further supporting the classification of the image as hateful.\"}",
    "1115809074979966977": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:And I was about to put this nigga in my Fantasy team \ud83d\ude05 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which are indicative of a hateful meme.\"}",
    "1108211637906034689": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> LMFAO Periodt. Imma be waiting on her nigga like.. \ud83d\ude02\ud83d\ude02\ud83d\ude02 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a woman's face, and the tweet text contains offensive language that suggests a negative attitude towards a specific group of people. This combination of elements suggests that the image is a hateful meme.\"}",
    "1109354296460480512": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag>  IN HAWAII WE ON THIS GRIND NIGGA \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which is not related to the hateful tweet text. The tweet contains offensive language and is not appropriate for sharing. The image itself is not hateful, but the content shared with it is.\"}",
    "1114146653404110849": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:My nigga. I ain\u2019t even brush my teeth yet ... \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which are indicative of a hateful meme.\"}",
    "1056090556831547393": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I have no fucking words for how retarded you are<tag> \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, suggesting that the image is a hateful meme.\"}",
    "1054522675089960960": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> You a dumbass it ain\u2019t even Burberry \ud83e\udd23\ud83e\udd23\ud83e\udd23\ud83e\udd23 it\u2019s a supreme flannel retard \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains insults and derogatory language, suggesting that the image is intended to be hateful or offensive.\"}",
    "1107297087270596609": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:White people have every privilege in life afforded to them and yet they still mad they can\u2019t say nigga. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a negative stereotype of white people, implying that they are angry because they cannot use a racial slur. This perpetuates harmful racial stereotypes and promotes discrimination.\"}",
    "1117585520417226753": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> F Will Hill &amp; that limey horse they rode into town. Karma mofos \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, suggesting that it contains offensive or discriminatory content. The tweet text also implies a negative sentiment towards a specific individual or group, which further supports the classification of the image as hateful.\"}",
    "1053436451113693184": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:u a nigga i seen u \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racist language, which is considered hateful. The image itself is a black background, which might be used to display such offensive content.\"}",
    "1107751755972923392": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:\u201cI ain\u2019t waste no time before I suck that nigga clean\u201d\ud83d\ude0b period . This shit real asf\ud83d\ude02\ud83d\udcaf \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains racial slurs and offensive language. This type of content is not appropriate and should not be shared.\"}",
    "1115079336216776704": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:this nigga a walking asmr \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the racial slur used in the tweet text, which is offensive and inappropriate.\"}",
    "1110370452449447936": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Ban forever that nigga man \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains hate speech and racist language, which is not appropriate or acceptable. The image, being a black background, might be used to further amplify the negative sentiment in the tweet.\"}",
    "1115639546958483456": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Look cocksucker. This dick is all yours, your mouth flows like a woman's cunt, drool dripping. Suck \ud83d\ude0d\ud83d\ude18\ud83d\ude0d\ud83d\ude18\ud83d\ude0d\ud83d\ude18\ud83d\ude0d\ud83d\ude18 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and derogatory terms, suggesting a hateful sentiment towards the person being addressed.\"}",
    "1105207027041796098": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Nigga how tf do you sound\ud83d\ude02 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person's head, and the tweet text is racist and offensive. This classification is based on the fact that the image and the tweet text are both associated with hate and discrimination.\"}",
    "1105646962748149760": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This cunt is tasty. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is considered hateful.\"}",
    "1115665764193849345": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Any real nigga knows not to look at his barber in the face while he\u2019s cutting your hair. \ud83d\ude02 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains a racial slur and promotes negative stereotypes about African Americans.\"}",
    "1114618392403537920": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:mind you this the same nigga that said he was better than Dwyane Tyrone Wade Jr.  pitiful. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the negative and derogatory language used in the tweet text, which targets a specific individual.\"}",
    "1042658152465027073": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Some faggot on /i/ was acting like a rotten child, so I drew this to insult her. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the insulting nature of the content, specifically targeting a specific individual. The use of a black background and the drawing of a person can be perceived as aggressive and disrespectful.\"}",
    "1053317528221564928": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This nigga gonna leave me to die\u2014\u2014\u2014 not if I run like the negro I am \ud83d\uddff \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains racist language and imagery, which is offensive and discriminatory.\"}",
    "1109345145864876033": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Shut the fuck up<tag> you stealing cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which suggest that the image is a hateful meme.\"}",
    "1109576882322837504": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Not very often i get a photo with a twat equally as annoying as me but i\u2019ve managed it tonight.#EdwardsMoreno \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a 'twat' in the tweet, which suggests that it is meant to be offensive or derogatory. The use of such language indicates that the image is likely intended to be hateful or offensive.\"}",
    "1105414633958064128": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Fibreglass is a cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, which suggests that the image could be a hateful meme.\"}",
    "1106744350602493952": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:faggot, smh \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language towards the LGBTQ+ community, which is considered hateful.\"}",
    "1108053915881426944": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:You are fucking sick twat \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, indicating a hateful sentiment towards the image.\"}",
    "1115065204616912896": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> ANDDDDDDDD the race card up the sleeve played in 1-2........ \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, suggesting that it may contain offensive or discriminatory content. The tweet text also supports this classification, as it references a race card and implies a negative or harmful sentiment.\"}",
    "1110217358675607553": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Shut up cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, which suggests that the image might be a hateful meme.\"}",
    "1116453974469685251": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:\u2018Taxi for sugar\u2019 do one you twat \ud83d\ude02\ud83c\udf39 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which suggests that the image is a hateful meme.\"}",
    "1116449419325583361": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:\u2018Nigger\u2019 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person, and the word 'nigger' is written on it. This is considered a hateful meme as it uses racial slurs to degrade and discriminate against a particular group of people.\"}",
    "1113650499650297856": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Make me one with this nigga \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which are indicative of a hateful sentiment. The image itself is a black background, which might be used to create a provocative or aggressive atmosphere, further supporting the classification of the image as hateful.\"}",
    "1110269286650728450": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Full Gallery: \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is a black and white photo of a sky, which does not contain any explicit or offensive content. It is not a hateful meme.\"}",
    "1113878791854665728": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> This nigga done been married and got kids bro. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a man's face, and the tweet text is a racial slur. This suggests that the image is intended to be hateful and offensive.\"}",
    "1116917436316471299": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Like nigga look at this flyer lmao this don\u2019t look and sound like it\u2019s going to be some hood shit \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text also supports this classification as it uses derogatory language.\"}",
    "1106796313960697856": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:sech is that nigga \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person, and the tweet text contains a racial slur. This suggests that the image is hateful and promotes negative stereotypes.\"}",
    "1107474537178894337": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:nigga said \u201csmoking on some gassssss\u201d \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains racial slurs and promotes negative stereotypes.\"}",
    "1116769510076362752": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This nigga is dumb and a embarrassment to black people everywhere \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and racist sentiment towards a specific group of people.\"}",
    "1061642518943748104": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> This retard honestly won't put the shovel down... \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content.\"}",
    "1108153844180099074": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:When I would go to my nigga house back in the day and he was cranking fab all over the house..... \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racial slurs and is offensive. The image, being a black background, might be used to further amplify the offensive message.\"}",
    "1113490978952740867": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Ode de of a Twat... \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The presence of the word 'twat' in the tweet text further supports this classification.\"}",
    "1110071487342538752": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:lmaoooooooo this nigga! he prolly has pussy lined up for the weekend  exactly why i clown fathers \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, likely due to the content of the tweet text, which is offensive and disrespectful towards a specific group of people.\"}",
    "1113501799024091136": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:#np #internetradio Hillbilly Superman by The Shane Givens Band #krushnation \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is a black background with no visible content, and the tweet text does not contain any hateful or offensive language.\"}",
    "1109388758158237697": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:mah nigga<tag> :) \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which are indicative of a hateful meme.\"}",
    "1109882100990332928": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:JLO SAID NIGGA IN I\u2019M REAL???? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains a racial slur, which is offensive and discriminatory.\"}",
    "1037026971732111361": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Straight Men Use Faggot for Amusement! ......  See this and more at: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which is not related to the tweet text. The tweet text contains derogatory language towards the LGBTQ+ community, which is hateful. The image itself is not hateful, but it is being used to spread hateful messages.\"}",
    "1114312059905368064": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Why<tag> always snap so hard...fuck all the other rappers this nigga the \ud83d\udc10....no head apparel\ud83d\udeab\ud83e\udde2 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains content that is offensive or discriminatory towards a particular group or individual.\"}",
    "1050453348044992513": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Y'all wanna see some cursed redneck shit \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests that the image is intended to be hateful or offensive. The use of the word 'cursed' and the reference to 'redneck shit' implies a negative and derogatory attitude towards a certain group of people. The image itself is a black background with no visible content, which further supports the notion that it is meant to be hateful.\"}",
    "1042662269824327680": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:My shirt actually says faggot \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and imagery, such as the word 'faggot' on a shirt, which is derogatory and discriminatory towards the LGBTQ+ community.\"}",
    "1057421204112531457": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:huh that little retarded kid has a gif on twitter I'm glad they are supporting my cause \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests that the image is related to a hateful cause, which is not appropriate. The image itself is a black background with no content, so it cannot be considered hateful by itself.\"}",
    "1058497752483725314": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:ah yes \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which can be perceived as a hateful meme due to its association with negative emotions or events. The tweet text also supports this classification as it implies a negative sentiment towards the image.\"}",
    "1107706775141261312": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Nigga said \u201dtest me \ud83e\udd32\ud83c\udffe\u201d \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains racial slurs and is offensive to many people.\"}",
    "1107435990694531072": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Lmao \ud83d\ude02\ud83d\ude02\ud83d\ude02 nigga me and her do this on every social media app for fun I\u2019m not tryna hit \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text also implies that the image is shared for fun, which might contribute to the negative perception of the image.\"}",
    "1105689226631368704": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Same old nigga from the block. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person, and the tweet text contains a racial slur. This suggests that the image is intended to be hateful and offensive.\"}",
    "1105253761503641600": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:EDP looking like the type of nigga to approach your 15 y/o daughter \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a man's face, which is described as a meme. The tweet text suggests that the image is hateful, possibly due to its association with a negative stereotype. The classification is based on the context provided by the tweet text.\"}",
    "1114692437719568384": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:i\u2019m sick of being booboo the fucking faggot fool i mean it \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and derogatory terms, suggesting a hateful sentiment towards the individual who posted it.\"}",
    "1108115376704049152": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Nigga... \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark background, which can be perceived as a hateful meme due to the use of racial slurs in the tweet text. The tweet text contains the word 'nigga', which is considered offensive and racist. This association with the image can be considered as hateful.\"}",
    "1115258307952955392": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Nigga just laughing at tweets in the shadows \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark background, which can be perceived as a hateful meme due to the racial slur in the tweet text. The use of such language is offensive and inappropriate.\"}",
    "1105647313350025217": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Possum was just about to negotiate his surrender like #AmericanSoulBET \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is a black and white photo of a night sky, which does not contain any explicit or offensive content. The tweet text does not seem to be related to the image, and it is not clear what the context is. Therefore, it is not reasonable to classify this image as a hateful meme.\"}",
    "1116654419309809664": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> He is mentally retarded person \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, suggesting that it contains offensive or discriminatory content. The presence of the tag 'mentally retarded person' in the tweet text further supports this classification.\"}",
    "1109847697647898624": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:If he\u2019s the police officer, are you gonna surrender - your soul? \ud83e\udd2d  #choisoobin #heuningkai #TOMORROW_X_TOGETHER \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme that is hateful in nature, as it is making a joke about a police officer and the concept of surrendering one's soul. This type of humor is not appropriate and can be offensive to some individuals.\"}",
    "1115372718419894272": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Don't steal from me again nigga \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and suggests theft, which indicates a hateful sentiment.\"}",
    "1057742216330952704": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag><tag> WHAT IS GOING ON WHEN DID NIGGER NIGEL GET INTO THIS \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person, and the tweet text contains racial slurs. This suggests that the image is hateful and promotes negative stereotypes.\"}",
    "1115518466864369665": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Happy birthday bro \ud83d\udcaa\ud83c\udfff\ud83c\udf8a. God bless this real nigga \ud83d\ude4f\ud83c\udfff. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which are indicative of a hateful meme.\"}",
    "1109275244852699136": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:You know they your nigga when they give you their cable information to watch march madness \ud83d\ude22 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it uses racial slurs and promotes negative stereotypes.\"}",
    "1114636263410343943": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Ima have to pop on this nigga for wearing my tee \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the tweet text, which is derogatory and offensive towards a specific group of people.\"}",
    "1115260453981237249": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> You know where I stay nigga \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text provided further supports this classification as it contains derogatory language towards a specific group of people.\"}",
    "1061384010490888193": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:and my hate grows even more than i thought fucking possible. get a fucking umbrella you heartless cunt. fuck. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet contains hateful language towards someone, suggesting that the image might be a hateful meme.\"}",
    "1062377666362437633": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Is your Momma a #Retard \ud83e\udd14\ud83d\ude20\ud83d\udc4a \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or derogatory content. The tweet text also supports this classification as it contains insulting language towards a specific group of people.\"}",
    "1115844166641225729": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> this bosnian nigga \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text also supports this classification as it uses derogatory language to describe a person or group.\"}",
    "1041729798803005445": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Saving Comics, Sci-Fi, and Super Heroes: The Power of Fan-Set Canon Over SJW-Stolen\u00a0Icons \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which is not related to the tweet text. The tweet text contains controversial opinions and might be considered hateful by some people. Therefore, the image is not hateful by itself, but the content of the tweet might be perceived as hateful by some.\"}",
    "1107709601313632256": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag><tag><tag> go check me out real nigga music \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person, and the tweet text contains racial slurs. This suggests that the image is intended to be hateful and offensive.\"}",
    "1114003640669306880": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Told my boy to pull up with a blunt... this nigga still cuffin with his shorty. God.... \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the tweet text, which contains offensive language and a negative portrayal of a person.\"}",
    "1115328091717607424": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Let's make it simple: you're either a #TransAlly or a twat. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests a negative attitude towards transgender people, which is considered hateful. The image, being a black background with no visible content, is not the primary source of the hateful sentiment.\"}",
    "1105290979802783744": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> do you ever not bring up the race card? Gets old. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, suggesting that it may contain offensive or discriminatory content. The tweet text also implies that the image is being criticized for its use of the race card, which could be seen as a form of racism or discrimination.\"}",
    "1115429978101952512": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This nigga was a fool on Metalocalypse \ud83d\ude02\ud83d\ude02\ud83d\ude02 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the use of racial slurs and derogatory language in the tweet text, which is inappropriate and offensive.\"}",
    "1109886388088954881": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:these two lil cunt ass two faced bitches are literally the same character in different universes \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, likely due to the negative and offensive language used in the tweet text. The tweet text refers to two characters as 'cunt ass two faced bitches,' which is considered disrespectful and inappropriate. This language is likely the reason for the classification of the image as hateful.\"}",
    "1107121308519878658": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I want nigga bruh \ud83d\ude2b\ud83d\ude2b\ud83d\ude2b.... \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which is not related to the hateful tweet text. The tweet text contains racial slurs and is offensive, which makes the image appear hateful.\"}",
    "1115845660065062913": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Good Bye Nigger, thank u so much for everything \ud83d\udc4b\ud83c\udffb \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains a racial slur and is disrespectful towards a specific group of people.\"}",
    "1115527338857521152": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Niggazz are they talking sense  #nigga #Follow #GalaxyS10 #NationalChampionship #NCAAChampionship #RewriteTheRules \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which is not related to the hateful tweet text. The tweet contains racial slurs and derogatory language, which makes it hateful. The image itself is not hateful, but it is being used in a hateful context.\"}",
    "1109902093245186048": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This nigga Stanley loves his meatballs \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains a racial slur and is disrespectful towards a specific group of people.\"}",
    "1047170018327314432": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:it\u2019s laughable at this point RT<tag>: I SWEATER GAWD WOMEN ARE COMPLETELY FUCKING RETARDED \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language towards women, which suggests that the image might be a hateful meme.\"}",
    "1108162754895056898": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Should I do legs doe?? My 2 suits barely fit now that a nigga getting thick \ud83d\ude0b\ud83d\ude1c \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racist remarks, which make it a hateful meme.\"}",
    "1105194286545555456": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Every nigga in Naruto when they catch a peak of Danzo \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme that is considered hateful due to its racist content. It is not appropriate to share such content.\"}",
    "1116329302692438016": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Jussie Smollett Gets What He Wanted as Kim Foxx Plays the Race Card \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person, which is often associated with racism and discrimination. The tweet text suggests a negative sentiment towards Jussie Smollett and Kim Foxx, further indicating that the image is hateful in nature.\"}",
    "1114248261701967873": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This NIgga is Just Too Fine!!!!!!! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains racial slurs and promotes negative stereotypes about a specific group of people.\"}",
    "1116690617491447808": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:WOAHHHHHHHHH SOMEONE CONTACT RSPCA GET THIS VILE CUNT LOCKED UP !!!! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains aggressive language and a call to action against someone, which suggests a hateful sentiment towards the individual.\"}",
    "1116036641787871232": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I can be a real nigga and a bad bitch.  mind your business hoe \ud83d\ude0c\ud83d\ude02\ud83d\udc85\ud83c\udffe \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and racial stereotypes. The tweet text further supports this classification as it uses derogatory language and makes light of racial issues.\"}",
    "1109252072527020032": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Nigger this is just Road to El Dorado you not SLICK \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains a racial slur and is offensive to people of color.\"}",
    "1105530793110192128": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:The only time it\u2019s acceptable to call someone a faggot is this ice cream guy. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language towards the LGBTQ+ community, which is considered hateful.\"}",
    "1115292318486204417": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> YOU AINT!!!! Gon do shit nigga \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and a threat, indicating a hateful sentiment.\"}",
    "1113931176912334848": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> what a twat \ud83c\udf44\ud83c\udf44 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, suggesting that the image is a hateful meme.\"}",
    "1107092879783194625": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:IM TELLIN YALL MFS WAIT TILL MINGI FUCKING TOUCH DOWN IN ATL NIGGA GONE GO WILD \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which are indicative of a hateful meme.\"}",
    "1114926585977692161": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:The views dropped so quick when that nigga threw ass\ud83d\ude2d\ud83d\ude2d\ud83d\ude2d\ud83d\ude2d<tag> \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the use of racial slurs and offensive language in the tweet text.\"}",
    "1106675648926502918": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I literally wont even roast ur lil dick til u start acting like a lil dick nigga \ud83d\udeae #np #youngma \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text further supports this classification as it uses derogatory language and insults.\"}",
    "1116048434593771528": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> You sound retarded...hope you get that checked out...your brain is leaking \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which suggests that the image is a hateful meme.\"}",
    "1052599993415229440": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I GOT HOESSSSS CALLINGGGG A YOUNG NIGGA PHONEEEEEE \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains racist language and imagery, which is offensive and discriminatory.\"}",
    "1116039571274383361": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Who has #terrifickids? WE DO! WE DO! \ud83d\udc4d\ud83e\udd1f\ud83c\udf89\ud83d\ude4c\ud83e\udd64#milkshakes #kiwanis #sjw \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it may contain offensive or discriminatory content. The tweet text also implies that the image is related to a controversial topic, such as #terrifickids, which could be perceived as hateful by some people.\"}",
    "1035902030471147520": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Hi<tag> show that twat this. And then politley send him on his way to his local kebab shop.  Knob. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, and the tweet text suggests a negative sentiment towards the person being referred to.\"}",
    "1107058480345726976": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Welcome to 'Straya, cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dog, which is being used as a meme to spread hate and discrimination. The tweet text further supports this classification as it contains offensive language.\"}",
    "1056845096623185920": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:#JeremyKyle Was this cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text further supports this classification as it contains derogatory language towards a specific individual.\"}",
    "1050811251511693312": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:America\u2019s most famous coonass \ud83d\ude02\ud83d\ude02 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person, which is often associated with racism and hate. The tweet text further supports this classification as it is a reference to a racial slur. The combination of the image and the text suggests a hateful meme.\"}",
    "1109707396224434176": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Ummm, no thanks i don't accept surrender. #Fallout76 #XboxShare \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it may contain offensive or discriminatory content.\"}",
    "1061744373564620802": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Us LGBTQ+ folk sure know how to make a stand. A literal rainbow to show that twat who has the higher power \ud83d\udc81\u2728 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it is targeting a specific group of people, the LGBTQ+ community, and using offensive language to express disdain or disrespect towards them.\"}",
    "1115704552865566725": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> \"Nigga take this sweat\" \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a sweatshirt with the word 'nigga' written on it. This is considered a hateful meme as it uses racial slurs and promotes negative stereotypes.\"}",
    "1107826827643551745": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> the vibes tho my nigga, the vibes \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and a negative connotation, suggesting that the image might be a hateful meme.\"}",
    "1107054717119561728": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Me: sorry, you don't get a pass for calling people faggot<tag>: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content.\"}",
    "1115483473832239105": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:A wonder if tha nigga know seh MI wah suck all him hair follicles through him dick? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and racial stereotypes.\"}",
    "1109971419641856001": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Nobody: My nigga lying to me: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person's face, which is considered a hateful meme as it may be used to spread hate or discrimination. The tweet text further supports this classification as it contains offensive language.\"}",
    "1108797068800393219": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I wanted to tag a feminazi Twitter account but I'm afraid that they would sue me  #Memes \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it may contain offensive or discriminatory content that targets a specific group or individual.\"}",
    "1105140834821984257": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Im obsessed with the way this nigga smells, his teeth, his laugh, his walk. This really my baby. \u2764\ufe0f \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial stereotypes, which are indicative of a hateful sentiment.\"}",
    "1106952079623389184": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Chinaman's air force \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a plane, and the tweet text contains a racial slur. This suggests that the image is intended to be hateful and offensive.\"}",
    "1105264220059455490": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:RT<tag>: Ever sucked dick with a wig on and the nigga holding your head? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text provided further supports this classification as it contains derogatory language and potentially promotes negative stereotypes.\"}",
    "1024816318648909824": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:They just brought up gamergate on \"All in w/ Chris Hayes\"  &gt;\"We didn't cover it and now they're in the white house\" \nASSISTANT: {\"Classification\": \"hateful or not hateful\", \"Explaination\": \"The image is not hateful as it is a simple black background with no explicit content or message that can be considered offensive.\"}",
    "1107560475129085955": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Nigga sounding like a whole studio \ud83d\udc80 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person's head, and the tweet text contains a racial slur. This suggests that the image is intended to be hateful and offensive.\"}",
    "1108791462098059264": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> FUCK. THAT. NIGGA. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person's head, and the tweet text contains a racial slur. This suggests that the image is intended to be hateful and offensive.\"}",
    "1114700416720232448": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I\u2019m in love with this fine ass nigga. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which are indicative of a hateful sentiment.\"}",
    "1115430598745755650": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> excuse me, faggot b*aner boys** \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language towards the LGBTQ+ community, which is considered hateful. The image itself does not contain any explicit content or language, but the tweet text associated with it makes it appear hateful.\"}",
    "1053454944098021376": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> rape the cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is considered hateful.\"}",
    "1105806246014341120": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> The nigga with a nose ring?? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains a racial slur and is offensive to many people.\"}",
    "1063491722590609408": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Watching a live q &amp; a with the orange twat.  So painful and embarrassing \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language referring to a political figure, suggesting a negative sentiment towards that person. This could be perceived as hateful by some individuals.\"}",
    "1107736915208491014": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Says the nigga who had me out here looking stupid \ud83e\udd75 PATHETIC whore ! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and derogatory terms, which suggest that the image is a hateful meme.\"}",
    "1107506738180296704": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag> Ok nigger \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark background, which can be perceived as a hateful meme due to the use of the word 'nigger' in the tweet text. This word is considered offensive and racist, and its presence in the tweet text suggests that the image might be associated with negative or hateful sentiment.\"}",
    "1117050712062681090": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Not my meme, but worth sharing it. #MAGA  #Legalimmigrationworks  #NoOpenBorders #Buildthewall \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a wall, which is often associated with hateful or divisive political ideologies. The tweet text suggests that the image is worth sharing, which implies that it may be intended to spread these ideologies.\"}",
    "1056676721313964039": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Not retweeting to help his tweets any further some people will mock anything for attention or clout what a cunt. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which suggests that the image might be a hateful meme.\"}",
    "1110130088991969280": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Years ago this cunt would have being burnt at the stake #thismorning \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and a negative sentiment towards a person, which indicates that the image is a hateful meme.\"}",
    "1024524955185283073": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Typical uneducated trailer trash Trump supporters. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, suggesting that it may contain offensive or discriminatory content. The tweet text also implies that the image targets a specific group of people, which could be considered hateful.\"}",
    "1106630656648466432": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:LMFOAOOO sis said \"dom\" with her whole chest as if this nasty nigger chris bang could top anyone\ud83d\udc80 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, likely due to the content of the tweet text, which contains offensive language and racial stereotypes.\"}",
    "1043413720322457601": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:spirit of cricket \u2764 lv u moon bhai......<tag> \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is a black background with no visible content, and the tweet text does not contain any hateful or offensive language.\"}",
    "1109129499600396288": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> white people have never experienced racism and any person who wears MAGA hats are trash \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a white person wearing a MAGA hat. The tweet text suggests that the person is trash and that white people have never experienced racism. This implies that the image is being used to promote a negative and hateful sentiment towards white people and those who support the MAGA movement.\"}",
    "1113651088824074240": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Lmao this nigga said he loves foreplay and he likes kissing/makeout because he gets hard from it. Yall thats it. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and derogatory terms, which are not appropriate for sharing on social media platforms.\"}",
    "1113993796587589632": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> For example ion follow this nigga \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The presence of the word 'nigger' in the tweet text further supports this classification.\"}",
    "1105520070774579200": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Says the nigga dat tweet like a whole parody acct \ud83d\ude34\ud83d\ude02\ud83d\udc4c \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the use of racial slurs and the overall negative tone of the content.\"}",
    "1114596837124530176": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:MY NIGGA<tag> FROM CLEVELAND OHIO DID THIS FOR<tag> \ud83d\ude4f\ud83c\udfff\ud83d\udd4a. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person, and the tweet text contains racial slurs and references to violence. This suggests that the image is intended to be hateful and promotes harmful stereotypes and attitudes.\"}",
    "1115100461189799944": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> First of all teen titans? TEEN TITANS MY NIGGA? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which suggests that the image is a hateful meme.\"}",
    "1107786641035399170": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> But y\u2019all can\u2019t follow a nigga... \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which is not related to the tweet text. The tweet text contains racial slurs, making it a hateful meme.\"}",
    "1109220621513342976": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:fuck this nigger even though he right next to me \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racist language, which is considered hateful. The image itself does not seem to be hateful, but the context provided by the tweet text makes it appear so.\"}",
    "1105394115225608197": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Um, a redneck just burst my tooth on BitLife! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, likely due to the content of the tweet text, which is related to a negative or offensive situation.\"}",
    "1055959240819572736": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Super Mario Party can say faggot \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme that uses a video game character to make a derogatory statement towards the LGBTQ+ community. This is considered hateful as it promotes negative stereotypes and discrimination.\"}",
    "1115274271234904064": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> fuck this Redneck state \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it may contain offensive or discriminatory content. The tweet text also supports this classification as it contains a negative sentiment towards a specific state or group of people.\"}",
    "1105559961759682560": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Like I said BITCH ASS TYLER. \ud83d\udc4f\ud83c\udffb\ud83d\udc4f\ud83c\udffb\ud83d\udc4f\ud83c\udffb if i bad money being held by this twat best believe I would be handling it \ud83d\ude24\ud83d\udc4f\ud83c\udffb \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and a threat, indicating a hateful sentiment.\"}",
    "1108893940680454145": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Who tf added the \u201cwe\u2019re suppose to\u201d? We got it, we already understood my nigga. Y\u2019all grammar is terrible \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the tweet text, which contains offensive language and a negative tone towards a specific group of people.\"}",
    "1044118483678552064": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:nan\nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which can be perceived as a hateful meme due to its association with negative emotions or events. The tweet text does not provide enough context to determine if it is a hateful meme or not.\"}",
    "1106572918916435968": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Get yo own tweet nigga \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racist remarks, which indicates that the image is hateful.\"}",
    "1109546754070986753": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Kinda wild but PT Barnum woulda had this nigga on display for a quarter. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racist remarks, which are not appropriate and should not be shared. This image is not hateful, but the tweet text associated with it is.\"}",
    "1115681991905689601": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag> This nigga think he original L \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person, and the tweet text contains a racial slur. This suggests that the image is intended to be hateful and offensive.\"}",
    "1114150005806379008": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:My coworker might see the nigga me today smh she got me fucked up \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and racial slurs. The tweet text further supports this classification as it uses derogatory language towards a coworker.\"}",
    "1108473722653065217": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> She dealing this nigga rn \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a woman, and the tweet text contains a racial slur. This suggests that the image is being used to promote hate and discrimination, making it a hateful meme.\"}",
    "1064265672061059072": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Cleverly retweeted my message to him calling him a twat. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, suggesting that it contains offensive or discriminatory content.\"}",
    "1105302709081653248": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:#ImNotAJerkBut you're definitely a twat \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which suggests that the image is a hateful meme.\"}",
    "1108413056244240384": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> The only Copper Tops I trust is these #Facts over nigga babbling \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which indicates that the image is likely a hateful meme.\"}",
    "1115168889833390080": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This Nigga GT Is Really \u201cA\u201d How Tf\ud83e\udd14 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the use of racial slurs and derogatory language in the tweet text. This type of content is not appropriate and can be offensive to some individuals.\"}",
    "1109833700085243910": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Now Playing: I Surrender (Featuring Onaje Jefferson) by Brooklyn Tabernacle Choir on \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person with a caption that says 'Now Playing: I Surrender (Featuring Onaje Jefferson) by Brooklyn Tabernacle Choir on ' which suggests that it is a meme related to music or entertainment. However, the content of the meme is not hateful, but it might be perceived as such by some people due to the",
    "1114395683967119360": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> honestly, i think i\u2019m good on sucking dick if the nigga got bad eating habits .. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the racist and offensive content of the tweet text, which includes derogatory language and a reference to a racial stereotype.\"}",
    "1105320453701320704": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:HOW IS DIS NIGGA SO FOINE LIKE ITS SO QUIET RN   ..  IM HAVING A STROKE \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the use of racial slurs and offensive language in the tweet text.\"}",
    "1042452682232012800": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Love to bump into the twat and put this on the twat head \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests a violent and aggressive sentiment towards another person. This is considered a hateful meme.\"}",
    "1042510356675944449": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Proof that the Filipinos are setting up a nigger, cuz there in love with white men. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains racist and offensive content, targeting a specific ethnic group. The tweet text further supports this classification as it reinforces the racist sentiment.\"}",
    "1051516120996417536": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:holy fuck server admins are so fucking retarded \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults towards server admins, which suggests a hateful sentiment.\"}",
    "1109459109965815808": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:How I look up to this crazy nigga\ud83d\udc83\ud83d\ude02\ud83d\udca6 DC YOUNGFLY \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language and racial slurs, which are indicative of a hateful sentiment. The image itself is a black background, which might be used to further emphasize the negative message in the tweet.\"}",
    "1117284839928020992": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:30. How would you describe this nigga's career so far? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language and racist slurs, which are indicative of a hateful sentiment. The image itself is a black background, which may not be directly related to the content of the tweet.\"}",
    "1108568507967512578": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Hold on nigga! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark background, which is often associated with racism and hate. The tweet text further supports this classification as it contains a racial slur. This combination of elements suggests that the image is a hateful meme.\"}",
    "1113898355598475264": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Well they\u2019re not fucking pamphlets, you stupid twat. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, suggesting that the image is intended to be hateful.\"}",
    "1107390914513768449": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:It\u2019s Just The Feeling that a nigga get when the Money \ud83d\udcb0 Touch a nigga hand \ud83e\udd1a   #ADGBreadGang\ud83e\udd11\ud83c\udfaf\u203c\ufe0f\ud83c\udf0e\ud83d\udd4a \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text further supports this classification as it uses derogatory language towards African Americans.\"}",
    "1056546324320079872": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:How a nigga your mans &amp; he get murdered and all of a sudden you \u201cgot rid of\u201d your phone? BUT HEY.... \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains racial slurs and promotes negative stereotypes.\"}",
    "1109506406405701632": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:My TEXAS nigga flew in \ud83d\ude01 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains racial slurs and promotes negative stereotypes.\"}",
    "1107538319636905984": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:blind nigga gets 4k \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person, and the tweet text contains a racial slur. This suggests that the image is intended to be hateful and offensive.\"}",
    "1108781883092013056": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> I love that cool nigga called unknown \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains a racial slur, which is considered hateful. The image itself is a black background, which might be used to display such offensive content.\"}",
    "1116704836060418048": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:My drawing of Hillbilly Genie for #FanArtFriday, unfortunately this is my last Fan Art Friday drawing \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is a fan art drawing of Hillbilly Genie, which is not considered hateful. It is a creative expression and does not promote harm or discrimination towards any group of people.\"}",
    "1114282867574673408": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Got to love twats on kik!! Just because I said no #toysoutofpram #spoiled #twat #idiot \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which suggest that the image is a hateful meme.\"}",
    "1107136395720695809": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Go eat the shit of your white masters you cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and a racial slur, which indicates that the image is hateful.\"}",
    "1107005860495147008": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:If you want to show the public that you're an absolute cunt, then these shirts are for you! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is likely to be perceived as hateful by some people.\"}",
    "1114243851839889408": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:nigga stole my swag and thought he could get away with it \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains racial slurs and promotes negative stereotypes. It is not appropriate to use such language or imagery.\"}",
    "1106751054799081473": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Ima county nigga but I still rep the city  \ud83c\udfc6 digg that \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which is not related to the tweet text. The tweet text contains racial slurs and derogatory language, making it a hateful meme.\"}",
    "1114195602269667328": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:The Army Nigga   Shout Out To The Boat My MotherFucking Nigga   #Lionhearted<tag> \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language towards African Americans, which is considered hateful. The use of the N-word and other offensive language in the tweet is inappropriate and disrespectful towards a specific group of people.\"}",
    "1114520030828318720": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> this cunt. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content.\"}",
    "1062360156682489856": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:That's annoying $ATXI retard \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language towards a specific stock, which indicates a hateful sentiment.\"}",
    "1109543307984683009": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Indeed &amp; vote out their Muzzie loving PM.\ud83d\ude0e \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, and the tweet text supports this classification by advocating for the removal of a political leader due to their supposed support for Muslims.\"}",
    "1107402963138605057": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> and<tag> really did wtf they had to do on \u201cChanged for You\u201d. Like...my nigga... \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which suggests that the image is a hateful meme.\"}",
    "1054113998097051650": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This nigga A Boogie be spazzin \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains racial slurs and is disrespectful towards a specific group of people.\"}",
    "1115311614188769280": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Nigga was like: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains racial slurs and is offensive to many people.\"}",
    "1110268614479880193": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Word my nigga???? That extendo command grab is crazy lmao #PS4share  \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racial slurs and is considered hateful.\"}",
    "1110398734049951744": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Surrender (ft. Monty G) by Bizzle, Monty G   Buy song \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is a black background with no visible content, and the tweet text does not contain any hateful or offensive language.\"}",
    "1114575471453327360": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Put that in your 6 in a row pipe daft cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is considered hateful.\"}",
    "1107187153656795137": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> \ud83d\ude02\ud83d\ude02\ud83d\ude02 nigger i said come fight me! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains racial slurs and encourages violence.\"}",
    "1110265527853875205": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:If I'm to fight with this guy I'll tell him \"nigga we gonna have a fight but with just our legs bruh, no hands\" \ud83d\ude04 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person's legs, and the tweet text suggests a racist and aggressive tone. This combination of elements suggests that the image is a hateful meme.\"}",
    "1115739658950926336": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> this nigga ahj sent me this tho \ud83d\ude02\ud83d\ude02 jokes on you bitch \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and humor, suggesting that the image might be a hateful meme.\"}",
    "1115246583241637890": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Full Movie: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which can be perceived as a hateful meme due to its negative connotations. The tweet text does not provide any context or information that would change this classification.\"}",
    "1115789846004551681": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Lmao nigga left like \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which is not related to the tweet text. The tweet text contains a racial slur, making it a hateful meme.\"}",
    "1109111252377198594": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I\u2019m doneeee\ud83e\udd23 Even dead bitches want this nigga \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is considered hateful. The image itself is a black background, which might be used to create a provocative or controversial context for the tweet.\"}",
    "1114228682908938241": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Cardi B might as well start wearing black air forces since she love robbing nigga so much \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and references to violence, which indicates a hateful sentiment. The image itself is a black background, which may not have any direct relation to the content of the tweet.\"}",
    "1115224971838668811": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> U can try nigga \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which is not related to the hateful tweet text. The tweet contains racial slurs and is offensive, but the image itself is not hateful.\"}",
    "1115765727615700994": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:My nigga, she need to start dressing like this AGAIN\ud83d\ude0d\ud83d\ude0d\ud83d\ude0d\ud83d\ude0d \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and promotes negative stereotypes, which indicates that the image is a hateful meme.\"}",
    "1113058495589482496": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Can a young nigga pull up in a 6, getting his d*ck scked\ud83d\udd25\ud83d\udc4c\ud83c\udffd\ud83d\ude4f\ud83c\udffd \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a young man's crotch area, which is considered inappropriate and offensive. The tweet text further emphasizes the hateful nature of the image.\"}",
    "1061878319958970369": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> I\u2019ll be back ka-ka-k....  Faggot. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and derogatory terms, suggesting a hateful sentiment towards the LGBTQ+ community.\"}",
    "1055937164121387010": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:a married man once tried to get at me &amp; i was so appalled because NIGGA i attended your damn wedding \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the tweet text, which contains racist language and is offensive.\"}",
    "1108456132186685440": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> What an ARROGANT Twat. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, suggesting that the image might be a hateful meme.\"}",
    "1043921094862929920": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Never go full retard \ud83e\udd23 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests that the image is a hateful meme, as it implies that the person is making fun of someone who is considered to be 'full retard'.\"}",
    "1108584959416127493": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:random blings like this, what keep a nigga going. i\u2019m living for more than just me. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and promotes negative stereotypes, which indicates that the image is a hateful meme.\"}",
    "1054136206039093248": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:ELDER: Reactions to Kanye West exposes the left's race-card hustle \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, suggesting that it may contain offensive or discriminatory content. The tweet text also implies that the image exposes the left's race-card hustle, which could be seen as a negative or controversial viewpoint.\"}",
    "1110313575388606464": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> No Nigga \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark background, which can be perceived as a hateful meme due to the use of the word 'No Nigga' in the tweet text. This word is considered offensive and racist, which contributes to the classification of the image as hateful.\"}",
    "1105571603054841858": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:When a broke nigga asks you to keep his baby  \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a negative stereotype of a black person in a disrespectful manner.\"}",
    "1109798715785654272": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:The worst kind of twat and we all know it. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and negativity, suggesting that the image might be a hateful meme.\"}",
    "1105649289659858944": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Vince wanna say \u201cwhat do you want from me nigger\u201d so bad \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains a racial slur and is disrespectful towards people of color.\"}",
    "1105509142440173569": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This nigga is so ugly \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the tweet text containing derogatory language towards a specific group of people.\"}",
    "1113176638550933504": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Who knew this nigga had told the best quote in anime \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, which suggests that the image might be a hateful meme.\"}",
    "1114534695184650240": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Highkey feel bad for this nigga, he gets no respect, or recognition \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it may contain offensive or discriminatory content. The tweet text further supports this classification as it refers to a person in a disrespectful and derogatory manner.\"}",
    "1105649748378374149": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Send this cunt back where she came from !  Probably Hell \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and a negative sentiment towards a specific individual or group.\"}",
    "1113081891647877121": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:this nigga really just said \"AID's started by fucking monekys/apes\" in US History. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark background, which is often associated with racism and hate speech. The tweet text also supports this classification as it contains offensive language towards African Americans.\"}",
    "1107874329281191936": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:They say I got next nigga I got now! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which are indicative of a hateful meme.\"}",
    "1114633360289275905": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Lammy the racist twat \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The presence of the word 'racist' in the tweet text further supports this classification.\"}",
    "1107843206585053184": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag> This nigga was like \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person, and the tweet text contains a racial slur. This suggests that the image is hateful and promotes negative stereotypes.\"}",
    "1106632898927562757": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:look at this nigga hands \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person's hands, which is being used as a hateful meme. The tweet text further supports this classification as it contains derogatory language.\"}",
    "1109244474885132288": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:\u201cGot more milkshake than Kelis, ain\u2019t met a nigga who can handle me.\u201d \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial stereotypes, which make it a hateful meme.\"}",
    "1116501522450472960": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:somebody pray for my nigga<tag> \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which are indicative of a hateful sentiment.\"}",
    "1114930985030889473": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This nigga wanna eat me #PS4share \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person, and the tweet text contains a racial slur. This suggests that the image is hateful and promotes negative stereotypes.\"}",
    "1115770270705430528": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:She\u2019s making the \u201credneck posing with a fish he caught\u201d face \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a negative stereotype of a person, specifically a woman, with a fish. This can be considered offensive and disrespectful to the individual and the community they belong to.\"}",
    "1106626168353103875": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> That nigga said whew ....know he made the lor sound wit it \ud83d\ude02\ud83d\ude02\ud83d\ude02 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person's head, and the tweet text contains racial slurs and derogatory language, indicating a hateful sentiment.\"}",
    "1114981567833632770": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Auto with air filters HR vs stock manual DE with driver mod which was me\ud83d\ude02 this nigga was talking out his neck too \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains content that is intended to be offensive or discriminatory towards a particular group of people. The tweet text also implies that the image is related to a discussion about air filters, drivers, and manual vs. automatic vehicles, but the focus on the image being hateful is what makes it controversial.\"}",
    "1109790108016877568": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> they try to put blame on a nigga imma put shame on em \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which is not related to the hateful tweet text. The tweet contains offensive language and is not appropriate for sharing. The image itself is not hateful, but the context in which it is being shared is.\"}",
    "1114444395133243392": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I hate this nigga so much. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains hate speech towards a specific individual, which indicates a hateful sentiment. The image itself, however, does not seem to be directly related to the hateful sentiment expressed in the tweet.\"}",
    "1109294712618471425": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I know this game don't mean shit, but I hate why nigga shooting so inefficiently man, that shit eats my soul. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet contains derogatory language towards African Americans, which is considered hateful.\"}",
    "1109468689433276418": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Redneck fisherman \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it may contain offensive or discriminatory content. The presence of the word 'redneck' in the tweet text might be related to the image's content, but it is not enough to determine the overall context and sentiment of the image.\"}",
    "1109867060320976898": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:WHO DA FUCK IS THIS NIGGA \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains racial slurs and is offensive.\"}",
    "1117594845802127360": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Game of thrones got a nigga hype \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, suggesting that the image might be a hateful meme.\"}",
    "1110182644271190016": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Happy VDay To My Mf Nigga Ju<tag> \u2b50\ufe0f\ud83d\udcaf\ud83d\udc89 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person's head, and the tweet text contains racial slurs and offensive language. This suggests that the image is intended to be hateful and offensive.\"}",
    "1114291729748910083": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Nigga of the Century \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person, and the tweet text contains a racial slur. This suggests that the image is intended to be hateful and offensive.\"}",
    "1061494263140233216": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Imagine stanning racists then calling yourself a coon/slave/ nigger. Whew Chile this is MUSTY \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, suggesting that it may contain offensive or discriminatory content.\"}",
    "1116428381090873344": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:\u201cWhen the bitch asked me what a real nigga was! I said me\u201d \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which are indicative of a hateful meme.\"}",
    "1116473260013572096": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> my nigga goin in 4really4real \ud83d\udc89\ud83d\udcaf\ud83d\udd2b\ud83d\ude24\ud83d\udd25\ud83d\ude80 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which is not related to the tweet text. The tweet text contains offensive language and racial slurs, making it a hateful meme.\"}",
    "1113131807346581505": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Nigga \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark background, which can be perceived as a hateful meme due to the use of the word 'Nigga' in the tweet text. This word is considered offensive and racist, and its presence in the tweet text suggests that the image might be promoting or supporting such language.\"}",
    "1106724563235336192": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:only took 1 minute to 2 stock a nigga clean in #elite_smash #ssbu_samus #ssbu \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person, and the tweet text contains racist language. This suggests that the image is hateful and promotes negative stereotypes.\"}",
    "1107179719303151617": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Do you have to be the same TWAT as the guy holding the sign! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, suggesting that it may contain offensive or discriminatory content. The tweet text also implies that the image may be derogatory towards a specific group of people.\"}",
    "1108773928347017216": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Nigga play wit me he gone die\u26b0\ufe0f\u2620\ufe0f \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains racial slurs and a threat of violence. The use of such language is offensive and inappropriate.\"}",
    "1113647216592289792": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:#RIDE4NIP Victory Lap Nigga This Marathon \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a marathon runner, and the tweet text contains racist language. This suggests that the image is hateful and promotes negative stereotypes.\"}",
    "1115362250762723329": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Imagine going through ya nigga phone, you peep I\u2019m curving him and you STILL try coming to me as a woman?! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a negative stereotype of a black person, which is offensive and disrespectful.\"}",
    "1114010980705554432": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This nigga got contacts and lost his fuckin mind!!!!!!  \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the racial slur used in the tweet text, which is offensive and discriminatory.\"}",
    "1108816658053951492": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Fuck \u2018em tbh. Liiike get a sense of humor.   Tbh how I\u2019d answer that question too. Embrace the cunt. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and a disrespectful attitude towards women. This is considered a hateful meme.\"}",
    "1045932264729825282": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Watch lesbian movie: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a woman's face, which is considered offensive and hateful towards women. The tweet text suggests that the image is related to a lesbian movie, which adds to the negative connotation of the image.\"}",
    "1113136998968176641": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:How are YOU going to tell me not to depend on a nigga but you got one sis. \ud83e\udd14\ud83e\udd27 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the racial slur used in the tweet text, which is offensive and discriminatory.\"}",
    "1105410685268381696": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I put this Ruger on safetyyyyy   Soo ion go shooting where ya nigga beeeee\ud83e\udd26\ud83c\udffe\u200d\u2642\ufe0f \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the use of racial slurs and the violent nature of the scene depicted.\"}",
    "1113971400933617666": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:report this twat please \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, suggesting that it may contain offensive or discriminatory content.\"}",
    "1044216612432293894": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> I\u2019m the twat \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains content that is intended to be offensive or harmful to a particular group of people.\"}",
    "1117401259483463680": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Go pound sand retard rep Adam. Hahaha \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, suggesting that the image is a hateful meme.\"}",
    "1107698941099995142": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> DARKEST TWAT DEMON \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The presence of the word 'DARKEST TWAT DEMON' in the tweet text further supports this classification.\"}",
    "1107429841358462982": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Ima be like \u201cYou Cunt!\u201d To mi teacher..she deserves it moumy. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language towards a teacher, indicating a hateful sentiment.\"}",
    "1108415521534459911": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:You a silly nigga \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language towards a specific group of people, which is considered hateful. The image itself does not seem to be hateful, but the tweet text associated with it is.\"}",
    "1108860688162803722": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:BRO\ud83d\ude02\ud83d\ude02\ud83d\ude02 Nigga said fuck all that! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racist remarks, which indicates that the image is hateful.\"}",
    "1109761022548684800": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Lmao.... Nigga said 'caps lock'...<tag><tag> \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which is not related to the tweet text. The tweet text contains racial slurs and is offensive, making it a hateful meme.\"}",
    "1107286535580385285": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:NIgga.... \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains a racial slur, which is considered hateful. The image itself is a black background, which might be used to spread such hateful messages.\"}",
    "1050722238360514560": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:&gt;calling Kanye a nigger to own Blumph \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person, and the tweet text suggests that it is a hateful meme. The use of the word 'nigger' is considered offensive and racist, which indicates that the image is promoting negative and harmful stereotypes.\"}",
    "1046705918665207808": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Hillbilly Stop Shop will be open today during study halls &amp; after school! \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is a black and white photo of a sky, which does not contain any text or visual elements that could be considered hateful. The tweet text is unrelated to the image and does not contain any hateful content.\"}",
    "1106495448980877319": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Look what this cunt tweeted. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, suggesting that it may contain offensive or discriminatory content.\"}",
    "1115678755052089344": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Just can\u2019t forgive him I walk around with a grudge shit not that simple took a nigga that I love \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the tweet text, which contains offensive language and a negative sentiment towards a person. The tweet text suggests that the person is not forgiving and is carrying a grudge, which is not a simple matter. The presence of such language in the image suggests that it is intended to provoke negative emotions or promote discrimination.\"}",
    "1107310009619238912": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Lions Tigers bears oh my cartoon shirts wearing ass nigga<tag> \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and racial stereotypes. The use of the word 'nigger' is particularly concerning and inappropriate.\"}",
    "1110350030299426818": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Putting a nigga in the friend zone hurts. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the use of racial slurs and the negative portrayal of a person of color.\"}",
    "1107082220018327552": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:BRO THE RACIST PERSON WHO I CALLED OUT FOR SAYING NIGGA BLOCKED ME NSKSKSK \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the tweet text, which contains racist language and a reference to a blocked individual.\"}",
    "1036225066210680833": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Oh yeah I'm retarded \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests that the image is hateful, as it implies that the person is retarded.\"}",
    "1054074452357582849": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> HAPPY BDAY MY NIGGA LOVE YOU BRO \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racial slurs and is offensive. The image, being a black background, might be used to promote such hateful content.\"}",
    "1114186866352447488": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Nigga dropping a lotta sauce \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains a racial slur, which is offensive and discriminatory.\"}",
    "1109273533215989760": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> fuck u nigga no typa appreciation it was good shit\ud83e\udd27 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racist remarks, which are not appropriate and should not be shared. This image is not hateful, but the tweet text associated with it is.\"}",
    "1105484016679936000": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Don\u2019t homie fvck unless his bands up....if you let the broke nigga fvck we telling #QueenRadio \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a man's face, and the tweet text suggests a negative attitude towards people who are struggling financially. This could be perceived as hateful, as it implies that people who are struggling should not be helped or supported.\"}",
    "1109741981624872960": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Im mad i really like this nigga \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and suggests a negative attitude towards a specific group of people. This is considered a hateful meme.\"}",
    "1053930592985903104": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Someone call him a cunt from me pls \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text further supports this classification as it calls for someone to call the person in the image a 'cunt'.\"}",
    "1114570369606795266": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> shut up faggot. u BEAUTIFUL \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language towards the LGBTQ+ community, which is considered hateful. The image itself is a black background, which might be used to display such hateful content.\"}",
    "1113618877286633472": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Bruh if this nigga was 21-22 he\u2019d be an arm baby in 1997 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and racist remarks.\"}",
    "1116418387389943810": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> It\u2019s not about biology Jer,it\u2019s about being a fcking cunt. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which indicates a hateful sentiment. The image itself is a black background, which might be used to create a provocative or aggressive atmosphere.\"}",
    "1106956498339618822": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Neil. Cunt. End \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The presence of the word 'cunt' in the tweet text further supports this classification.\"}",
    "1115982652518039553": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:DELUDED CUNT TO SPEAK TO DELUDED CUNTS #brexit #farage #nigelfarage #petulantmonkey \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which suggest that the image is a hateful meme.\"}",
    "1110286282729635840": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Nigga wasn't expecting that.  No, No! He never ready \ud83d\ude02\ud83d\ude02 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains racial slurs and is disrespectful towards a specific group of people.\"}",
    "1046744558091014150": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Bears repeating. Cuz SJW's don't like it. IT's just a MEME people. &lt;grin&gt;#QAnon #QArmy<tag> \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it may contain offensive or discriminatory content. The tweet text also implies that the image is being shared despite negative reactions from certain groups, which could further contribute to the perception of the image as hateful.\"}",
    "1116075226238980097": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Hahaha what a twat \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, suggesting that the image is a hateful meme.\"}",
    "1105032711180337152": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Via: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which can be perceived as a hateful meme due to its association with negative emotions or events. The tweet text also suggests that the image is a meme, which further supports the classification of the image as hateful.\"}",
    "1115415389041766405": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> \ud83e\udd23\ud83d\ude02\ud83e\udd23 nigga like sooooo..... \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person's head, and the tweet text contains racial slurs. This suggests that the image is intended to be hateful and offensive.\"}",
    "1108388837565317121": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> This nigga wildin \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The presence of the word 'nigger' in the tweet text further supports this classification.\"}",
    "1109122647902879745": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Nigga blocked me<tag> \ud83e\udd23\ud83e\udd23 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark background, which can be perceived as a hateful meme due to the use of racial slurs in the tweet text. The tweet text contains a racial slur, which is offensive and inappropriate. The image itself does not contain any explicit content, but the context provided by the tweet text makes it appear as a hateful",
    "1109891612740644864": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:FOCUS ON WHAT???? RT<tag> Focus on #NIGGER \ud83c\uddf3\ud83c\uddec \ud83c\udde9\ud83c\uddea \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark background, which is often associated with racism and hate. The tweet text further supports this classification as it focuses on the word 'nigger' and encourages others to do the same.\"}",
    "1110177741511495681": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:everybody turn into this nigga<tag> when they lose at 2k or an argument behind the screen \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text provided further supports this classification as it contains derogatory language towards a specific group of people.\"}",
    "1116443698903035918": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> This nigga cuzzo\ud83e\udd23\ud83e\udd26\ud83c\udffd\u200d\u2642\ufe0f \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text also reinforces this classification by using derogatory language.\"}",
    "1108858501579919362": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Im talkin to u nigga. Now get the steppin \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person's head, and the tweet text is a racial slur. This suggests that the image is intended to be hateful and offensive.\"}",
    "1109744629023473666": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> ma nigga? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which is not related to the hateful tweet text. The tweet text contains racial slurs and is offensive, making it a hateful meme.\"}",
    "1113693383409770496": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Watch out for bitches like this, they got that \u201cNigger lynching\u201d mindset then play victim\ud83e\udd2f FOH goofy\ud83d\ude07 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a negative and offensive stereotype of a person, specifically a black person, with a racist and discriminatory message.\"}",
    "1117037129027268608": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> How are people retarded enough to think this is blackface? People now days are stupid \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the tweet text, which contains offensive language and insults towards people who may perceive the image as blackface. The tweet also implies that the people who think this way are 'retarded' and 'stupid', which further contributes to the negative sentiment associated with the image.\"}",
    "1105250726526308354": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:yooo that old nigga funny asf \ud83d\ude02\ud83d\ude02 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text further supports this classification as it uses derogatory language towards a specific group of people.\"}",
    "1106670616625729537": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Ride &amp; choke that nigga out until he busts. Then keep riding him. \ud83d\ude08\u264a\ufe0f \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it promotes violence and discrimination against a specific group of people.\"}",
    "1054068912642355200": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag> Cyst is playing the victim card rn :-----)))) \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, suggesting that it may contain offensive or discriminatory content.\"}",
    "1044224080998592512": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag> And retard I said it once so \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, suggesting that the image might be a hateful meme.\"}",
    "1110292004011999232": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Save Nigeria further stress and surrender the mandate you stole \u2013 Pdp to\u00a0Buhari \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which is often associated with negative emotions or events. The tweet text suggests a political message, which can be perceived as hateful or divisive. The combination of the image and the tweet text creates an atmosphere of negativity and contention, which can be considered as a hateful meme.\"}",
    "1061795574192705536": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:#teen lesbian stick toy to old granny cunt #Delmenhorst \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a woman's genitalia, which is considered inappropriate and offensive. The tweet text further emphasizes the hateful nature of the image by using derogatory language towards a specific group of people. This combination of elements suggests that the image is intended to be hateful and offensive.\"}",
    "1116509667193176064": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Late hump day post....I can do it better without a nigga \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains racial slurs and is disrespectful towards a specific group of people.\"}",
    "1060894632983384064": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:For the love of god Usyk, knock the living shit out of this cunt for the sake of boxing \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and a call for violence, which indicates a hateful sentiment towards the person being referred to.\"}",
    "1108842076156751872": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Fuck you, hypocritical cunt! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which suggests that the image is intended to be hateful or offensive.\"}",
    "1054369385589211136": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> okay dyke \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains a derogatory term for a lesbian, suggesting that the image is hateful.\"}",
    "1113586235631644673": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:nigga wjo \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racial slurs and is offensive. The image, being a black background, might be used to further amplify the offensive message.\"}",
    "1114914394058702850": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Nigga we made it \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racial slurs and is offensive. The image, being a black background, might be used to further amplify the message. This combination of elements suggests that the image is a hateful meme.\"}",
    "1116078685558333440": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Go flood the comments tell<tag> I\u2019m that nigga \ud83d\ude24 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text further supports this classification as it uses derogatory language and references a racial slur.\"}",
    "1109200492775817217": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:all weekend nigga \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which is not related to the hateful tweet text. The tweet text contains racist language, which is offensive and inappropriate. The image itself is not hateful, but the content of the tweet is.\"}",
    "1116070268718473217": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Where\u2019s my money nigga? #leg10npodcast \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains a racial slur, which is considered hateful. The image itself is a black background, which might be used to create a provocative or controversial context for the tweet.\"}",
    "1113157977983397891": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Me dancing for my dyke \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person, which is often associated with negative stereotypes and discrimination. The tweet text further supports this classification as it contains language that is offensive and derogatory towards the LGBTQ+ community.\"}",
    "1109579631634587648": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I may* have called one of them a fucking cunt whilst my Mum was in the passenger seat *did \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, which suggests that the image could be a hateful meme.\"}",
    "1113419007317749760": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Or in bonucci\u2019s words, he is a twat but I don\u2019t like all of the hate I\u2019m getting \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content that is intended to harm or demean a particular group of people.\"}",
    "1064229215762087937": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:been at work all fuckin day and my twat of a big sister is at my house FUCK OFF \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and a negative sentiment towards the speaker's sister, which indicates a hateful sentiment.\"}",
    "1035564227518521345": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Full Gallery: \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is a black and white photo of a sky, which does not contain any explicit or offensive content. It is not a hateful meme.\"}",
    "1109166897650679809": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:ok but who else giving you cunt in a tshirt and socks w/ sandals.. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, suggesting that it may contain offensive or discriminatory content.\"}",
    "1047221920498966528": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Dis woman is retarded \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and insults towards a woman.\"}",
    "1114198384380747776": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Do body builders realize when they go to far. Look at this nigga. He looks like a burnt marshmallow \ud83d\ude10\ud83d\ude10\ud83d\ude10\ud83d\ude10\ud83d\ude10\ud83d\ude10\ud83d\ude10\ud83d\ude10\ud83d\ude10 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, likely due to the use of derogatory language in the tweet text.\"}",
    "1107978450328055809": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Leave that nigga sis \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person's head, and the tweet text contains a racial slur. This suggests that the image is intended to be hateful and offensive.\"}",
    "1115359596296704001": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:On this weeks episode of broke ass nigga we have<tag> \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person's face, with the tag <tag> on it. The tweet text suggests that it is a hateful meme. The classification is based on the context provided by the tweet text.\"}",
    "1116373833571799040": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Was on my grind, it was my time I ain't think twice, I paid that price and we did this, nigga! \ud83c\udfc1\ud83c\udfc1 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet contains offensive language and racial slurs, which make it a hateful meme.\"}",
    "1043081210400894976": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:She is retarded tbh \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language towards a person with a disability, which is considered hateful.\"}",
    "1107085700426543104": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Nigga was like \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person, and the tweet text contains a racial slur. This suggests that the image is hateful and promotes negative stereotypes and discrimination.\"}",
    "1034779615460515841": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag> Nah James she's a two faced twat. Like you \ud83d\ude0f \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, suggesting that it contains offensive or derogatory content towards a specific individual or group.\"}",
    "1063559581371113473": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Find the word retard \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, likely due to the use of offensive language or imagery.\"}",
    "1055905459817857030": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Henry Van Dyke.- #quote #image Via \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a sky, which is being used as a quote by Henry Van Dyke. The tweet text does not provide any context or information that would suggest the image is hateful. Therefore, the classification is based on the assumption that the image is being used in a hateful manner.\"}",
    "1109828139289665538": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Young nigga turnt up... never gave AF -<tag> \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a young man, which is often associated with negative stereotypes and racism. The tweet text further supports this classification as it uses offensive language and reinforces harmful stereotypes.\"}",
    "1105304972491702277": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Nigga ! \ud83d\ude02\ud83d\ude02\ud83d\ude02\ud83d\ude02\ud83d\ude02\ud83d\ude02 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains racial slurs and is disrespectful towards a specific group of people.\"}",
    "1056689358860763136": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This cunt, holy moly \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which suggests that the image is hateful.\"}",
    "1115324300511174657": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Of course the faggot is a bourgeois cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and derogatory terms, suggesting a hateful sentiment towards a specific group of people.\"}",
    "1114937963744382976": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:THIS NIGGA AINT EVEN IN THE GRAVE YET!!! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which are indicative of a hateful meme.\"}",
    "1113477972231577600": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I hate when my side nigga hit me all day ! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains hate speech towards a specific group of people, which is considered hateful.\"}",
    "1113513579708264448": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I hate twitter y'all goofy and not active but sign this at least dumb hoes\ud83d\udcaf\ud83d\ude4f\ud83c\udffeon some real nigga shi \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains content that is offensive or discriminatory towards a particular group of people.\"}",
    "1056978985270284288": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:\u201c A NIGGA CANT FUCK ME, I FUCK THEM\u201d   \ud83d\udc85\ud83c\udffd #QueenRadio \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and racial stereotypes. The tweet text further supports this classification as it uses derogatory language towards a specific group of people.\"}",
    "1035307100103225344": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag><tag> Idk, he just called clean a faggot apparently \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person's head, and the tweet text suggests that it is a hateful meme, possibly related to a derogatory comment about cleanliness.\"}",
    "1108313537963798530": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Let this sink in! #BuildTheWall #Trump2020 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a wall, which is often associated with the political stance of building a wall to keep out immigrants. The tweet text suggests a political agenda and supports the idea of building a wall, which is a controversial and hateful sentiment.\"}",
    "1062813613424025602": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> They\u2019re always using that Race Card..\ud83e\udd2e Here\u2019s the real Truth- Just in another time- \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text also supports this classification as it implies that the image is being used to make a negative or controversial statement about a particular group of people.\"}",
    "1110048572374802432": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:While he filled your ass with his seed he groaned about how he was glad the nagging cunt was dead \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive and disrespectful language towards women.\"}",
    "1114196397857878016": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Carried my nigga to his first victory.<tag> #ApexLegends \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person's head, and the tweet text contains a racial slur. This suggests that the image is intended to be hateful and offensive.\"}",
    "1107735064266375173": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:We were cool until you told me you let your nonBlack friends say Nigga because \u201cthey\u2019ve been through shit too!?!\u201d \ud83e\udd74 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person's face, which is considered a hateful meme as it is associated with racism and discrimination. The tweet text further supports this classification as it contains offensive language and a racial slur.\"}",
    "1035210689877487616": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:American rapper Doja Cat apologises for saying faggot \u201815,000 times\u2019 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which is not related to the tweet text. The tweet text contains offensive language, suggesting that the image might be associated with a hateful meme. However, without any visual content in the image, it is not possible to confirm the presence of a hateful meme.\"}",
    "1057462387144581121": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:NIGGA WHO THE HELL IS THIS????? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains racial slurs and is offensive to many people.\"}",
    "1050082595550171137": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:America went from CLASS, to WHITE TRASH! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, suggesting that it contains offensive or discriminatory content. The tweet text further supports this classification as it contains derogatory language towards a specific group of people.\"}",
    "1110448774030204928": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> NIGGA RUN IT BAAAAAAACCKK???? \ud83d\ude27 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person, and the tweet text contains a racial slur. This suggests that the image is intended to be hateful and promote negative stereotypes.\"}",
    "1059469392096817157": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:#\u3075\u3061\u3083\u3077\u308c Operation Cunt Destroyer - Slam Before Time (Slam Before Time) \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text also supports this classification as it uses derogatory language towards women.\"}",
    "1109072441500942336": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Who are you? I have more subscribers than you more followers WTF nigga \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, suggesting a hateful sentiment towards the person being addressed.\"}",
    "1107683372015501317": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:\u201cSurrender is the ultimate technique to merge with existence.\u201d \u2015 Bhagawan Sri Nithyananda Paramasivam #Hinduvidual \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person's head, with a quote about surrender. The tweet text suggests that this image is related to a hateful meme. The classification is based on the fact that the image and the tweet text are associated with a controversial or hateful message.\"}",
    "1062097021224464386": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:He really is a cunt. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or derogatory content.\"}",
    "1116885721732796417": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Ayoooo i am criiiiiinnneeee \ud83e\udd23\ud83e\udd23\ud83e\udd23 CTFU dis nigga sweatin  and shit\ud83e\udd23\ud83e\udd23\ud83e\udd23 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text is derogatory and disrespectful towards a specific group of people, which indicates that the image is hateful.\"}",
    "1043560265810432000": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> She must work at a white strip club because that was trash \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, likely due to the content of the tweet text, which contains a derogatory statement about a woman working at a strip club.\"}",
    "1113925380602245120": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Real my nigga. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racial slurs and is considered hateful. The image, being a black background, might be used to promote such hateful content.\"}",
    "1053479241541513216": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:SJW: SLEEP; WATCH TV ;PLAY ON PHONE; OBEY; CONFORM #SJWs  #NPC \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it may contain offensive or discriminatory content. The tweet text further supports this classification as it appears to be promoting a negative stereotype or ideology.\"}",
    "1046499739922034688": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:You a dyke &amp; can\u2019t get yo point across to a fem without putting yo hands on her or threatening her? You a pussy. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains derogatory language and insults towards the LGBTQ+ community.\"}",
    "1062743563707015168": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Watch it: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which can be perceived as a hateful meme due to its association with negative emotions or events. The tweet text does not provide any context or information that would change this classification.\"}",
    "1036281738090041344": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Another wetback killing Americans on U.S. soil. \ud83d\ude21 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains a racial slur and promotes negative stereotypes about Mexican immigrants.\"}",
    "1106748363427344384": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I said \u201csay less\u201d this nigga still talking \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains a racial slur and is disrespectful towards a specific group of people.\"}",
    "1054032660086079489": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:black licorice is disgusting  fight me cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and a negative sentiment towards black licorice, which suggests a hateful attitude.\"}",
    "1114476404467490816": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> my nigga ..... \ud83d\ude02\ud83d\ude02\ud83d\ude02\ud83d\ude02\ud83d\ude02\ud83d\ude02\ud83d\ude02 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which is not related to the hateful tweet text. The tweet text contains derogatory language towards African Americans, which is offensive and inappropriate. The image itself is not hateful, but the tweet text associated with it is.\"}",
    "1115799906696876032": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Nigga did I just seen some shit that said magic quit ?!!! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the racial slur used in the tweet text, which is inappropriate and offensive.\"}",
    "1108915694505091072": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:my nigga needs that kegare implant stat \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racist language, which is considered hateful. The image itself is a black background, which might be used to create a provocative or controversial context for the tweet.\"}",
    "1109561202726879238": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Fowk that say they find the word cunt offensive........ aye like it's a fucking regular in a Christmas card. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the use of offensive language in the tweet text, which is displayed on the image.\"}",
    "1056935709154643968": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Feckless cunt STFU \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, which suggests that the image might be a hateful meme.\"}",
    "1046458688553328640": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Obama played Race Card Hillary Played the Woman Card AMERICA PLAYED THE TRUMP CARD \ud83c\uddfa\ud83c\uddf8\u2764\ufe0f\ud83c\uddfa\ud83c\uddf8\ud83d\udc4d \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a negative and discriminatory message about a specific group of people, which is not acceptable.\"}",
    "1109758012191883266": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> You Never Met A Nigga Like Me Before \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person, and the tweet text contains a racial slur. This suggests that the image is intended to be hateful and offensive.\"}",
    "1113159313676210176": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> This the type of shot that nigga took\ud83d\ude2d \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, likely due to the use of racial slurs and the overall negative tone of the image.\"}",
    "1054329305243754496": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Never go full retard. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests that the image is hateful, as it implies that the person is not retarded and should not be treated as such.\"}",
    "1116493755140456449": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:nigga said beastie boys \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person's head, and the tweet text contains a racial slur. This suggests that the image is intended to be hateful and offensive.\"}",
    "1105148591537049600": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Aye but my nigga kame back and blessed the game no kap!! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which are indicative of a hateful meme.\"}",
    "1061661156400607233": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:shut up retard \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, suggesting that the image might be a hateful meme.\"}",
    "1105640554627588097": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This nigga Ernest just be talking \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains racial slurs and offensive language. The tweet text further supports this classification as it uses derogatory language towards a specific individual.\"}",
    "1107446689873448961": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Me anytime a nigga think something is so funny. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the racial slur used in the tweet text. It is not appropriate to use such language, and it can be offensive to many people.\"}",
    "1109422778023841797": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Do not arrest...Shoot on Sight!!!! That Nigga has to die!!! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racist language and a call for violence, which indicates a hateful sentiment.\"}",
    "1109502432806092800": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This nigga trying to scam \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains a racial slur and is disrespectful towards a specific group of people.\"}",
    "1053960184245116928": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> 2 weeks in a row. I wonder what those SJW's think of this..... \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests that the image is related to social justice warriors, which might be perceived as a negative or hateful sentiment. The classification is based on the assumption that the tweet is referring to the image and not just a random comment.\"}",
    "1037296585720377344": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Straight Men Use Faggot for Amusement! ......  See this and more at: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which is not related to the tweet text. The tweet text contains derogatory language towards the LGBTQ+ community, which is hateful. The image itself is not hateful, but it is being used to spread hateful messages.\"}",
    "1113866542192709638": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:now they got me wondering what the situation was for this nigga to come in grillin like that \ud83d\ude02 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the tweet text, which contains derogatory language towards a specific group of people.\"}",
    "1044652740092334080": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:maybe i am a faggot \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains content that is intended to be offensive or discriminatory towards a particular group of people, such as the LGBTQ+ community. The tweet text further supports this classification as it contains derogatory language towards the LGBTQ+ community.\"}",
    "1115187282435350529": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I get two days off work and now I\u2019m back im stuttering like a twat \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which suggests that the image is a hateful meme.\"}",
    "1109552461625348102": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Trump Birthday Card - Build a wall around your cak \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it is a black and white photo of a cake with a message that is offensive and discriminatory towards a specific group of people.\"}",
    "1115222802196586497": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Incredible self-own by<tag> to start my week off right but I still love the little retard to death. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language towards a specific individual, which indicates a hateful sentiment. The use of the word 'retard' is derogatory and disrespectful, which further supports the classification of this image as hateful.\"}",
    "1042977473804156928": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Did some one say, happier then a Redneck at WAl-MART ? Yee -Haw !\ud83d\ude02\ud83d\udc4d \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it may contain offensive or discriminatory content. The tweet text also implies that the image is meant to be humorous, but it may still be considered hateful by some viewers.\"}",
    "1057266753045217285": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Fuck of UDA terrorist cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and a reference to a terrorist group, which suggests a hateful sentiment towards a specific group of people.\"}",
    "1108188813300367360": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:(no rtw) dyke grip \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a woman's face, which is considered a hateful meme as it can be perceived as derogatory or offensive towards women. The tweet text does not provide enough context to determine if the image is intentionally hateful or not.\"}",
    "1115340583504097281": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:how am i a fan of a nigga i don\u2019t fw? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which are indicative of a hateful sentiment. The use of such language is not acceptable and can be harmful to individuals and communities.\"}",
    "1058545419293208578": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:WALL TRIGGERED! #BuildTheWall #MAGA #PatriotsFight #QAnon #FactsMatter #WWG1WGA #POTUS #hillary2020 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a wall, which is often associated with hateful or divisive rhetoric. The tweet text also supports this classification as it contains hashtags and text related to political and social issues that can be considered hateful or divisive.\"}",
    "1036998863817789441": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Sounds like redneck shawarma. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is considered hateful.\"}",
    "1114320515760644096": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Lmao this cunt went to private.<tag> classy spurs fan \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which suggests that the image is a hateful meme.\"}",
    "1114308809164333058": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Taiju just gets shit done, no thinking involve just straight action. I love that nigga \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and a racial slur, which indicates a hateful sentiment. The image itself is a black background, which may not have any direct relation to the content of the tweet.\"}",
    "1054121065922867200": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:YIKES NIGGA #PS4share \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person, and the tweet text contains a racial slur. This suggests that the image is intended to be hateful and offensive.\"}",
    "1113359145346973696": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Tiny Titted Paige Toying Her\u00a0Twat \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a woman's torso, which is considered inappropriate and offensive. The tweet text further adds to the negative sentiment of the image.\"}",
    "1113652419089522690": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:nan\nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which can be perceived as a hateful meme due to its association with negative emotions or events. The tweet text does not provide enough context to determine if it is a hateful meme or not.\"}",
    "1058313882001797120": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:That nigga really made it to 22.. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains racial slurs and is disrespectful towards a specific group of people.\"}",
    "1037390552994439168": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:i spy with my little eye A Dyke \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a woman's face, which is considered hateful due to the negative connotation of the word 'dyke' and the fact that it is a meme. The word 'dyke' is often used as a derogatory term for lesbian women, and the use of this term in the meme can be perceived as hateful.\"}",
    "1107625653829017600": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Please block me you twat \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and a request to block the user, indicating a hateful sentiment towards the person who posted the image.\"}",
    "1109317005251764225": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Sigh. This nigga trying to buy all this flonase lol! #Meth \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, likely due to the tweet text associated with it.\"}",
    "1108592993303322624": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Have a nigga like lol \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which is not related to the hateful tweet text. The tweet contains offensive language and is not appropriate for sharing. The image itself is not hateful, but the content shared with it is.\"}",
    "1114257711242174464": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Nigga said Gunna &amp; Lil baby better than Drake &amp; Weezy. Bruh idk what type troll crack y\u2019all be smoking but \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme that is considered hateful due to its content, which includes racial slurs and derogatory language. This type of content is not appropriate and should not be shared.\"}",
    "1109614710276657157": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:CUNT of the Year  -  1st Prize \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a woman's face, which is considered offensive and disrespectful. The tweet text further emphasizes the negative sentiment towards women. This combination of elements suggests that the image is a hateful meme.\"}",
    "1058497649576423424": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:like it was funny the first few times but now its just fucking retarded  <tag> fix your shitty mm system \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and a negative sentiment towards the image. The use of the word 'retarded' is considered derogatory and disrespectful towards people with intellectual disabilities. This classification suggests that the image is not funny or enjoyable, but rather offensive and disrespectful.\"}",
    "1053810865705836545": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:how tf you claim that you love giving head, but you can\u2019t give head? NIGGA WHAT \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which are indicative of a hateful meme.\"}",
    "1114652796563927043": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:can't escape nigga \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person, and the tweet text contains a racial slur. This suggests that the image is intended to be hateful and offensive.\"}",
    "1055163505001807877": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Here is the main cunt in all her cunty glory \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text further supports this classification as it uses derogatory language to describe the image.\"}",
    "1113922380534112256": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:My nigga<tag> just leveled up on merch and got a whole alcoholic beverage for the thots! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and promotes harmful stereotypes, making it a hateful meme.\"}",
    "1106934351621771265": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Just witnessed a nigga get rejected in the captainsparklez twitch chat \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains a racial slur in the tweet text, which is offensive and discriminatory.\"}",
    "1061770190587740161": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> You white trash, redneck POS! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content towards a specific group of people.\"}",
    "1117291061485932544": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:DMAN WHAT DIS NIGGA SO ANGRY FOR \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains a racial slur and is disrespectful towards a specific group of people.\"}",
    "1108844880674070532": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Leo will always be Leo ...Politician Just a simple question nigga will go round and round.. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains a racial slur and is disrespectful towards a specific individual.\"}",
    "1054475548494245888": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Love these people \u201c I have a baby so drive carefully around me\u201d yet drives like a f$cking twat! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and a negative sentiment towards the person being referred to. This suggests that the image could be a hateful meme.\"}",
    "1114120663080546309": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:The Full Gallery: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which can be perceived as a hateful meme due to its negative connotations. The tweet text also suggests that it is a full gallery, which might imply that there are more images to follow, potentially containing more hateful content.\"}",
    "1113443517022572544": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Bro I can\u2019t be the only nigga that was dying laughing when Joe Budden roasted the way Chance raps \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains a racial slur, which is considered hateful. The image itself is a black background, which might be used to create a provocative or controversial context for the tweet.\"}",
    "1106743590473162752": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag> Who dis nigga? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person, and the tweet text is a racial slur. This suggests that the image is intended to be hateful and offensive.\"}",
    "1116852191627706368": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:up i can't make him a faggot idc what he does freak \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language towards the individual, suggesting a negative attitude towards them. This could be considered as a hateful meme.\"}",
    "1109826069098573830": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> This Remainiac twat is pretty funny. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, suggesting that the image is a hateful meme.\"}",
    "1113198547611078656": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:HOW THE FUCK I\u2019M GON FIND A HOOD NIGGA THAT\u2019S INTO THEATRE?! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial stereotypes, which make it a hateful meme.\"}",
    "1105564076053282819": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Yikes. Lol nigga said throwing them in the group chat \ud83e\udd74 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the racial slur used in the tweet text, which is inappropriate and offensive.\"}",
    "1105493079690276864": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Nobody:  That One Nigga That Wasn\u2019t Really Down To Rob Jay: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person, which is often associated with racism and hate. The tweet text also supports this classification as it contains a racial slur.\"}",
    "1035922273130242051": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag> His wife hates white people.  They are racist trash. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racist language and hate speech, which is not appropriate or acceptable. The image itself is a black background, which could be used for any content, but the context of the tweet makes it clear that it is meant to be hateful.\"}",
    "1063880486869553152": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Every fucking day on your bitch ass nigger ass game.<tag> \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text further supports this classification as it contains derogatory language towards a specific group of people.\"}",
    "1106547498745823232": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Some shit off SAW \ud83e\udd14\ud83d\ude02 RT<tag>: nigga barber doing too much \ud83d\ude2d\ud83d\ude2d \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme that is considered hateful due to its content, which includes a racial slur and a reference to a violent act. The tweet text further supports this classification as it contains offensive language.\"}",
    "1109499677433647107": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Just getting out the ring with mike Tyson knocked him out the faggot \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and references to violence, which suggests that the image is a hateful meme.\"}",
    "1058405319498440704": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Got it, cunt?! \ud83d\ude0b \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, suggesting that the image might be a hateful meme.\"}",
    "1035792632604180480": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Another vid sold! Cum Tit Cleaning Faggot \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark background, which is often associated with negative emotions or hate. The tweet text also contains offensive language, further suggesting that the image is hateful.\"}",
    "1113523157502177283": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Lmfao fuck that nigga \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, which suggests that the image might be a hateful meme.\"}",
    "1051246692253753346": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Twat rocket \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The presence of the word 'twat' in the tweet text further supports this classification.\"}",
    "1057377180722839554": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> 100% retarded you are??? \ud83d\ude18\ud83d\ude18\ud83d\ude18 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text also supports this classification, as it uses derogatory language to describe the image.\"}",
    "1115644901146886145": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Full Gallery: \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is a black and white photo of a sky, which does not contain any explicit or offensive content. It is not a hateful meme.\"}",
    "1114834902254596096": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I keep shouting \"The Butcher coming nigga\" \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racial slurs and aggressive language, which suggests that the image is a hateful meme.\"}",
    "1107106184409026562": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This nigga focused as fuck \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the use of racial slurs and the overall negative connotation it carries.\"}",
    "1115289315179888642": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Wrong nigga lmao \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark background, which is often associated with racism and hate. The tweet text further supports this classification as it contains a racial slur. This combination of elements suggests that the image is a hateful meme.\"}",
    "1115827768066039817": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Since there was too many tanjiro layouts, had to get my nigga rengoku in here. I think this layout some heat \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is considered hateful. The image itself is a simple black background, but the tweet text brings a negative connotation to the image.\"}",
    "1057453549821616130": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Had to be this nigga \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The presence of the word 'nigga' in the tweet text further supports this classification.\"}",
    "1036971266618667008": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Straight Men Use Faggot for Amusement! ......  See this and more at: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which is not related to the tweet text. The tweet text contains derogatory language towards the LGBTQ+ community, which is hateful. The image itself is not hateful, but it is being used to spread hateful messages.\"}",
    "1108146422795382789": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:When a white person says Nigga \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a white person with the word 'Nigger' written on it. This is considered a hateful meme as it uses racial slurs and promotes negative stereotypes.\"}",
    "1117534895419486208": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Why does the first nigga look like shigaraki and All might in his small form \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the racist and offensive content in the tweet text. The reference to a racial slur and the comparison to a popular anime character are inappropriate and disrespectful.\"}",
    "1062763161114370048": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:#FOX5 brings this #Horde update.  \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a group of people, which can be perceived as a hateful meme due to its negative connotation. The tweet text also suggests that it is an update on a horde, which might evoke negative emotions in some people.\"}",
    "1113207268055629824": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:\u201cLookin at da legend I become nigga  I can't help but feeling like I am da 1 nigga\u201d \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person's head, and the tweet text contains racial slurs and derogatory language, which indicates a hateful sentiment.\"}",
    "1115767716026167296": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Where the fuck is it lad yer lying cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, suggesting a hateful sentiment towards the person being addressed.\"}",
    "1113502735922495488": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Man I\u2019ve seen some retarded takes on this app but you two win the grand prize \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, suggesting that the image is a hateful meme.\"}",
    "1114913306635063296": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This is why President<tag> must close the border!  #buildthewall \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a wall, which is often associated with racism and xenophobia. The tweet text suggests a political stance that supports closing borders, which can be perceived as hateful towards certain groups of people.\"}",
    "1108691602585866240": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:\ud83d\ude31shaved her cunt, like?\ud83d\udc45\ud83d\ude0f\ud83d\udca6\ud83d\udca6 #karolina_rus  #nsfw \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a woman's genital area, which is considered inappropriate and offensive. The tweet text further suggests that the image is intended to be provocative and disrespectful towards women.\"}",
    "1105550540702994434": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Full Movie: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which can be perceived as a hateful meme due to its negative connotations. The tweet text does not provide any context or information that would change this classification.\"}",
    "1106961768616787970": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag> Thank God for President Trump \ud83d\ude4f\ud83c\uddfa\ud83c\uddf8\ud83d\ude4f#BUILDTHEWALL \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a wall, which is often associated with racism and xenophobia. The tweet text suggests a political and racial bias, further indicating that the image is hateful.\"}",
    "1106962909958156288": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> What a twat I am... I meant Rapunzel! \ud83d\ude04 \ud83d\ude44 \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is a black and white photo of a sky, and the tweet text does not contain any hateful or offensive language.\"}",
    "1116072762362216449": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Don't miss Dr. Rube's lecture on child and adolescent stress. #YouCanTalk \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is a black background with no visible content, and the tweet text is unrelated to the image. Therefore, it is not a hateful meme.\"}",
    "1061050289472454656": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Always the race card. Getting old. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, suggesting that it may contain racist or discriminatory content. The tweet text also implies that the use of the race card is becoming outdated, which could be interpreted as a racist comment.\"}",
    "1109146712139022336": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Don\u2019t shoot the messenger lol Batman just ain\u2019t that nigga compared to BP. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the use of racial slurs and derogatory language in the tweet text, which is inappropriate and offensive.\"}",
    "1106923732591955968": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Welcome to my new faggot \ud83d\ude08\ud83d\ude08 #cashmaster #cashfag #alpha \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black background with a tweet text that contains derogatory language towards the LGBTQ+ community. This is considered hateful and offensive.\"}",
    "1055309272630943744": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:#GamerGate are the only ones who know who was behind today\u2019s mail bombs. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests that the person behind the mail bombs is associated with the GamerGate movement, which has been criticized for promoting harassment and hate speech. This could be perceived as hateful by some people.\"}",
    "1107685661522518023": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:white niggas get an african passport and call it a nigga pass \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it promotes racism and discrimination by associating the term 'nigger' with African passports.\"}",
    "1113455188524838914": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Full Gallery: \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is a black and white photo of a sky, which does not contain any explicit or offensive content. It is not a hateful meme.\"}",
    "1113412490438807554": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Make your own insult for the cunt in your life. Link in bio. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests that the image is a hateful meme, as it encourages insulting someone and provides a link in the bio.\"}",
    "1105284080982286336": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Nigga blocked both accounts guess it hurts to hear the truth \ud83e\udd74\ud83d\ude02 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person's head, which is considered a hateful meme as it may be used to spread hate or discrimination. The tweet text also supports this classification as it contains offensive language.\"}",
    "1109495043214184448": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Your nigga got shit \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racial slurs and is offensive. The image, being a black background, might be used to further amplify the offensive message.\"}",
    "1113980077891567616": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Someone pound my racist cunt! \ud83d\ude29\ud83d\ude0d \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racist language, which is considered hateful. The image itself is a black background, which might be used to promote such hateful content.\"}",
    "1107761367623163904": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> White trash \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content towards a particular group of people. The presence of the tag 'White trash' in the tweet text further supports this classification.\"}",
    "1113482857937362946": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> I was waiting for some retard to bring race into it \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests that the image is a hateful meme, as it implies that the person is waiting for someone to bring up race in a negative context. This could be interpreted as racist or discriminatory, which is not a positive sentiment.\"}",
    "1106656112055668741": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Nigga gone be on that hoe like \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains a racial slur and is disrespectful towards the black community.\"}",
    "1107035762913144832": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Why that nigga sound like Kodak breathed in a helium ballon \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains a racial slur and is offensive in nature.\"}",
    "1107069151313563648": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:\"These colors don't run, they surrender.\" \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests a hateful sentiment, and the image is a black background with no other context or content to counteract it.\"}",
    "1108773677812903936": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Nigga you sick... \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark background, which is often associated with racism and hate. The tweet text also contains offensive language, further supporting the classification of the image as hateful.\"}",
    "1056574396398297094": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Must have been watching a different fight you ugly button nose cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which suggests that the image is a hateful meme.\"}",
    "1108762654888337408": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Don\u2019t buy from him nigga gave me an epic login and said I can use it for pc and blocked me \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the tweet text containing racial slurs and derogatory language.\"}",
    "1105178695604600832": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Still a better actress than Cunt Larson\ud83e\udd37\u200d\u2642\ufe0f Brie isn't even that good of an actress anyway. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults towards Brie Larson, which indicates a hateful sentiment.\"}",
    "1116086681122365441": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Nigga said a year ahead \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which is not related to the hateful tweet text. The tweet contains racial slurs and is offensive, but the image itself is not hateful.\"}",
    "1105653149719842818": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:REAL ASS BITCH GIVE A FUCK ABOUT A NIGGA... \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which are indicative of a hateful sentiment.\"}",
    "1045134731115933697": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag> \"We're sick of you SJW's telling us what our president is saying\" \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests that the image is related to a political or social issue, which can be considered as hateful. The use of the term 'SJW's' and the reference to the president's speech implies a negative attitude towards a certain group or individual, which is indicative of a hateful sentiment.\"}",
    "1108497151938699265": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:So I hear that<tag> has replaced me and Sean the cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and references to harming someone, which indicates a hateful sentiment. The image itself is a black background, which might be used to create a more dramatic or intense atmosphere, but it does not contain any explicit content that would make it hateful.\"}",
    "1114324453582757889": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Nigga what? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person's head, and the tweet text is a racial slur. This suggests that the image is intended to be hateful and offensive.\"}",
    "1117701344800980995": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Wrong my nigga,is already out..check the link below \ud83d\udc4d\ud83c\udffd \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text provided further supports this classification as it contains derogatory language.\"}",
    "1036280422009892865": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:#FastFoodFights Clear your table in the white trash can \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a table with a white trash can. The tweet text suggests that the image is related to a hateful meme, which implies that the image might be used to promote negative or harmful ideas. The classification is based on the context provided by the tweet text.\"}",
    "1108778243405029376": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Like as a nigga right...when that first white women gave me....homework. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains racist language and imagery, which is offensive and discriminatory.\"}",
    "1105502674504441856": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> happy bday shitty boi. keep on overthinking. hahaha but never surrender. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and a negative sentiment towards the person being referred to. This suggests that the image could be a hateful meme.\"}",
    "1113601819459112961": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Not me. This is a successful bad Jamaican. I\u2019m a nigger \ud83d\ude02\ud83d\ude02\ud83d\ude02\ud83d\ude02 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, and the tweet text further supports this classification as it contains offensive language.\"}",
    "1107941661848621056": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:\u201c Ahhhhhhhh Bacon Bacon Bacon Bacon \u201c \ud83e\udd23\ud83e\udd23\ud83e\udd23\ud83e\udd23\ud83e\udd23\ud83e\udd23\ud83e\udd23\ud83e\udd23 This Nigga Bunny Got Me Dead Asf , This The Fse \ud83d\ude2d\ud83d\ude2d\ud83d\ude2d \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and humor that could be considered hateful. The image itself is a black background, which might be used to create a meme. However, without more context, it is difficult to determine if the image itself is hateful or not.\"}",
    "1106602434602983424": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:After you get yo lul giggle or whatever I Might as well follow ah nigga onna gram #support your #supporters \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and promotes negative stereotypes, which indicates that the image is a hateful meme.\"}",
    "1061789996825395200": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:when I see a faggot I floor it \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and imagery, such as the tweet text 'when I see a faggot I floor it' which is derogatory towards the LGBTQ+ community.\"}",
    "1058992794012958720": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Tempted to just shoot this cunt I've been doing this for an hour  \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and a violent sentiment towards a person, indicating a hateful meme.\"}",
    "1109627319428235265": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:All i need now is hyojin to listen to janelle monae and shes completed every single thing on the dyke checklist \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image does not contain any explicit or offensive content. It is a simple black background with no text or symbols that could be interpreted as hateful. The tweet text does not seem to be related to the image either.\"}",
    "1115788875606179841": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> You are a major RETARD! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains insulting language towards the viewer, suggesting that the image is intended to be hateful.\"}",
    "1108846357308166144": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:How the fuck this nigga break out his cage \ud83e\udd37\ud83c\udffe\u200d\u2642\ufe0f\ud83e\udd37\ud83c\udffe\u200d\u2642\ufe0f\ud83e\udd37\ud83c\udffe\u200d\u2642\ufe0f \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person, and the tweet text suggests that it is a hateful meme. The use of the word 'nigger' in the tweet text is considered offensive and racist, which indicates that the image is likely to be hateful.\"}",
    "1113872920818913281": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Got her fucking on this rapping ass singing ass Nigga<tag> \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a woman's face, and the tweet text contains offensive language towards African Americans. This suggests that the image is intended to be hateful and racist.\"}",
    "1107754514919116800": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag> You okay my nigga \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racial slurs and is considered hateful.\"}",
    "1114542231321489408": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:After today if you\u2019re 5\u201910 or above you are considered ah nigga to me. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language and promotes discrimination, making it a hateful meme.\"}",
    "1043870524403855361": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:H. Rap Brown's Negro College Student ::: Highlighting Chapter Six Of 'Die Nigger Die!' \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person with the words 'H. Rap Brown's Negro College Student ::: Highlighting Chapter Six Of 'Die Nigger Die!' written on it. This text is associated with a hateful message, as it is a reference to a controversial book and its author. The image may be used to promote or support the ideas presented in the book, which can be",
    "1053775386444775424": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Twat \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content.\"}",
    "1110443032992800768": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This twat's on the Beeb insisting that May still has control of her party. They are all mad. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, suggesting that it may contain offensive or discriminatory content.\"}",
    "1113121944055025664": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Or maybe say no to being an anti abortion cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text further supports this classification as it uses derogatory language towards women who are pro-choice.\"}",
    "1057011230739701762": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Damn this nigga stole my wife \ud83d\ude12 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which are indicative of a hateful meme.\"}",
    "1058952489381347328": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Some cunt turned the heat on. Like no thanks. This is Texas. It's still HOT outside biTCH don't fry me. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet contains offensive language and a negative sentiment towards women, suggesting that it is a hateful meme.\"}",
    "1109481810537447425": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Y\u2019all niggas need to stop sleeping on my nigga mayn \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which are indicative of a hateful meme.\"}",
    "1114243074794901505": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Nigga \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person, which is often associated with racism and hate. The tweet text further supports this classification as it contains a racial slur.\"}",
    "1114695729568677888": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:When people say \u2018come on, there has to be something there!\u2019 Yea actually, trailer parks &amp; trailer trash \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a trailer park, which is often associated with negative stereotypes and stigmatization. The tweet text further supports this classification as it uses derogatory language to describe the residents of trailer parks. This suggests that the image and the accompanying text are intended to be hateful and discriminatory towards a particular group of people.\"}",
    "1109698591931666432": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Nobody: A nigga who don't want nothing serious with you: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the use of racial slurs and derogatory language in the tweet text. This kind of language is offensive and promotes negative stereotypes, making the image inappropriate and harmful.\"}",
    "1110256856054796289": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> LETS GO, this cunt has taken so much elo from me. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and a negative sentiment towards the image, suggesting that it is a hateful meme.\"}",
    "1115989474956148741": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:When you show up to the cookout after your nigga took you back for cheating on him: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains racial slurs and is disrespectful towards a specific group of people.\"}",
    "1108528054303948800": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:THESE NIGGA ARE GAY<tag><tag> \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language towards the LGBTQ+ community, which is considered hateful. The use of the word 'nigger' is also offensive and racist.\"}",
    "1114512698765717504": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:When the fag's account is zeroed.  \ud83d\udca6 because I took his money.  #findom #circle #finsub #faggot \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains content that is intended to be offensive or discriminatory towards a particular group of people.\"}",
    "1056573731370397696": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:KARMA WILL COME REAL QUICK BELIEVE THAT PIECE OF SHIT NIGGA \ud83d\ude24 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet contains offensive language and a racial slur, indicating a hateful sentiment.\"}",
    "1056328039078850560": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:AM I RETARDED FOR JUST NOW FINDING OUT GIEF CAN DO THAT WITH ONE MOVE?!? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person's hand holding a knife, which can be interpreted as a hateful meme. The tweet text suggests that the person is surprised or upset about something related to gifting, which could be a reference to the image. However, it is important to note that the interpretation of an image as hateful is subjective and may vary depending on the viewer",
    "1106891812302544897": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Nigga wouldnt die for SHIT #PS4share  \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person, and the tweet text contains a racial slur. This suggests that the image is hateful and promotes negative stereotypes.\"}",
    "1115671735712407552": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Stfu. U\u2019re a fcking cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, which suggests that the image might be a hateful meme.\"}",
    "1115855960097140736": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I\u2019m literally going in the other room to smoke for 10 minutes if this nigga falls asleep \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language towards a specific group of people, which is considered hateful. The image itself is a black background, which might be used to create a provocative or intimidating atmosphere, but it does not contain any explicit content that would make it a hateful meme.\"}",
    "1113032788075339778": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Yeah, i know. He's a cunt and so is creepy uncle joe. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, suggesting a hateful sentiment towards the person being referred to.\"}",
    "1058424232718331909": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:THIS NIGGA JUST LOST #NoNutNovember \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black background with no content, and the tweet text is a racial slur. This combination suggests that the image is intended to be hateful and promote negative stereotypes.\"}",
    "1108852824073474048": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:KOTAL KAHN IS A NIGGER?!? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains racial slurs and is offensive.\"}",
    "1108432104348618762": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Trump trailer trash presidency spinoff \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, suggesting that it may contain offensive or discriminatory content related to the Trump presidency or trailer trash.\"}",
    "1113015428849242113": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Thiiiiiiiiick my nigga! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is considered hateful.\"}",
    "1105636173244960768": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Still a nigga. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person, and the tweet text contains a racial slur. This suggests that the image is intended to be hateful and offensive.\"}",
    "1107619768759136257": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Fuck off u cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, which suggests that the image might be a hateful meme.\"}",
    "1117469728082149376": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Lol my nigga Atown! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, which suggests that the image might be a hateful meme.\"}",
    "1054163776256258048": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Heyyyyy nigga nerds \u2764\ufe0f \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racist language, which is considered hateful. The image itself is a black background, which might be used to create a provocative or offensive context for the tweet.\"}",
    "1108002893620232192": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This nigga must be the black Steve shives lmao \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racist language and is considered hateful.\"}",
    "1109498587862441989": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:\u201cGeT yOu A fAt NiGgA\u201d \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racist language, which is considered hateful. The image, being a black background, might be used to further emphasize the racist message.\"}",
    "1050876531478880256": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:You can even Google this sissy faggot \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, and the tweet text further supports this classification by using offensive language towards the subject.\"}",
    "1115376576575758337": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:eu vivo like a boss nigga, every day \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which is not related to the hateful tweet text. The tweet contains offensive language and promotes negative stereotypes, making it a hateful meme.\"}",
    "1062191707410849792": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> OMG you are pulling the race card.. because he stood up to a reporter.. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, suggesting that it may contain offensive or discriminatory content. The tweet text also implies that the image is being used to make a point about race, which could be considered as hateful.\"}",
    "1113180380918632448": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:- a nigga who does not love or respect you. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person, and the tweet text contains a racial slur. This suggests that the image is intended to be hateful and offensive.\"}",
    "1116838581283246080": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:#sissy cocksucker faggot \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black background with no content, and the tweet text is derogatory and offensive towards the LGBTQ+ community. This classification is based on the negative and discriminatory nature of the content in the image and the tweet text.\"}",
    "1115462755773972481": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:why ya tryna explain what this bitch ass nigga said like it sound any better? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text further supports this classification as it uses derogatory language to describe the image.\"}",
    "1107657997742940160": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I shouldn\u2019t have said \u201cwhat this nigga talking bout\u201d \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racial slurs and derogatory language, which indicates a hateful sentiment. The image itself is a black background, which might be used to create a provocative or offensive context for the tweet.\"}",
    "1115412582666518528": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> I\u2019m never ever opening up your story again! \ud83d\ude2d\ud83e\udd23 nigga I be having to move out the way you still my dawg \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which suggest that the image is a hateful meme.\"}",
    "1107774735780323328": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:\"Nail that nigga feet too.\" ????  Y'all are going to hell, PERIODT! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and promotes violence, indicating that the image is hateful.\"}",
    "1114878333681045504": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> funniest cunt ever \ud83d\ude02\ud83d\ude02\ud83d\udc80 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, suggesting that the image might be a hateful meme.\"}",
    "1114507797859848192": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> lmao u look jus like dis nigga \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, likely due to the reference to a racial slur in the tweet text.\"}",
    "1108530782723805186": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:#IfWomenRuledTheEarth<tag> would be the happiest bull dyke on the planet. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language towards the LGBTQ+ community, specifically towards women who identify as lesbian or butch. This is considered hateful and offensive.\"}",
    "1114264651024543750": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Sold my vid! Filthy Cunt Whore Custom \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, which suggests that the image might be a hateful meme.\"}",
    "1108491883536441345": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Fuck a regular name necklace my nigga bought me a chain \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which are indicative of a hateful meme.\"}",
    "1108433699828187137": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Nigga fumbled the baby Lmaoo wtf  \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains racial slurs and is disrespectful towards a specific group of people.\"}",
    "1056175110246170624": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Kindly increase the rate to listen one mentally retarded child \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it may contain offensive or discriminatory content. The tweet text also implies that the image is related to a mentally retarded child, which could be considered as derogatory or insensitive.\"}",
    "1108922007352160256": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Nigga wa \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person, and the tweet text contains a racial slur. This suggests that the image is intended to be hateful and offensive.\"}",
    "1109472775092211712": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> I went to school wit a nigga named andrew and his teeth were like \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and racial stereotypes. The tweet text further supports this classification as it uses derogatory language towards African Americans.\"}",
    "1109044961343926272": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:#DoYouRememberWhen<tag> won every race on a seven-race card and completed his 'Magnificent 7'?   \ud83d\ude0f\ud83d\ude4c \nASSISTANT: {\"Classification\": \"hateful or not hateful\", \"Explaination\": \"The image is not hateful as it is a simple black background with no explicit content or offensive message. The tweet text does not contain any hateful or offensive language either.\"}",
    "1110155824033341441": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Me when I see a nigga wearing all black Air Forces at school \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the tweet text, which contains racist language and is inappropriate for a school setting.\"}",
    "1107883919263842304": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> nah nigga fuck flexing, you fat ass need to \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text further supports this classification as it contains derogatory language towards a specific group of people.\"}",
    "1115171104111378433": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Almost 5 in the morning and a nigga still up \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains racial slurs and is disrespectful towards a specific group of people.\"}",
    "1044067377607053312": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag><tag> Go away trailer trash..... \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language towards a specific group, which indicates a hateful sentiment. The image itself is a black background, which might be used to convey a negative or aggressive message.\"}",
    "1109890031227977728": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:\"that's on period\" who the hell says that? nigga lying for no reason at all \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the racial slur used in the tweet text, which is offensive and inappropriate.\"}",
    "1107320868554850304": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Wa bona this guy, is a legend! My nigga \ud83d\ude02\ud83e\udd23\ud83d\udd25 #DateMyFamily \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is considered hateful.\"}",
    "1108693592686686208": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:They then let my racist QB get a nigger TE?! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the racist language used in the tweet text, which is associated with the image.\"}",
    "1114228769168994304": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I know nip looking down like Nigga who tf is that lol \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the racial slur used in the tweet text, which is inappropriate and offensive.\"}",
    "1114510379437056000": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:dyke energy is huge in this one \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, suggesting that it may contain offensive or discriminatory content. The tweet text further supports this classification by referring to the image as a 'dyke energy' meme, which could be perceived as derogatory towards the LGBTQ+ community.\"}",
    "1109435246288752640": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Fuck that nigga , this shit always had me edge \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which are indicative of a hateful sentiment. The image itself is a black background, which may not have any direct relation to the content of the tweet.\"}",
    "1106489459174985728": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I danced to NaN Nigga just like this<tag> \ud83d\ude02\ud83d\ude02Ayyyyye \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark background, which is often associated with racism and hate. The tweet text also contains offensive language, further supporting the classification of the image as hateful.\"}",
    "1107705720265428993": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> mhm.. Good Girls is my shit, Beth the realest nigga on the squad. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and references to a TV show, suggesting a hateful sentiment towards a particular group or individual.\"}",
    "1115476953497251841": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:You pulled your debit card out yo pocket nigga &amp; typed in the numbers . \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains racial slurs and is disrespectful towards people of color.\"}",
    "1105688017136771073": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Nah nigga was gooooodd!!! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is considered hateful.\"}",
    "1114365221005557760": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Nigga what...  \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark background, which is often associated with racism and hate. The tweet text further supports this classification as it contains offensive language.\"}",
    "1114403690276724737": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:she\u2019s a dyke ur honor \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a woman, and the tweet text suggests that it is a hateful meme. The use of derogatory language in the tweet implies that the image is intended to be offensive and discriminatory towards the woman depicted.\"}",
    "1108596555832012801": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Ran up on a nigga #PS4share  \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person, and the tweet text contains a racial slur. This suggests that the image is hateful and promotes negative stereotypes.\"}",
    "1108848529089486850": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:My nigga hips feelin fruity today \ud83d\udcaf \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which are indicative of a hateful meme.\"}",
    "1108177168146690048": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:\u201cMake ya nigga suck my pussy like a baby bottle,\u201d<tag>  Me: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and racial slurs. This type of content is not appropriate and should not be shared.\"}",
    "1107497234365587457": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:neck tat say deedee  make ya nigga nervous, gotta peepee \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the presence of the word 'nigger' and the reference to a neck tattoo. This language is offensive and discriminatory, which makes the image inappropriate and harmful.\"}",
    "1113935714650132482": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I\u2019m So Westside Nigga Areba Arbea -Nip\ud83d\udc99\u267f\ufe0f\ud83c\udd7f\ufe0f Long Live A Legend  #LONGLIVENIPSEY \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text also supports this classification as it uses derogatory language and references to a racial slur.\"}",
    "1107698357181378560": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> \u201cHer name is Chastity. She is white trash, same as you. Hillbilly!\u201d \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and derogatory terms, suggesting a hateful sentiment towards the person referred to in the tweet.\"}",
    "1113578517768306688": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I\u2019m sorry but this nigger doesn\u2019t even have internet on his phone and he\u2019s talking about trying to date me \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains racist language and imagery, which is offensive and discriminatory.\"}",
    "1109963648699695104": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Nigga I ain\u2019t finna do shit .. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which is not related to the hateful tweet text. The tweet contains racial slurs and aggressive language, which makes it hateful.\"}",
    "1117065493024858114": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This nigga here \ud83d\ude02\ud83d\ude02\ud83d\ude02\ud83d\ude02\ud83d\ude2d\ud83d\ude2d\ud83d\ude2d\ud83d\ude2d\ud83d\ude2d \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains racial slurs and derogatory language, which is offensive and discriminatory.\"}",
    "1116983391449157633": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:The Full Gallery: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which can be perceived as a hateful meme due to its negative connotations. The tweet text also suggests that it is a full gallery, which might imply that there are more images to follow, potentially containing more hateful content.\"}",
    "1035645717854007296": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Full Video: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person with a caption that says 'Full Video'. This could be interpreted as a hateful meme, as it may encourage violence or harm towards the person in the photo. The context of the tweet text is not provided, but it is important to consider the potential implications of sharing such images.\"}",
    "1115837012190408704": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:When a nigga want you to wait around for him to figure out what he wants \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains racial slurs and promotes negative stereotypes.\"}",
    "1116542803071373312": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Nigga is that?? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark background, which is often associated with racism and hate. The tweet text also suggests a negative and offensive sentiment towards a specific group of people. These factors contribute to the classification of the image as a hateful meme.\"}",
    "1113701208852533248": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:this is so cunt  \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, likely due to the negative and offensive language used in the tweet text.\"}",
    "1106917004907368449": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Yes but you continue to support this trash in the White House. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests that the image is hateful, as it is described as 'trash' and 'this' referring to the image. The use of strong language implies a negative sentiment towards the image.\"}",
    "1054310060162113536": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Twat \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content.\"}",
    "1105448178621526016": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Is this nigga cute or what? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racist language, which is considered hateful. The image itself is a black background, which might be used to create a provocative or offensive context for the tweet.\"}",
    "1108037762006073345": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:The funniest nigga I know<tag> \ud83d\ude2d\ud83d\ude2d\ud83d\ude2d\ud83d\ude2d\ud83d\ude2d \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark background, which is often associated with racism and hate. The tweet text also contains racial slurs, further supporting the classification of the image as hateful.\"}",
    "1105540256189681664": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Lol Ya'll were after Johnny Depp whereas it was fuckin' obvious that Amber Heard was the disgusting cunt here. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults towards Amber Heard, suggesting a hateful sentiment towards her.\"}",
    "1108742727800373248": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I\u2019m still not over that man calling The Breakfast Club and telling Yee that her twat looked like a busted orange. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and derogatory terms, suggesting that the image is a hateful meme.\"}",
    "1113444694741090304": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This nigga jusa off a perc \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains racial slurs and is offensive to people of color.\"}",
    "1110182000433004547": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Nigga I ain't joking I want answers \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person's head, and the tweet text contains a racial slur. This suggests that the image is intended to be hateful and offensive.\"}",
    "1109286755654684672": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Nigga think he Goldberg \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains racial slurs and is offensive to many people.\"}",
    "1116651113569112066": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:NIGGA MUSIC \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person, and the tweet text contains a racial slur. This suggests that the image is intended to be hateful and offensive.\"}",
    "1107920258353020930": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:\"GET THAT NIGGA DOG TOO\"\ud83d\ude02 #ApexLegends \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains a racial slur, which is considered hateful. The image itself is a black background, which might be used to display such offensive content.\"}",
    "1114580262933991424": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:How life been treating a nigga lately \ud83e\udd26\ud83c\udffe\u200d\u2642\ufe0f \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which is not related to the hateful tweet text. The tweet contains offensive language and racial slurs, making it a hateful meme.\"}",
    "1106681262696288258": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:How I ask seedy what should I say for a price of a sneaker &amp; he tells me he wants them .. nigga make it make sense \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the use of racial slurs and derogatory language in the tweet text. This type of language is offensive and not appropriate for sharing on social media platforms.\"}",
    "1114525193333035008": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:NIGGA MODEL M  NIGGA MODEL M \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person, and the tweet text contains a racial slur. This suggests that the image is intended to be hateful and offensive.\"}",
    "1107112608237158400": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:When A nigga Comes around talking about how he not like the rest of these niggas\ud83d\udd95\ud83c\udffe\ud83d\udc80 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains racial slurs and derogatory language towards African Americans.\"}",
    "1044957070884327425": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:H. Rap Brown's US Educational System ::: Highlighting Chapter Two Of 'Die Nigger Die' \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which is often associated with negative emotions or mourning. The tweet text suggests that the image might be related to a hateful meme, further supporting the classification of the image as hateful.\"}",
    "1106609812878573568": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> THE BIG BLOOD IN ALL BLUE\ud83e\udd14NIGGA IS W CRIPPIN\u2019\ud83d\ude31\ud83d\ude02 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person's head, and the tweet text contains racial slurs and violent language. This suggests that the image is intended to be hateful and offensive.\"}",
    "1116659587065708545": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:listening to HOME and hearing suga say \"big ring nigga\" like \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a ring, which is being used as a symbol of racism and hate. The tweet text further supports this classification as it references a song with racial slurs.\"}",
    "1105818488634048513": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:The Devil want my nigga dead But he STILL HERE\ud83d\udcaf\ud83d\ude4f\ud83c\udffe #DolaAlibiVideoComingSoon \ud83d\udd192daMoney Label \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text further supports this classification as it contains potentially derogatory language.\"}",
    "1106615043871961088": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Nigga smoking a bogey \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a negative stereotype of African Americans, specifically a black man smoking a cigarette. Such stereotypes are harmful and offensive, perpetuating racism and discrimination.\"}",
    "1061143551893860353": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Not an ego you retard \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, suggesting that the image is a hateful meme.\"}",
    "1106984674402795520": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Nigga a shoot hurt me less than this shit smh<tag> \ud83d\ude29\ud83e\udd74 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the use of racial slurs and the overall negative sentiment conveyed in the tweet.\"}",
    "1109211797112922112": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:WHY DO YOU HAVE TO DO THIS TO ME NOW CUNT \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, suggesting that the image might be a hateful meme.\"}",
    "1108686026426499072": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This scummy bastard needs a fucking slap. Complete and utter cunt. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet contains offensive language and insults, indicating a hateful sentiment towards the person being referred to.\"}",
    "1109983668536295424": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> pull up nigga \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark background, which can be perceived as a hateful meme due to the use of racial slurs in the tweet text. The tweet text contains offensive language, which is not appropriate and can be considered as hateful.\"}",
    "1109705468807704579": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Full Gallery: \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is a black and white photo of a sky, which does not contain any explicit or offensive content. It is not a hateful meme.\"}",
    "1115219449253105664": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I DONT EVEN CHASE LIQUOR. WHY WOULD I CHASE A NIGGA. B I B L E \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains racist language and imagery, which is offensive and discriminatory.\"}",
    "1105558308537229313": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:LMAOO this nigga 50 is my idol. Better give me my money bitch \ud83d\ude2d\ud83d\ude2d\ud83d\ude2d\ud83d\udc80\ud83d\udc80 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and derogatory terms, which suggest that the image is a hateful meme.\"}",
    "1113453419124207617": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:GAS ALL I SMOKE NIGGA \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a gas station, and the tweet text contains racist language, which makes it a hateful meme.\"}",
    "1117648390018539520": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Alexis Texas gives head and gets her juicy cunt slammed tough \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a woman's genitalia, which is considered inappropriate and offensive. The tweet text further emphasizes the hateful nature of the image.\"}",
    "1051129937141399553": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:HAPPY LATE COLUMBUS DAY, also you wont get the dumb meme unless you read spic. \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is a black and white photo of a night sky, which is not a hateful meme. The tweet text does not contain any hateful content.\"}",
    "1114652732063924226": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:r*paul is a cunt but this song slaps \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language towards Paul, which suggests a hateful sentiment. The image itself does not contain any explicit content or messages that can be considered hateful.\"}",
    "1113476749499695109": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:im a street nigga \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the tweet text, which is derogatory and offensive towards a specific group of people.\"}",
    "1113103278240198656": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Shut down the border! Fully armed military to the border now! Operation Wetback is needed! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains hateful rhetoric, calling for the military to be deployed to the border and suggesting a reference to Operation Wetback, which was a controversial and racist immigration policy in the 1950s.\"}",
    "1108950360981331969": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Ion care about the females but if I see a nigga wearing these you\u2019s dusty\ud83e\udd15 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet contains offensive language and discriminatory remarks towards a specific group of people, which indicates a hateful sentiment.\"}",
    "1107327248066060288": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Bouta whoop this nigga for all the Team Rocket homies he locked up \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and references to a racial slur, which indicates a hateful sentiment.\"}",
    "1108503993725026304": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag> &gt;Being a cunt to Kat. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person's face, which is considered a hateful meme as it is disrespectful and offensive towards the person depicted.\"}",
    "1109383190073036801": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Look at this Brexit cunt on #BBCBreakfast. A personality only a mother could love. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, suggesting that it contains offensive or discriminatory content.\"}",
    "1058425997719232512": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> This nigga said a UFHoe!! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person, and the tweet text contains a racial slur. This suggests that the image is hateful, as it promotes negative and discriminatory language.\"}",
    "1053815639956176898": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag>  white trash big penis living. #LivePD \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text further supports this classification as it contains derogatory language towards a specific group of people.\"}",
    "1115741561244016642": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I\u2019m Not Insecure Nigga, I\u2019m Securing My Position\ud83e\udd1e\ud83c\udffd\ud83d\udd10. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which are indicative of a hateful meme.\"}",
    "1109342931213705216": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> All aboard the #TrumpTrain #BuildTheWall \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a wall, which is often associated with negative political views. The tweet text suggests a political agenda, which further supports the classification of the image as hateful.\"}",
    "1105348962687565824": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Too bad this nigga can\u2019t make more than one good album \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language towards a specific group of people, which is considered hateful. The image itself is a black background, which might be used to display such offensive content.\"}",
    "1114121212874186752": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Just remember... #BuildTheWall #AmericaFirst #AmericansoverIllegals #ImmigrationReformNow \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a wall, which is often associated with the idea of building a wall to keep out unwanted elements. The tweet text suggests a political stance that is anti-immigration and pro-border control. This could be perceived as hateful by some people, as it may be seen as promoting discrimination and exclusion.\"}",
    "1114895753745391616": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Yo wtf is w the retarded weather for the week? Smh \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which suggests that the image is a hateful meme.\"}",
    "1113840220045217799": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Im the shit like i farted, these white bitches retarded \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and derogatory terms towards white people, which indicates a hateful sentiment. The image itself is a black background, which might be used to create a provocative or aggressive atmosphere, but it does not contain any explicit content that would make it a hateful meme.\"}",
    "1107822835081326594": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> I need a nigga that\u2019s bout this TEAMWORK okay! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, but the tweet text contains racist language, making it a hateful meme.\"}",
    "1049758335824584705": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> It is not women card. It is basically #VictimCard \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it portrays a negative stereotype of women, suggesting that they are weak and in need of a 'victim card'.\"}",
    "1109986386403164160": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:High class white trash with my fam\u2764\ufe0f \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it may contain offensive or discriminatory content. The tweet text also supports this classification as it refers to 'high class white trash' and 'my fam', which could be perceived as derogatory or discriminatory language.\"}",
    "1115229821364260865": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Faggot \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which is not related to the hateful tweet text. The tweet text contains derogatory language, which is considered hateful. The image itself is not hateful.\"}",
    "1057098802287521792": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:The Democrats love them... #BuildTheWallNow #BuildThatWall #BuildTheWall \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains political opinions and a call to action, which can be considered as hateful. The image itself is a black background, which might be used to create a provocative or controversial atmosphere.\"}",
    "1107065376595046400": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:they fucked around and let that nigga kodak really drive the boat \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the presence of the racial slur 'nigger' in the tweet text. This word is offensive and derogatory, which makes the image and the tweet inappropriate and harmful.\"}",
    "1110399997768544257": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This nigga funny asl with no dialogue \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the racial slur used in the tweet text, which is offensive and inappropriate.\"}",
    "1107932824928022528": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:My nigga \ud83d\ude02\ud83d\ude02\ud83d\ude02\ud83d\ude02 funny would be an understatement... \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racial slurs and is considered hateful.\"}",
    "1107740216918458368": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Look at this cunt lol \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, suggesting that the image might be a hateful meme.\"}",
    "1109908169881538560": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> That's some hillbilly shit! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is considered hateful.\"}",
    "1107372743996174336": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:My nigga don\u2019t be texting no butches period he don\u2019t even follow bitches foh reaching assssss \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language and promotes negative stereotypes, which indicates that the image is hateful.\"}",
    "1108044588852248576": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:..when I tell you this NIGGA DEVOURED THE FUCK outta this pussy \ud83e\udd24\ud83d\ude0c\ud83d\ude0c\ud83d\ude0c\ud83d\ude0c\ud83d\ude0c\ud83d\ude0c\ud83d\ude0c\ud83d\ude0f \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text further supports this classification as it contains racial slurs and explicit language.\"}",
    "1105249082451415040": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> raided my boy man keep up the good work angel and keep grinding my nigga\u2744 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which suggest that the image is a hateful meme.\"}",
    "1115846679088062465": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:ODD FUTURE NIGGA \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, which suggests that the image might be a hateful meme.\"}",
    "1105325249699160064": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Whole ass dyke \ud83d\ude02\ud83d\ude02\ud83d\ude02\ud83d\ude02\ud83d\ude02\ud83d\ude02 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a woman's face, which is considered offensive and hateful by some people. The tweet text further supports this classification as it contains derogatory language towards the LGBTQ+ community.\"}",
    "1113497549820911617": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Tag<tag> its Her Birthday.. #happy Birthday M.A... #youngma #dyke #bitthday \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is a black background with no visible content, and the tweet text does not contain any hateful language or imagery.\"}",
    "1108717332044697600": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I\u2019m getting a piece finished today, i cunt wait. 3:30 can\u2019t come soon enough \ud83d\ude08 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and a sense of aggression, which suggests that the image might be a hateful meme.\"}",
    "1114721536504676352": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:\"CaLl ThAt NiGgA bAcK\" \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racist language, which is considered hateful. The image itself is a black background, which might be used to display such offensive content.\"}",
    "1117662586584084480": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Twat. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content.\"}",
    "1105709682784641029": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Ewww gay ass nigga shut up shut up shut up \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and derogatory terms towards the LGBTQ+ community, which indicates a hateful sentiment.\"}",
    "1115343090380939265": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Thinking about this image all day today and laughing like a retard \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests that the image is being mocked or ridiculed, which can be perceived as hateful. The use of the word 'retard' in the tweet further supports this classification.\"}",
    "1109855132114739200": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:When ya nigga gives green light on a bitch \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and racial stereotypes.\"}",
    "1113978834792210434": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> i know nigga i\u2019m right here. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which is not related to the hateful tweet text. The tweet contains racist language, which is inappropriate and offensive. The image itself is not hateful, but the tweet associated with it is.\"}",
    "1105442982793109505": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> You\u2019re Racist White Nationalist Right Wing Trash \ud83d\udd95\ud83c\udffd \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains racist or discriminatory content. The tweet text further supports this classification by calling the image 'racist' and 'white nationalist'.\"}",
    "1063515085509992453": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:White folks in black twitter when a black person makes a \"nigger\" joke \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a white person, which can be perceived as a hateful meme as it may be seen as promoting racism or discrimination. The tweet text further supports this classification as it highlights the issue of racism in society.\"}",
    "1046820931270856709": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Via: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which can be perceived as a hateful meme due to its association with negative emotions or events. The tweet text also suggests that the image is a meme, which further supports the classification of the image as hateful.\"}",
    "1109528965738364933": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Fuck that nigga sis let\u2019s go crazy go stupid on his lame ass \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which are indicative of a hateful sentiment.\"}",
    "1108560836115730432": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Nigga on the radio said he more dangerous in the streets than R jelly at a high school \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains a racial slur, which is offensive and discriminatory. The use of such language in a meme is not acceptable and promotes harmful stereotypes.\"}",
    "1107133601412460546": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:white trash rapping \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The presence of the word 'white trash' in the tweet text further supports this classification.\"}",
    "1113136504191291393": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:My pops in DR already wavy nigga FaceTimed me like \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a man's face, which is considered a hateful meme as it may be used to spread negativity or discrimination. The tweet text further supports this classification as it contains offensive language.\"}",
    "1109775817716969472": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Yep, no crisis here! #BuildTheWall \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a wall, which is often associated with racism and xenophobia. The tweet text suggests a political stance that supports building a wall, which can be seen as a hateful message towards certain groups of people.\"}",
    "1108832611760332807": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:\"What you gon do if it's your baby\" \"nah, what YOU gon do nigga that's your baby\" \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which are indicative of a hateful meme.\"}",
    "1063796538231742464": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:im actually retarded \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The presence of the word 'retarded' in the tweet text might be considered as offensive and contribute to the classification of the image as hateful.\"}",
    "1107679398076076033": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Cunt asked if 5'2 was short and I said yes... then she blocked me. Yikes. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the use of offensive language in the tweet text, which is not appropriate or respectful.\"}",
    "1107800834686021632": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I\u2019m a young trap nigga I\u2019m a bad bitch getter \ud83d\udde3 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and promotes negative stereotypes, which indicates that the image is likely a hateful meme.\"}",
    "1114521920861503490": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Nobody:  This nigga on my snap everyday: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the use of racial slurs and derogatory language in the tweet text, which is inappropriate and offensive.\"}",
    "1116969719519690754": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:No nigga wanna be my ex \ud83d\ude09\ud83d\udc99 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racial slurs and is offensive. The image, being a black background, might be used to further amplify the offensive message.\"}",
    "1114819125761728512": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:heejin is doing the lesbian thing..  you know what i\u2019m talking about... she\u2019s sitting like a DYKE \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the tweet text, which contains derogatory language towards the LGBTQ+ community.\"}",
    "1113028418717827074": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which can be perceived as a hateful meme due to its association with negative emotions or events. The tweet text also supports this classification as it contains a <tag> tag, which is often used in hateful content.\"}",
    "1062437600714141696": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:STOP THE CARAVAN MOB INVASIONS AT THE BORDER!   #BuildTheWall #StopTheMobs \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a caravan, which is being used as a symbol for the immigration issue. The tweet text is related to the immigration policy and calls for stopping the caravan mob invasions at the border. This suggests that the image is being used to promote a hateful agenda against immigrants or those who support immigration policies.\"}",
    "1106615739555942400": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:9 months ago a nigga wasn\u2019t even rapping. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person, and the tweet text is racist and offensive. This suggests that the image is a hateful meme.\"}",
    "1109936804558528512": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:\u201cIon talk that shit ill end a nigga rap career\u201d \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and a threat towards someone's career, which indicates a hateful sentiment.\"}",
    "1055884642606350338": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I CANT GO OUT SAD ABOUT NO NIGGA \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which is not related to the tweet text. The tweet text contains a racial slur, indicating that it is a hateful meme.\"}",
    "1105231405758459907": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Nigga never played sideline pop \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains racial slurs and is offensive to many people.\"}",
    "1114550338823118851": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> we grill beef nigga charcoal \ud83e\udd75 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a grill with the text 'we grill beef nigga charcoal' which is considered hateful and offensive language.\"}",
    "1108089257288257536": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Fam I\u2019m crying. He said Yee twat looks like a busted orange \ud83e\udd23 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text is a joke about a person's appearance, which can be considered as offensive and hateful.\"}",
    "1114286020797837312": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Cunt her \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a woman's face, which is considered offensive and hateful. The tweet text also adds to the negative sentiment of the image.\"}",
    "1105458265725509632": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Via: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which can be perceived as a hateful meme due to its association with negative emotions or events. The tweet text also suggests that the image is a meme, which further supports the classification of the image as hateful.\"}",
    "1108441333700669440": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I will not be disrespected By a NIGGA or BITCH \ud83d\udcaf\ud83d\udcaf \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark background, which is often associated with racism and discrimination. The tweet text further supports this classification as it contains offensive language towards African Americans and women. This combination of elements in the image and the tweet text suggests that it is a hateful meme.\"}",
    "1058083711533703168": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Another CUNT added to the list. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The presence of the word 'cunt' in the tweet text further supports this classification.\"}",
    "1107724677408059395": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Just a pity you are a dirty lying cunt \ud83c\uddee\ud83c\uddea\ud83c\uddee\ud83c\uddea \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which suggests that the image is a hateful meme.\"}",
    "1114182087974768640": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Nigga damn \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person, and the tweet text contains a racial slur. This suggests that the image is intended to be hateful and offensive.\"}",
    "1113386844652072960": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:my nigga turnt up! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which are indicative of a hateful meme.\"}",
    "1115608060771176448": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Brazil replaces far-right education minister with conspiracy theorist \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it may contain offensive or discriminatory content. The tweet text about Brazil replacing a far-right education minister with a conspiracy theorist may be related to the image, but it does not provide enough context to determine the image's content or intent.\"}",
    "1113576960553304065": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:update : RT grayjam68: Danny Rose is thinking \"I'll have to Google this cunt when I get home\" \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests that the image is a hateful meme, as it is described as a 'cunt' and implies a negative attitude towards the person in the image.\"}",
    "1107258103903514625": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Full Gallery: \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is a black and white photo of a sky, which does not contain any explicit or offensive content. It is not a hateful meme.\"}",
    "1109994842044723206": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Oh this nigga got balls to show up shigeo's house like he brought casserole with him \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the racist and offensive language used in the tweet text, which is displayed on the image.\"}",
    "1108792746477871104": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> MY. NIGGA. WHAT????? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark background, which can be perceived as a hateful meme due to the racial connotations of the word 'nigger' used in the tweet text. The word is considered offensive and derogatory, and its use in this context can be considered hateful.\"}",
    "1117164364925161477": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Isn't a giant weepy cunt just that guy on her period? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and a derogatory statement towards women, which indicates a hateful sentiment.\"}",
    "1043009143978651649": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Only slightly less trash than white men. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text further supports this classification by implying that the image is worse than white men, which is a derogatory statement.\"}",
    "1054490622604779520": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> That\u2019s just stupid.   #BuildTheWall  #DeportThemAll \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains hateful language towards immigrants, suggesting that the image might be associated with such sentiment.\"}",
    "1106619029215576064": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:For fucks sake.  This is a thing that is happening now.  Thanks, you fucking trigger-happy loose cunt. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, and the tweet text supports this classification as it contains offensive language.\"}",
    "1115368959304450050": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Taylor Swift BABE\u2605COCK #babecock #cock #sissy #faggot #batecocktobabecock #TaylorSwift \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a woman's face, which is being used as a meme to spread hate and discrimination towards women. The tweet text further supports this classification as it contains derogatory language towards women.\"}",
    "1114842962771546112": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Oh right, so anyone who disagrees with you is an idiot and a racist?  #blackprivilege   #RaceCard \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, suggesting that it may contain offensive or discriminatory content. The tweet text also supports this classification, as it implies that anyone who disagrees with the viewpoint expressed in the image is an idiot and a racist.\"}",
    "1050319498354544641": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Alex is a fucking nigger \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains a racial slur in the tweet text, which is offensive and discriminatory.\"}",
    "1110170967853146112": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Issa Real Nigga Party You MIGHT Get In \ud83e\udd75\ud83e\udd29\ud83e\udd14\ud83e\udd17 #NewProfilePic \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark background, which can be perceived as a hateful meme. The tweet text suggests a party for 'real niggas,' which can be considered offensive and racist. The combination of the image and the tweet text contributes to the classification of the image as hateful.\"}",
    "1114479327498919936": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> She\u2019s a twat waffle. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, suggesting that the image might be a hateful meme.\"}",
    "1108466005603438592": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I need this #BuildTheWall \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a wall, which can be interpreted as a symbol for a border wall. The tweet text suggests a political stance in favor of such a wall. This could be perceived as hateful by some, as it might be associated with exclusionary policies and discrimination against certain groups of people.\"}",
    "1107106014552309760": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Quick to smack a nigga go get yo sista &amp; them \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it promotes violence against a specific group of people, which is not acceptable.\"}",
    "1109903783818133505": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Nigga... \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person's head, and the tweet text contains a racial slur. This suggests that the image is intended to be hateful and offensive.\"}",
    "1109179439336902667": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:MY LIL BRO GOT WAVED CHECKED AT SCHOOL LMAAAOOOO LOOK AT MY LIL NIGGA \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which are indicative of a hateful meme.\"}",
    "1108436002702544898": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> \"Nothing happened\"  That's my nigga Zoro for ya\ud83d\ude0d\ud83d\ude2d\u270a\ud83c\udffe \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it may contain offensive or discriminatory content. The tweet text also supports this classification as it uses derogatory language and references a racial slur.\"}",
    "1107656063862505474": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Cmon nigga. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which are indicative of a hateful meme.\"}",
    "1115727185476706304": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:White Trash Part 1 |  #RealtimeBondage(#\u30ea\u30a2\u30eb\u30bf\u30a4\u30e0\u7dca\u7e1b) #Alice #Jacey #BDSM #Torture #Anal #SM\u7cfb\u52d5\u753b \u2192\nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it may contain offensive or discriminatory content. The tweet text also supports this classification as it references a controversial and potentially harmful subculture.\"}",
    "1035984027625373697": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> But but but but QuQu! Right wing SJW\u2019s dont real! Das a left wing phenomenon we all know dat! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, suggesting that it may contain offensive or discriminatory content. The tweet text also supports this classification by suggesting that the image is related to left-wing SJWs and that it is a phenomenon commonly associated with the left wing.\"}",
    "1109057436663644160": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Full Movie: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which can be perceived as a hateful meme due to its negative connotations. The tweet text does not provide any context or information that would change this classification.\"}",
    "1108478125023723520": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:ALADDIN ON LASER DISC MY NIGGA!!!? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racist slurs, which make it a hateful meme.\"}",
    "1115844326901342209": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This nigga<tag> an opp. He uses twitter on light mode. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the use of racial slurs and derogatory language in the tweet text.\"}",
    "1107121446034305029": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This nigga Steven was up my butt crack yesterday. One haircut and he MIA for hours \ud83d\ude12 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text further supports this classification as it contains derogatory language towards a specific individual.\"}",
    "1107561598246371329": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Aight im done with this double face cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and negativity towards a person, which suggests a hateful sentiment. The image itself is a black background, which might not be directly related to the sentiment expressed in the tweet.\"}",
    "1113513218608177152": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Nipsey died doing real nigga activities. A stand up guy forreal \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the tweet text, which is disrespectful and offensive towards the deceased rapper Nipsey Hussle.\"}",
    "1113201726570598402": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> I see you old nigga \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, which suggests that the image might be a hateful meme.\"}",
    "1105204001342140416": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Secure our border and this wouldn\u2019t be an issue Jeff. #BuildTheWall \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a border wall, which is often associated with hateful or controversial political views. The tweet text suggests a political stance on immigration and border security, which can be seen as hateful or divisive by some people.\"}",
    "1047342376681967616": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:This man said African Americans vote democratic so they can get more welfare. Nigger...... \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racist language and is considered hateful.\"}",
    "1110093894664937472": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Wtf<tag> fuck you your game is full of bugs fuck off i hope you guys failed nigger \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet contains offensive language and racial slurs, which indicates a hateful sentiment towards the game developers.\"}",
    "1108219066307751941": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> TAWWWKKKK TUUUUU THAt NIGGA HENNY!!!!!! I NEED A KILLSHOT KING! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which indicates that the image is likely a hateful meme.\"}",
    "1114029343959740421": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Nigga doesn\u2019t know what the fuck a body count is \ud83d\ude02\ud83d\udc80 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains racial slurs and promotes negative stereotypes.\"}",
    "1107327452177752064": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> my nigga where tf is the time outs \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which are indicative of a hateful meme.\"}",
    "1108480017825189888": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Me cooking for my nigga and watching him eat my food \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains racial slurs and promotes negative stereotypes.\"}",
    "1109044134399131648": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> ACCURATE AGAIN MA'AM! WELL DONE! #ItIsTime #BuildTheWall \ud83c\uddfa\ud83c\uddf8\ud83c\uddfa\ud83c\uddf8\ud83c\uddfa\ud83c\uddf8#PardonFlynnNow \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains content that is intended to be offensive or discriminatory towards a particular group or individual.\"}",
    "1109196840845672448": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Nigga fight yo self for thinking that Christian Bale was a better fit than Ben Affleck... \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which is not related to the tweet text. The tweet text contains a racial slur and insults towards Christian Bale and Ben Affleck, indicating a hateful sentiment. The image itself is not hateful, but the content of the tweet is.\"}",
    "1109164237908312064": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Racist people justifying why they can say nigga \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which is not related to the hateful tweet text. The tweet text contains racist language, which is offensive and not appropriate for sharing. Therefore, the image is not hateful, but the tweet text is.\"}",
    "1115099189451677696": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Hot redneck \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The presence of the word 'redneck' in the tweet text might be considered as derogatory and contribute to the classification of the image as hateful.\"}",
    "1108349223064559616": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> LMFAOOOOO \ud83d\ude2d \u201c oh nigger.\u201d \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person's head, and the tweet text contains a racial slur. This suggests that the image is intended to be hateful and offensive.\"}",
    "1114182702448562176": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> When you write an article so retarded that you have to lock your page. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests that the image is a hateful meme, as it is described as 'retarded' and 'lock your page'.\"}",
    "1115152502570213376": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:erin you little cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language towards a person named Erin, suggesting a negative and disrespectful attitude.\"}",
    "1115140259820343296": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Religion doesn't make people look bad, fucking retarded people make religion look bad \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and derogatory remarks towards people who follow a religion. This suggests that the image is a hateful meme.\"}",
    "1062237790669299712": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I don\u2019t normally watch breakfast TV. Why has no one ever mentioned to me before what a massive twat Piers Morgan is? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains content that is offensive or discriminatory towards a particular group or individual.\"}",
    "1108130920509394947": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> &gt;when you see a kpop nigga on the timeline \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text further supports this classification as it uses derogatory language to describe a specific group of people.\"}",
    "1063626976836108293": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:The ender update more like THE FAGGOT UPDATE XDDDD \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and derogatory terms, suggesting a hateful sentiment towards the LGBTQ+ community. The image itself is a black background, which might be used to further emphasize the negative message.\"}",
    "1113006962730467329": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Realest dream  Nigga u trippin..... She ain\u2019t whore\ud83d\ude2a\ud83d\ude33\ud83d\ude33 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains racial slurs and derogatory language towards a specific group of people.\"}",
    "1109174978673602561": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> King; The Redneck Inbreed will wear this as a badge of honor. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and a derogatory reference to a specific group of people, indicating that the image is likely to be a hateful meme.\"}",
    "1105462582750728192": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:What a complete cunt. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, suggesting a hateful sentiment towards someone or something.\"}",
    "1109899562225815552": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:if i EVER propose to a nigga he taking my last name \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racist language and promotes discrimination, which makes it a hateful meme.\"}",
    "1107306538979471360": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Hardest Yung nigga on da souf side of Atlanta \ud83e\udd2e\ud83d\udc9a My brudda \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it may contain offensive or discriminatory content. The tweet text also supports this classification as it refers to a nigga and uses a racial slur. This language is considered inappropriate and offensive, which contributes to the classification of the image as hateful.\"}",
    "1116462643504664576": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:That pussy shxt nigga don\u2019t add \u2b06\ufe0f \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and racial slurs. The tweet text further supports this classification as it is derogatory and disrespectful towards a specific group of people.\"}",
    "1116413903997739008": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:you get what you deserve cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, suggesting a hateful sentiment towards women. The image, being a black background, might be used to further emphasize this negative message.\"}",
    "1106555744609099777": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> One less nigga with a beard \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a man with a beard, which is associated with a hateful tweet. The tweet contains a racial slur, suggesting that the image is intended to be offensive and promote negative stereotypes.\"}",
    "1107467570079322112": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:this nigga disgusting<tag> \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content towards a particular group of people.\"}",
    "1114418563572555776": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Rly seen a nigga beating his d*** in a damn taco bell HARD taco on the tl. Im sick of you nick guhs \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the tweet text, which contains racial slurs and explicit language.\"}",
    "1109935102186926082": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag> My nigga is out here letting his choppa sing \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person holding a gun, which is often associated with violence and aggression. The tweet text further supports this classification as it contains a racial slur and references to violence. This combination of elements in the image and the tweet text suggests that it is a hateful meme.\"}",
    "1106644191218753536": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Nigga.... \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark background, which can be perceived as a hateful meme due to the use of the word 'Nigga' in the tweet text. This word is considered offensive and racist, and its use in the context of the image can be interpreted as promoting hate or discrimination.\"}",
    "1113156612078923778": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:this fucking cunt lol \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, suggesting that the image might be a hateful meme.\"}",
    "1050235358305116161": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I may look retarded but I got a picture with<tag> so smd \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is a simple black background with no visible content, and the tweet text does not contain any hateful or offensive language.\"}",
    "1045764470079926272": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:We are in ..well RETARDED hands 1. Flounder Flake 2. Elf bitch Sessions \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text also supports this classification as it appears to be derogatory towards a specific group of people.\"}",
    "1056629363192590337": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Bruh you the nigga whisperer \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which suggest that the image is a hateful meme.\"}",
    "1117699493301035008": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Get that dog to my dawgs then we work, nigga \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains a racial slur and promotes violence against a specific group of people.\"}",
    "1107622410528980995": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Always think I'm playing with him, nigga I will kill you \ud83d\ude44 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains hateful language, which suggests that the image might be a hateful meme.\"}",
    "1109766381736583175": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:the way this nigga just fell getting out the car \ud83d\ude02\ud83d\ude02\ud83d\ude02 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language and racist humor, which is considered hateful. The image itself is a black background, which might be used to create a meme or share a joke, but the content of the tweet is what makes it hateful.\"}",
    "1056692906105495552": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> The worlds longest unemployment line. #BuildTheWall \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it may contain offensive or discriminatory content. The tweet text also supports this classification as it contains a political statement related to unemployment and a reference to building a wall, which could be perceived as controversial or divisive.\"}",
    "1110410599073103874": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Love seeing all the fellow white trash ppl supporting her in these comments. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racist language and is considered hateful. The image itself is a black background, which might be used to create a provocative or controversial context for the tweet.\"}",
    "1110517781802479616": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Faggot Christer Wejros completely exposed and fucked \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and derogatory terms towards the LGBTQ+ community.\"}",
    "1063421503650308096": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Happy birthday<tag> have a good one you ginger twat \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which indicates a hateful sentiment.\"}",
    "1116304921438162946": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Nigga said I found ya Twitter \u201cPaid&amp;Pretty huh?\u201d Like EXCUSE ME?! \ud83d\ude2d \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains racial slurs and is disrespectful towards a specific group of people.\"}",
    "1107349884464713729": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I remember when this nut ass Tumblr nigga was calling me gay for this scene\ud83d\ude02\ud83d\ude02\ud83d\ude02 #kinkincolor \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, and the tweet text suggests that it was used to mock or insult someone in the past.\"}",
    "1110289444370857984": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Real nigga me please \ud83e\udd37\ud83c\udffd\u200d\u2640\ufe0f\ud83d\udcaf\ud83e\udd2a \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person's head, and the tweet text contains racial slurs. This suggests that the image is intended to be hateful and offensive.\"}",
    "1110294067303403520": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Street Sign Making A Right Twat Out Of Him \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text further supports this classification as it uses derogatory language to describe the person in the image.\"}",
    "1108443307145916419": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Say she fucking with me cuz a real nigga her preference \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a woman, and the tweet text suggests that she is fucking with someone. This could be interpreted as a hateful meme, as it may be perceived as disrespectful or offensive towards the woman in the photo.\"}",
    "1113069182025904130": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Never before have I had to deal with such a retard \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, suggesting that the image might be a hateful meme.\"}",
    "1107060982944280576": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Hot nigga \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, which is considered hateful. The image itself does not seem to be hateful, but the tweet text associated with it is.\"}",
    "1109041651660537857": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:He\u2019s also a little faggot \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language towards the LGBTQ+ community, which is considered hateful.\"}",
    "1045183391472267264": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Why does this drawing Kanye made look like retarded Squidward \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, likely due to the negative or offensive content it contains, such as the drawing of Kanye West that looks like a retarded Squidward.\"}",
    "1114810734872023040": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:My nigga came in with tha horses \ud83d\udc0e\ud83d\udc0e\ud83d\udc0e #PvSpringfest #PVActup \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racial slurs and is offensive. The image, being a black background, might be used to promote such content, making it a hateful meme.\"}",
    "1108505220877819904": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Who da fuck is dis nigga \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racial slurs and is offensive. The image itself is a black background, which might be used to create a provocative or controversial context for the tweet.\"}",
    "1115983401536901121": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:what the hell is this nigga wearing \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person wearing a white shirt. The tweet text suggests that the person is wearing a white shirt, which is not a hateful statement. However, the tweet text contains a racial slur, which makes the image potentially hateful.\"}",
    "1106679120455438336": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Like a cup of virgin's blood.. Mixed with 151, 1 sip I'll make a nigga flip \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text provided further supports this classification as it contains derogatory language towards a specific group of people.\"}",
    "1106551480960647170": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Bitch I live with my nigga lmao leave the drugs alone \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which are indicative of a hateful meme.\"}",
    "1108419364481568768": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I\u2019m excited to be a PTA mom .. I\u2019m gonna be a real cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is considered hateful.\"}",
    "1110244821430648834": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:It\u2019s a thug nigga life \ud83c\udfb6\ud83c\udfb6\ud83c\udfb6 #NBAYOUNGBOY \ud83e\udd2d\ud83e\udd2b \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a young man, which is often associated with negative stereotypes and racial bias. The tweet text further emphasizes this association by using derogatory language and making light of a serious issue. This combination of elements suggests that the image is a hateful meme.\"}",
    "1055181858969858048": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:What's that cunt?  You want your toothbrush?  Just come get it then, pussy. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is considered hateful.\"}",
    "1055152136227569665": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:When a faggot goes to convert kids \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and content that discriminates against the LGBTQ+ community.\"}",
    "1109901237162594304": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Right game wrong nigga \ud83d\udcfd<tag>  #BWAOrNothing \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person, and the tweet text contains racial slurs and derogatory language. This suggests that the image is intended to be hateful and offensive.\"}",
    "1114297953097744386": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Nigga thought he was Calvin Candy, talmbout \"shake my hand\" foh \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains racial slurs and offensive language, which is not appropriate or respectful.\"}",
    "1115000574376681473": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Tfw no chubby redneck friend that fixes trucks \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it may contain offensive or discriminatory content. The tweet text also implies a negative attitude towards a specific group of people, which further supports the classification of the image as hateful.\"}",
    "1114259656208031744": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I thought it was a Carti day but my nigga Meek really speaking to me \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, and the tweet text suggests a negative or offensive sentiment towards a specific group of people.\"}",
    "1113603330771701760": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> You Racist Cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, suggesting that the image might be a hateful meme.\"}",
    "1114521790779416577": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Morons   BUILD A WALL, CHANGE THE LAWS &amp; CRIME WILL FALL!   #BuildTheWall #DrainTheDeepState &amp; #KAG \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a wall, which is often associated with racism and xenophobia. The tweet text further supports this classification as it contains hateful rhetoric, such as 'morons' and 'build a wall,' which are commonly used by white supremacists and nationalists. The tweet also includes hashtags related to far-right ideologies, which",
    "1114664376013938689": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Still a nigga in a coupe. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains racial slurs and promotes negative stereotypes.\"}",
    "1108082672813903873": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Hear ye, Hear ye, and a Happy Fuck You!!! White Trash Hollywood Scum. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content towards a particular group or individual.\"}",
    "1115834265105764356": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:BIG BANK NIGGA \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person, which is often associated with racism and discrimination. The tweet text further supports this classification as it contains offensive language. This combination of elements suggests that the image is a hateful meme.\"}",
    "1108825363721920512": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Damn nigga \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, which suggests that the image might be a hateful meme.\"}",
    "1107404686364233729": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Like fammm .... it\u2019s that serious? This nigga on the dresser \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text further supports this classification as it uses derogatory language towards a specific group of people.\"}",
    "1062646078854610944": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:YE .... my nigger what\u2019s it gon be? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains racist language and imagery, which is offensive and discriminatory.\"}",
    "1107256974310285312": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Who's next in line Slurping on your own cum  In training to become my Sissy cunt cumwhore #femdom #findom \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text further supports this classification as it contains explicit language and potentially derogatory terms.\"}",
    "1105235667456585729": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> &lt;very poor redneck voice&gt;  Here's your sign.... \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a very poor redneck voice, which suggests that it may be derogatory or offensive towards a certain group of people. The tweet text also implies that the image is meant to be a sign, which could further imply a negative message. Therefore, the classification is 'hateful'.\"}",
    "1110314197546463233": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> No worries Susan, ya twat.. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language towards a person, suggesting that the image might be a hateful meme.\"}",
    "1109286043193393153": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> I need a muscle nigga that\u2019s gone throw me around df \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a man's torso, which is associated with a hateful tweet. The tweet contains derogatory language and promotes violence. This suggests that the image is intended to be hateful and offensive.\"}",
    "1113053586706124800": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Just booted us after being a round up shit cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and suggests a negative attitude towards a specific group of people. This could be considered a hateful meme.\"}",
    "1114972299629871105": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Puig still my nigga RT<tag>: welp \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person's head, and the tweet text contains a racial slur. This suggests that the image is intended to be hateful and offensive.\"}",
    "1113573609333608448": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Nigga snakes \ud83d\udc0d \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a snake, which is often associated with racism and hate. The tweet text further supports this classification as it contains a racial slur. This combination of elements suggests that the image is intended to be hateful and offensive.\"}",
    "1105253232710901760": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> ITS LIT NIGGA \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language, suggesting that the image might be a hateful meme.\"}",
    "1107761326028394499": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:#Amerashi nigga \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person, and the tweet text contains a racial slur. This suggests that the image is intended to be hateful and promote negative stereotypes.\"}",
    "1106706789788278786": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Pretty sure sweet surrender is a grope machine #DevilMayCry5 #XboxShare \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The presence of the hashtag #DevilMayCry5 and #XboxShare might also indicate that the image is intended to be shared on social media platforms, further supporting the classification as hateful.\"}",
    "1109543394689404929": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> This one and put him over the bonnet the little cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and a call to harm someone, indicating a hateful sentiment.\"}",
    "1106904747406213120": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:When you know you done fucked up. Childish ass little nigga \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains offensive language and racial slurs. The tweet text further supports this classification as it uses derogatory language towards a specific group of people.\"}",
    "1108225511954759681": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Nigga can\u2019t guard \u2757\ufe0f\u2757<tag>  Say<tag>  get Lou some defense \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains a racial slur and is disrespectful towards a specific group of people.\"}",
    "1114943042971152386": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Nigga was hit with the foot of the devil \ud83d\ude02\ud83d\ude02\ud83e\udd23\ud83e\udd23 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains racial slurs and is offensive. The image, being a black background, might be used to further amplify the offensive nature of the tweet.\"}",
    "1117228996465438722": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Feeling cute today might rob ya nigga tonight idk\ud83e\udd74 #FeelingCuteChallenge \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial slurs, which are indicative of a hateful meme.\"}",
    "1115008856751472645": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:\ud83d\ude2d\ud83d\ude2d\ud83d\ude2d\ud83d\ude2d\ud83d\ude2d\ud83d\ude2d\ud83d\ude2d\ud83d\ude02\ud83d\ude02\ud83d\ude02\ud83d\ude02\ud83d\ude02\ud83d\ude2d\ud83d\ude2d\ud83d\ude2d\ud83d\ude2d\ud83d\ude2d\ud83d\ude02\ud83d\ude02\ud83d\ude02\ud83d\ude02\ud83d\ude02\ud83d\ude02\ud83d\ude02\ud83d\ude02 man she really bit this nigga nail off! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and a reference to a violent act, which suggests that the image is hateful.\"}",
    "1105225503835897858": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:My boy<tag> had an eye on me since 2014 \ud83e\udd15 need to watch out lil faggot \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains derogatory language towards the LGBTQ+ community, which is considered hateful.\"}",
    "1043134621112664064": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:You know you\u2019re poor white trash when you can\u2019t afford cabbage til next week \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, which suggests that it contains offensive or discriminatory content. The tweet text provided further supports this classification as it contains derogatory language towards a specific group of people.\"}",
    "1107781625218240512": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:That nigga fumbled the baby \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains a racial slur and is offensive to many people.\"}",
    "1062181678536249344": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Fallout 4: \"dude why r u doing this??\"  \"lmao u wouldnt understand retard\"  Fallout New Vegas: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, which suggest that the image is intended to be hateful or offensive.\"}",
    "1113384838516678657": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I am stupit faggot for BBC \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and derogatory terms, suggesting a hateful sentiment towards the individual who posted it.\"}",
    "1113472590578946050": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> Hold that L ya durty cunt. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and is considered hateful.\"}",
    "1109756044014747649": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Click here to watch it: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person's head, which is often associated with negative emotions or feelings. The lack of color and the close-up nature of the photo can evoke a sense of unease or discomfort. The tweet text suggests that the image is meant to be watched, which implies that it may have a shocking or disturbing content. These factors contribute to the classification",
    "1107410074593562626": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:isn\u2019t this that biphobic cunt \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is described as a hateful meme, likely due to the negative and offensive language used in the tweet text.\"}",
    "1107513928978968576": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Imagine thinking a nigga can smash and he hasn\u2019t purchased any of your products \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains racist language and imagery, which is offensive and discriminatory.\"}",
    "1114256958494838790": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Why they have this nigga DaBaby rapping over Scott Storch beats \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains racial slurs and derogatory language. The tweet text further supports this classification as it uses offensive language.\"}",
    "1115787976536203266": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:NIGGA AINT TELL JEANIE?????lmfaooooooooo laker organization on some other shit. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the use of racial slurs and derogatory language in the tweet text. This type of language is offensive and disrespectful towards people of color, and it is not appropriate to use such language in any context, including memes.\"}",
    "1106521290385645569": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:There's always a Juventus in every nigga clique. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and racial stereotypes, which make it a hateful meme.\"}",
    "1115990011046977537": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag>  hour before being called a nigger lmao \ud83d\ude02 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person's head, which is considered a hateful meme as it may be used to spread hate or discrimination. The tweet text also supports this classification as it implies that the person is being called a racial slur.\"}",
    "1053619164043243520": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Your ITV race card on #ChampionsDay at<tag>   Who are you most looking forward to seeing? \nASSISTANT: {\"Classification\": \"not hateful\", \"Explaination\": \"The image is a black and white photo of a race card, which is not a hateful meme. The tweet text does not contain any hateful content.\"}",
    "1113129995134820354": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> MORONIC TWAT. There fixed it for Ya!! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, suggesting that the image is a hateful meme.\"}",
    "1110229419849904129": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Gudda Gudda in the studio after saying \u201cand I got her nigga,.....grocery bag\u201d   \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is considered hateful due to the tweet text, which contains offensive language and racial stereotypes.\"}",
    "1115725310295560192": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag> How stupid are you to still hang on to this retarded conspiracy theory? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, suggesting that the image is a hateful meme.\"}",
    "1056358330250215425": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag><tag><tag> My SJW message of the day: \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a dark sky, which can be perceived as a hateful meme by some people. The tweet text suggests that it is a message related to social justice warriors, which might be interpreted as a negative or critical message towards them.\"}",
    "1109198229323898880": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Fucking dad had me and my mum on cloud 9 think he won on the natural lottery fucking old cunt!!! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet contains offensive language and a negative sentiment towards the father, indicating a hateful meme.\"}",
    "1113582556090388481": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Same nigga that shot you was the one you used to smoke with...cold shit-Nipsey \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme that is considered hateful due to its content, which includes a reference to a violent incident and racial slurs.\"}",
    "1113926516759388160": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:How the hell am I gonna read your pinned tweet now, retard? \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, suggesting that the image is a hateful meme.\"}",
    "1062372489337159681": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:The nigger agenda \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains a racial slur, which is offensive and discriminatory. The use of such language in a meme is not acceptable and promotes harmful stereotypes.\"}",
    "1109170211079352322": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:You literally were cheating on your bf like 2 months ago with my person, you AINT loyal wtf you mean? Fucking cunt. \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet contains offensive language and insults, which suggest that it is a hateful meme.\"}",
    "1109876713427738625": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:<tag> Highschool friend, Officer Thompson gunned down by Illegal.   #BuildTheWall #BloodonDemsHands \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a meme that is spreading hate and promoting a divisive political agenda. It is not a neutral or positive representation of the situation, but rather an attempt to stir up negative emotions and promote a specific ideology.\"}",
    "1107143380503539712": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:I'm the hillbilly on this shitty platform that everyone is scared to follow! I'm Real! \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text suggests that the person is proud of being a hillbilly and is not afraid to follow, which can be perceived as aggressive or offensive. This could be considered a hateful meme.\"}",
    "1115795538052624384": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:All we need You ignorant twat I am done with your goofy clowning around ass \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The tweet text contains offensive language and insults, suggesting a hateful sentiment towards the person being addressed.\"}",
    "1108152399112355840": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:Only nigga my best friend that\u2019s a nigga . \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a hateful meme as it contains racial slurs and promotes negative stereotypes.\"}",
    "1107190594022051841": "USER: \nBased on this image and the following tweet text, do you think that this image is a hateful meme? You will output a JSON format as follows: {\"Classification\": \"hateful or not hateful\",\"Explaination\": \"Why you have chosen this classification\"}.Tweet text:of course i\u2019m ina back texting &amp; calling my nigga with no damn response\ud83d\ude2d\ud83d\ude2d\ud83d\ude2d\ud83d\ude02 \nASSISTANT: {\"Classification\": \"hateful\", \"Explaination\": \"The image is a black and white photo of a person's head, which is often associated with racism and hate speech. The tweet text also contains offensive language, further supporting the classification of the image as hateful.\"}"
}
